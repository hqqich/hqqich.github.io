
            
        
        
            
        
        
            
        
        
            
        
        
            
        
        
            
        
            
        
        
            
        
            
        
        
            
        
        
        
            
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
            
        
        
            
        
            
        
        
            
        
        
            
        
        
        
        [{"categories":[],"content":"遇到的问题 数据库乱码问题\n测试模块 RPC 远程调用返回的结果为:\n测试结果：{\u0026#34;activity\u0026#34;:{\u0026#34;activityDesc\u0026#34;:\u0026#34;?????????\u0026#34;,\u0026#34;activityId\u0026#34;:100002,\u0026#34;activityName\u0026#34;:\u0026#34;????\u0026#34;,\u0026#34;beginDateTime\u0026#34;:1705215282000,\u0026#34;endDateTime\u0026#34;:1705215282000,\u0026#34;stockCount\u0026#34;:100,\u0026#34;takeCount\u0026#34;:10},\u0026#34;result\u0026#34;:{\u0026#34;code\u0026#34;:\u0026#34;0000\u0026#34;,\u0026#34;info\u0026#34;:\u0026#34;成功\u0026#34;}} 明显的乱码问题，查看数据库，发现插入的时候就以及乱码了，看了一下配置文件中的数据库连接 url，发现使用了 useUnicode=true，并没有指定字符集，所以添加一下 utf-8 字符集即可，完整 url: jdbc:mysql://127.0.0.1:3306/lottery?useUnicode=true\u0026amp;characterEncoding=UTF-8\n再进行一轮测试，测试结果：\n测试结果：{\u0026#34;activity\u0026#34;:{\u0026#34;activityDesc\u0026#34;:\u0026#34;仅用于插入数据测试\u0026#34;,\u0026#34;activityId\u0026#34;:100003,\u0026#34;activityName\u0026#34;:\u0026#34;测试活动\u0026#34;,\u0026#34;beginDateTime\u0026#34;:1705218054000,\u0026#34;endDateTime\u0026#34;:1705218054000,\u0026#34;stockCount\u0026#34;:100,\u0026#34;takeCount\u0026#34;:10},\u0026#34;result\u0026#34;:{\u0026#34;code\u0026#34;:\u0026#34;0000\u0026#34;,\u0026#34;info\u0026#34;:\u0026#34;成功\u0026#34;}} ","permalink":"http://localhost:1313/hugo-blog/public/post/dev-log/day01/","tags":[{"LinkTitle":"Sql","RelPermalink":"/hugo-blog/public/tags/sql/"}],"title":"day01"},{"categories":[],"content":"3.1、MYSQL 存储过程中的关键语法 # 将语句的结束符号从分号;临时改为两个$$(可以是自定义)，其中，使用命令delimiter ; 将语句的结束符号恢复为分号。 # 1、声明语句结束符，可以自定义: DELIMITER $$ 或 DELIMITER // # 2、声明存储过程: CREATE PROCEDURE demo_in_parameter(IN p_in int) # 3、存储过程开始和结束符号: BEGIN .... END # 4、变量赋值: SET @p_in=1 # 5、变量定义: DECLARE l_int int unsigned default 0; # 6、创建mysql存储过程、存储函数: create procedure 存储过程名(参数) # 7、存储过程体: create function 存储函数名(参数) 3.2、存储过程的案例 解析：默认情况下，存储过程和默认数据库相关联，如果想指定存储过程创建在某个特定的数据库下，那么在过程名前面加数据库名做前缀。 在定义过程时，使用 DELIMITER 命令将语句的结束符号从分号;临时改为两个 ，使得过程体中使用的分号被直接传递到服务器，而不会被客户端（如mysql）解释。\n1 mysql\u0026gt; delimiter $$　# 将语句的结束符号从分号;临时改为两个$$(可以是自定义)。 2 mysql\u0026gt; CREATE PROCEDURE delete_matches(IN p_playerno INTEGER) 3 -\u0026gt; BEGIN 4 -\u0026gt; DELETE FROM MATCHES 5 -\u0026gt; WHERE playerno = p_playerno; 6 -\u0026gt; END$$ 7 Query OK, 0 rows affected (0.01 sec) 8 9 mysql\u0026gt; delimiter;　# 将语句的结束符号恢复为分号。 3.3、调用存储过程： 解析：在存储过程中设置了需要传参的变量p_playerno，调用存储过程的时候，通过传参将57赋值给p_playerno，然后进行存储过程里的SQL操作。\n1 call sp_name[(传参)]; 调用存储过程的案例，如下所示： 1 mysql\u0026gt; select * from MATCHES; 2 +---------+--------+----------+-----+------+ 3 | MATCHNO | TEAMNO | PLAYERNO | WON | LOST | 4 +---------+--------+----------+-----+------+ 5 | 1 | 1 | 6 | 3 | 1 | 6 | 7 | 1 | 57 | 3 | 0 | 7 | 8 | 1 | 8 | 0 | 3 | 8 | 9 | 2 | 27 | 3 | 2 | 9 | 11 | 2 | 112 | 2 | 3 | 10 +---------+--------+----------+-----+------+ 11 5 rows in set (0.00 sec) 12 13 mysql\u0026gt; call delete_matches(57); 14 Query OK, 1 row affected (0.03 sec) 15 16 mysql\u0026gt; select * from MATCHES; 17 +---------+--------+----------+-----+------+ 18 | MATCHNO | TEAMNO | PLAYERNO | WON | LOST | 19 +---------+--------+----------+-----+------+ 20 | 1 | 1 | 6 | 3 | 1 | 21 | 8 | 1 | 8 | 0 | 3 | 22 | 9 | 2 | 27 | 3 | 2 | 23 | 11 | 2 | 112 | 2 | 3 | 24 +---------+--------+----------+-----+------+ 25 4 rows in set (0.00 sec) 3.4、存储过程体 存储过程体包含了在过程调用时必须执行的语句，例如：dml、ddl语句，if-then-else和while-do语句、声明变量的declare语句等。　过程体格式：以begin开始，以end结束(可嵌套)。\nBEGIN BEGIN BEGIN statements; END END END 注意：每个嵌套块及其中的每条语句，必须以分号结束，表示过程体结束的begin-end块(又叫做复合语句compound statement)，则不需要分号。\n3.5、为语句块贴标签： 标签有两个作用：\n1）、增强代码的可读性。\n2）、在某些语句(例如:leave和iterate语句)，需要用到标签。\n[begin_label:] BEGIN [statement_list] END [end_label] 例如：\nlabel1: BEGIN label2: BEGIN label3: BEGIN statements; END label3 ; END label2; END label1 4、存储过程的参数 MySQL存储过程的参数用在存储过程的定义，共有三种参数类型，IN、OUT、INOUT，形式如：\nCREATE PROCEDURE 存储过程名([[IN |OUT |INOUT ] 参数名 数据类形...]) 如果过程没有参数，也必须在过程名后面写上小括号例：\nCREATE PROCEDURE sp_name ([proc_parameter[,...]]) …… 确保参数的名字不等于列的名字，否则在过程体中，参数名被当做列名来处理。\n4.1、IN输入参数 IN 输入参数：表示调用者向过程传入值（传入值可以是字面量或变量），默认是IN输入参数，如果不填写，就是默认的IN输入参数。\n# 以下可以看出，p_in 在存储过程中被修改，但并不影响 @p_in 的值，因为前者为局部变量、后者为全局变量。 mysql\u0026gt; delimiter $$ mysql\u0026gt; create procedure in_param(in p_in int) -\u0026gt; begin -\u0026gt; select p_in; -\u0026gt; set p_in=2; -\u0026gt; select P_in; -\u0026gt; end$$ mysql\u0026gt; delimiter ; mysql\u0026gt; set @p_in=1; mysql\u0026gt; call in_param(@p_in); +------+ | p_in | +------+ | 1 | +------+ +------+ | P_in | +------+ | 2 | +------+ mysql\u0026gt; select @p_in; +-------+ | @p_in | +-------+ | 1 | +-------+ 4.2、OUT输出参数 OUT 输出参数：表示过程向调用者传出值(可以返回多个值)（传出值只能是变量）。\nmysql\u0026gt; delimiter // mysql\u0026gt; create procedure out_param(out p_out int) -\u0026gt; begin -\u0026gt; select p_out; -\u0026gt; set p_out=2; -\u0026gt; select p_out; -\u0026gt; end -\u0026gt; // mysql\u0026gt; delimiter ; mysql\u0026gt; set @p_out=1; mysql\u0026gt; call out_param(@p_out); +-------+ | p_out | +-------+ | NULL | +-------+ #因为out是向调用者输出参数，不接收输入的参数，所以存储过程里的p_out为null +-------+ | p_out | +-------+ | 2 | +-------+ mysql\u0026gt; select @p_out; +--------+ | @p_out | +--------+ | 2 | +--------+ #调用了out_param存储过程，输出参数，改变了p_out变量的值 4.3、INOUT 输入输出参数 INOUT 输入输出参数：既表示调用者向过程传入值，又表示过程向调用者传出值（值只能是变量）。\nmysql\u0026gt; delimiter $$ mysql\u0026gt; create procedure inout_param(inout p_inout int) -\u0026gt; begin -\u0026gt; select p_inout; -\u0026gt; set p_inout=2; -\u0026gt; select p_inout; -\u0026gt; end -\u0026gt; $$ mysql\u0026gt; delimiter ; mysql\u0026gt; set @p_inout=1; mysql\u0026gt; call inout_param(@p_inout); +---------+ | p_inout | +---------+ | 1 | +---------+ +---------+ | p_inout | +---------+ | 2 | +---------+ mysql\u0026gt; select @p_inout; +----------+ | @p_inout | +----------+ | 2 | +----------+ #调用了inout_param存储过程，接受了输入的参数，也输出参数，改变了变量 5、存储过程声明变量 1）、用户变量名一般以@开头。\n2）、滥用用户变量会导致程序难以理解及管理。\n5.1、变量定义 局部变量声明一定要放在存储过程体的开始：\nDECLARE variable_name [,variable_name...] datatype [DEFAULT value]; 其中，datatype 为 MySQL 的数据类型，如: int, float, date,varchar(length)，例如：\nDECLARE l_int int unsigned default 4000000; DECLARE l_numeric number(8,2) DEFAULT 9.95; DECLARE l_date date DEFAULT \u0026#39;1999-12-31\u0026#39;; DECLARE l_datetime datetime DEFAULT \u0026#39;1999-12-31 23:59:59\u0026#39;; DECLARE l_varchar varchar(255) DEFAULT \u0026#39;This will not be padded\u0026#39;; 5.2、变量赋值 SET 变量名 = 表达式值 [,variable_name = expression ...] 5.3、用户变量 在MySQL客户端使用用户变量：\nmysql \u0026gt; SELECT \u0026#39;Hello World\u0026#39; into @x; mysql \u0026gt; SELECT @x; +-------------+ | @x | +-------------+ | Hello World | +-------------+ mysql \u0026gt; SET @y=\u0026#39;Goodbye Cruel World\u0026#39;; mysql \u0026gt; SELECT @y; +---------------------+ | @y | +---------------------+ | Goodbye Cruel World | +---------------------+ mysql \u0026gt; SET @z=1+2+3; mysql \u0026gt; SELECT @z; +------+ | @z | +------+ | 6 | +------+ 在存储过程中使用用户变量：\nmysql \u0026gt; CREATE PROCEDURE GreetWorld( ) SELECT CONCAT(@greeting,\u0026#39; World\u0026#39;); mysql \u0026gt; SET @greeting=\u0026#39;Hello\u0026#39;; mysql \u0026gt; CALL GreetWorld( ); +----------------------------+ | CONCAT(@greeting,\u0026#39; World\u0026#39;) | +----------------------------+ | Hello World | +----------------------------+ 在存储过程间传递全局范围的用户变量：\nmysql\u0026gt; CREATE PROCEDURE p1() SET @last_procedure=\u0026#39;p1\u0026#39;; mysql\u0026gt; CREATE PROCEDURE p2() SELECT CONCAT(\u0026#39;Last procedure was \u0026#39;,@last_procedure); mysql\u0026gt; CALL p1( ); mysql\u0026gt; CALL p2( ); +-----------------------------------------------+ | CONCAT(\u0026#39;Last procedure was \u0026#39;,@last_proc | +-----------------------------------------------+ | Last procedure was p1 | +-----------------------------------------------+ 6、存储过程的注释 MySQL 存储过程可使用两种风格的注释。　两个横杆\u0026ndash;：该风格一般用于单行注释。\nc 风格： 一般用于多行注释。\nmysql \u0026gt; DELIMITER // mysql \u0026gt; CREATE PROCEDURE proc1 -- name存储过程名 -\u0026gt; (IN parameter1 INTEGER) -\u0026gt; BEGIN -\u0026gt; DECLARE variable1 CHAR(10); -\u0026gt; IF parameter1 = 17 THEN -\u0026gt; SET variable1 = \u0026#39;birds\u0026#39;; -- 使用SET进行变量赋值，知识点很重要。 -\u0026gt; ELSE -\u0026gt; SET variable1 = \u0026#39;beasts\u0026#39;; -\u0026gt; END IF; -\u0026gt; INSERT INTO table1 VALUES (variable1); -\u0026gt; END -\u0026gt; // mysql \u0026gt; DELIMITER ; 7、存储过程的查询、修改、删除、调用控制 7.1、MySQL存储过程的调用 用call和你过程名以及一个括号，括号里面根据需要，加入参数，参数包括输入参数、输出参数、输入输出参数。具体的调用方法可以参看上面的例子。\n7.2、MySQL存储过程的查询 我们像知道一个数据库下面有那些表，我们一般采用 show tables; 进行查看。那么我们要查看某个数据库下面的存储过程，是否也可以采用呢？答案是，我们可以查看某个数据库下面的存储过程，但是是另一钟方式。\n我们可以用以下语句进行查询：\nselect name from mysql.proc where db=\u0026#39;数据库名\u0026#39;; 或者 select routine_name from information_schema.routines where routine_schema=\u0026#39;数据库名\u0026#39;; 或者 show procedure status where db=\u0026#39;数据库名\u0026#39;; 如果我们想知道，某个存储过程的详细，那我们又该怎么做呢？是不是也可以像操作表一样用describe 表名进行查看呢？\n答案是：我们可以查看存储过程的详细，但是需要用另一种方法：SHOW CREATE PROCEDURE 数据库.存储过程名;就可以查看当前存储过程的详细。\n7.3、MySQL存储过程的调用 ALTER PROCEDURE 更改用 CREATE PROCEDURE 建立的预先指定的存储过程，其不会影响相关存储过程或存储功能。\n7.4、MySQL存储过程的调用 删除一个存储过程比较简单，和删除表一样：\nDROP PROCEDURE 从 MySQL 的表格中删除一个或多个存储过程。\n8、MySQL存储过程的控制语句 8.1、变量作用域 内部的变量在其作用域范围内享有更高的优先权，当执行到 end。变量时，内部变量消失，此时已经在其作用域外，变量不再可见了，应为在存储过程外再也不能找到这个申明的变量，但是你可以通过 out 参数或者将其值指派给会话变量来保存其值。\nmysql \u0026gt; DELIMITER // mysql \u0026gt; CREATE PROCEDURE proc3() -\u0026gt; begin -\u0026gt; declare x1 varchar(5) default \u0026#39;outer\u0026#39;; -\u0026gt; begin -\u0026gt; declare x1 varchar(5) default \u0026#39;inner\u0026#39;; -\u0026gt; select x1; -\u0026gt; end; -\u0026gt; select x1; -\u0026gt; end; -\u0026gt; // mysql \u0026gt; DELIMITER ; 8.2、条件语句，if-then-else 语句 mysql \u0026gt; DELIMITER // mysql \u0026gt; CREATE PROCEDURE proc2(IN parameter int) -\u0026gt; begin -\u0026gt; declare var int; -\u0026gt; set var=parameter+1; -\u0026gt; if var=0 then -\u0026gt; insert into t values(17); -\u0026gt; end if; -\u0026gt; if parameter=0 then -\u0026gt; update t set s1=s1+1; -\u0026gt; else -\u0026gt; update t set s1=s1+2; -\u0026gt; end if; -\u0026gt; end; -\u0026gt; // mysql \u0026gt; DELIMITER ; 8.3、条件语句，case语句： 使用的语法，如下所示：\ncase when var=0 then insert into t values(30); when var\u0026gt;0 then when var\u0026lt;0 then else end case 使用的案例，如下所示：\nmysql \u0026gt; DELIMITER // mysql \u0026gt; CREATE PROCEDURE proc3 (in parameter int) -\u0026gt; begin -\u0026gt; declare var int; -\u0026gt; set var=parameter+1; -\u0026gt; case var -\u0026gt; when 0 then -\u0026gt; insert into t values(17); -\u0026gt; when 1 then -\u0026gt; insert into t values(18); -\u0026gt; else -\u0026gt; insert into t values(19); -\u0026gt; end case; -\u0026gt; end; -\u0026gt; // mysql \u0026gt; DELIMITER ; 8.4、循环语句while ···· end while 使用的语法，如下所示：\nwhile 条件 do --循环体 end while 使用的案例，如下所示：\nmysql \u0026gt; DELIMITER // mysql \u0026gt; CREATE PROCEDURE proc4() -\u0026gt; begin -\u0026gt; declare var int; -\u0026gt; set var=0; -\u0026gt; while var\u0026lt;6 do -\u0026gt; insert into t values(var); -\u0026gt; set var=var+1; -\u0026gt; end while; -\u0026gt; end; -\u0026gt; // mysql \u0026gt; DELIMITER ; 8.5、循环语句repeat···· end repeat 它在执行操作后检查结果，而 while 则是执行前进行检查。\n使用的语法，如下所示：\nrepeat --循环体 until 循环条件 end repeat; 使用的案例，如下所示：\nmysql \u0026gt; DELIMITER // mysql \u0026gt; CREATE PROCEDURE proc5 () -\u0026gt; begin -\u0026gt; declare v int; -\u0026gt; set v=0; -\u0026gt; repeat -\u0026gt; insert into t values(v); -\u0026gt; set v=v+1; -\u0026gt; until v\u0026gt;=5 -\u0026gt; end repeat; -\u0026gt; end; -\u0026gt; // mysql \u0026gt; DELIMITER ; 8.6、循环语句loop ·····endloop loop 循环不需要初始条件，这点和 while 循环相似，同时和 repeat 循环一样不需要结束条件, leave 语句的意义是离开循环。\nmysql \u0026gt; DELIMITER // mysql \u0026gt; CREATE PROCEDURE proc6 () -\u0026gt; begin -\u0026gt; declare v int; -\u0026gt; set v=0; -\u0026gt; LOOP_LABLE:loop -\u0026gt; insert into t values(v); -\u0026gt; set v=v+1; -\u0026gt; if v \u0026gt;=5 then -\u0026gt; leave LOOP_LABLE; -\u0026gt; end if; -\u0026gt; end loop; -\u0026gt; end; -\u0026gt; // mysql \u0026gt; DELIMITER ; 8.7、循环语句LABLES 标号： 标号可以用在 begin repeat while 或者 loop 语句前，语句标号只能在合法的语句前面使用。可以跳出循环，使运行指令达到复合语句的最后一步。\nITERATE 通过引用复合语句的标号,来从新开始复合语句:\nmysql \u0026gt; DELIMITER // mysql \u0026gt; CREATE PROCEDURE proc10 () -\u0026gt; begin -\u0026gt; declare v int; -\u0026gt; set v=0; -\u0026gt; LOOP_LABLE:loop -\u0026gt; if v=3 then -\u0026gt; set v=v+1; -\u0026gt; ITERATE LOOP_LABLE; -\u0026gt; end if; -\u0026gt; insert into t values(v); -\u0026gt; set v=v+1; -\u0026gt; if v\u0026gt;=5 then -\u0026gt; leave LOOP_LABLE; -\u0026gt; end if; -\u0026gt; end loop; -\u0026gt; end; -\u0026gt; // mysql \u0026gt; DELIMITER ; ","permalink":"http://localhost:1313/hugo-blog/public/post/mysql/mysql%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B/","tags":[{"LinkTitle":"Sql","RelPermalink":"/hugo-blog/public/tags/sql/"}],"title":"mysql存储过程"},{"categories":[],"content":"我们用three.js可以绘制出各种酷炫的画面，但是当我们想要一个更加真实的物理效果的话，这个时候我们就需要一个物理的库，接下来我们就讲解一下今天要学习的canon，它可以给我们提供一个更加真实的物理效果，像物体的张力、摩擦力、拉伸、反弹等等各种真实的物理效果。该库都能够有一个非常好的模拟。\nPS：目前博主在一家互联网公司工作，该公司的编码风格是vue+tsx ，所以接下来的项目以该编码风格进行举例，详细了解参考我之前的文章：地址 。\ncanon基本使用 Cannon 是一种轻量级 的 JavaScript 3D 物理引擎，用于实现虚拟世界中的物理模拟和交互。它提供了一套强大的功能，能够处理刚体碰撞、力学模拟、约束系统等物理效果，使开发者能够在 Web 应用程序和游戏中实现逼真的物理行为。\nCannon的官网：地址 ，提供了一系列关于物理运动在three世界的实现，实现案例 的效果非常直观，展示了物理运动的魅力，如下：\nTest for external image 接下来我们在three.js的vue项目 中使用Cannon，终端执行如下命令安装，具体参考：官网 `npm i cannon-es` 接下来我们通过tsx风格语法撰写three基础项目实现：\nimport { defineComponent } from \u0026#34;vue\u0026#34;; import * as THREE from \u0026#39;three\u0026#39; import { OrbitControls } from \u0026#39;three/examples/jsm/controls/OrbitControls.js\u0026#39; import * as CANNON from \u0026#39;cannon-es\u0026#39; import \u0026#39;./index.scss\u0026#39; import { div } from \u0026#34;three/examples/jsm/nodes/Nodes.js\u0026#34;; export default defineComponent({ setup() { // 初始化物理世界 const world = new CANNON.World() // 初始化物理世界的重力 world.gravity.set(0, -9.82, 0) // 初始化3D世界 const scene = new THREE.Scene() // 初始化相机 const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000) camera.position.z = 3 // 初始化渲染器 const renderer = new THREE.WebGLRenderer({ antialias: true }) renderer.setSize(window.innerWidth, window.innerHeight) document.body.appendChild(renderer.domElement) // 初始化控制器 const controls = new OrbitControls(camera, renderer.domElement) controls.enableDamping = true // 渲染 let clock = new THREE.Clock() const animate = () =\u0026gt; { let delta = clock.getDelta() controls.update() renderer.render(scene, camera) requestAnimationFrame(animate) } animate() return () =\u0026gt; { \u0026lt;div\u0026gt;\u0026lt;/div\u0026gt; } } }) 接下来我们需要给场景添加一些物体，如下：\n// 创建一个物理球体，半径为0.5 const sphereShape = new CANNON.Sphere(0.5) // 创建一个刚体 const sphereBody = new CANNON.Body({ mass: 1, shape: sphereShape, position: new CANNON.Vec3(0, 5, 0) }) // 将刚体添加到物理世界中 world.addBody(sphereBody) // 物理世界创建的东西不显示，所以我们要再通过three.js再创建一个球 const sphereGeometry = new THREE.SphereGeometry(0.5, 32, 32) // 创建一个几何体 const sphereMaterial = new THREE.MeshBasicMaterial({ color: 0x00ff00 }) // 创建一个球体材质 const shpereMesh = new THREE.Mesh(sphereGeometry, sphereMaterial) // 创建一个球体网格 // 将网格添加到3D场景中 scene.add(shpereMesh) 打开控制台，可以看到我们的球体已经显示出来了：\n接下来我们要把物理世界的球体给到我们three渲染出来的球体，让两者开始关联起来。在每一帧中，根据物理引擎模拟的结果来更新 Three.js 场景中球体网格的位置和旋转状态，从而实现了基于物理引擎的球体模拟效果，如下：\n得到的结果如下：\n基础碰撞使用 上面我们实现了一个物体的自由下落，接下来我们实现物体与平面的碰撞效果。如下添加平面：\n// 创建一个物理世界的平面 const planeShape = new CANNON.Plane() // 创建一个刚体 const planeBody = new CANNON.Body({ mass: 0, // 设置质量为0，不受碰撞的影响 shape: planeShape, position: new CANNON.Vec3(0, 0, 0) }) // 设置刚体旋转（设置旋转X轴） planeBody.quaternion.setFromAxisAngle(new CANNON.Vec3(1, 0, 0), -Math.PI / 2) // 将刚体添加到物理世界当中 world.addBody(planeBody) // 物理世界创建的东西不显示，所以我们要再通过three.js再创建一个平面 const planeGeometry = new THREE.PlaneGeometry(10, 10) // 因为渲染的东西不是无限衍生，这里给10x10 // 创建一个平面材质 const planeMaterial = new THREE.MeshBasicMaterial({ color: 0xffff00 }) // 创建一个平面网格 const planeMesh = new THREE.Mesh(planeGeometry, planeMaterial) // 旋转平面90度让其平铺 planeMesh.rotation.x = -Math.PI / 2 // 将网格添加到3D场景当中 scene.add(planeMesh) 当然除了我们设置平面质量为0之外，我们也可以设置平面为静态效果，也不受碰撞影响：\n最终得到的效果如下:\n那我们让物理世界和渲染世界的平面倾斜度加上0.1，小球是否会滑落而掉下去呢？测试一下：\n得到的效果如下，可见小球是不会掉落下去的，因为物理世界的平面是无限衍生的，即使渲染世界的平面有限，小球仍然会走物理世界的规律，如下：\n如果我们想在物理世界有一个有限大的平面的话， 我们可以通过构建一个立方体，然后把立方体压扁形成一个平面来使用，因为立方体已经有高度了，所以我们也不需要在旋转90度了，稍微给点倾斜度0.1即可，代码如下：\n得到的效果如下，可见到我们的小球已经实现了掉落的效果：\n上面两标题的案例代码如下：\nimport { defineComponent } from \u0026#34;vue\u0026#34;; import * as THREE from \u0026#39;three\u0026#39; import { OrbitControls } from \u0026#39;three/examples/jsm/controls/OrbitControls.js\u0026#39; import * as CANNON from \u0026#39;cannon-es\u0026#39; import \u0026#39;./index.scss\u0026#39; export default defineComponent({ setup() { // 初始化物理世界 const world = new CANNON.World() // 初始化物理世界的重力 world.gravity.set(0, -9.82, 0) // 初始化3D世界 const scene = new THREE.Scene() // 初始化相机 const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000) camera.position.z = 3 // 初始化渲染器 const renderer = new THREE.WebGLRenderer({ antialias: true }) renderer.setSize(window.innerWidth, window.innerHeight) document.body.appendChild(renderer.domElement) // 初始化控制器 const controls = new OrbitControls(camera, renderer.domElement) controls.enableDamping = true // 创建一个物理球体，半径为0.5 const sphereShape = new CANNON.Sphere(0.5) // 创建一个刚体 const sphereBody = new CANNON.Body({ mass: 1, shape: sphereShape, position: new CANNON.Vec3(0, 5, 0) }) // 将刚体添加到物理世界中 world.addBody(sphereBody) // 物理世界创建的东西不显示，所以我们要再通过three.js再创建一个球 const sphereGeometry = new THREE.SphereGeometry(0.5, 32, 32) // 创建一个几何体 const sphereMaterial = new THREE.MeshBasicMaterial({ color: 0x00ff00 }) // 创建一个球体材质 const shpereMesh = new THREE.Mesh(sphereGeometry, sphereMaterial) // 创建一个球体网格 // 将网格添加到3D场景中 scene.add(shpereMesh) // 创建一个物理世界的平面 // const planeShape = new CANNON.Plane() const planeShape = new CANNON.Box(new CANNON.Vec3(5, 0.1, 5)) // 创建一个刚体 const planeBody = new CANNON.Body({ // mass: 0, // 设置质量为0，不受碰撞的影响 shape: planeShape, position: new CANNON.Vec3(0, 0, 0), type: CANNON.Body.STATIC // 设置物体为静态，不受碰撞的影响 }) // 设置刚体旋转（设置旋转X轴） planeBody.quaternion.setFromAxisAngle(new CANNON.Vec3(1, 0, 0), 0.1) // 将刚体添加到物理世界当中 world.addBody(planeBody) // 物理世界创建的东西不显示，所以我们要再通过three.js再创建一个平面 // const planeGeometry = new THREE.PlaneGeometry(10, 10) // 因为渲染的东西不是无限衍生，这里给10x10 const planeGeometry = new THREE.BoxGeometry(10, 0.2, 10) // 创建一个平面材质 const planeMaterial = new THREE.MeshBasicMaterial({ color: 0xffff00 }) // 创建一个平面网格 const planeMesh = new THREE.Mesh(planeGeometry, planeMaterial) // 旋转平面90度让其平铺 planeMesh.rotation.x = 0.1 // 将网格添加到3D场景当中 scene.add(planeMesh) // 渲染 let clock = new THREE.Clock() const animate = () =\u0026gt; { // 获取了两次渲染之间的时间差，通常用于控制动画和物理模拟。 let delta = clock.getDelta() // 使用时间差来推进物理世界的模拟 world.step(delta) // 更新球体网格的位置和旋转 // 将物理引擎中球体的位置赋值给 Three.js 中球体网格（shpereMesh）的位置，从而将物理模拟的结果更新到可视化场景中。 shpereMesh.position.copy(sphereBody.position) // 将物理引擎中球体的旋转状态赋值给 Three.js 中球体网格（shpereMesh）的旋转状态，确保网格的旋转与物理模拟一致。 shpereMesh.quaternion.copy(sphereBody.quaternion) controls.update() renderer.render(scene, camera) requestAnimationFrame(animate) } animate() return () =\u0026gt; { \u0026lt;div\u0026gt;\u0026lt;/div\u0026gt; } } }) 材质与摩擦系数设置 cannon的材质可以模拟我们现实生活当中的物理的效果，比如说我们可以设置它的摩擦系数，弹性系数来实现我们这个物体的滑动的有摩擦的效果。借助上面的案例，我们将球体换成立方体，因为要创建多个立方体，这里我们设置一个变量用于存储\n// 创建网格数组 let phyMeshes: any[] = [] // 物理世界 let meshes: any[] = [] // 渲染世界 // 创建物理立方体 const boxShape = new CANNON.Box(new CANNON.Vec3(0.5, 0.5, 0.5)) // 设置立方体的材质 const boxMaterialCon = new CANNON.Material(\u0026#34;boxMaterial\u0026#34;) // 创建一个刚体 const boxBody = new CANNON.Body({ shape: boxShape, position: new CANNON.Vec3(0, 15, 0), mass: 1, material: boxMaterialCon }) // 将刚体添加到物理世界当中 world.addBody(boxBody) phyMeshes.push(boxBody) // 创建立方体几何体 const boxGeometry = new THREE.BoxGeometry(1, 1, 1) // 创建立方体材质 const boxMaterial = new THREE.MeshBasicMaterial({ color: 0x00ff00 }) // 创建立方体网格 const boxMesh = new THREE.Mesh(boxGeometry, boxMaterial) // 将网格添加到3D场景当中 scene.add(boxMesh) meshes.push(boxMesh) 在渲染函数处，我们变量数组来推进物理世界模拟：\n最终得到是效果如下：\n接下来我们添加第二个物体，将第二个物体的摩擦系数设置为0，第一个物体和平面的摩擦系数设置为0.7，代码如下：\n// 创建网格数组 let phyMeshes: any[] = [] // 物理世界 let meshes: any[] = [] // 渲染世界 // 创建物理立方体 const boxShape = new CANNON.Box(new CANNON.Vec3(0.5, 0.5, 0.5)) // 设置立方体的材质 const boxMaterialCon = new CANNON.Material(\u0026#34;boxMaterial\u0026#34;) boxMaterialCon.friction = 0.7 // 创建一个刚体 const boxBody = new CANNON.Body({ shape: boxShape, position: new CANNON.Vec3(0, 15, 0), mass: 1, material: boxMaterialCon }) // 将刚体添加到物理世界当中 world.addBody(boxBody) phyMeshes.push(boxBody) // 创建立方体几何体 const boxGeometry = new THREE.BoxGeometry(1, 1, 1) // 创建立方体材质 const boxMaterial = new THREE.MeshBasicMaterial({ color: 0x00ff00 }) // 创建立方体网格 const boxMesh = new THREE.Mesh(boxGeometry, boxMaterial) // 将网格添加到3D场景当中 scene.add(boxMesh) meshes.push(boxMesh) // 创建第二个物理立方体（使用第一个物理立方体的内容，材质不同） const boxSlipperyMaterial = new CANNON.Material(\u0026#34;boxSlipperyMaterial\u0026#34;) boxSlipperyMaterial.friction = 0 // 摩擦系数为0 // 创建刚体 const boxBody2 = new CANNON.Body({ shape: boxShape, position: new CANNON.Vec3(1, 5, 0), // 区别于第一个物体，位置改变一下 mass: 1, material: boxSlipperyMaterial }) // 将刚体添加到物理世界当中 world.addBody(boxBody2) phyMeshes.push(boxBody2) // 创建立方体几何体（使用第一个物体的内容） const boxMesh2 = new THREE.Mesh(boxGeometry, boxMaterial) // 将网格添加到3D场景当中 scene.add(boxMesh2) meshes.push(boxMesh2) // 创建一个物理世界的平面 // const planeShape = new CANNON.Plane() const planeShape = new CANNON.Box(new CANNON.Vec3(5, 0.1, 5)) // 创建一个刚体 const planeBody = new CANNON.Body({ // mass: 0, // 设置质量为0，不受碰撞的影响 shape: planeShape, position: new CANNON.Vec3(0, 0, 0), type: CANNON.Body.STATIC, // 设置物体为静态，不受碰撞的影响 material: boxMaterialCon }) // 设置刚体旋转（设置旋转X轴） planeBody.quaternion.setFromAxisAngle(new CANNON.Vec3(1, 0, 0), 0.1) // 将刚体添加到物理世界当中 world.addBody(planeBody) // 物理世界创建的东西不显示，所以我们要再通过three.js再创建一个平面 // const planeGeometry = new THREE.PlaneGeometry(10, 10) // 因为渲染的东西不是无限衍生，这里给10x10 const planeGeometry = new THREE.BoxGeometry(10, 0.2, 10) // 创建一个平面材质 const planeMaterial = new THREE.MeshBasicMaterial({ color: 0xffff00 }) // 创建一个平面网格 const planeMesh = new THREE.Mesh(planeGeometry, planeMaterial) // 旋转平面90度让其平铺 planeMesh.rotation.x = 0.1 // 将网格添加到3D场景当中 scene.add(planeMesh) 最终得到的效果如下，可以看到我们设置的第二个物体因为很光滑，所以很容易就滑落下去：\n弹性与接触材质设置 上文我们介绍了摩擦效果的操作，接下来我们继续开始讲解物体的弹性操作，我们根据上文的代码，再创建第三个立方体，然后给该立方体添加弹性系数\n// 创建第三个物理立方体（使用第一个物理立方体的内容，材质不同） const boxBouncyMaterial = new CANNON.Material(\u0026#34;boxBouncyMaterial\u0026#34;) boxBouncyMaterial.friction = 0.1 boxBouncyMaterial.restitution = 1 // 设置弹性系数为1 // 创建刚体 const boxBody3 = new CANNON.Body({ shape: boxShape, mass: 1, position: new CANNON.Vec3(2, 5, 3), material: boxBouncyMaterial }) // 将刚体添加到物理世界当中 world.addBody(boxBody3) phyMeshes.push(boxBody3) // 创建几何体（使用第一个立方体的内容以及材质） const boxMesh3 = new THREE.Mesh(boxGeometry, boxMaterial) // 添加网格 // 将网格添加到3D场景当中 scene.add(boxMesh3) meshes.push(boxMesh3) 给立方体设置弹性系数之后，如果我们想让弹性效果奏效的话，我们也需要给平面网格设置相同的弹性系数，因为平面网格使用的材质是第一个立方体的材质，所以我们只要给第一个立方体设置弹性系数即可，如下：\n最终得到的效果如下，可以看到设置高度高的物体，从高处下落反弹的效果是很直观的：\n当然我们也没有必要单独设置一下立方体和平面的弹性和摩擦系数，我们也可以通过接触材质的系数设置两个材质之间的一个弹性和摩擦系数，来实现相应的效果，如下：\n// 创建第三个物理立方体（使用第一个物理立方体的内容，材质不同） const boxBouncyMaterial = new CANNON.Material(\u0026#34;boxBouncyMaterial\u0026#34;) // boxBouncyMaterial.friction = 0.1 // boxBouncyMaterial.restitution = 1 // 设置弹性系数为1 // 创建刚体 const boxBody3 = new CANNON.Body({ shape: boxShape, mass: 1, position: new CANNON.Vec3(2, 5, 3), material: boxBouncyMaterial }) // 将刚体添加到物理世界当中 world.addBody(boxBody3) phyMeshes.push(boxBody3) // 创建几何体（使用第一个立方体的内容以及材质） const boxMesh3 = new THREE.Mesh(boxGeometry, boxMaterial) // 添加网格 // 将网格添加到3D场景当中 scene.add(boxMesh3) meshes.push(boxMesh3) // 定义接触材质 const material3toplane = new CANNON.ContactMaterial( boxMaterialCon, boxBouncyMaterial, { friction: 0, restitution: 1 } ) // 将接触材质添加到物理世界当中 world.addContactMaterial(material3toplane) 最终呈现的效果依然很明显：\n碰撞与碰撞组 Cannon中的碰撞指的是游戏开发中物体之间的相互作用，通常包括物体之间的碰撞检测和碰撞响应两个部分。碰撞检测用于判断物体是否发生了碰撞，而碰撞响应则是在发生碰撞时对物体进行相应的处理，比如改变物体的速度、方向等。如下我们设置代码来实现：\n依次创建立方体、球体、圆柱体到场景当中，举例代码如下：\n接下来我们给创建到场景的立方体添加一个初速度使其运动来碰撞另外两个物体，如下：\n这里给出完整的代码来给大家进行学习：\nimport { defineComponent } from \u0026#34;vue\u0026#34;; import * as THREE from \u0026#39;three\u0026#39; import { OrbitControls } from \u0026#39;three/examples/jsm/controls/OrbitControls.js\u0026#39; import * as CANNON from \u0026#39;cannon-es\u0026#39; import \u0026#39;./index.scss\u0026#39; export default defineComponent({ setup() { // 初始化物理世界 const world = new CANNON.World() // 初始化物理世界的重力 world.gravity.set(0, -9.82, 0) // 初始化3D世界 const scene = new THREE.Scene() // 初始化相机 const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000) camera.position.z = 8 camera.position.y = 5 camera.position.x = 2 // 初始化渲染器 const renderer = new THREE.WebGLRenderer({ antialias: true }) renderer.setSize(window.innerWidth, window.innerHeight) document.body.appendChild(renderer.domElement) // 初始化控制器 const controls = new OrbitControls(camera, renderer.domElement) controls.enableDamping = true // 创建网格数组 let phyMeshes: any[] = [] // 物理世界 let meshes: any[] = [] // 渲染世界 // 创建物理立方体 const boxShape = new CANNON.Box(new CANNON.Vec3(0.5, 0.5, 0.5)) // 设置立方体的材质 const boxMaterialCon = new CANNON.Material(\u0026#34;boxMaterial\u0026#34;) boxMaterialCon.friction = 0 // 创建一个刚体 const boxBody = new CANNON.Body({ shape: boxShape, position: new CANNON.Vec3(2, 0.8, 0), mass: 1, material: boxMaterialCon }) // 将刚体添加到物理世界当中 world.addBody(boxBody) phyMeshes.push(boxBody) // 创建立方体几何体 const boxGeometry = new THREE.BoxGeometry(1, 1, 1) // 创建立方体材质 const boxMaterial = new THREE.MeshBasicMaterial({ color: 0x00ff00 }) // 创建立方体网格 const boxMesh = new THREE.Mesh(boxGeometry, boxMaterial) // 将网格添加到3D场景当中 scene.add(boxMesh) meshes.push(boxMesh) // 创建物理球 const spereShape = new CANNON.Sphere(0.5) // 创建一个刚体 const sphereBody = new CANNON.Body({ shape: spereShape, position: new CANNON.Vec3(0, 0.8, 0), mass: 1, material: boxMaterialCon }) // 将刚体添加到物理世界当中 world.addBody(sphereBody) phyMeshes.push(sphereBody) // 创建球的几何体 const sphereGeometry = new THREE.SphereGeometry(0.5, 32, 32) // 创建球的材质 const sphereMaterial = new THREE.MeshBasicMaterial({ color: 0x0000ff }) // 创建球网格 const sphereMesh = new THREE.Mesh(sphereGeometry, sphereMaterial) // 将网格添加到3D场景当中 scene.add(sphereMesh) meshes.push(sphereMesh) // 创建物理圆柱体 const cylinderShape = new CANNON.Cylinder(0.5, 0.5, 1, 32) // 创建一个刚体 const cylinderBody = new CANNON.Body({ shape: cylinderShape, position: new CANNON.Vec3(-2, 0.8, 0), mass: 1, material: boxMaterialCon }) // 将刚体添加到物理世界当中 world.addBody(cylinderBody) phyMeshes.push(cylinderBody) // 创建圆柱体几何体 const cylinderGeometry = new THREE.CylinderGeometry(0.5 ,0.5, 1, 32) // 创建圆柱体材质 const cylinderMaterial = new THREE.MeshBasicMaterial({ color: 0xff0000 }) // 创建圆柱体网格 const cylinderMesh = new THREE.Mesh(cylinderGeometry, cylinderMaterial) // 将网格添加到3D场景当中 scene.add(cylinderMesh) meshes.push(cylinderMesh) // 创建一个物理世界的平面 // const planeShape = new CANNON.Plane() const planeShape = new CANNON.Box(new CANNON.Vec3(5, 0.1, 5)) // 创建一个刚体 const planeBody = new CANNON.Body({ // mass: 0, // 设置质量为0，不受碰撞的影响 shape: planeShape, position: new CANNON.Vec3(0, 0, 0), type: CANNON.Body.STATIC, // 设置物体为静态，不受碰撞的影响 material: boxMaterialCon }) // 设置刚体旋转（设置旋转X轴） // planeBody.quaternion.setFromAxisAngle(new CANNON.Vec3(1, 0, 0), 0.1) // 将刚体添加到物理世界当中 world.addBody(planeBody) // 物理世界创建的东西不显示，所以我们要再通过three.js再创建一个平面 // const planeGeometry = new THREE.PlaneGeometry(10, 10) // 因为渲染的东西不是无限衍生，这里给10x10 const planeGeometry = new THREE.BoxGeometry(10, 0.2, 10) // 创建一个平面材质 const planeMaterial = new THREE.MeshBasicMaterial({ color: 0xffff00 }) // 创建一个平面网格 const planeMesh = new THREE.Mesh(planeGeometry, planeMaterial) // 旋转平面90度让其平铺 // planeMesh.rotation.x = 0.1 // 将网格添加到3D场景当中 scene.add(planeMesh) // 设置立方体的初始速度 boxBody.velocity.set(-2, 0, 0) // 渲染 let clock = new THREE.Clock() const animate = () =\u0026gt; { // 获取了两次渲染之间的时间差，通常用于控制动画和物理模拟。 let delta = clock.getDelta() world.step(delta) // 使用时间差来推进物理世界的模拟 for(let i = 0; i \u0026lt; phyMeshes.length; i++) { meshes[i].position.copy(phyMeshes[i].position) meshes[i].quaternion.copy(phyMeshes[i].quaternion) } controls.update() renderer.render(scene, camera) requestAnimationFrame(animate) } animate() return () =\u0026gt; { \u0026lt;div\u0026gt;\u0026lt;/div\u0026gt; } } }) 接下来实现碰撞组，碰撞组是为了更高效地管理和处理碰撞而引入的概念。通过将具有相似碰撞特性的物体分组，可以在碰撞检测和碰撞响应时只考虑同一组内的物体之间的碰撞，从而减少不必要的计算量，提高游戏的性能和效率。代码如下：\n我们设置立方体为组1，然后碰撞掩码就是能够和谁发生碰撞，我们设置立方体可以和所有物体碰撞：\n在球体的分组当中，我们设置碰撞掩码如下，可以看到我们的球不能碰撞圆柱体：\n最终呈现的效果如下：\n给出案例的完整代码供大家学习：\nimport { defineComponent } from \u0026#34;vue\u0026#34;; import * as THREE from \u0026#39;three\u0026#39; import { OrbitControls } from \u0026#39;three/examples/jsm/controls/OrbitControls.js\u0026#39; import * as CANNON from \u0026#39;cannon-es\u0026#39; import \u0026#39;./index.scss\u0026#39; export default defineComponent({ setup() { // 初始化物理世界 const world = new CANNON.World() // 初始化物理世界的重力 world.gravity.set(0, -9.82, 0) // 初始化3D世界 const scene = new THREE.Scene() // 初始化相机 const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000) camera.position.z = 8 camera.position.y = 5 camera.position.x = 2 // 初始化渲染器 const renderer = new THREE.WebGLRenderer({ antialias: true }) renderer.setSize(window.innerWidth, window.innerHeight) document.body.appendChild(renderer.domElement) // 初始化控制器 const controls = new OrbitControls(camera, renderer.domElement) controls.enableDamping = true // 创建网格数组 let phyMeshes: any[] = [] // 物理世界 let meshes: any[] = [] // 渲染世界 // 设置碰撞组，数值要用2的幂 const GROUP1 = 1 // 分组立方体 const GROUP2 = 2 // 分组球体 const GROUP3 = 4 // 分组圆柱体 const GROUP4 = 8 // 分组平面 // 创建物理立方体 const boxShape = new CANNON.Box(new CANNON.Vec3(0.5, 0.5, 0.5)) // 设置立方体的材质 const boxMaterialCon = new CANNON.Material(\u0026#34;boxMaterial\u0026#34;) boxMaterialCon.friction = 0 // 创建一个刚体 const boxBody = new CANNON.Body({ shape: boxShape, position: new CANNON.Vec3(2, 0.8, 0), mass: 1, material: boxMaterialCon, collisionFilterGroup: GROUP1, // 设置碰撞组 collisionFilterMask: GROUP2 | GROUP3 | GROUP4, // 碰撞掩码，可以和二组和三、四组碰撞 }) // 将刚体添加到物理世界当中 world.addBody(boxBody) phyMeshes.push(boxBody) // 创建立方体几何体 const boxGeometry = new THREE.BoxGeometry(1, 1, 1) // 创建立方体材质 const boxMaterial = new THREE.MeshBasicMaterial({ color: 0x00ff00 }) // 创建立方体网格 const boxMesh = new THREE.Mesh(boxGeometry, boxMaterial) // 将网格添加到3D场景当中 scene.add(boxMesh) meshes.push(boxMesh) // 创建物理球 const spereShape = new CANNON.Sphere(0.5) // 创建一个刚体 const sphereBody = new CANNON.Body({ shape: spereShape, position: new CANNON.Vec3(0, 0.8, 0), mass: 1, material: boxMaterialCon, collisionFilterGroup: GROUP2, // 设置碰撞组 collisionFilterMask: GROUP1 | GROUP4, // 碰撞掩码，可以和一、四组碰撞 }) // 将刚体添加到物理世界当中 world.addBody(sphereBody) phyMeshes.push(sphereBody) // 创建球的几何体 const sphereGeometry = new THREE.SphereGeometry(0.5, 32, 32) // 创建球的材质 const sphereMaterial = new THREE.MeshBasicMaterial({ color: 0x0000ff }) // 创建球网格 const sphereMesh = new THREE.Mesh(sphereGeometry, sphereMaterial) // 将网格添加到3D场景当中 scene.add(sphereMesh) meshes.push(sphereMesh) // 创建物理圆柱体 const cylinderShape = new CANNON.Cylinder(0.5, 0.5, 1, 32) // 创建一个刚体 const cylinderBody = new CANNON.Body({ shape: cylinderShape, position: new CANNON.Vec3(-2, 0.8, 0), mass: 1, material: boxMaterialCon, collisionFilterGroup: GROUP3, // 设置碰撞组 collisionFilterMask: GROUP1 | GROUP4, // 碰撞掩码，可以和一、四组碰撞 }) // 将刚体添加到物理世界当中 world.addBody(cylinderBody) phyMeshes.push(cylinderBody) // 创建圆柱体几何体 const cylinderGeometry = new THREE.CylinderGeometry(0.5 ,0.5, 1, 32) // 创建圆柱体材质 const cylinderMaterial = new THREE.MeshBasicMaterial({ color: 0xff0000 }) // 创建圆柱体网格 const cylinderMesh = new THREE.Mesh(cylinderGeometry, cylinderMaterial) // 将网格添加到3D场景当中 scene.add(cylinderMesh) meshes.push(cylinderMesh) // 创建一个物理世界的平面 // const planeShape = new CANNON.Plane() const planeShape = new CANNON.Box(new CANNON.Vec3(5, 0.1, 5)) // 创建一个刚体 const planeBody = new CANNON.Body({ // mass: 0, // 设置质量为0，不受碰撞的影响 shape: planeShape, position: new CANNON.Vec3(0, 0.1, 0), type: CANNON.Body.STATIC, // 设置物体为静态，不受碰撞的影响 material: boxMaterialCon, collisionFilterGroup: GROUP4, // 设置碰撞组 collisionFilterMask: GROUP1 | GROUP2 | GROUP3, // 碰撞掩码，可以和一组、二组和三组碰撞 }) // 设置刚体旋转（设置旋转X轴） // planeBody.quaternion.setFromAxisAngle(new CANNON.Vec3(1, 0, 0), 0.1) // 将刚体添加到物理世界当中 world.addBody(planeBody) // 物理世界创建的东西不显示，所以我们要再通过three.js再创建一个平面 // const planeGeometry = new THREE.PlaneGeometry(10, 10) // 因为渲染的东西不是无限衍生，这里给10x10 const planeGeometry = new THREE.BoxGeometry(10, 0.2, 10) // 创建一个平面材质 const planeMaterial = new THREE.MeshBasicMaterial({ color: 0xffff00 }) // 创建一个平面网格 const planeMesh = new THREE.Mesh(planeGeometry, planeMaterial) // 旋转平面90度让其平铺 // planeMesh.rotation.x = 0.1 // 将网格添加到3D场景当中 scene.add(planeMesh) // 设置立方体的初始速度 boxBody.velocity.set(-2, 0, 0) // 渲染 let clock = new THREE.Clock() const animate = () =\u0026gt; { // 获取了两次渲染之间的时间差，通常用于控制动画和物理模拟。 let delta = clock.getDelta() world.step(delta) // 使用时间差来推进物理世界的模拟 for(let i = 0; i \u0026lt; phyMeshes.length; i++) { meshes[i].position.copy(phyMeshes[i].position) meshes[i].quaternion.copy(phyMeshes[i].quaternion) } controls.update() renderer.render(scene, camera) requestAnimationFrame(animate) } animate() return () =\u0026gt; { \u0026lt;div\u0026gt;\u0026lt;/div\u0026gt; } } }) ","permalink":"http://localhost:1313/hugo-blog/public/post/threejs/three.js--%E6%8E%A2%E5%AF%BBcannon.js%E6%9E%84%E5%BB%BA%E9%9C%87%E6%92%BC%E7%9A%843d%E7%89%A9%E7%90%86%E4%BA%A4%E4%BA%92%E4%BD%93%E9%AA%8C%E4%B8%80/","tags":[{"LinkTitle":"Sql","RelPermalink":"/hugo-blog/public/tags/sql/"}],"title":"Three.js--》探寻Cannon.js构建震撼的3D物理交互体验（一）"},{"categories":[],"content":"一、为什么选择 Three.js？ Three.js 是基于 WebGL 的轻量级 3D 引擎，无需复杂的数学计算即可实现：\n3D 模型渲染 动画与交互 物理引擎集成 高性能可视化 对比原生 WebGL：Three.js 封装了 90% 以上的底层代码，开发效率提升 80%！\n二、环境搭建 方案一：\n\u0026lt;!-- 引入Three.js最新版 --\u0026gt; \u0026lt;script src=\u0026#34;https://unpkg.com/three@0.158.0/build/three.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;!-- 引入辅助工具 --\u0026gt; \u0026lt;script src=\u0026#34;https://unpkg.com/three@0.158.0/examples/js/controls/OrbitControls.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://unpkg.com/three@0.158.0/examples/js/libs/stats.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 注意：Three.js 在较新的版本中对模块的引入方式进行了调整，直接通过\u0026lt;script\u0026gt;标签引入的加载方式可能会出现问题。\n方案二：在项目中使用\n安装Three.js `npm install three` 引入Three.js库 // 引入 Three.js 核心库 import * as THREE from \u0026#39;three\u0026#39;; // 引入轨道控制器 import { OrbitControls } from \u0026#39;three/examples/jsm/controls/OrbitControls.js\u0026#39;; // 引入性能监控工具 import Stats from \u0026#39;three/examples/jsm/libs/stats.module.js\u0026#39;; 核心三要素：\n// 场景 const scene = new THREE.Scene(); // 相机（透视投影） const camera = new THREE.PerspectiveCamera(75, window.innerWidth/window.innerHeight, 0.1, 1000); // 渲染器 const renderer = new THREE.WebGLRenderer(); renderer.setSize(window.innerWidth, window.innerHeight); document.body.appendChild(renderer.domElement); 三、核心组件详解（含性能优化 ） 1. 几何体 // 基础几何体 const geometry = new THREE.BoxGeometry(); // 立方体 const geometry = new THREE.SphereGeometry(5, 32, 32); // 球体 // 复杂几何体 import { OBJLoader } from \u0026#39;three/addons/loaders/OBJLoader.js\u0026#39;; const loader = new OBJLoader(); loader.load(\u0026#39;model.obj\u0026#39;, function(object) { scene.add(object); }); 2. 材质 性能优化方案：\n// 使用MeshStandardMaterial替代MeshPhongMaterial const material = new THREE.MeshStandardMaterial({ color: 0x00ff00, metalness: 0.5, roughness: 0.3 }); // 实例化材质池（适用于大规模场景） const materialPool = new THREE.InstancedMesh(geometry, material, 1000); 3. 灯光 // 环境光 const ambientLight = new THREE.AmbientLight(0xffffff, 0.5); // 平行光（模拟太阳光） const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8); directionalLight.position.set(5, 10, 10); 四、动画与交互实现 1. 基础动画 function animate() { requestAnimationFrame(animate); // 旋转动画 cube.rotation.x += 0.01; cube.rotation.y += 0.01; renderer.render(scene, camera); } animate(); 2. 鼠标交互 // 射线检测 const raycaster = new THREE.Raycaster(); const mouse = new THREE.Vector2(); document.addEventListener(\u0026#39;mousemove\u0026#39;, function(event) { mouse.x = (event.clientX / window.innerWidth) * 2 - 1; mouse.y = -(event.clientY / window.innerHeight) * 2 + 1; }); function onMouseClick(event) { raycaster.setFromCamera(mouse, camera); const intersects = raycaster.intersectObjects(scene.children); if (intersects.length \u0026gt; 0) { intersects[0].object.material.color.set(0xff0000); } } 五、性能优化指南（提升 50% 渲染效率） 减少 Draw Call： // 使用InstancedMesh替代多次add() const instancedMesh = new THREE.InstancedMesh(geometry, material, 1000); scene.add(instancedMesh); 层级优化： // 合并静态模型 import { BufferGeometryUtils } from \u0026#39;three/addons/utils/BufferGeometryUtils.js\u0026#39;; const mergedGeometry = BufferGeometryUtils.mergeBufferGeometries(geometries); 材质缓存： const materialCache = new Map(); function getMaterial(type) { if (!materialCache.has(type)) { materialCache.set(type, new THREE.MeshStandardMaterial({ ... })); } return materialCache.get(type); } 六、常见问题解决方案 1. 模型加载异常 // 加载进度监听 loader.load(\u0026#39;model.obj\u0026#39;, function(object) { scene.add(object); }, function(xhr) { console.log((xhr.loaded / xhr.total * 100) + \u0026#39;% loaded\u0026#39;); }, function(error) { console.error(\u0026#39;加载失败:\u0026#39;, error); }); 2. 内存泄漏检测 // 使用Stats.js监控性能 const stats = new Stats(); document.body.appendChild(stats.dom); function updateStats() { stats.begin(); // 渲染逻辑 stats.end(); requestAnimationFrame(updateStats); } 完整代码\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Three.js Quick Start\u0026lt;/title\u0026gt; \u0026lt;!-- 引入Three.js最新版 --\u0026gt; \u0026lt;script src=\u0026#34;https://unpkg.com/three@0.158.0/build/three.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;!-- 引入辅助工具 --\u0026gt; \u0026lt;script src=\u0026#34;https://unpkg.com/three@0.158.0/examples/js/controls/OrbitControls.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://unpkg.com/three@0.158.0/examples/js/libs/stats.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;script\u0026gt; // 场景 const scene = new THREE.Scene(); // 相机（透视投影） const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000); camera.position.z = 5; // 渲染器 const renderer = new THREE.WebGLRenderer(); renderer.setSize(window.innerWidth, window.innerHeight); document.body.appendChild(renderer.domElement); // 几何体 const geometry = new THREE.BoxGeometry(); // 材质 const material = new THREE.MeshStandardMaterial({ color: 0x00ff00, metalness: 0.5, roughness: 0.3 }); // 网格对象 const cube = new THREE.Mesh(geometry, material); scene.add(cube); // 灯光 // 环境光 const ambientLight = new THREE.AmbientLight(0xffffff, 0.5); scene.add(ambientLight); // 平行光（模拟太阳光） const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8); directionalLight.position.set(5, 10, 10); scene.add(directionalLight); // 轨道控制器 const controls = new THREE.OrbitControls(camera, renderer.domElement); // 性能监控 const stats = new Stats(); document.body.appendChild(stats.dom); // 射线检测 const raycaster = new THREE.Raycaster(); const mouse = new THREE.Vector2(); document.addEventListener(\u0026#39;mousemove\u0026#39;, function (event) { mouse.x = (event.clientX / window.innerWidth) * 2 - 1; mouse.y = -(event.clientY / window.innerHeight) * 2 + 1; }); document.addEventListener(\u0026#39;click\u0026#39;, function (event) { raycaster.setFromCamera(mouse, camera); const intersects = raycaster.intersectObjects(scene.children); if (intersects.length \u0026gt; 0) { intersects[0].object.material.color.set(0xff0000); } }); // 动画函数 function animate() { requestAnimationFrame(animate); // 旋转动画 cube.rotation.x += 0.01; cube.rotation.y += 0.01; renderer.render(scene, camera); stats.update(); } animate(); \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 七、实战项目推荐 3D 产品展示：使用 GLB 格式模型 + 轨道控制器 数据可视化：通过 BufferGeometry 生成自定义几何体 虚拟现实：配合 WebVR 插件实现沉浸式体验 八、学习资源推荐 官方文档 示例库 社区论坛 ","permalink":"http://localhost:1313/hugo-blog/public/post/threejs/%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B-three.js%E4%BB%8E-0-%E5%88%B0-1-%E6%9E%84%E5%BB%BA-3d-%E5%8F%AF%E8%A7%86%E5%8C%96%E9%A1%B9%E7%9B%AE/","tags":[{"LinkTitle":"Three.js","RelPermalink":"/hugo-blog/public/tags/three.js/"}],"title":"快速上手 Three.js：从 0 到 1 构建 3D 可视化项目"},{"categories":[{"LinkTitle":"A Category with Slug","RelPermalink":"/hugo-blog/public/categories/with-slug/"}],"content":" Photo by Behnam Norouzi on Unsplash\nTest for external image Test for svg ","permalink":"http://localhost:1313/hugo-blog/public/post/i18n-blog/image-process/","tags":[{"LinkTitle":"CustomTag","RelPermalink":"/hugo-blog/public/tags/custom/"}],"title":"Image Process"},{"categories":[{"LinkTitle":"Themes","RelPermalink":"/hugo-blog/public/categories/themes/"},{"LinkTitle":"Syntax","RelPermalink":"/hugo-blog/public/categories/syntax/"}],"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae.Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nTables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables Italics Bold Code italics bold code Code Blocks Code block with backticks 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block with Hugo\u0026rsquo;s internal highlight shortcode \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese List with checkbox Create a Hugo site Add content Add a style Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL+ALT+Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nThe above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"http://localhost:1313/hugo-blog/public/post/i18n-blog/markdown-syntax/","tags":[{"LinkTitle":"Markdown","RelPermalink":"/hugo-blog/public/tags/markdown/"},{"LinkTitle":"Css","RelPermalink":"/hugo-blog/public/tags/css/"},{"LinkTitle":"Html","RelPermalink":"/hugo-blog/public/tags/html/"},{"LinkTitle":"Tag1","RelPermalink":"/hugo-blog/public/tags/tag1/"},{"LinkTitle":"Tag2","RelPermalink":"/hugo-blog/public/tags/tag2/"}],"title":"Markdown Syntax Guide"},{"categories":[],"content":"Hugo ships with several Built-in Shortcodes for rich content, along with a Privacy Config and a set of Simple Shortcodes that enable static and no-JS versions of various social media embeds.\nBiliBili Simple Shortcode Asciinema Embed Shortcode Local Shortcode ","permalink":"http://localhost:1313/hugo-blog/public/post/i18n-blog/rich-content/","tags":[{"LinkTitle":"Shortcodes","RelPermalink":"/hugo-blog/public/tags/shortcodes/"},{"LinkTitle":"Privacy","RelPermalink":"/hugo-blog/public/tags/privacy/"}],"title":"Rich Content"},{"categories":[],"content":"Lorem est tota propiore conpellat pectoribus de pectora summo.\nRedit teque digerit hominumque toris verebor lumina non cervice subde tollit usus habet Arctonque, furores quas nec ferunt. Quoque montibus nunc caluere tempus inhospita parcite confusaque translucet patri vestro qui optatis lumine cognoscere flos nubis! Fronde ipsamque patulos Dryopen deorum.\nExierant elisi ambit vivere dedere Duce pollice Eris modo Spargitque ferrea quos palude Rursus nulli murmur; hastile inridet ut ab gravi sententia! Nomine potitus silentia flumen, sustinet placuit petis in dilapsa erat sunt. Atria tractus malis.\nComas hunc haec pietate fetum procerum dixit Post torum vates letum Tiresia Flumen querellas Arcanaque montibus omnes Quidem et Vagus elidunt The Van de Graaf Canon Mane refeci capiebant unda mulcebat Victa caducifer, malo vulnere contra dicere aurato, ludit regale, voca! Retorsit colit est profanae esse virescere furit nec; iaculi matertera et visa est, viribus. Divesque creatis, tecta novat collumque vulnus est, parvas. Faces illo pepulere tempus adest. Tendit flamma, ab opes virum sustinet, sidus sequendo urbis.\nIubar proles corpore raptos vero auctor imperium; sed et huic: manus caeli Lelegas tu lux. Verbis obstitit intus oblectamina fixis linguisque ausus sperare Echionides cornuaque tenent clausit possit. Omnia putatur. Praeteritae refert ausus; ferebant e primus lora nutat, vici quae mea ipse. Et iter nil spectatae vulnus haerentia iuste et exercebat, sui et.\nEurytus Hector, materna ipsumque ut Politen, nec, nate, ignari, vernum cohaesit sequitur. Vel mitis temploque vocatus, inque alis, oculos nomen non silvis corpore coniunx ne displicet illa. Crescunt non unus, vidit visa quantum inmiti flumina mortis facto sic: undique a alios vincula sunt iactata abdita! Suspenderat ego fuit tendit: luna, ante urbem Propoetides parte.\n","permalink":"http://localhost:1313/hugo-blog/public/post/i18n-blog/placeholder-text/","tags":[{"LinkTitle":"Markdown","RelPermalink":"/hugo-blog/public/tags/markdown/"},{"LinkTitle":"Text","RelPermalink":"/hugo-blog/public/tags/text/"}],"title":"Placeholder Text"},{"categories":[],"content":"Mathematical notation in a Hugo project can be enabled by using third party JavaScript libraries.\nIn this example we will be using KaTeX Create a partial under /layouts/partials/math.html Within this partial reference the Auto-render Extension or host these scripts locally. Include the partial in your templates like so: {{ if or .Params.math .Site.Params.math }} {{ partial \u0026#34;math.html\u0026#34; . }} {{ end }} To enable KaTeX globally set the parameter math to true in a project\u0026rsquo;s configuration To enable KaTeX on a per page basis include the parameter math: true in content files Note: Use the online reference of Supported TeX Functions Examples Inline math: \\(\\varphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887…\\) Block math: $$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$\n","permalink":"http://localhost:1313/hugo-blog/public/post/i18n-blog/math-typesetting/","tags":[],"title":"Math Typesetting"},{"categories":[],"content":"Emoji can be enabled in a Hugo project in a number of ways.\nThe emojify function can be called directly in templates or Inline Shortcodes .\nTo enable emoji globally, set enableEmoji to true in your site\u0026rsquo;s configuration and then you can type emoji shorthand codes directly in content files; e.g.\n🙈 :see_no_evil: 🙉 :hear_no_evil: 🙊 :speak_no_evil:\nThe Emoji cheat sheet is a useful reference for emoji shorthand codes.\nN.B. The above steps enable Unicode Standard emoji characters and sequences in Hugo, however the rendering of these glyphs depends on the browser and the platform. To style the emoji you can either use a third party emoji font or a font stack; e.g.\n.emoji { font-family: Apple Color Emoji, Segoe UI Emoji, NotoColorEmoji, Segoe UI Symbol, Android Emoji, EmojiSymbols; } ","permalink":"http://localhost:1313/hugo-blog/public/post/i18n-blog/emoji-support/","tags":[{"LinkTitle":"Emoji","RelPermalink":"/hugo-blog/public/tags/emoji/"}],"title":"Emoji Support"},{"categories":[],"content":"Written in Go, Hugo is an open source static site generator available under the Apache Licence 2.0. Hugo supports TOML, YAML and JSON data file types, Markdown and HTML content files and uses shortcodes to add rich content. Other notable features are taxonomies, multilingual mode, image processing, custom output formats, HTML/CSS/JS minification and support for Sass SCSS workflows.\nHugo makes use of a variety of open source projects including:\nhttps://github.com/yuin/goldmark https://github.com/alecthomas/chroma https://github.com/muesli/smartcrop https://github.com/spf13/cobra https://github.com/spf13/viper Hugo is ideal for blogs, corporate websites, creative portfolios, online magazines, single page applications or even a website with thousands of pages.\nHugo is for people who want to hand code their own website without worrying about setting up complicated runtimes, dependencies and databases.\nWebsites built with Hugo are extremely fast, secure and can be deployed anywhere including, AWS, GitHub Pages, Heroku, Netlify and any other hosting provider.\nLearn more and contribute on GitHub .\n","permalink":"http://localhost:1313/hugo-blog/public/about/","tags":[],"title":"About"},{"categories":[],"content":"","permalink":"http://localhost:1313/hugo-blog/public/manifest.json","tags":[],"title":""},{"categories":[],"content":"@[toc]\n一、什么是ArrarList ArrayList是Java中的一个动态数组类，可以根据实际需要自动调整数组的大小。ArrayList是基于数组实现的，它内部维护的是一个Object数组，默认初始化容量为10，当添加的元素个数超过了当前容量时，会自动扩容。\nArrayList也被广泛用于Java中的集合框架，例如Java中的List和Vector都是基于ArrayList实现的。下面是ArrayList常见的方法及其使用方法。\n使用场景: ArrayList适用于需要动态添加、删除元素的场景，可以用于存储不确定数量的数据。ArrayList也可以用于需要频繁访问集合元素的场景，因为它的底层是基于数组实现的，可以通过索引值快速访问元素。\n另外，由于ArrayList是基于数组实现的，因此在数据量较大时，会占用较多的内存空间，因此需要考虑内存的使用。对于频繁进行插入、删除操作的场景，可以使用LinkedList来代替ArrayList。\n总之，ArrayList更适合于需要频繁访问、添加、删除元素的场景，而LinkedList则更适合于需要频繁进行插入和删除操作的场景。\n二、常见方法 返回类型 方法 描述 boolean add(E o) 将指定元素追加到此列表的结尾。 void add(int index, E element) 将指定的元素插入此列表中的指定位置。 boolean addAll(Collection\u0026lt;? extends E\u0026gt; c) 按照指定 Collection 的迭代器所返回的元素顺序，将该 Collection 中的所有元素追加到此列表的尾部。 boolean addAll(int index, Collection\u0026lt;? extends E\u0026gt; c) 从指定的位置开始，将指定 Collection 中的所有元素插入到此列表中。 void clear() 从此列表中移除所有元素。 void ensureCapacity(int minCapacity) 如有必要，增加此 ArrayList 实例的容量，以确保它至少能够容纳最小容量参数所指定的元素数。 E get(int index) 返回此列表中指定位置上的元素。 int indexOf(Object elem) 搜索指定参数第一次出现的位置，使用 equals 方法进行相等性测试。 boolean isEmpty() 测试此列表中是否没有元素。 int lastIndexOf(Object elem) 返回指定的对象在列表中最后一次出现的位置索引。 E remove(int index) 移除此列表中指定位置处的元素。 boolean remove(Object o) 从此列表中移除指定元素的单个实例（如果存在），此操作是可选的。 protected void removeRange(int fromIndex, int toIndex) 移除列表中索引在 fromIndex（包括）和 toIndex（不包括）之间的所有元素。 E set(int index, E element) 用指定的元素替代此列表中指定位置上的元素。 int size() 返回此列表的元素数。 下面是一个示例代码:\nadd()方法： 在ArrayList末尾添加元素或在指定位置添加。\nimport java.util.ArrayList; public class ArrayListDemo { public static void main(String[] args) { ArrayList\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;String\u0026gt;(); list.add(\u0026#34;apple\u0026#34;); list.add(\u0026#34;banana\u0026#34;); list.add(\u0026#34;orange\u0026#34;); System.out.println(list); } } 输出结果为：\n[apple, banana, orange] get()方法： 获取指定位置元素。\nimport java.util.ArrayList; public class ArrayListDemo { public static void main(String[] args) { ArrayList\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;String\u0026gt;(); list.add(\u0026#34;apple\u0026#34;); list.add(\u0026#34;banana\u0026#34;); list.add(\u0026#34;orange\u0026#34;); String fruit = list.get(1); System.out.println(fruit); } } 输出结果为：\nbanana remove()方法： 删除指定位置或指定元素。\nimport java.util.ArrayList; public class ArrayListDemo { public static void main(String[] args) { ArrayList\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;String\u0026gt;(); list.add(\u0026#34;apple\u0026#34;); list.add(\u0026#34;banana\u0026#34;); list.add(\u0026#34;orange\u0026#34;); list.remove(1); System.out.println(list); list.remove(\u0026#34;orange\u0026#34;); System.out.println(list); } } 输出结果为：\n[apple, orange] [apple] size()方法： 获取ArrayList的元素个数。\nimport java.util.ArrayList; public class ArrayListDemo { public static void main(String[] args) { ArrayList\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;String\u0026gt;(); list.add(\u0026#34;apple\u0026#34;); list.add(\u0026#34;banana\u0026#34;); list.add(\u0026#34;orange\u0026#34;); int size = list.size(); System.out.println(size); } } 输出结果为：\n3 set()方法： 替换指定位置的元素。\nimport java.util.ArrayList; public class ArrayListDemo { public static void main(String[] args) { ArrayList\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;String\u0026gt;(); list.add(\u0026#34;apple\u0026#34;); list.add(\u0026#34;banana\u0026#34;); list.add(\u0026#34;orange\u0026#34;); list.set(1, \u0026#34;pear\u0026#34;); System.out.println(list); } } 输出结果为：\n[apple, pear, orange] indexOf()方法： 查找指定元素的位置。\nimport java.util.ArrayList; public class ArrayListDemo { public static void main(String[] args) { ArrayList\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;String\u0026gt;(); list.add(\u0026#34;apple\u0026#34;); list.add(\u0026#34;banana\u0026#34;); list.add(\u0026#34;orange\u0026#34;); int index = list.indexOf(\u0026#34;banana\u0026#34;); System.out.println(index); } } 输出结果为：\n1 clear()方法： 清空ArrayList中的所有元素。\nimport java.util.ArrayList; public class ArrayListDemo { public static void main(String[] args) { ArrayList\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;String\u0026gt;(); list.add(\u0026#34;apple\u0026#34;); list.add(\u0026#34;banana\u0026#34;); list.add(\u0026#34;orange\u0026#34;); list.clear(); System.out.println(list); } } 输出结果为：\n[] 有不好的地方,可以指出大家一起共同进步\n","permalink":"http://localhost:1313/hugo-blog/public/post/java/java%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6%E4%B8%89arraylist%E5%B8%B8%E8%A7%81%E6%96%B9%E6%B3%95%E7%9A%84%E4%BD%BF%E7%94%A8/","tags":[],"title":""},{"categories":[],"content":"@[toc]\n一、什么是LinkedList LinkedList是Java中的一个双向链表。\n它实现了List和Deque接口，在使用时可以像List一样使用元素索引，也可以像Deque一样使用队列操作。\nLinkedList每个节点都包含了前一个和后一个节点的引用，因此可以很方便地在其中进行节点的插入、删除和移动。\n相比于ArrayList，LinkedList的插入和删除操作效率更高，但是访问元素时效率较低，因为需要遍历链表来寻找目标元素。\nLinkedList的使用场景主要是场景是需要频繁执行插入和删除操作且对访问操作的效率要求较低的情况。例如队列、栈等数据结构的实现，或者是需要实现LRU缓存淘汰策略的场景。\n二、常用的方法 返回类型 方法 描述 boolean add(E o) 将指定元素追加到此列表的结尾。 void add(int index, E element) 在此列表中指定的位置插入指定的元素。 boolean addAll(Collection\u0026lt;? extends E\u0026gt; c) 追加指定 collection 中的所有元素到此列表的结尾，顺序是指定 collection 的迭代器返回这些元素的顺序。 boolean addAll(int index, Collection\u0026lt;? extends E\u0026gt; c) 将指定集合中的所有元素从指定位置开始插入此列表。 void addFirst(E o) 将指定元素插入此列表的开头。 void addLast(E o) 将指定元素追加到此列表的结尾。 void clear() 从此列表中移除所有元素。 boolean contains(Object o) 如果此列表包含指定元素，则返回 true。 E get(int index) 返回此列表中指定位置处的元素。 E getFirst() 返回此列表的第一个元素。 E getLast() 返回此列表的最后一个元素。 int indexOf(Object o) 返回此列表中首次出现的指定元素的索引，如果列表中不包含此元素，则返回 -1。 int lastIndexOf(Object o) 返回此列表中最后出现的指定元素的索引，如果列表中不包含此元素，则返回 -1。 ListIterator listIterator(int index) 返回此列表中的元素的列表迭代器（按适当顺序），从列表中指定位置开始。 E peek() 找到但不移除此列表的头（第一个元素）。 E remove() 找到并移除此列表的头（第一个元素）。 E remove(int index) 移除此列表中指定位置处的元素。 boolean remove(Object o) 移除此列表中首次出现的指定元素。 E removeFirst() 移除并返回此列表的第一个元素。 E removeLast() 移除并返回此列表的最后一个元素。 E set(int index, E element) 将此列表中指定位置的元素替换为指定的元素。 int size() 返回此列表的元素数。 下面是一个示例代码：\n2.1 add()： 在链表的末尾添加元素。如果需要在指定位置添加元素，则可以使用add(index, element)方法。\n代码演示：\nLinkedList\u0026lt;String\u0026gt; list = new LinkedList\u0026lt;\u0026gt;(); list.add(\u0026#34;apple\u0026#34;); list.add(\u0026#34;banana\u0026#34;); list.add(\u0026#34;orange\u0026#34;); System.out.println(list); // 结果:[apple, banana, orange] 2.2 remove()： 在链表中删除指定元素。如果需要删除指定位置的元素，则可以使用remove(index)方法。\n代码演示：\nLinkedList\u0026lt;String\u0026gt; list = new LinkedList\u0026lt;\u0026gt;(); list.add(\u0026#34;apple\u0026#34;); list.add(\u0026#34;banana\u0026#34;); list.add(\u0026#34;orange\u0026#34;); list.remove(\u0026#34;banana\u0026#34;); System.out.println(list); // 结果:[apple, orange] 2.3 get()： 获取指定位置的元素。\n代码演示：\nLinkedList\u0026lt;String\u0026gt; list = new LinkedList\u0026lt;\u0026gt;(); list.add(\u0026#34;apple\u0026#34;); list.add(\u0026#34;banana\u0026#34;); list.add(\u0026#34;orange\u0026#34;); String second = list.get(1); System.out.println(second); // 结果:banana 2.4 set()： 替换指定位置的元素。\n代码演示：\nLinkedList\u0026lt;String\u0026gt; list = new LinkedList\u0026lt;\u0026gt;(); list.add(\u0026#34;apple\u0026#34;); list.add(\u0026#34;banana\u0026#34;); list.add(\u0026#34;orange\u0026#34;); list.set(1, \u0026#34;grape\u0026#34;); System.out.println(list); // 结果:[apple, grape, orange] 2.5 clear()： 清空链表中的所有元素。\n代码演示：\nLinkedList\u0026lt;String\u0026gt; list = new LinkedList\u0026lt;\u0026gt;(); list.add(\u0026#34;apple\u0026#34;); list.add(\u0026#34;banana\u0026#34;); list.add(\u0026#34;orange\u0026#34;); list.clear(); System.out.println(list); // 结果:[] 2.6 size()： 返回链表中的元素数量。\n代码演示：\nLinkedList\u0026lt;String\u0026gt; list = new LinkedList\u0026lt;\u0026gt;(); list.add(\u0026#34;apple\u0026#34;); list.add(\u0026#34;banana\u0026#34;); list.add(\u0026#34;orange\u0026#34;); int size = list.size(); System.out.println(size); //结果:3 2.7 contains()： 判断链表中是否包含指定元素。\n代码演示：\nLinkedList\u0026lt;String\u0026gt; list = new LinkedList\u0026lt;\u0026gt;(); list.add(\u0026#34;apple\u0026#34;); list.add(\u0026#34;banana\u0026#34;); list.add(\u0026#34;orange\u0026#34;); boolean hasApple = list.contains(\u0026#34;apple\u0026#34;); System.out.println(hasApple); //结果: true 2.8 addFirst()： 在链表的头部插入元素。\n代码演示：\nLinkedList\u0026lt;String\u0026gt; list = new LinkedList\u0026lt;\u0026gt;(); list.add(\u0026#34;apple\u0026#34;); list.add(\u0026#34;banana\u0026#34;); list.add(\u0026#34;orange\u0026#34;); list.addFirst(\u0026#34;pear\u0026#34;); System.out.println(list); // 结果:[pear, apple, banana, orange] 2.9 addLast()： 在链表的尾部插入元素。\n代码演示：\nLinkedList\u0026lt;String\u0026gt; list = new LinkedList\u0026lt;\u0026gt;(); list.add(\u0026#34;apple\u0026#34;); list.add(\u0026#34;banana\u0026#34;); list.add(\u0026#34;orange\u0026#34;); list.addLast(\u0026#34;pear\u0026#34;); System.out.println(list); // 结果:[apple, banana, orange, pear] 2.10 getFirst()： 获取链表的第一个元素。\n代码演示：\nLinkedList\u0026lt;String\u0026gt; list = new LinkedList\u0026lt;\u0026gt;(); list.add(\u0026#34;apple\u0026#34;); list.add(\u0026#34;banana\u0026#34;); list.add(\u0026#34;orange\u0026#34;); String first = list.getFirst(); System.out.println(first); // 结果:apple 2.11 getLast()： 获取链表的最后一个元素。\n代码演示：\nLinkedList\u0026lt;String\u0026gt; list = new LinkedList\u0026lt;\u0026gt;(); list.add(\u0026#34;apple\u0026#34;); list.add(\u0026#34;banana\u0026#34;); list.add(\u0026#34;orange\u0026#34;); String last = list.getLast(); System.out.println(last); // 结果:orange 2.12 removeFirst()： 移除链表的第一个元素。\n代码演示：\nLinkedList\u0026lt;String\u0026gt; list = new LinkedList\u0026lt;\u0026gt;(); list.add(\u0026#34;apple\u0026#34;); list.add(\u0026#34;banana\u0026#34;); list.add(\u0026#34;orange\u0026#34;); list.removeFirst(); System.out.println(list); // 结果:[banana, orange] 2.13 removeLast()： 移除链表的最后一个元素。\n代码演示：\nLinkedList\u0026lt;String\u0026gt; list = new LinkedList\u0026lt;\u0026gt;(); list.add(\u0026#34;apple\u0026#34;); list.add(\u0026#34;banana\u0026#34;); list.add(\u0026#34;orange\u0026#34;); list.removeLast(); System.out.println(list); // 结果:[apple, banana] 所有代码演示的,运行结果：\n[apple, banana, orange] [apple, orange] banana [apple, grape, orange] [] 3 true [pear, apple, banana, orange] [apple, banana, orange, pear] apple orange [banana, orange] [apple, banana] ","permalink":"http://localhost:1313/hugo-blog/public/post/java/java%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6%E4%BA%8Clinkedlist%E5%B8%B8%E8%A7%81%E6%96%B9%E6%B3%95%E7%9A%84%E4%BD%BF%E7%94%A8/","tags":[],"title":""},{"categories":[],"content":"Map是Java中的一种集合，它是一种键值对的映射表，可以根据键快速获取对应的值。 @[toc]\n1. 常见使用方式 以下是Java中Map的常见方法使用示例及运行结果：\n1.1 存储键值对 使用put()方法向Map中添加键值对：\nMap\u0026lt;String, Integer\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;apple\u0026#34;, 10);//新增键值对,左边键右边值 map.put(\u0026#34;banana\u0026#34;, 20); System.out.println(map); 输出结果：\n{banana=20, apple=10} 1.2. 获取值 使用get()方法根据键获取对应的值：\nMap\u0026lt;String, Integer\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;apple\u0026#34;, 10); map.put(\u0026#34;banana\u0026#34;, 20); int value = map.get(\u0026#34;apple\u0026#34;);//获取指定键的值 System.out.println(value); 输出结果：\n10 1.3. 判断是否包含某个键或值 使用containsKey()和containsValue()方法：\nMap\u0026lt;String, Integer\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;apple\u0026#34;, 10); map.put(\u0026#34;banana\u0026#34;, 20); boolean hasKey = map.containsKey(\u0026#34;apple\u0026#34;);//判断此map集合里是否存在指定键 boolean hasValue = map.containsValue(20);//判断此map集合里是否存在指定值 System.out.println(hasKey); System.out.println(hasValue); 输出结果：\ntrue true 1.4. 获取所有键或值 使用keySet()和values()方法获取所有键或值：\nMap\u0026lt;String, Integer\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;apple\u0026#34;, 10); map.put(\u0026#34;banana\u0026#34;, 20); Set\u0026lt;String\u0026gt; keys = map.keySet();//获取所有的键 Collection\u0026lt;Integer\u0026gt; values = map.values();//获取所有的值 System.out.println(keys); System.out.println(values); 输出结果：\n[banana, apple] [20, 10] 1.5. 删除键值对 使用remove()方法删除键值对：\nMap\u0026lt;String, Integer\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;apple\u0026#34;, 10); map.put(\u0026#34;banana\u0026#34;, 20); map.remove(\u0026#34;banana\u0026#34;);//根据指定的键删除该键值对 System.out.println(map); 输出结果：\n{apple=10} 2. 循环方式 Map提供了很多不同的循环方式，可根据需求选择不同的方式。以下列举了五种常见的循环方式：\n2.1使用for-each循环遍历： 使用for-each循环遍历Map中的所有键值对，代码示例：\nMap\u0026lt;String, Integer\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); for (Map.Entry\u0026lt;String, Integer\u0026gt; entry : map.entrySet()) { String key = entry.getKey(); Integer value = entry.getValue(); // Do something with key and value } 2.2使用Iterator遍历： 使用Iterator遍历Map中的所有键值对，代码示例：\nMap\u0026lt;String, Integer\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); Iterator\u0026lt;Map.Entry\u0026lt;String, Integer\u0026gt;\u0026gt; it = map.entrySet().iterator(); while (it.hasNext()) { Map.Entry\u0026lt;String, Integer\u0026gt; entry = it.next(); String key = entry.getKey(); Integer value = entry.getValue(); // Do something with key and value } 2.3遍历所有键： 使用keySet()方法获取所有键，然后遍历所有键，代码示例：\nMap\u0026lt;String, Integer\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); for (String key : map.keySet()) { Integer value = map.get(key); // Do something with key and value } 2.4遍历所有值： 使用values()方法获取所有值，然后遍历所有值，代码示例：\nMap\u0026lt;String, Integer\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); for (Integer value : map.values()) { // Do something with value } 2.5 使用Lambda表达式遍历： 使用Lambda表达式遍历Map中的所有键值对，代码示例：\nMap\u0026lt;String, Integer\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.forEach((key, value) -\u0026gt; { // Do something with key and value }); 总结的有什么不好的地方,可以指出,大家共同进步。\n","permalink":"http://localhost:1313/hugo-blog/public/post/java/%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6%E4%B8%80-java%E4%B8%ADmap%E7%9A%84%E5%B8%B8%E8%A7%81%E6%96%B9%E6%B3%95%E7%9A%84%E4%BD%BF%E7%94%A8%E5%8F%8A%E5%BE%AA%E7%8E%AF%E7%9A%84%E4%BA%94%E7%A7%8D%E6%96%B9%E5%BC%8F/","tags":[],"title":""},{"categories":[],"content":"","permalink":"http://localhost:1313/hugo-blog/public/search/_index.de/","tags":[],"title":""},{"categories":[],"content":"","permalink":"http://localhost:1313/hugo-blog/public/search/_index.es/","tags":[],"title":""},{"categories":[],"content":"","permalink":"http://localhost:1313/hugo-blog/public/search/_index.fr/","tags":[],"title":""},{"categories":[],"content":"","permalink":"http://localhost:1313/hugo-blog/public/search/_index.hi/","tags":[],"title":""},{"categories":[],"content":"","permalink":"http://localhost:1313/hugo-blog/public/search/_index.jp/","tags":[],"title":""},{"categories":[],"content":"","permalink":"http://localhost:1313/hugo-blog/public/search/_index.nl/","tags":[],"title":""},{"categories":[],"content":"","permalink":"http://localhost:1313/hugo-blog/public/search/_index.pl/","tags":[],"title":""},{"categories":[],"content":"","permalink":"http://localhost:1313/hugo-blog/public/search/_index.ru/","tags":[],"title":""},{"categories":[],"content":"一、Spring Web MVC 注解 (1)@RequestMapping @RequestMapping注解的主要用途是将Web请求与请求处理类中的方法进行映射。Spring MVC和Spring WebFlux 都通过RquestMappingHandlerMapping和RequestMappingHndlerAdapter两个类来提供对@RequestMapping注解的支持。\n@RequestMapping注解对请求处理类中的请求处理方法进行标注；@RequestMapping注解拥有以下的六个配置属性：\nvalue:映射的请求URL或者其别名 method:兼容HTTP的方法名 params:根据HTTP参数的存在、缺省或值对请求进行过滤 header:根据HTTP Header的存在、缺省或值对请求进行过滤 consume:设定在HTTP请求正文中允许使用的媒体类型 product:在HTTP响应体中允许使用的媒体类型 提示：在使用@RequestMapping之前，请求处理类还需要使用@Controller或@RestController进行标记\n下面是使用@RequestMapping的两个示例：\n图片\n@RequestMapping还可以对类进行标记，这样类中的处理方法在映射请求路径时，会自动将类上@RequestMapping设置的value拼接到方法中映射路径之前，如下：\n图片\n(2)@RequestBody @RequestBody 在处理请求方法的参数列表中使用，它可以将请求主体中的参数绑定到一个对象中，请求主体参数是通过HttpMessageConverter传递的，根据请求主体中的参数名与对象的属性名进行匹配并绑定值。此外，还可以通过@Valid注解对请求主体中的参数进行校验。\n下面是一个使用@RequestBody的示例：\n图片\n(3)@GetMapping @GetMapping注解用于处理HTTP GET请求，并将请求映射到具体的处理方法中。具体来说，@GetMapping 是一个组合注解，它相当于是@RequestMapping(method=RequestMethod.GET)的快捷方式。\n下面是@GetMapping的一个使用示例：\n图片\n(4)@PostMapping @PostMapping注解用于处理HTTP POST请求，并将请求映射到具体的处理方法中。@PostMapping与@GetMapping一样，也是一个组合注解，它相当于是@RequestMapping(method=HttpMethod.POST)的快捷方式。\n下面是使用@PostMapping的一个示例：\n图片\n(5)@PutMapping @PutMapping注解用于处理HTTP PUT请求，并将请求映射到具体的处理方法中，@PutMapping是一个组合注解，相当于是@RequestMapping(method=HttpMethod.PUT)的快捷方式。\n下面是使用@PutMapping的一个示例：\n图片\n(6)@DeleteMapping @DeleteMapping注解用于处理HTTP DELETE请求，并将请求映射到删除方法中。@DeleteMapping是一个组合注解，它相当于是@RequestMapping(method=HttpMethod.DELETE)的快捷方式。\n下面是使用@DeleteMapping的一个示例：\n图片\n(7)@PatchMapping @PatchMapping注解用于处理HTTP PATCH请求，并将请求映射到对应的处理方法中。@PatchMapping相当于是@RequestMapping(method=HttpMethod.PATCH)的快捷方式。\n下面是一个简单的示例：\n图片\n(8)@ControllerAdvice @ControllerAdvice是@Component注解的一个延伸注解，Spring会自动扫描并检测被@ControllerAdvice所标注的类。@ControllerAdvice需要和@ExceptionHandler、@InitBinder以及@ModelAttribute注解搭配使用，主要是用来处理控制器所抛出的异常信息。\n首先，我们需要定义一个被@ControllerAdvice所标注的类，在该类中，定义一个用于处理具体异常的方法，并使用@ExceptionHandler注解进行标记。\n此外，在有必要的时候，可以使用@InitBinder在类中进行全局的配置，还可以使用@ModelAttribute配置与视图相关的参数。使用@ControllerAdvice注解，就可以快速的创建统一的，自定义的异常处理类。\n下面是一个使用@ControllerAdvice的示例代码：\n图片\n(9)@ResponseBody @ResponseBody会自动将控制器中方法的返回值写入到HTTP响应中。特别的，@ResponseBody注解只能用在被@Controller注解标记的类中。如果在被@RestController标记的类中，则方法不需要使用@ResponseBody注解进行标注。@RestController相当于是@Controller和@ResponseBody的组合注解。\n下面是使用该注解的一个示例\n图片\n(10)@ExceptionHandler @ExceptionHander注解用于标注处理特定类型异常类所抛出异常的方法。当控制器中的方法抛出异常时，Spring会自动捕获异常，并将捕获的异常信息传递给被@ExceptionHandler标注的方法。\n下面是使用该注解的一个示例：\n图片\n(11)@ResponseStatus @ResponseStatus注解可以标注请求处理方法。使用此注解，可以指定响应所需要的HTTP STATUS。特别地，我们可以使用HttpStauts类对该注解的value属性进行赋值。\n下面是使用@ResponseStatus注解的一个示例：\n图片\n(12)@PathVariable @PathVariable注解是将方法中的参数绑定到请求URI中的模板变量上。可以通过@RequestMapping注解来指定URI的模板变量，然后使用@PathVariable注解将方法中的参数绑定到模板变量上。\n特别地，@PathVariable注解允许我们使用value或name属性来给参数取一个别名。下面是使用此注解的一个示例：\n图片\n模板变量名需要使用{ }进行包裹，如果方法的参数名与URI模板变量名一致，则在@PathVariable中就可以省略别名的定义。\n下面是一个简写的示例：\n图片\n提示：如果参数是一个非必须的，可选的项，则可以在@PathVariable中设置require = false\n(13)@RequestParam @RequestParam注解用于将方法的参数与Web请求的传递的参数进行绑定。使用@RequestParam可以轻松的访问HTTP请求参数的值。\n下面是使用该注解的代码示例：\n[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-lIG3tAYG-1654676320675)(data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)]图片\n该注解的其他属性配置与@PathVariable的配置相同，特别的，如果传递的参数为空，还可以通过defaultValue设置一个默认值。示例代码如下：\n[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-sP1YdG8n-1654676320675)(data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)]图片\n(14)@Controller @Controller是@Component注解的一个延伸，Spring 会自动扫描并配置被该注解标注的类。此注解用于标注Spring MVC的控制器。下面是使用此注解的示例代码：\n[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-Ij2lwefP-1654676320676)(data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)]图片\n(15)@RestController @RestController是在Spring 4.0开始引入的，这是一个特定的控制器注解。此注解相当于@Controller和@ResponseBody的快捷方式。当使用此注解时，不需要再在方法上使用@ResponseBody注解。\n下面是使用此注解的示例代码：\n图片\n(16)@ModelAttribute 通过此注解，可以通过模型索引名称来访问已经存在于控制器中的model。下面是使用此注解的一个简单示例：\n图片\n与@PathVariable和@RequestParam注解一样，如果参数名与模型具有相同的名字，则不必指定索引名称，简写示例如下：\n图片\n特别地，如果使用@ModelAttribute对方法进行标注，Spring会将方法的返回值绑定到具体的Model上。示例如下：\n图片\n在Spring调用具体的处理方法之前，被@ModelAttribute注解标注的所有方法都将被执行。\n(17)@CrossOrigin @CrossOrigin注解将为请求处理类或请求处理方法提供跨域调用支持。如果我们将此注解标注类，那么类中的所有方法都将获得支持跨域的能力。使用此注解的好处是可以微调跨域行为。使用此注解的示例如下：\n[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-GZdahscU-1654676320677)(data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)]图片\n(18)@InitBinder @InitBinder注解用于标注初始化WebDataBinider 的方法，该方法用于对Http请求传递的表单数据进行处理，如时间格式化、字符串处理等。下面是使用此注解的示例：\n[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-qwhBzLeR-1654676320678)(data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)]图片\n二、Spring Bean 注解 在本小节中，主要列举与Spring Bean相关的4个注解以及它们的使用方式。\n(19)@ComponentScan @ComponentScan注解用于配置Spring需要扫描的被组件注解注释的类所在的包。可以通过配置其basePackages属性或者value属性来配置需要扫描的包路径。value属性是basePackages的别名。此注解的用法如下：\n(20)@Component @Component注解用于标注一个普通的组件类，它没有明确的业务范围，只是通知Spring被此注解的类需要被纳入到Spring Bean容器中并进行管理。此注解的使用示例如下：\n[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-45XIt1Jl-1654676320678)(data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)]图片\n(21)@Service @Service注解是@Component的一个延伸（特例），它用于标注业务逻辑类。与@Component注解一样，被此注解标注的类，会自动被Spring所管理。下面是使用@Service注解的示例：\n图片\n(22)@Repository @Repository注解也是@Component注解的延伸，与@Component注解一样，被此注解标注的类会被Spring自动管理起来，@Repository注解用于标注DAO层的数据持久化类。此注解的用法如下：\n图片 Java项目分享 最新整理全集，找项目不累啦 07版 三、Spring DI与Bean Scops注解 Spring DI (Dependency Inject)\n(23)@DependsOn @DependsOn注解可以配置Spring IoC容器在初始化一个Bean之前，先初始化其他的Bean对象。下面是此注解使用示例代码：\n[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-zm9jdnxn-1654676320679)(data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)]图片\n(24)@Bean @Bean注解主要的作用是告知Spring，被此注解所标注的类将需要纳入到Bean管理工厂中。@Bean注解的用法很简单，在这里，着重介绍@Bean注解中initMethod和destroyMethod的用法。示例如下：\n图片\nScops注解\n(25)@Scope @Scope注解可以用来定义@Component标注的类的作用范围以及@Bean所标记的类的作用范围。@Scope所限定的作用范围有：singleton、prototype、request、session、globalSession或者其他的自定义范围。这里以prototype为例子进行讲解。\n当一个Spring Bean被声明为prototype（原型模式）时，在每次需要使用到该类的时候，Spring IoC容器都会初始化一个新的改类的实例。在定义一个Bean时，可以设置Bean的scope属性为prototype：scope=“prototype”,也可以使用@Scope注解设置，如下：\n@Scope(value=ConfigurableBeanFactory.SCOPE_PROPTOTYPE) 下面将给出两种不同的方式来使用@Scope注解，示例代码如下：\n图片\n(26)@Scope 单例模式 当@Scope的作用范围设置成Singleton时，被此注解所标注的类只会被Spring IoC容器初始化一次。在默认情况下，Spring IoC容器所初始化的类实例都为singleton。同样的原理，此情形也有两种配置方式，示例代码如下：\n[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-bDDbfc8t-1654676320680)(data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)]图片\n四、容器配置注解 (27)@Autowired @Autowired注解用于标记Spring将要解析和注入的依赖项。此注解可以作用在构造函数、字段和setter方法上。\n作用于构造函数\n下面是@Autowired注解标注构造函数的使用示例：\n图片\n作用于setter方法\n下面是@Autowired注解标注setter方法的示例代码：\n图片\n作用于字段\n@Autowired注解标注字段是最简单的，只需要在对应的字段上加入此注解即可，示例代码如下：\n图片\n(28)@Primary 当系统中需要配置多个具有相同类型的bean时，@Primary可以定义这些Bean的优先级。下面将给出一个实例代码来说明这一特性：\n[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-4zixihpW-1654676320681)(data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==)]图片\n输出结果：\nthis is send DingDing method message. (29)@PostConstruct与@PreDestroy 值得注意的是，这两个注解不属于Spring,它们是源于JSR-250中的两个注解，位于common-annotations.jar中。@PostConstruct注解用于标注在Bean被Spring初始化之前需要执行的方法。@PreDestroy注解用于标注Bean被销毁前需要执行的方法。下面是具体的示例代码：\n图片\n(30)@Qualifier 当系统中存在同一类型的多个Bean时，@Autowired在进行依赖注入的时候就不知道该选择哪一个实现类进行注入。此时，我们可以使用@Qualifier注解来微调，帮助@Autowired选择正确的依赖项。下面是一个关于此注解的代码示例：\n图片\n五、Spring Boot注解 (31)@SpringBootApplication @SpringBootApplication注解是一个快捷的配置注解，在被它标注的类中，可以定义一个或多个Bean，并自动触发自动配置Bean和自动扫描组件。此注解相当于@Configuration、@EnableAutoConfiguration和@ComponentScan的组合。\n在Spring Boot应用程序的主类中，就使用了此注解。示例代码如下：\n@SpringBootApplication public class Application{ public static void main(String [] args){ SpringApplication.run(Application.class,args); } } (32)@EnableAutoConfiguration @EnableAutoConfiguration注解用于通知Spring，根据当前类路径下引入的依赖包，自动配置与这些依赖包相关的配置项。\n(33)@ConditionalOnClass与@ConditionalOnMissingClass 这两个注解属于类条件注解，它们根据是否存在某个类作为判断依据来决定是否要执行某些配置。下面是一个简单的示例代码：\n@Configuration@ConditionalOnClass(DataSource.class)class MySQLAutoConfiguration { //... } (34)@ConditionalOnBean与@ConditionalOnMissingBean 这两个注解属于对象条件注解，根据是否存在某个对象作为依据来决定是否要执行某些配置方法。示例代码如下：\n@Bean@ConditionalOnBean(name=\u0026#34;dataSource\u0026#34;)LocalContainerEntityManagerFactoryBean entityManagerFactory(){ //... } @Bean @ConditionalOnMissingBean public MyBean myBean(){ //... } (34)@ConditionalOnProperty @ConditionalOnProperty注解会根据Spring配置文件中的配置项是否满足配置要求，从而决定是否要执行被其标注的方法。示例代码如下：\n@Bean@ConditionalOnProperty(name=\u0026#34;alipay\u0026#34;,havingValue=\u0026#34;on\u0026#34;) Alipay alipay(){ return new Alipay(); } (35)@ConditionalOnResource 此注解用于检测当某个配置文件存在使，则触发被其标注的方法，下面是使用此注解的代码示例：\n@ConditionalOnResource(resources = \u0026#34;classpath:website.properties\u0026#34;) Properties addWebsiteProperties(){ //... } (36)@ConditionalOnWebApplication与 @ConditionalOnNotWebApplication 这两个注解用于判断当前的应用程序是否是Web应用程序。如果当前应用是Web应用程序，则使用Spring WebApplicationContext,并定义其会话的生命周期。下面是一个简单的示例：\n@ConditionalOnWebApplicationHealthCheckController healthCheckController(){ //... } (37)@ConditionalExpression 此注解可以让我们控制更细粒度的基于表达式的配置条件限制。当表达式满足某个条件或者表达式为真的时候，将会执行被此注解标注的方法。\n@Bean@ConditionalException(\u0026#34;${localstore} \u0026amp;\u0026amp; ${local == \u0026#39;true\u0026#39;}\u0026#34;) LocalFileStore store(){ //... } (38)@Conditional @Conditional注解可以控制更为复杂的配置条件。在Spring内置的条件控制注解不满足应用需求的时候，可以使用此注解定义自定义的控制条件，以达到自定义的要求。下面是使用该注解的简单示例：\n@Conditioanl(CustomConditioanl.class) CustomProperties addCustomProperties(){ //... } 真的时候，将会执行被此注解标注的方法。\n@Bean@ConditionalException(\u0026#34;${localstore} \u0026amp;\u0026amp; ${local == \u0026#39;true\u0026#39;}\u0026#34;) LocalFileStore store(){ //... } (38)@Conditional @Conditional注解可以控制更为复杂的配置条件。在Spring内置的条件控制注解不满足应用需求的时候，可以使用此注解定义自定义的控制条件，以达到自定义的要求。下面是使用该注解的简单示例：\n@Conditioanl(CustomConditioanl.class) CustomProperties addCustomProperties(){ //... } 文章知识点与官方知识档案匹配，可进一步学习相关知识\n云原生入门技能树 首页 概览 17255 人正在系统学习中\n本文转自 https://blog.csdn.net/m0_62676056/article/details/125187034 ，如有侵权，请联系删除。\n","permalink":"http://localhost:1313/hugo-blog/public/post/dev-log/springboot38-%E4%B8%AA%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3/","tags":[],"title":"【SpringBoot】38 个常用注解"},{"categories":[],"content":" 公众号：字节数组 希望对你有所帮助 🤣🤣\n在蛮久前有同事问过我关于一个 Gson 和 Kotlin dataClass 的问题，当时答不上来也没去细究，但一直都放在心底，今天就认真探究下原因，也输出总结了一下，希望能帮助你避开这个坑 😂😂\n来看个小例子，猜猜其运行结果会是怎样的\n/** * @Author: leavesCZY * @Desc: * @公众号：字节数组 */ data class UserBean(val userName: String, val userAge: Int) fun main() { val json = \u0026#34;\u0026#34;\u0026#34;{\u0026#34;userName\u0026#34;:null,\u0026#34;userAge\u0026#34;:26}\u0026#34;\u0026#34;\u0026#34; val userBean = Gson().fromJson(json, UserBean::class.java) //第一步 println(userBean) //第二步 printMsg(userBean.userName) //第三步 } fun printMsg(msg: String) { } UserBean 是一个 dataClass，其 userName 字段被声明为非 null 类型，而 json 字符串中 userName 对应的值明确就是 null，那用 Gson 到底能不能反序列化成功呢？程序能不能成功运行完以上三个步骤？\n实际上程序能够正常运行到第二步，但在执行第三步的时候反而直接报 NPE 异常了\nUserBean(userName=null, userAge=26) Exception in thread \u0026#34;main\u0026#34; java.lang.NullPointerException: Parameter specified as non-null is null: method temp.TestKt.printMsg, parameter msg at temp.TestKt.printMsg(Test.kt) at temp.TestKt.main(Test.kt:16) at temp.TestKt.main(Test.kt) 一、为啥会抛出 NEP？ printMsg 方法接收了参数后实际上什么也没做，为啥会抛出 NPE？\n通过 IDEA 将printMsg反编译为 Java 方法，可以发现方法内部会对入参进行空校验，当发现为 null 时就会直接抛出 NullPointerException\npublic static final void printMsg(@NotNull String msg) { Intrinsics.checkNotNullParameter(msg, \u0026#34;msg\u0026#34;); } 这个比较好理解，毕竟 Kotlin 的类型系统会严格区分可 null 和不可为 null 两种类型，其区分手段之一就是会自动在我们的代码里插入一些类型校验逻辑，即自动加上了非空断言，当发现不可为 null 的参数传入了 null 的话就会马上就抛出 NPE，即使我们并没有用到该参数\n当然，这个自动插入的校验逻辑只会在 Kotlin 代码中生成，如果我们是将 userBean.userName传给 Java 方法的话，就不会有这个效果，而是会等到我们使用到了该参数时才发生 NPE\n二、Kotlin 的 nullSafe 失效了吗？ 既然 UserBean 中的 userName 字段已经被声明为非 null 类型了，那么为什么还可以反序列化成功呢？按照我自己的第一直觉，应该在进行反序列的时候就直接抛出异常才对，Gson 是怎么绕过 Kotlin 的 null 检查的呢？\n这个需要来看下 Gson 是如何实现反序列的\n通过断点，可以发现 UserBean 是在 ReflectiveTypeAdapterFactory 里完成构建的，这里的主要步骤就分为两步：\n通过 constructor.construct()得到一个 UserBean 对象，此时该对象内部的属性值都为默认值 遍历 JsonReader，根据 Json 内部的 key 值和 UserBean 包含的字段进行对应，对应得上的话就进行赋值 第二步很好理解，那第一步又是具体怎么实现的？再断点看下constructor.construct()是如何实现的\nconstructor 的取值途径可以在 ConstructorConstructor 这个类中看到\n分为三种可能：\nnewDefaultConstructor。通过反射无参构造函数来生成对象 newDefaultImplementationConstructor。通过反射为 Collection 和 Map 等集合框架类型来生成对象 newUnsafeAllocator。通过 Unsafe 包来生成对象，是最后兜底的方案 首先，第二个肯定不符合条件，看第一个和第三个就行\n作为一个 dataClass，UserBean 是否有无参构造函数呢？反编译后可以看到是没有的，只有一个包含两个参数的构造函数，所以第一步也肯定会反射失败\npublic final class UserBean { @NotNull private final String userName; private final int userAge; @NotNull public final String getUserName() { return this.userName; } public final int getUserAge() { return this.userAge; } public UserBean(@NotNull String userName, int userAge) { Intrinsics.checkNotNullParameter(userName, \u0026#34;userName\u0026#34;); super(); this.userName = userName; this.userAge = userAge; } ··· } 此外，还有一种方法可以验证出来 UserBean 没有被调用到构造函数。我们知道，子类在通过构造函数来进行初始化的时候，肯定是需要先连锁调用父类的构造函数，那么就可以通过为 UserBean 声明一个父类，然后通过判断父类的 init 方法块是否有打印日志就可以知道 UserBean 是否有被调用到构造函数了\nopen class Person() { init { println(\u0026#34;Person\u0026#34;) } } data class UserBean(val userName: String, val userAge: Int) : Person() 前两种都无法满足，再来看 newUnsafeAllocator 是如何进行兜底的\nUnsafe 是位于 sun.misc 包下的一个类，主要提供一些用于执行低级别、不安全操作的方法，如直接访问系统内存资源、自主管理内存资源等，这些方法在提升 Java 运行效率、增强 Java 语言底层资源操作能力方面起到了很大的作用。但由于 Unsafe 类使 Java 语言拥有了类似 C 语言指针一样操作内存空间的能力，这无疑也增加了程序发生相关指针问题的风险。在程序中过度、不正确使用 Unsafe 类会使得程序出错的概率变大，使得 Java 这种安全的语言变得不再安全，因此对 Unsafe 的使用一定要慎重\nUnsafe 提供了一个非常规实例化对象的方法：allocateInstance，该方法提供了通过 Class 对象就可以创建出相应实例的功能，而且不需要调用其构造函数、初始化代码、JVM 安全检查等，即使构造函数是 private 的也能通过此方法进行实例化\nGson 的 UnsafeAllocator 类中就通过 allocateInstance 方法来完成了 UserBean 的初始化，因此也不会调用到其构造函数\n做下总结：\nUserBean 的构造函数只有一个，其包含两个构造参数，在构造函数内部也对 userName 这个字段进行了 null 检查，当发现为 null 时会直接抛出 NPE Gson 是通过 Unsafe 包来实例化 UserBean 对象的，并不会调用到其构造函数，相当于绕过了 Kotlin 的 null 检查，所以即使 userName 值为 null 最终也能够反序列化成功 三、构造参数默认值失效？ 再看个例子\n如果我们为 UserBean 的 userName 字段设置了一个默认值，且 json 中不包含该 key，那么会发现默认值并不会生效，还是为 null\n/** * @Author: leavesCZY * @Desc: * @公众号：字节数组 */ data class UserBean(val userName: String = \u0026#34;leavesC\u0026#34;, val userAge: Int) fun main() { val json = \u0026#34;\u0026#34;\u0026#34;{\u0026#34;userAge\u0026#34;:26}\u0026#34;\u0026#34;\u0026#34; val userBean = Gson().fromJson(json, UserBean::class.java) println(userBean) } UserBean(userName=null, userAge=26) 为构造参数设置默认值是一个很常见的需求，能降低使用者初始化对象的成本，而且如果将 UserBean 作为网络请求接口的承载体的话，接口可能不会返回该字段，此时也希望该字段能够有个默认值\n通过上一节内容的分析，我们知道 Unsafe 包是不会调用 UserBean 的任何构造函数的，所以默认值也一定不会生效，那就只能找其它解决方案了，有以下几种方案可以解决：\n1、无参构造函数 UserBean 提供一个无参构造函数，让 Gson 通过反射该函数来实例化 UserBean，从而同时进行默认值赋值\ndata class UserBean(val userName: String, val userAge: Int) { constructor() : this(\u0026#34;leavesC\u0026#34;, 0) } 2、添加注解 可以通过向构造函数添加一个 @JvmOverloads 注解来解决，这种方式实际上也是通过提供一个无参构造函数来解决问题的。所以缺点就是需要每个构造参数都提供默认值，所以才能生成无参构造函数\ndata class UserBean @JvmOverloads constructor( val userName: String = \u0026#34;leavesC\u0026#34;, val userAge: Int = 0 ) 3、声明为字段 这种方式和前两种类似，也是通过间接提供一个无参构造函数来实现的。将所有字段都声明在类内部而非构造参数，此时声明的字段也一样具有默认值\nclass UserBean { var userName = \u0026#34;leavesC\u0026#34; var userAge = 0 override fun toString(): String { return \u0026#34;UserBean(userName=$userName, userAge=$userAge)\u0026#34; } } 4、改用 moshi Gson 由于本身定位就是用于 Java 语言的，所以目前对于 Kotlin 的友好程度不高，导致默认值无法直接生效。我们可以改用另外一个 Json 序列化库：moshi moshi 是 square 提供的一个开源库，对 Kotlin 的支持程度会比 Gson 高很多\n导入依赖：\ndependencies { implementation \u0026#39;com.squareup.moshi:moshi-kotlin:1.11.0\u0026#39; } 此时不需要做特殊操作，在反序列化的时候默认值就可以直接生效\ndata class UserBean(val userName: String = \u0026#34;leavesC\u0026#34;, val userAge: Int) fun main() { val json = \u0026#34;\u0026#34;\u0026#34;{\u0026#34;userAge\u0026#34;:26}\u0026#34;\u0026#34;\u0026#34; val moshi = Moshi.Builder() .addLast(KotlinJsonAdapterFactory()) .build() val jsonAdapter: JsonAdapter\u0026lt;UserBean\u0026gt; = moshi.adapter(UserBean::class.java) val userBean = jsonAdapter.fromJson(json) println(userBean) } UserBean(userName=leavesC, userAge=26) 但如果 json 字符串中 userName 字段明确返回了 null 的话，此时也会由于类型校验不通过导致直接抛出异常，而这严格来说也更加符合 Kotlin 风格\nfun main() { val json = \u0026#34;\u0026#34;\u0026#34;{\u0026#34;userName\u0026#34;:null,\u0026#34;userAge\u0026#34;:26}\u0026#34;\u0026#34;\u0026#34; val moshi = Moshi.Builder() .addLast(KotlinJsonAdapterFactory()) .build() val jsonAdapter: JsonAdapter\u0026lt;UserBean\u0026gt; = moshi.adapter(UserBean::class.java) val userBean = jsonAdapter.fromJson(json) println(userBean) } Exception in thread \u0026#34;main\u0026#34; com.squareup.moshi.JsonDataException: Non-null value \u0026#39;userName\u0026#39; was null at $.userName at com.squareup.moshi.internal.Util.unexpectedNull(Util.java:663) at com.squareup.moshi.kotlin.reflect.KotlinJsonAdapter.fromJson(KotlinJsonAdapter.kt:87) at com.squareup.moshi.internal.NullSafeJsonAdapter.fromJson(NullSafeJsonAdapter.java:41) at com.squareup.moshi.JsonAdapter.fromJson(JsonAdapter.java:51) at temp.TestKt.main(Test.kt:21) at temp.TestKt.main(Test.kt) 四、扩展知识 再来看个扩展知识，和 Gson 无直接关联，但是在开发中也是蛮重要的一个知识点\njson 为空字符串，此时 Gson 可以成功反序列化，且得到的 userBean 为 null\nfun main() { val json = \u0026#34;\u0026#34; val userBean = Gson().fromJson(json, UserBean::class.java) } 如果加上类型声明：UserBean?，那也可以成功反序列化\nfun main() { val json = \u0026#34;\u0026#34; val userBean: UserBean? = Gson().fromJson(json, UserBean::class.java) } 如果加上的类型声明是 UserBean 的话，那就比较好玩了，会直接抛出 NullPointerException\nfun main() { val json = \u0026#34;\u0026#34; val userBean: UserBean = Gson().fromJson(json, UserBean::class.java) } Exception in thread \u0026#34;main\u0026#34; java.lang.NullPointerException: Gson().fromJson(json, UserBean::class.java) must not be null at temp.TestKt.main(Test.kt:22) at temp.TestKt.main(Test.kt) 以上三个例子会有不同区别的原因是什么呢？\n这就要牵扯到 Kotlin 的平台类型了。Kotlin 的一大特色就可以和 Java 实现百分百互通，平台类型是 Kotlin 对 Java 所作的一种平衡性设计。Kotlin 将对象的类型分为了可空类型和不可空类型两种，但 Java 平台的一切对象类型均为可空的，当在 Kotlin 中引用 Java 变量时，如果将所有变量均归为可空类型，最终将多出许多 null 检查；如果均看成不可空类型，那么就很容易就写出忽略了NPE 风险的代码。为了平衡两者，Kotlin 引入了平台类型，即当在 Kotlin 中引用 Java 变量值时，既可以将之看成可空类型，也可以将之看成不可空类型，由开发者自己来决定是否进行 null 检查\n因此，当我们从 Kotlin 承接 Gson 这个 Java 类返回的变量时，既可以将其当做 UserBean 类型，也可以当做 UserBean? 类型。而如果我们直接显式声明为 UserBean 类型，就说明我们确信返回的是非空类型，当返回的是 null 时就会触发 Kotlin 的 null 检查，导致直接抛出 NullPointerException\n关于平台类型的知识点摘抄自我的另一篇 Kotlin 教程文章：两万六千字带你 Kotlin 入门 ","permalink":"http://localhost:1313/hugo-blog/public/post/kotlin/gson-%E5%92%8C-kotlin-data-class-%E7%9A%84%E9%81%BF%E5%9D%91%E6%8C%87%E5%8D%97/","tags":[],"title":"Gson 和 Kotlin Data Class 的避坑指南"},{"categories":[],"content":"HTML常用特殊字符 以下是HTML中常用的特殊符号及其编码：\n特殊符号 编码 描述 \u0026amp;lt; \u0026amp;amp;lt; 小于号 \u0026amp;gt; \u0026amp;amp;gt; 大于号 \u0026amp;amp; \u0026amp;amp;amp; \u0026amp;符号 \u0026amp;quot; \u0026amp;amp;quot; 双引号 \u0026amp;apos; \u0026amp;amp;apos; 单引号 HTML所有特殊字符 以下是HTML中所有特殊符号及其编码：\n特殊符号 编码 描述 nbsp; \u0026amp;amp;nbsp; 空格 \u0026amp;iexcl; \u0026amp;amp;iexcl; 逆向感叹号 \u0026amp;cent; \u0026amp;amp;cent; 分 \u0026amp;pound; \u0026amp;amp;pound; 英镑 \u0026amp;curren; \u0026amp;amp;curren; 通用货币符号 \u0026amp;yen; \u0026amp;amp;yen; 日元 \u0026amp;brvbar; \u0026amp;amp;brvbar; 断竖线 \u0026amp;sect; \u0026amp;amp;sect; 小节符号 \u0026amp;uml; \u0026amp;amp;uml; 分音符号 \u0026amp;copy; \u0026amp;amp;copy; 版权符号 \u0026amp;ordf; \u0026amp;amp;ordf; 序数指示符（女） \u0026amp;laquo; \u0026amp;amp;laquo; 左法语引号 \u0026amp;not; \u0026amp;amp;not; 非 \u0026amp;shy; \u0026amp;amp;shy; 不显式断字 \u0026amp;reg; \u0026amp;amp;reg; 注册符号 \u0026amp;macr; \u0026amp;amp;macr; 长音符 \u0026amp;deg; \u0026amp;amp;deg; 度数符号 \u0026amp;plusmn; \u0026amp;amp;plusmn; 正负号 \u0026amp;sup2; \u0026amp;amp;sup2; 上角标2 \u0026amp;sup3; \u0026amp;amp;sup3; 上角标3 \u0026amp;acute; \u0026amp;amp;acute; 急促音符 \u0026amp;micro; \u0026amp;amp;micro; 微符号 \u0026amp;para; \u0026amp;amp;para; 段落符 \u0026amp;middot; \u0026amp;amp;middot; 间隔符 \u0026amp;cedil; \u0026amp;amp;cedil; 大写逗号 \u0026amp;sup1; \u0026amp;amp;sup1; 上角标1 \u0026amp;ordm; \u0026amp;amp;ordm; 序数指示符（男） \u0026amp;raquo; \u0026amp;amp;raquo; 右法语引号 \u0026amp;frac14; \u0026amp;amp;frac14; 分数1/4 \u0026amp;frac12; \u0026amp;amp;frac12; 分数1/2 \u0026amp;frac34; \u0026amp;amp;frac34; 分数3/4 \u0026amp;iquest; \u0026amp;amp;iquest; 逆向问号 \u0026amp;Agrave; \u0026amp;amp;Agrave; 大写a重音字母 \u0026amp;Aacute; \u0026amp;amp;Aacute; 大写a重音字母 \u0026amp;Acirc; \u0026amp;amp;Acirc; 大写a带抑扬顿 \u0026amp;Atilde; \u0026amp;amp;Atilde; 大写a带波浪符号 \u0026amp;Auml; \u0026amp;amp;Auml; 大写a带分音符号 \u0026amp;Aring; \u0026amp;amp;Aring; 大写a带圆圈（瑞典） \u0026amp;AElig; \u0026amp;amp;AElig; 大写ae字母 \u0026amp;Ccedil; \u0026amp;amp;Ccedil; 大写c带大写逗号 \u0026amp;Egrave; \u0026amp;amp;Egrave; 大写e重音字母 \u0026amp;Eacute; \u0026amp;amp;Eacute; 大写e重音字母 \u0026amp;Ecirc; \u0026amp;amp;Ecirc; 大写e带抑扬顿 \u0026amp;Euml; \u0026amp;amp;Euml; 大写e带分音符号 \u0026amp;Igrave; \u0026amp;amp;Igrave; 大写i重音字母 \u0026amp;Iacute; \u0026amp;amp;Iacute; 大写i重音字母 \u0026amp;Icirc; \u0026amp;amp;Icirc; 大写i带抑扬顿 \u0026amp;Iuml; \u0026amp;amp;Iuml; 大写i带分音符号 \u0026amp;ETH; \u0026amp;amp;ETH; 大写eth字母 \u0026amp;Ntilde; \u0026amp;amp;Ntilde; 大写n带波浪符号 \u0026amp;Ograve; \u0026amp;amp;Ograve; 大写o重音字母 \u0026amp;Oacute; \u0026amp;amp;Oacute; 大写o重音字母 \u0026amp;Ocirc; \u0026amp;amp;Ocirc; 大写o带抑扬顿 \u0026amp;Otilde; \u0026amp;amp;Otilde; 大写o带波浪符号 \u0026amp;Ouml; \u0026amp;amp;Ouml; 大写o带分音符号 \u0026amp;times; \u0026amp;amp;times; 乘号 \u0026amp;Oslash; \u0026amp;amp;Oslash; 大写o带斜杠 \u0026amp;Ugrave; \u0026amp;amp;Ugrave; 大写u重音字母 \u0026amp;Uacute; \u0026amp;amp;Uacute; 大写u重音字母 \u0026amp;Ucirc; \u0026amp;amp;Ucirc; 大写u带抑扬顿 \u0026amp;Uuml; \u0026amp;amp;Uuml; 大写u带分音符号 \u0026amp;Yacute; \u0026amp;amp;Yacute; 大写y重音字母 \u0026amp;THORN; \u0026amp;amp;THORN; 大写thorn字母 \u0026amp;szlig; \u0026amp;amp;szlig; 小写sharp s符号 \u0026amp;agrave; \u0026amp;amp;agrave; 小写a重音字母 \u0026amp;aacute; \u0026amp;amp;aacute; 小写a重音字母 \u0026amp;acirc; \u0026amp;amp;acirc; 小写a带抑扬顿 \u0026amp;atilde; \u0026amp;amp;atilde; 小写a带波浪符号 \u0026amp;auml; \u0026amp;amp;auml; 小写a带分音符号 \u0026amp;aring; \u0026amp;amp;aring; 小写a带圆圈（瑞典） \u0026amp;aelig; \u0026amp;amp;aelig; 小写ae字母 \u0026amp;ccedil; \u0026amp;amp;ccedil; 小写c带大写逗号 \u0026amp;egrave; \u0026amp;amp;egrave; 小写e重音字母 ","permalink":"http://localhost:1313/hugo-blog/public/post/dev-log/html%E4%B8%AD%E7%9A%84%E5%B8%B8%E7%94%A8%E7%9A%84%E7%89%B9%E6%AE%8A%E5%AD%97%E7%AC%A6%E4%BB%A5%E5%8F%8A%E6%89%80%E6%9C%89%E7%89%B9%E6%AE%8A%E5%AD%97%E7%AC%A6/","tags":[],"title":"HTML中的常用的特殊字符以及所有特殊字符"},{"categories":[],"content":" 公众号：字节数组 希望对你有所帮助 🤣🤣\n本系列文章会陆续对 Java 和 Android 的集合框架（JDK 1.8，Android SDK 30）中的几个常见容器结合源码进行介绍，了解不同容器在数据结构、适用场景、优势点上的不同，希望对你有所帮助 🤣🤣\n一、数组和链表 很多集合框架在底层结构都使用到了数组和链表这两种数据结构，它们在数据存储方式和优劣点这两方面有着很大区别，这里先来介绍下这两者的结构和区别\n1、数组 假设现在有六个元素存放在数组中，则数组在内存中的存储结构就如下所示\n数组是一块连续的内存空间，元素按照坐标索引依次排列，可以直接通过坐标定位到每一个数据的内存地址，例如可以直接通过坐标 3 获取到 element4，省去了从头到尾的遍历操作，因此随机读取数据的效率较高 相对应的，由于数组要求元素是连续存储的，因此在添加和移除数据时有可能需要移动大量数据，所以在添加和移除数据时效率较低 数组在使用前需要先指定其空间大小，在声明空间大小后无法再次修改。如果我们在使用前已知待存入的数据量的话，自然可以将数组初始化为目标容量，这样就不会浪费内存空间了。但实际上数据量往往是未知的，经常会因为申请了较大的内存空间导致浪费，或者是申请少了导致需要后续扩容，而数组在扩容时只能创建一个新的数组并将数据整体迁移，这就影响到了数组的运行性能 ArrayList 底层就是用数组来存储数据\n2、链表 假设现在有四个元素依靠链表来存放，链表在内存中的存储结构就如下所示\n图中所展示的是一个双向链表，即每个结点除了包含实际的数据外，还存在两个引用分别指向上一个结点（prev）和下一个结点（next），各个结点通过这种双向链接从而串联在一起。此外还存在两个引用分别指向头结点（first）和尾结点（last），方便进行正向遍历和反向遍历 链表不要求有连续的内存空间，新添加的结点可以在内存中的任何位置，只要上一个结点和下一个结点互相保存有对方的引用即可，这也导致在随机访问数据时只能遍历整个链表，在最坏的情况下甚至需要全量遍历。当然，可以根据实际情况来选择是正向遍历还是反向遍历，以此提高访问效率，但总的来说链表在随机访问数据时效率要比数组低 在添加或移除元素时，只需要修改相邻结点对指定结点的引用即可，而不需像数组那样需要移动元素，因此链表在添加和移除元素时效率较高 链表不需事先申请内存空间，根据实际使用情况进行动态申请即可 此外还存在一种单向链表的结构，即每个结点包含对下一个结点的引用 next，但不包含 prev，所以单向链表只能从头到尾进行遍历 LinkedList 底层就是用链表来存储数据\n二、ArrayList ArrayList 应该是大多数开发者使用得最为频繁的集合容器了，ArrayList 实现了 List 接口，是一个有序容器，即元素的存放顺序与添加顺序保持一致，允许添加相同元素，包括 null 。ArrayList 底层通过数组来进行数据存储，当向 ArrayList 中添加元素时如果发现数组空间不足，ArrayList 会自动对底层数组进行扩容并迁移现有数据\n1、类声明 从 ArrayList 实现的接口可以看出来它是支持快速访问，可克隆，可序列化的\npublic class ArrayList\u0026lt;E\u0026gt; extends AbstractList\u0026lt;E\u0026gt; implements List\u0026lt;E\u0026gt;, RandomAccess, Cloneable, java.io.Serializable 2、成员变量 ArrayList 一共包含以下几个成员变量，主要看 elementData。elementData 是用于存放数据的底层数组，由于其数据类型声明为 Object，所以可以用来存放任何类型的数据。而 ArrayList 属于泛型类，如果我们在初始化时就指定了数据类型的话，依靠 Java 泛型为我们提供的语法糖，我们在向 elementData 存取数据时编译器就会自动进行类型校验和类型转换，确保存入和取出的数据类型是安全的\n//序列化ID private static final long serialVersionUID = 8683452581122892189L; //进行扩容操作后的最小容量 private static final int DEFAULT_CAPACITY = 10; //如果外部为集合设置的初始化大小为 0，则将 elementData 指向此空数组 private static final Object[] EMPTY_ELEMENTDATA = {}; //如果在初始化集合时使用的是无参构造函数，则将 elementData 指向此空数组 private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {}; //用来存放元素的数组 transient Object[] elementData; //集合大小 private int size; //ArrayList 的快照版本号 protected transient int modCount = 0; 3、构造函数 如果已经知道目标数据量大小的话，在初始化 ArrayList 的时候我们可以直接传入最终的容量值，这样效率会更高一些。因为如果 initialCapacity 过大，则会造成内存浪费；如果 initialCapacity 过小，可能会导致后续需要多次扩容，每次扩容都需要复制原有数据到新数组，这会降低运行效率\n如果我们使用的是无参构造函数或者是指定的 initialCapacity 为 0，此时也只会将 elementData 指向空数组，并不会新建一个数组变量\n//指定集合的初始容量，以此来进行数组的初始化操作 public ArrayList(int initialCapacity) { if (initialCapacity \u0026gt; 0) { this.elementData = new Object[initialCapacity]; } else if (initialCapacity == 0) { this.elementData = EMPTY_ELEMENTDATA; } else { throw new IllegalArgumentException(\u0026#34;Illegal Capacity: \u0026#34;+initialCapacity); } } //外部没有指定初始容量，暂且使用空数组 public ArrayList() { this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; } //传入一份初始数据来进行初始化 public ArrayList(Collection\u0026lt;? extends E\u0026gt; c) { elementData = c.toArray(); if ((size = elementData.length) != 0) { // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); } else { this.elementData = EMPTY_ELEMENTDATA; } } 4、获取元素 在获取指定索引处的元素时，ArrayList 都是直接通过坐标值来获取元素，无需从头遍历，所以说 ArrayList 遍历和随机访问的效率较高\n@SuppressWarnings(\u0026#34;unchecked\u0026#34;) E elementData(int index) { return (E) elementData[index]; } public E get(int index) { //判断取值范围是否合法 rangeCheck(index); return elementData(index); } 5、添加元素 ArrayList 添加元素的操作就不是那么理想了。如果是直接向集合尾端添加数据，那么直接定位到该位置进行赋值即可；如果是向集合的中间位置 index 插入数据，则需要将数组中索引 index 后的所有数据向后推移一位，然后将数据插入到空出的位置上。此外，在插入数据前 elementData 可能已经空间不足了，那么还需要先进行扩容操作。扩容操作会创建一个新的符合大小的数组，并将原数组中的数据迁移到新数组中，然后让 elementData 指向新数组\n由此可以看出来，向集合添加数据和进行扩容都可能会导致数组元素大量移动，所以说 ArrayList 存入数据的效率并不高\npublic boolean add(E e) { //在需要的时候进行扩容 ensureCapacityInternal(size + 1); elementData[size++] = e; return true; } public void add(int index, E element) { rangeCheckForAdd(index); //在需要的时候进行扩容 ensureCapacityInternal(size + 1); //将索引 index 后的所有数值向后推移一位 System.arraycopy(elementData, index, elementData, index + 1,size - index); elementData[index] = element; size++; } 以上说的是存入单个数据的情况，此外还有存入整个集合的情况\n//如果待添加的数据不为空则返回 true，否则返回 false public boolean addAll(Collection\u0026lt;? extends E\u0026gt; c) { Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); //将数组 a 复制到 elementData 的尾端 System.arraycopy(a, 0, elementData, size, numNew); size += numNew; return numNew != 0; } //从指定索引处添加数据，如果待添加的数据不为空则返回 true，否则返回 false public boolean addAll(int index, Collection\u0026lt;? extends E\u0026gt; c) { rangeCheckForAdd(index); Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); //需要移动的数组元素数量 int numMoved = size - index; //因为要添加的数据可能刚好是从数组最尾端开始添加，所以 numMoved 可能为 0 //所以只在 numMoved \u0026gt; 0 的时候才需要对数组的元素值进行移动，以此空出位置给数组 a if (numMoved \u0026gt; 0) System.arraycopy(elementData, index, elementData, index + numNew, numMoved); //将数组 a 包含的数据添加到 elementData 中 System.arraycopy(a, 0, elementData, index, numNew); size += numNew; return numNew != 0; } 6、移除元素 因为数组是一种内存地址连续的数据结构，所以移除某个元素同样可能导致大量元素移动\n//移除指定索引处的元素值，并返回该值 public E remove(int index) { rangeCheck(index); modCount++; //待移除的元素值 E oldValue = elementData(index); //因为要移除元素导致需要移动的元素数量 int numMoved = size - index - 1; //因为要移除的元素可能刚好是数组最后一位，所以 numMoved 可能为 0 //所以只在 numMoved \u0026gt; 0 的时候才需要对数组的元素值进行移动 if (numMoved \u0026gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); //不管数组是否需要对元素值进行移动，数组的最后一位都是无效数据了 //此处将之置为 null 以帮助GC回收 elementData[--size] = null; return oldValue; } //移除集合中包含的第一位元素值为 o 的对象 //如果包含该对象，则返回 true ，否则返回 false public boolean remove(Object o) { if (o == null) { for (int index = 0; index \u0026lt; size; index++) if (elementData[index] == null) { fastRemove(index); return true; } } else { for (int index = 0; index \u0026lt; size; index++) if (o.equals(elementData[index])) { fastRemove(index); return true; } } return false; } 7、扩容机制 再来看下数组的扩容机制的具体实现逻辑\nensureCapacity 方法的入参参数 minCapacity 就用于指定希望扩容后的最小空间，但 minCapacity 最终不会小于 DEFAULT_CAPACITY，即扩容后的数组容量不会小于 10。之所以要进行最小容量的限制，是为了减少多次扩容的可能性，10 以内的数组很容易就发生扩容\n如果在初始化 ArrayList 前已知目标数据的数据量，最好就使用ArrayList(int initialCapacity)来进行初始化，直接让底层数组扩充到目标大小，或者是在添加数据前就调用 ensureCapacity 方法直接让数组扩容到目标大小，避免之后赋值过程中多次扩容\npublic void ensureCapacity(int minCapacity) { int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) ? 0 : DEFAULT_CAPACITY; if (minCapacity \u0026gt; minExpand) { ensureExplicitCapacity(minCapacity); } } private void ensureCapacityInternal(int minCapacity) { if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) { minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); } ensureExplicitCapacity(minCapacity); } private void ensureExplicitCapacity(int minCapacity) { modCount++; //如果当前数组大小的确是比需要的最小空间 minCapacity 小，则进行扩容 if (minCapacity - elementData.length \u0026gt; 0) grow(minCapacity); } 实际上完成扩容操作的是 grow(int minCapacity) 方法。在扩容前，会先判断如果将容量提升到当前的 1.5 倍是否能达到 minCapacity 的要求 ，如果符合要求则直接将容量扩充到当前的 1.5 倍，否则扩充到 minCapacity，但最终容量不能大于 Integer.MAX_VALUE\n构建出一个新的符合大小的数组后，就将原数组中的元素复制到新数组中，至此就完成了扩容\n//数组可扩容到的最大容量 private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; private void grow(int minCapacity) { int oldCapacity = elementData.length; //假设扩容后的空间大小是原先的1.5倍 int newCapacity = oldCapacity + (oldCapacity \u0026gt;\u0026gt; 1); if (newCapacity - minCapacity \u0026lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE \u0026gt; 0) newCapacity = hugeCapacity(minCapacity); elementData = Arrays.copyOf(elementData, newCapacity); } 8、修改元素 //将索引 index 出的元素值置为 element，并返回原始数值 public E set(int index, E element) { rangeCheck(index); E oldValue = elementData(index); elementData[index] = element; return oldValue; } 9、遍历数组 遍历数组的方法包含以下几个，逻辑都比较简单，直接看注释即可。一个比较重要的知识点是看方法内部对 modCount 的校验\n@Override public void forEach(Consumer\u0026lt;? super E\u0026gt; action) { Objects.requireNonNull(action); final int expectedModCount = modCount; @SuppressWarnings(\u0026#34;unchecked\u0026#34;) final E[] elementData = (E[]) this.elementData; final int size = this.size; for (int i=0; modCount == expectedModCount \u0026amp;\u0026amp; i \u0026lt; size; i++) { //将集合元素依次传递给 accept 方法 action.accept(elementData[i]); } //如果 modCount 值被改动了，说明遍历过程中数组有被改动到 //那么就停止遍历并抛出异常 if (modCount != expectedModCount) { throw new ConcurrentModificationException(); } } //按照给定规则对集合元素进行过滤，如果元素符合过滤规则那就将之移除 @Override public boolean removeIf(Predicate\u0026lt;? super E\u0026gt; filter) { Objects.requireNonNull(filter); //要移除的元素个数 int removeCount = 0; //用于标记集合是哪个索引位置需要被移除 final BitSet removeSet = new BitSet(size); final int expectedModCount = modCount; final int size = this.size; for (int i=0; modCount == expectedModCount \u0026amp;\u0026amp; i \u0026lt; size; i++) { @SuppressWarnings(\u0026#34;unchecked\u0026#34;) final E element = (E) elementData[i]; //依次判断集合元素是否符合过滤规则 if (filter.test(element)) { //set 方法将导致索引位置 i 的元素变为 true removeSet.set(i); removeCount++; } } //不允许在排序的过程中集合被其它方法修改了数组（例如：移除元素） if (modCount != expectedModCount) { throw new ConcurrentModificationException(); } //只有 removeCount \u0026gt; 0 才说明需要移除元素 final boolean anyToRemove = removeCount \u0026gt; 0; if (anyToRemove) { //集合移除指定元素后的大小 final int newSize = size - removeCount; for (int i=0, j=0; (i \u0026lt; size) \u0026amp;\u0026amp; (j \u0026lt; newSize); i++, j++) { //略过被标记为 true 的位置，直接跳到不需要移除元素的数组索引位 i = removeSet.nextClearBit(i); //有效数据逐渐从尾部向头部聚集 elementData[j] = elementData[i]; } //移除尾部的无效数据，有利于GC回收 for (int k=newSize; k \u0026lt; size; k++) { elementData[k] = null; } this.size = newSize; //不允许在排序的过程中集合被其它方法修改了数组（例如：移除元素） if (modCount != expectedModCount) { throw new ConcurrentModificationException(); } modCount++; } return anyToRemove; } //将集合元素遍历传递给 operator，并将原始数据替换为 operator 的返回值 @Override @SuppressWarnings(\u0026#34;unchecked\u0026#34;) public void replaceAll(UnaryOperator\u0026lt;E\u0026gt; operator) { Objects.requireNonNull(operator); final int expectedModCount = modCount; final int size = this.size; for (int i=0; modCount == expectedModCount \u0026amp;\u0026amp; i \u0026lt; size; i++) { //依次传递数组元素给 apply 方法，并将其返回值替换原始数据 elementData[i] = operator.apply((E) elementData[i]); } //不允许在排序的过程中集合被其它方法修改了数组（例如：移除元素） if (modCount != expectedModCount) { throw new ConcurrentModificationException(); } modCount++; } 10、迭代器 ArrayList 内部包含一个用于迭代元素的 Iterator 实现类，其用法如下所示\npublic static void main(String[] args) { List\u0026lt;String\u0026gt; stringList = new ArrayList\u0026lt;\u0026gt;(); stringList.add(\u0026#34;https://github.com/leavesCZY\u0026#34;); Iterator\u0026lt;String\u0026gt; iterator = stringList.iterator(); if (iterator.hasNext()) { String next = iterator.next(); System.out.println(next); } } 在这里有个小细节，ArrayList 里多处使用到了 modCount 这个成员变量，modCount 相当于对 ArrayList 的一个简单“快照”，即类似于 ArrayList 的一个版本号，每当添加、移除和修改元素时，modCount 都会递增\n在我们遍历 ArrayList 的过程中，如果同时进行增减元素的操作，或者是存在多线程同时增减元素，那么就会导致遍历结果变得不可靠，或者是直接就导致数组越界异常，所以 ArrayList 就通过 modCount 来标记当前的迭代行为是否处于可靠状态。如果在遍历数组元素的过程中判断到 modCount 的值前后发生了变化，就说明在遍历过程中 ArrayList 被改动了，此时就认定遍历结果不可靠，直接抛出异常。需要注意的是，modCount 做的只是一个简单校验，无法准确判断出当前的遍历操作就真的是安全的\nprotected transient int modCount = 0; public Iterator\u0026lt;E\u0026gt; iterator() { return new Itr(); } private class Itr implements Iterator\u0026lt;E\u0026gt; { //lastRet 指向的元素的下一个元素的索引 int cursor; //最后一个返回的元素的索引 //如果值为 -1，说明还未返回过元素或者改元素被移除了 int lastRet = -1; //用于验证集合的数据结构在迭代的过程中是否被修改了 int expectedModCount = modCount; //是否还有元素未被遍历 public boolean hasNext() { return cursor != size; } //获取下一个元素 @SuppressWarnings(\u0026#34;unchecked\u0026#34;) public E next() { checkForComodification(); int i = cursor; //如果索引值超出取值范围则抛出异常 if (i \u0026gt;= size) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; //如果索引值超出数组的可索引范围则抛出异常 if (i \u0026gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i + 1; return (E) elementData[lastRet = i]; } //移除 lastRet 指向的元素 public void remove() { if (lastRet \u0026lt; 0) throw new IllegalStateException(); checkForComodification(); try { ArrayList.this.remove(lastRet); //因为 lastRet 位置原始的元素被移除了，所以此时 lastRet 指向的元素是原先 lastRet+1 位置的元素 cursor = lastRet; lastRet = -1; //因为是 Itr 主动对集合进行修改，所以此处需要主动更新 expectedModCount 值，避免之后抛出异常 expectedModCount = modCount; } catch (IndexOutOfBoundsException ex) { throw new ConcurrentModificationException(); } } //遍历从索引 cursor 开始之后剩下的元素 @Override @SuppressWarnings(\u0026#34;unchecked\u0026#34;) public void forEachRemaining(Consumer\u0026lt;? super E\u0026gt; consumer) { Objects.requireNonNull(consumer); final int size = ArrayList.this.size; int i = cursor; if (i \u0026gt;= size) { return; } final Object[] elementData = ArrayList.this.elementData; if (i \u0026gt;= elementData.length) { throw new ConcurrentModificationException(); } //遍历调用 accept 方法 while (i != size \u0026amp;\u0026amp; modCount == expectedModCount) { consumer.accept((E) elementData[i++]); } cursor = i; lastRet = i - 1; checkForComodification(); } //判断迭代器在遍历集合的过程中，集合是否被外部改动了（例如被其它迭代器移除了元素） //如果是的话则抛出异常 final void checkForComodification() { if (modCount != expectedModCount) throw new ConcurrentModificationException(); } } 11、效率测试 最后再来测试下 ArrayList 扩容次数的高低对其运行效率的影响\n对三个 ArrayList 存入相同数据量的数据，但分别为 ArrayList 指定不同的初始化大小\npublic static void main(String[] args) { long startTime = System.currentTimeMillis(); List\u0026lt;String\u0026gt; stringList = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; 300000; i++) { stringList.add(\u0026#34;leavesC \u0026#34; + i); } long endTime = System.currentTimeMillis(); System.out.println(\u0026#34;初始容量为0，所用时间：\u0026#34; + (endTime - startTime) + \u0026#34;毫秒\u0026#34;); startTime = System.currentTimeMillis(); List\u0026lt;String\u0026gt; stringList2 = new ArrayList\u0026lt;\u0026gt;(100000); for (int i = 0; i \u0026lt; 300000; i++) { stringList2.add(\u0026#34;leavesC \u0026#34; + i); } endTime = System.currentTimeMillis(); System.out.println(\u0026#34;初始容量为100000，所用时间：\u0026#34; + (endTime - startTime) + \u0026#34;毫秒\u0026#34;); startTime = System.currentTimeMillis(); List\u0026lt;String\u0026gt; stringList3 = new ArrayList\u0026lt;\u0026gt;(300000); for (int i = 0; i \u0026lt; 300000; i++) { stringList3.add(\u0026#34;leavesC \u0026#34; + i); } endTime = System.currentTimeMillis(); System.out.println(\u0026#34;初始容量为300000，所用时间：\u0026#34; + (endTime - startTime) + \u0026#34;毫秒\u0026#34;); } 三种方式下 ArrayList 之间的运行效率差距还是很大的，虽然这种测试方法并不严谨，但也可以看到在省去扩容操作后 ArrayList 的运行效率还是提升了很多的\n初始容量为0，所用时间：39毫秒 初始容量为100000，所用时间：32毫秒 初始容量为300000，所用时间：13毫秒 三、LinkedList LinkedList 同时实现了 List 接口和 Deque 接口，所以既可以将 LinkedList 当做一个有序容器，也可以将之看作一个队列（Queue），同时又可以看作一个栈（Stack）。虽然 LinkedList 和 ArrayList 一样都实现了 List 接口，但其底层是通过双向链表来实现的，所以插入和删除元素的效率都要比 ArrayList 高，但也因此随机访问的效率要比 ArrayList 低\n1、类声明 从 LinkedList 实现的几个接口可以看出来，LinkedList 是支持快速访问，可克隆，可序列化的，而且可以将之看成一个支持有序访问的队列或者栈\npublic class LinkedList\u0026lt;E\u0026gt; extends AbstractSequentialList\u0026lt;E\u0026gt; implements List\u0026lt;E\u0026gt;, Deque\u0026lt;E\u0026gt;, Cloneable, java.io.Serializable LinkedList 内部通过双向链表的数据结构来实现的，每个链表结点除了存储本结点的数据元素外，还有两个指针分别用于指向其上下两个相邻结点，这个结点就是 LinkedList 中的静态类 Node\nprivate static class Node\u0026lt;E\u0026gt; { //当前结点包含的实际元素 E item; //指向下一个结点 Node\u0026lt;E\u0026gt; next; //指向上一个结点 Node\u0026lt;E\u0026gt; prev; Node(Node\u0026lt;E\u0026gt; prev, E element, Node\u0026lt;E\u0026gt; next) { this.item = element; this.next = next; this.prev = prev; } } 2、成员变量 //双向链表包含的结点总数，即数据总量 transient int size = 0; //双向链表的头结点 transient Node\u0026lt;E\u0026gt; first; //双向链表的尾结点 transient Node\u0026lt;E\u0026gt; last; //序列化ID private static final long serialVersionUID = 876323262645176354L; 当中的成员变量 first 和 last 分别用于指向链表的头部和尾部结点，因此 LinkedList 的数据结构图是类似于这样的\n3、构造函数 LinkedList 不需要去请求一片连续的内存空间来存储数据，而是在每次有新的元素需要添加时再来动态请求内存空间，因此 LinkedList 的两个构造函数都很简单\npublic LinkedList() { } //传入初始数据 public LinkedList(Collection\u0026lt;? extends E\u0026gt; c) { this(); addAll(c); } 4、添加元素 add(E e) 方法用于向链表的尾部添加结点，因为有 last 指向链表的尾结点，因此向尾部添加新元素只需要修改几个引用即可，效率较高\n//将元素 e 作为尾结点添加 //因为 LinkedList 允许添加相同元素，所以此方法固定返回 true public boolean add(E e) { linkLast(e); return true; } //将元素 e 置为尾结点 void linkLast(E e) { //先保存原尾结点 final Node\u0026lt;E\u0026gt; l = last; //构建新的尾结点，并指向原尾结点 final Node\u0026lt;E\u0026gt; newNode = new Node\u0026lt;\u0026gt;(l, e, null); last = newNode; //如果原尾结点为 null，说明原链表包含的元素个数为 0，则此时插入的尾结点同时即为头结点 //如果原尾结点不为 null，则将 next 指向新的尾结点 if (l == null) first = newNode; else l.next = newNode; //元素个数加1 size++; modCount++; } add(int index, E element) 方法用于向指定索引处添加元素，需要先通过索引 index 获取相应位置的结点，并在该位置开辟一个新的结点来存储元素 element，最后还需要修改相邻结点间的引用\n//在索引 index 处插入元素 element public void add(int index, E element) { //判断索引大小是否合法，不合法则抛出 IndexOutOfBoundsException checkPositionIndex(index); //如果 index == size，则将 element 作为尾结点来添加 //否则则在索引 index 前开辟一个新结点 if (index == size) linkLast(element); else linkBefore(element, node(index)); } //将元素 e 置为 succ 结点的上一个结点 void linkBefore(E e, Node\u0026lt;E\u0026gt; succ) { //保存 succ 的上一个结点信息 final Node\u0026lt;E\u0026gt; pred = succ.prev; //构建元素 e 对应的结点 final Node\u0026lt;E\u0026gt; newNode = new Node\u0026lt;\u0026gt;(pred, e, succ); //将结点 succ 的上一个结点指向 newNode succ.prev = newNode; //如果 pred 为 null，说明 succ 是头结点，则将 newNode 置为新的头结点 if (pred == null) first = newNode; else pred.next = newNode; //元素个数加1 size++; modCount++; } 5、移除元素 remove() 方法有两种重载形式，其内部都是通过调用 unlink(Node\u0026lt;E\u0026gt; x) 方法来移除指定结点在链表中的引用，不同于 ArrayList 在移除元素时可能导致的大量数据移动，LinkedList 只需要通过移除引用即可将指定元素从链表中移除\n//移除索引 index 处的结点 public E remove(int index) { //判断索引大小是否合法，不合法则抛出 IndexOutOfBoundsException checkElementIndex(index); return unlink(node(index)); } //对链表进行正向遍历，移除第一个元素值为 o 的结点 //如果移除成功则返回 true，否则返回 false public boolean remove(Object o) { if (o == null) { for (Node\u0026lt;E\u0026gt; x = first; x != null; x = x.next) { if (x.item == null) { //移除结点 x unlink(x); return true; } } } else { for (Node\u0026lt;E\u0026gt; x = first; x != null; x = x.next) { if (o.equals(x.item)) { //移除结点 x unlink(x); return true; } } } return false; } //移除结点 x 并返回其包含的元素值 E unlink(Node\u0026lt;E\u0026gt; x) { final E element = x.item; final Node\u0026lt;E\u0026gt; next = x.next; final Node\u0026lt;E\u0026gt; prev = x.prev; //如果 prev == null，说明结点 x 为头结点，则将头结点置为原先的第二个结点 //如果 prev != null，则移除对结点 x 的引用 if (prev == null) { first = next; } else { prev.next = next; x.prev = null; } //如果 next == null，则说明结点 x 为尾结点，则将尾结点置为原先的倒数第二个结点 //如果 next != null，则移除对结点 x 的引用 if (next == null) { last = prev; } else { next.prev = prev; x.next = null; } //帮助GC回收 x.item = null; //元素个数减1 size--; modCount++; return element; } 6、随机访问元素 对于单向链表来说，如果想随机定位到某个结点，那么只能通过从头结点开始遍历的方式来定位，最极端的情况下需要遍历整个链表才能定位到目标结点。如果是双向链表，则可以选择正向遍历或者反向遍历，最极端的情况下需要遍历一半链表才能定位到目标结点。所以，相比数组来说 LinkedList 的随机访问效率并不高\n//获取索引 index 处的结点元素 public E get(int index) { //判断索引大小是否合法，不合法则抛出 IndexOutOfBoundsException checkElementIndex(index); return node(index).item; } //将索引 index 处的结点包含的元素修改为 element，并返回旧元素 public E set(int index, E element) { //判断索引大小是否合法，不合法则抛出 IndexOutOfBoundsException checkElementIndex(index); Node\u0026lt;E\u0026gt; x = node(index); E oldVal = x.item; x.item = element; return oldVal; } //获取索引 index 处的结点 Node\u0026lt;E\u0026gt; node(int index) { //size \u0026gt;\u0026gt; 1 的含义即为：将 size 值除以 2 //如果 index 靠近链表的头部，则从头部向尾部正向遍历查找结点 //如果 index 靠近链表的尾部，则从尾部向头部反向遍历查找结点 //最极端的情况下遍历一半元素才能定位到目标节点 if (index \u0026lt; (size \u0026gt;\u0026gt; 1)) { Node\u0026lt;E\u0026gt; x = first; for (int i = 0; i \u0026lt; index; i++) x = x.next; return x; } else { Node\u0026lt;E\u0026gt; x = last; for (int i = size - 1; i \u0026gt; index; i--) x = x.prev; return x; } } 7、几个常用的方法 //判断是否包含元素 o public boolean contains(Object o) { return indexOf(o) != -1; } //获取元素个数 public int size() { return size; } //清空链表元素，将各个结点之间的引用都切断 public void clear() { for (Node\u0026lt;E\u0026gt; x = first; x != null; ) { Node\u0026lt;E\u0026gt; next = x.next; x.item = null; x.next = null; x.prev = null; x = next; } first = last = null; size = 0; modCount++; } //返回第一个元素值为 o 的结点所在的索引值 //如果查找不到，则返回 -1 public int indexOf(Object o) { int index = 0; if (o == null) { for (Node\u0026lt;E\u0026gt; x = first; x != null; x = x.next) { if (x.item == null) return index; index++; } } else { for (Node\u0026lt;E\u0026gt; x = first; x != null; x = x.next) { if (o.equals(x.item)) return index; index++; } } return -1; } //返回最后一个元素值为 o 的结点所在的索引值 //如果查找不到，则返回 -1 public int lastIndexOf(Object o) { int index = size; if (o == null) { for (Node\u0026lt;E\u0026gt; x = last; x != null; x = x.prev) { index--; if (x.item == null) return index; } } else { for (Node\u0026lt;E\u0026gt; x = last; x != null; x = x.prev) { index--; if (o.equals(x.item)) return index; } } return -1; } 8、Deque 接口 以上介绍的几个方法都是 List 接口中所声明的，接下来看下 Deque 接口中的方法\n其实 Deque 接口中很多方法的含义都是类似的，且一些方法都是相互调用的，并不算复杂\n//将元素 e 置为头结点 public void addFirst(E e) { linkFirst(e); } //将元素 e 置为尾结点 public void addLast(E e) { linkLast(e); } //将元素 e 作为尾结点添加 public boolean offer(E e) { return add(e); } //将元素 e 作为头结点添加 public boolean offerFirst(E e) { addFirst(e); return true; } //将元素 e 作为尾结点添加 public boolean offerLast(E e) { addLast(e); return true; } //获取头部结点的元素值 public E peekFirst() { final Node\u0026lt;E\u0026gt; f = first; return (f == null) ? null : f.item; } //获取尾部结点的元素值 public E peekLast() { final Node\u0026lt;E\u0026gt; l = last; return (l == null) ? null : l.item; } //获取头部结点的元素值，并将之从链表中移除 public E pollFirst() { final Node\u0026lt;E\u0026gt; f = first; return (f == null) ? null : unlinkFirst(f); } //获取尾部结点的元素值，并将之从链表中移除 public E pollLast() { final Node\u0026lt;E\u0026gt; l = last; return (l == null) ? null : unlinkLast(l); } //将元素 e 作为头结点添加 public void push(E e) { addFirst(e); } //获取头部结点的元素值，并将之从链表中移除 public E pop() { return removeFirst(); } //从链表头部向尾部正向遍历，移除第一个元素值为 o 的结点 //如果移除成功则返回 true，否则返回 false public boolean removeFirstOccurrence(Object o) { return remove(o); } //从链表尾部向头部反向遍历，移除第一个元素值为 o 的结点 //如果移除成功则返回 true，否则返回 false public boolean removeLastOccurrence(Object o) { if (o == null) { for (Node\u0026lt;E\u0026gt; x = last; x != null; x = x.prev) { if (x.item == null) { unlink(x); return true; } } } else { for (Node\u0026lt;E\u0026gt; x = last; x != null; x = x.prev) { if (o.equals(x.item)) { unlink(x); return true; } } } return false; } 9、效率测试 上面说过，LinkedList 相比 ArrayList 在添加和移除元素时效率上会高很多，但随机访问元素的效率要比 ArrayList 低，这里也来做个测试，验证两者之间的差别\n分别向 ArrayList 和 LinkedList 存入同等数据量的数据，然后各自移除 100 个元素以及遍历 10000 个元素，观察两者所用的时间\nArrayList：\npublic static void main(String[] args) { List\u0026lt;String\u0026gt; stringArrayList = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; 300000; i++) { stringArrayList.add(\u0026#34;leavesC \u0026#34; + i); } long startTime = System.currentTimeMillis(); for (int i = 0; i \u0026lt; 100; i++) { stringArrayList.remove(100 + i); } long endTime = System.currentTimeMillis(); System.out.println(\u0026#34;移除 ArrayList 中的100个元素,用时：\u0026#34; + (endTime - startTime) + \u0026#34;毫秒\u0026#34;); startTime = System.currentTimeMillis(); for (int i = 0; i \u0026lt; 10000; i++) { stringArrayList.get(i); } endTime = System.currentTimeMillis(); System.out.println(\u0026#34;遍历 ArrayList 中的10000个元素,用时：\u0026#34; + (endTime - startTime) + \u0026#34;毫秒\u0026#34;); } LinkedList：\npublic static void main(String[] args) { List\u0026lt;String\u0026gt; stringLinkedList = new LinkedList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; 300000; i++) { stringLinkedList.add(\u0026#34;leavesC \u0026#34; + i); } long startTime = System.currentTimeMillis(); for (int i = 0; i \u0026lt; 100; i++) { stringLinkedList.remove(100 + i); } long endTime = System.currentTimeMillis(); System.out.println(\u0026#34;移除 LinkedList 中的100个元素,用时：\u0026#34; + (endTime - startTime) + \u0026#34;毫秒\u0026#34;); startTime = System.currentTimeMillis(); for (int i = 0; i \u0026lt; 10000; i++) { stringLinkedList.get(i); } endTime = System.currentTimeMillis(); System.out.println(\u0026#34;遍历 LinkedList 中的10000个元素,用时：\u0026#34; + (endTime - startTime) + \u0026#34;毫秒\u0026#34;); } 可以看出来两者之间的差距还是非常大的，在使用集合框架前需要根据实际应用场景来决定使用哪一个\n移除 ArrayList 中的100个元素,用时：18毫秒 遍历 ArrayList 中的10000个元素,用时：1毫秒 移除 LinkedList 中的100个元素,用时：0毫秒 遍历 LinkedList 中的10000个元素,用时：237毫秒 ","permalink":"http://localhost:1313/hugo-blog/public/post/kotlin/java--android-%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6%E9%A1%BB%E7%9F%A5%E9%A1%BB%E4%BC%9A1/","tags":[],"title":"Java \u0026 Android 集合框架须知须会（1）"},{"categories":[],"content":" 公众号：字节数组 希望对你有所帮助 🤣🤣\n本系列文章会陆续对 Java 和 Android 的集合框架（JDK 1.8，Android SDK 30）中的几个常见容器结合源码进行介绍，了解不同容器在数据结构、适用场景、优势点上的不同，希望对你有所帮助 🤣🤣\n一、HashMap HashMap 是一种用于存储键值对的数据类型，基于哈希表的 Map 接口的非同步实现，key 可以为 null，不允许插入重复的 key，允许 value 重复\nHashMap 实际上是数组+链表+红黑树的结合体，其底层包含一个数组，数组中每一项元素的类型分为四种可能：null、单独一个结点、链表、红黑树（JDK1.8 开始通过使用红黑树来提高元素查找效率）。当往 HashMap 中存入元素时，会先根据 key 的哈希值得到该元素在数组中的位置（即数组下标），如果该位置上已经存放有其它元素了，那么在这个位置上的元素将以链表或者红黑树的形式来存放，如果该位置上没有元素，就直接向该位置存放元素。因此 HashMap 要求 key 必须是不可变对象，即 key 的哈希值不能发生改变，否则就会导致后续访问时无法定位到它的存放位置了\n1、哈希 Hash，一般翻译做哈希或者散列，是把输入的任意对象通过哈希算法变换成固定长度的输出，该输出就是哈希值。不同的输入可能会哈希成相同的输出，所以不可能从哈希值来确定唯一的输入值，但可以将哈希值作为这个对象的一个特征\n哈希的作用可以通过举一个例子来说明。假设存在一千个单词，现在需要从中找到“hello”这个单词的位置索引，那么最直观的做法就是将这些单词存储到一个长度为一千的数组中并进行遍历，最坏的结果就需要遍历一千次。如果单词数量越多，那么需要的数组空间就会越多，平均需要进行遍历的次数也会越高。为了节省内存空间并减少遍历次数，我们可以通过哈希算法拿到每个单词的哈希值，将这些哈希值映射为一个长度为一百的数组内的索引值，在该索引位置上保存对应的单词。如果采用的哈希算法足够优秀，不同的单词得到的哈希值就具有很大的随机性，这样一千个单词就可以均匀地分布到数组内了，最好的情况就是每个数组位置只保存十个单词，这十个单词再按照链表或者其它数据结构串联起来。这样我们在查找的时候只需要计算出“hello”对应的索引值，然后在这个索引位置遍历十个单词即可。如果数组空间足够大，哈希算法得到的索引值足够均匀，那么最好的情况就是只需要进行一次查找就可以得到目标结果，最坏的结果也只是需要查找该位置上的所有单词即可，大大减少了遍历次数\nHashMap 内部就采用了哈希算法来存储元素。但由于哈希算法对于不同的输入有可能会哈希成相同的输出，而且数组空间不可能是无限大的，所以在同个数组位置上就不可避免的需要存储多个元素了，这种情况就叫做哈希冲突。此外，HashMap 不保证元素的存储顺序和迭代顺序，因为根据需要 HashMap 会对元素重新哈希，元素的顺序也会被再次打乱，因此在不同时间段其存储顺序和迭代顺序都可能会发现变化。此外，HashMap 也不保证线程安全，如果有多个线程同时进行写操作的话可能会导致数据错乱甚至线程死锁\n2、类声明 public class HashMap\u0026lt;K, V\u0026gt; extends AbstractMap\u0026lt;K, V\u0026gt; implements Map\u0026lt;K, V\u0026gt;, Cloneable, Serializable 3、常量 HashMap 中的全局常量主要看以下几个\n//哈希桶数组的默认容量 static final int DEFAULT_INITIAL_CAPACITY = 1 \u0026lt;\u0026lt; 4; //哈希桶数组能够达到的最大容量 static final int MAXIMUM_CAPACITY = 1 \u0026lt;\u0026lt; 30; //装载因子 static final float DEFAULT_LOAD_FACTOR = 0.75f; //为了提高效率，当链表的长度超出这个值时，就将链表转换为红黑树 static final int TREEIFY_THRESHOLD = 8; //当红黑树的长度小于这个值时，就将红黑树转换为链表 static final int UNTREEIFY_THRESHOLD = 6; 装载因子用于规定数组在自动扩容之前数据占有其容量的最高比例，即当数据量占有数组的容量达到这个比例后，数组将自动扩容。装载因子衡量的是一个散列表的空间的使用程度，装载因子越大表示散列表的装填程度越高，反之愈小。对于使用链表的散列表来说，查找一个元素的平均时间是O(1+a)，因此装载因子越大，对空间的利用程度就越高，相对应的是查找效率越低。如果装载因子太小，那么数组的数据将过于稀疏，对空间的利用率就变低，相应查找效率也会提升\n官方默认的装载因子大小是 DEFAULT_LOAD_FACTOR，即 0.75，是平衡空间利用率和查找效率两者之后的结果。在实际情况中，如果内存空间较多而对时间效率要求很高，可以选择降低装载因子大小；如果内存空间紧张而对时间效率要求不高，则可以选择加大装载因子\n此外，即使装载因子和哈希算法设计得再合理，也难免会出现由于哈希冲突导致链表长度过长的情况，这也将影响 HashMap 的性能。为了优化性能，从 JDK1.8 开始引入了红黑树，当链表长度超出 TREEIFY_THRESHOLD 规定的值时，链表就会被转换为红黑树，利用红黑树快速增删改查的特点以提高 HashMap 的性能\n4、变量 //哈希桶数组，在第一次使用时才初始化 //容量值应是2的整数倍 transient Node\u0026lt;K, V\u0026gt;[] table; /** * Holds cached entrySet(). Note that AbstractMap fields are used * for keySet() and values(). */ transient Set\u0026lt;Map.Entry\u0026lt;K, V\u0026gt;\u0026gt; entrySet; //Map的大小 transient int size; //每当Map的结构发生变化时，此参数就会递增 //当在对Map进行迭代操作时，迭代器会检查此参数值 //如果检查到此参数的值发生变化，就说明在迭代的过程中Map的结构发生了变化，因此会直接抛出异常 transient int modCount; //数组的扩容临界点，当数组的数据量达到这个值时就会进行扩容操作 //计算方法：当前容量 x 装载因子 int threshold; //使用的装载因子值 final float loadFactor; 5、构造函数 //设置Map的初始化大小和装载因子 public HashMap(int initialCapacity, float loadFactor) { if (initialCapacity \u0026lt; 0) throw new IllegalArgumentException(\u0026#34;Illegal initial capacity: \u0026#34; + initialCapacity); if (initialCapacity \u0026gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor \u0026lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\u0026#34;Illegal load factor: \u0026#34; + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); } //设置初始化大小 public HashMap(int initialCapacity) { this(initialCapacity, DEFAULT_LOAD_FACTOR); } //使用默认值 public HashMap() { this.loadFactor = DEFAULT_LOAD_FACTOR; } //传入初始数据 public HashMap(Map\u0026lt;? extends K, ? extends V\u0026gt; m) { this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false); } 6、插入键值对 在上边说过，HashMap 是 数组+链表+红黑树 的结合体，数组中每一项元素的类型分为四种可能：null、单独一个结点、链表、红黑树\n每一个要插入的键值对都会被包装为 Node 对象，根据 key 的哈希值来决定 Node 对象在数组中的位置。如果计算出的位置此时不包含值则直接将 Node 对象放到该位置即可；如果包含值则说明发生了哈希碰撞，此时就需要将 Node 对象插入到链表或者是红黑树中。如果 key 与链表或红黑树中某个已有结点的 key 相等（hash 值相等且两者 equals 成立），则新添加的 Node 对象将覆盖原有数据\n当哈希算法的计算结果越分散均匀，发生哈希碰撞的概率就越小，HashMap 的存取效率就会越高\nNode 类的声明如下所示\nstatic class Node\u0026lt;K,V\u0026gt; implements Map.Entry\u0026lt;K,V\u0026gt; { //key 的哈希值 final int hash; final K key; V value; //下一个结点 Node\u0026lt;K,V\u0026gt; next; Node(int hash, K key, V value, Node\u0026lt;K,V\u0026gt; next) { this.hash = hash; this.key = key; this.value = value; this.next = next; } public final K getKey() { return key; } public final V getValue() { return value; } public final String toString() { return key + \u0026#34;=\u0026#34; + value; } public final int hashCode() { return Objects.hashCode(key) ^ Objects.hashCode(value); } public final V setValue(V newValue) { V oldValue = value; value = newValue; return oldValue; } public final boolean equals(Object o) { if (o == this) return true; if (o instanceof Map.Entry) { Map.Entry\u0026lt;?,?\u0026gt; e = (Map.Entry\u0026lt;?,?\u0026gt;)o; if (Objects.equals(key, e.getKey()) \u0026amp;\u0026amp; Objects.equals(value, e.getValue())) return true; } return false; } } 插入键值对的方法是 put(K key, V value)\npublic V put(K key, V value) { return putVal(hash(key), key, value, false, true); } //计算 key 的哈希值 static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h \u0026gt;\u0026gt;\u0026gt; 16); } putVal 方法较为复杂，因为该方法要考虑以下几种情况：\n如果 table 还未初始化或者容量为 0 则进行初始化和扩容 判断是否存在哈希冲突 如果不存在哈希冲突，则直接将该键值对存入计算出来的位置 如果存在哈希冲突，则将键值对添加到该位置的红黑树或者链表上，并且在链表达到最大长度时将链表转换为红黑树 当存在相同 key 的结点时，判断是否需要覆盖旧值 为 LinkedHashMap 预留方法埋点 当保存键值对后，进行必要的扩容 /** * @param hash hash for key * @param key the key * @param value the value to put * @param onlyIfAbsent 为 true 表示不会覆盖有相同 key 的非 null value，否则会覆盖原有值 * @param evict if false, the table is in creation mode. * @return previous value, or null if none */ final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node\u0026lt;K, V\u0026gt;[] tab; Node\u0026lt;K, V\u0026gt; p; int n, i; //如果 table 还未初始化或者容量为0，则调用 resize 方法进行初始化 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //判断要存入的 key 是否存在哈希冲突 //p 指向了键值对希望存入的数组位置 //p 等于 null 说明不存在冲突 if ((p = tab[i = (n - 1) \u0026amp; hash]) == null) //直接在索引 i 处构建包含待存入元素的结点 tab[i] = newNode(hash, key, value, null); else { //走入本分支，说明待存入的 key 存在哈希冲突 Node\u0026lt;K, V\u0026gt; e; K k; //p 值已在上一个 if 语句中赋值了，此处就直接来判断 Node key 的相等性 if (p.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) //会走进这里，说明 p 结点 key 和待存入的键值对 key 相等 //此时该位置可能只有一个结点，也有可能是红黑树或者链表， //那么 e 就指向该冲突结点 //此时就已经找到了键值对待存入的位置了 e = p; //如果 Node key 不相等，且头结点是 TreeNode 类型，说明此时该位置当前是采用红黑树来处理哈希冲突 else if (p instanceof TreeNode) //如果红黑树中不存在相同 key 的话则插入保存键值对并返回 null，否则不保存并返回该该相同 key 的结点 e = ((TreeNode\u0026lt;K, V\u0026gt;) p).putTreeVal(this, tab, hash, key, value); else { //该位置当前是采用链表来处理哈希冲突 for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { //会走进这里，说明遍历到了链表尾部，且链表中每个结点的 key 均不相等 //那么就将其添加到链表尾部 p.next = newNode(hash, key, value, null); //如果链表的长度已达到允许的最大长度，那么就将链表转换为红黑树 if (binCount \u0026gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) //找到了相同 key 的结点，即 e break; p = e; } } //如果 e != null，说明原先存在相同 key 的键值对 //那么就再来判断下是否需要覆盖 value if (e != null) { V oldValue = e.value; //如果 onlyIfAbsent 为 false 或者 oldValue 为 null 则覆盖原有值 if (!onlyIfAbsent || oldValue == null) e.value = value; //用于 LinkedHashMap ，在 HashMap 中是空实现 afterNodeAccess(e); return oldValue; } } ++modCount; //判断是否需要扩容 if (++size \u0026gt; threshold) resize(); //用于 LinkedHashMap ，在 HashMap 中是空实现 afterNodeInsertion(evict); return null; } 7、获取 value 获取 value 对应的是 get(Object key)方法\npublic V get(Object key) { Node\u0026lt;K, V\u0026gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; } //根据 key 获取结点 final Node\u0026lt;K, V\u0026gt; getNode(int hash, Object key) { Node\u0026lt;K, V\u0026gt;[] tab; Node\u0026lt;K, V\u0026gt; first, e; int n; K k; //只有当 table 不为空且 hash 对应的位置不为 null 时说明才有可能存在该 key if ((tab = table) != null \u0026amp;\u0026amp; (n = tab.length) \u0026gt; 0 \u0026amp;\u0026amp; (first = tab[(n - 1) \u0026amp; hash]) != null) { if (first.hash == hash \u0026amp;\u0026amp; ((k = first.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) //如果与头结点相等的话说明找到了对应值 return first; // e != null 说明存在该位置存在链表或红黑树，那么就从这两者中获取 if ((e = first.next) != null) { if (first instanceof TreeNode) //红黑树 return ((TreeNode\u0026lt;K, V\u0026gt;) first).getTreeNode(hash, key); do { //链表 if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) return e; } while ((e = e.next) != null); } } return null; } 8、移除结点 从 Map 中移除键值对的操作，对于其底层数据结构的体现就是要移除对某个 Node 对象的引用，这个数据结构可能是数组、红黑树、或者链表\n//如果真的存在该 key，则返回对应的 value，否则返回 null public V remove(Object key) { Node\u0026lt;K, V\u0026gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value; } /** * @param value key对应的值，只有当matchValue为true时才需要使用到，否则忽略该值 * @param matchValue 如果为 true ，则只有当找到key和value均匹配的结点时才会移除该结点，否则只要key相等就直接移除该元素 * @param movable if false do not move other nodes while removing * @return the node, or null if none */ final Node\u0026lt;K, V\u0026gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) { Node\u0026lt;K, V\u0026gt;[] tab; Node\u0026lt;K, V\u0026gt; p; int n, index; //只有当 table 不为空且 hash 对应的位置不为 null 时说明才有可能存在该 key if ((tab = table) != null \u0026amp;\u0026amp; (n = tab.length) \u0026gt; 0 \u0026amp;\u0026amp; (p = tab[index = (n - 1) \u0026amp; hash]) != null) { Node\u0026lt;K, V\u0026gt; node = null, e; K k; V v; if (p.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) //如果与头结点 p 的 key 相等，那么就已经找到了目标 node node = p; else if ((e = p.next) != null) { //存在红黑树或者链表 if (p instanceof TreeNode) //红黑树 node = ((TreeNode\u0026lt;K, V\u0026gt;) p).getTreeNode(hash, key); else { //链表 do { if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) { node = e; break; } p = e; } while ((e = e.next) != null); } } //node != null 说明存在 key 对应结点 //如果 matchValue 为 false ，则此处就可以直接移除结点 node //如果 matchValue 为 true ，则当 value 相等时才需要移除该结点 if (node != null \u0026amp;\u0026amp; (!matchValue || (v = node.value) == value || (value != null \u0026amp;\u0026amp; value.equals(v)))) { if (node instanceof TreeNode) //红黑树 ((TreeNode\u0026lt;K, V\u0026gt;) node).removeTreeNode(this, tab, movable); else if (node == p) //对应 key 与头结点相等的情况，此时直接将指针移向下一位即可 tab[index] = node.next; else //链表 p.next = node.next; ++modCount; --size; //用于 LinkedHashMap ，在 HashMap 中是空实现 afterNodeRemoval(node); return node; } } return null; } 9、哈希算法 在插入、查询和移除键值对时，定位到哈希桶数组的对应位置都是很关键的第一步，只有 HashMap 中的元素尽量分布均匀，才能尽量让数组中的每个位置都只保存一个 Node，避免频繁地去构建和遍历链表或者红黑树，这就需要依靠于一个比较好的哈希算法了\n以下是 HashMap 中计算 key 值的哈希值以及根据哈希值获取其在哈希桶数组中位置的方法\nstatic final int hash(Object key) { int h; //高位参与运算 return (key == null) ? 0 : (h = key.hashCode()) ^ (h \u0026gt;\u0026gt;\u0026gt; 16); } //根据 key 值获取 Value public V get(Object key) { Node\u0026lt;K, V\u0026gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; } //查找指定结点 final Node\u0026lt;K, V\u0026gt; getNode(int hash, Object key) { ··· //只有当 table 不为空且 hash 对应的位置不为 null 才有可获取的元素值 if ((tab = table) != null \u0026amp;\u0026amp; (n = tab.length) \u0026gt; 0 \u0026amp;\u0026amp; (first = tab[(n - 1) \u0026amp; hash]) != null) { ··· } return null; } 可以看到，key 的哈希值是按照 (h = key.hashCode()) ^ (h \u0026gt;\u0026gt;\u0026gt; 16)的算法来得到的，该算法可以拆解为三步：\n通过 key.hashCode() 拿到 key 的 hashCode，即 h 通过 h \u0026raquo;\u0026gt; 16 将 h 的高 16 位迁移到低 16 位，高 16 位全变成 0 将以上两步得到的值进行异或运算，最终得到的结果值的高 16 位和 h 的高 16 位一样，低 16 位即 h的高16位和 h的低16位 的异或运算结果 key 在哈希桶数组的位置索引则是通过 (n - 1) \u0026amp; hash 来计算得到的，n 即哈希桶数组的容量。HashMap 要求哈希桶数组的容量是 2 的幂次方，即要求 n 是 16、32、64、128 这种格式，相对应的 n -1 的二进制位是：\nn 等于 16，n -1 就等于 1111 n 等于 32，n -1 就等于 11111 n 等于 64，n -1 就等于 111111 n 等于 128，n -1 就等于 1111111 可以看出来，不管 hash 值是多少，通过 (n - 1) \u0026amp; hash 计算得到的索引值的大小都不会超出 n 本身，大于等于 0 且小于等于 n - 1，这也符合我们对数组索引值范围的要求。再加上 hash 值的生成规则同时使用到了 hashCode 的高 16 位和低 16 位，在 hashCode 的基础上加大了随机性，使得最终通过 (n - 1) \u0026amp; hash 计算得到的索引值的随机性也比较大，从而使得元素可以比较均匀地分布在哈希桶数组中，减少了哈希冲突的概率\n10、扩容 如果哈希桶数组很大，即使是较差的哈希算法，元素也会比较分散；如果哈希桶数组很小，即使是好的哈希算法也会出现较多哈希碰撞的情况，所以就需要在空间成本和时间成本之间权衡，除了需要设计较好的哈希算法以便减少哈希冲突外，也需要在合适的的时机对哈希桶数组进行扩容\n当 HashMap 中的元素越来越多时，因为数组的容量是固定的，所以哈希冲突的几率也会越来越高，为了提高效率，此时就需要对 HashMap 中的数组进行扩容，而扩容操作最消耗性能的地方就在于：原数组中的数据必须重新计算其在新数组中的位置并迁移到新数组中\n那么 HashMap 扩容操作的触发时机是什么时候呢？当 HashMap 中的元素个数超出 threshold 时（数组容量 与 loadFactor 的乘积），就会进行数组扩容。例如，假设数组当前大小是 16，loadFactor 值是 0.75，那么当 HashMap 中的元素个数达到 12 个时，就会自动触发扩容操作，把数组的大小扩充到 2 * 16 = 32，即扩大一倍，然后重新计算每个元素在新数组中的位置，这是一个非常消耗性能的操作，所以如果已经预知到待存入 HashMap 的数据量，那么在初始化 HashMap 时直接指定初始化大小会是一种更为高效的做法\n默认情况下，哈希数组的容量是 16，loadFactor 是 0.75，这是平衡空间利用率和时间效率两者之后的结果\n初始化数组和扩容数组这两个操作对应的是 resize()方法\nfinal Node\u0026lt;K, V\u0026gt;[] resize() { //扩容前的数组 Node\u0026lt;K, V\u0026gt;[] oldTab = table; //扩容前数组的容量 int oldCap = (oldTab == null) ? 0 : oldTab.length; //当前的扩容临界值 int oldThr = threshold; //扩容后的数组容量和扩容临界值 int newCap, newThr = 0; if (oldCap \u0026gt; 0) { //oldCap \u0026gt; 0 对应的是 table 已被初始化的情况，此时是来判断是否需要进行扩容 //如果数组已达到最大容量，则不再进行扩容，并将扩容临界点 threshold 提升到 Integer.MAX_VALUE，结束 if (oldCap \u0026gt;= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } else if ((newCap = oldCap \u0026lt;\u0026lt; 1) \u0026lt; MAXIMUM_CAPACITY \u0026amp;\u0026amp; oldCap \u0026gt;= DEFAULT_INITIAL_CAPACITY) { //如果将数组的现有容量提升到两倍依然小于 MAXIMUM_CAPACITY，且现有容量大于等于 DEFAULT_INITIAL_CAPACITY //则将数组的容量和扩容临界值均提升为原先的两倍 newThr = oldThr \u0026lt;\u0026lt; 1; } //此处应该还有一种情况 //即将数组的现有容量提升到现在的两倍后大于等于 MAXIMUM_CAPACITY 的情况 //此时 newThr 等于 0，newCap 等于 oldCap 的两倍值 //此处并没有对 newCap 的数值进行还原，说明 HashMap 是允许扩容后容量超出 MAXIMUM_CAPACITY 的 //只是在现有容量超出 MAXIMUM_CAPACITY 后，不允许再次进行扩容 } else if (oldThr \u0026gt; 0) { //oldCap \u0026lt;= 0 \u0026amp;\u0026amp; oldThr \u0026gt; 0 //对应的是 table 还未被初始化，且在调用构造函数时有传入 initialCapacity 或者 Map 的情况 //此时就直接将容量提升为 threshold，在后边重新计算新的扩容临界值 newCap = oldThr; } else { //oldCap \u0026lt;= 0 \u0026amp;\u0026amp; oldThr \u0026lt;= 0 //对应的是 table 还未被初始化，且调用的是无参构造函数 //将 table 的容量扩充到默认大小，并使用默认的装载因子来计算扩容临界值 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int) (DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } if (newThr == 0) { float ft = (float) newCap * loadFactor; //计算扩容后新的扩容临界值 newThr = (newCap \u0026lt; MAXIMUM_CAPACITY \u0026amp;\u0026amp; ft \u0026lt; (float) MAXIMUM_CAPACITY ? (int) ft : Integer.MAX_VALUE); } threshold = newThr; @SuppressWarnings({\u0026#34;rawtypes\u0026#34;, \u0026#34;unchecked\u0026#34;}) Node\u0026lt;K, V\u0026gt;[] newTab = (Node\u0026lt;K, V\u0026gt;[]) new Node[newCap]; table = newTab; //如果旧数组中存在值，则需要将其中的数据复制到新数组中 if (oldTab != null) { for (int j = 0; j \u0026lt; oldCap; ++j) { Node\u0026lt;K, V\u0026gt; e; if ((e = oldTab[j]) != null) { oldTab[j] = null; //e.next == null 说明元素 e 没有产生 hash 冲突，因此可以直接转移该元素 if (e.next == null) //计算元素 e 在新数组中的位置 newTab[e.hash \u0026amp; (newCap - 1)] = e; else if (e instanceof TreeNode) //存在哈希冲突且是用了红黑树 ((TreeNode\u0026lt;K, V\u0026gt;) e).split(this, newTab, j, oldCap); else { //存在哈希冲突且是用了链表 Node\u0026lt;K, V\u0026gt; loHead = null, loTail = null; Node\u0026lt;K, V\u0026gt; hiHead = null, hiTail = null; Node\u0026lt;K, V\u0026gt; next; do { next = e.next; if ((e.hash \u0026amp; oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); if (loTail != null) { loTail.next = null; newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab; } 11、效率测试 这里来测试下不同的初始化大小和不同情况下的 hashCode 值对 HashMap 运行效率的影响\n首先来定义作为键值对 key 的类，hashCode() 方法直接返回其 value 属性\npublic class Key { private int value; public Key(int value) { this.value = value; } @Override public boolean equals(Object o) { if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Key key = (Key) o; return value == key.value; } @Override public int hashCode() { return value; } } 初始化大小从 200 到 20000 之间以 10 倍的倍数递增，向不同 HashMap 存入同等数据量的数据，观察存入数据所需要的时间\npublic class Test { private static final int MAX_KEY = 20000; private static final Key[] KEYS = new Key[MAX_KEY]; static { for (int i = 0; i \u0026lt; MAX_KEY; i++) { KEYS[i] = new Key(i); } } private static void test(int size) { long startTime = System.currentTimeMillis(); Map\u0026lt;Key, Integer\u0026gt; map = new HashMap\u0026lt;\u0026gt;(size); for (int i = 0; i \u0026lt; MAX_KEY; i++) { map.put(KEYS[i], i); } long endTime = System.currentTimeMillis(); System.out.println(\u0026#34;初始化大小是：\u0026#34; + size + \u0026#34;，用时：\u0026#34; + (endTime - startTime) + \u0026#34;毫秒\u0026#34;); } public static void main(String[] args) { for (int i = 20; i \u0026lt;= MAX_KEY; i *= 10) { test(i); } } } 在上述例子中，各个 Key 对象之间的哈希值各不相同，所以键值对在哈希桶数组中的分布可以说是很均匀的了，此时主要影响性能的就是扩容机制了，由日志可以看出此时不同的初始化大小对 HashMap 的性能影响还不大\n初始化大小是：20，用时：4毫秒 初始化大小是：200，用时：3毫秒 初始化大小是：2000，用时：4毫秒 初始化大小是：20000，用时：2毫秒 如果让 Key 类的 hashCode() 方法固定返回 100，那么每个 Key 对象在存在 HashMap 时肯定都会发生哈希冲突\n@Override public int hashCode() { return 100; } 可以看到此时存入同等数据量的数据所需要的时间就呈几何数增长了，说明如果存在大量哈希冲突的话对 HashMap 的影响还是很大的\n初始化大小是：20，用时：2056毫秒 初始化大小是：200，用时：1902毫秒 初始化大小是：2000，用时：1892毫秒 初始化大小是：20000，用时：1865毫秒 二、LinkedHashMap HashMap 并不保证元素的存储顺序和迭代顺序能够和存入顺序保持一致，即 HashMap 本身是无序的。为了解决这一个问题，Java 提供了 LinkedHashMap 来实现有序的 HashMap\n1、类声明 LinkedHashMap 是 HashMap 的子类，它保留了元素的插入顺序，其内部维护着一个按照元素插入顺序或者元素访问顺序来排列的链表，默认是按照元素的插入顺序来排列，就像使用 ArrayList 一样；如果是按照元素的访问顺序来排列，那么每次访问元素后该元素将移至链表的尾部，可以靠此来实现 LRUcache 缓存算法\npublic class LinkedHashMap\u0026lt;K,V\u0026gt; extends HashMap\u0026lt;K,V\u0026gt; implements Map\u0026lt;K,V\u0026gt; 2、结点类 HashMap 中每个存入的键值对都会被包装为 Node 对象，LinkedHashMap 则是包装为 Entry 对象，看 newNode 方法就知道了。Entry 类在 Node 类的基础上扩展了两个新的成员变量：before 和 after，这两个变量就是 LinkedHashMap 来实现有序访问的关键。每当保存了新的键值对，Entry 就会通过这两个变量将其和之前的键值对串联起来，保存为链表的尾结点，从而保留了键值对的顺序信息\n不管 Entry 在 HashMap 内部为了解决哈希冲突采用的是链表还是红黑树，这两个变量的指向都不受数据结构变化的影响。从这也可以看出集合框架在设计时一个很巧妙的地方：LinkedHashMap 内部没有新建一个链表用来维护元素的插入顺序，而是通过扩展父类来实现扩展功能\nstatic class Entry\u0026lt;K,V\u0026gt; extends HashMap.Node\u0026lt;K,V\u0026gt; { //用于指定上一个结点 before 和下一个结点 after Entry\u0026lt;K,V\u0026gt; before, after; Entry(int hash, K key, V value, Node\u0026lt;K,V\u0026gt; next) { super(hash, key, value, next); } } Node\u0026lt;K,V\u0026gt; newNode(int hash, K key, V value, Node\u0026lt;K,V\u0026gt; e) { LinkedHashMap.Entry\u0026lt;K,V\u0026gt; p = new LinkedHashMap.Entry\u0026lt;K,V\u0026gt;(hash, key, value, e); linkNodeLast(p); return p; } /** * The head (eldest) of the doubly linked list. */ transient LinkedHashMap.Entry\u0026lt;K,V\u0026gt; head; /** * The tail (youngest) of the doubly linked list. */ transient LinkedHashMap.Entry\u0026lt;K,V\u0026gt; tail; // link at the end of list private void linkNodeLast(LinkedHashMap.Entry\u0026lt;K,V\u0026gt; p) { LinkedHashMap.Entry\u0026lt;K,V\u0026gt; last = tail; tail = p; if (last == null) head = p; else { p.before = last; last.after = p; } } 3、变量 变量 accessOrder 用于决定 LinkedHashMap 中元素的排序方式，如果为 true 就按照元素访问顺序来排序，为 false 就按照元素插入顺序来排序\n//序列化ID private static final long serialVersionUID = 3801124242820219131L; //指向双向链表的头结点 transient LinkedHashMap.Entry\u0026lt;K,V\u0026gt; head; //指向最新访问的结点 transient LinkedHashMap.Entry\u0026lt;K,V\u0026gt; tail; final boolean accessOrder; 4、构造函数 默认情况下 LinkedHashMap 都是按照元素插入顺序来排序\npublic LinkedHashMap(int initialCapacity, float loadFactor) { super(initialCapacity, loadFactor); accessOrder = false; } public LinkedHashMap(int initialCapacity) { super(initialCapacity); accessOrder = false; } public LinkedHashMap() { super(); accessOrder = false; } public LinkedHashMap(Map\u0026lt;? extends K, ? extends V\u0026gt; m) { super(); accessOrder = false; putMapEntries(m, false); } public LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder) { super(initialCapacity, loadFactor); this.accessOrder = accessOrder; } 5、预留的方法 在 HashMap 中有三个预留的空方法，源码注释中也写明这三个函数就是为 LinkedHashMap 预留的\n// Callbacks to allow LinkedHashMap post-actions void afterNodeAccess(Node\u0026lt;K,V\u0026gt; p) { } void afterNodeInsertion(boolean evict) { } void afterNodeRemoval(Node\u0026lt;K,V\u0026gt; p) { } 当 HashMap 中的某个结点被访问了（例如调用了 get 方法）且 accessOrder 为 true，那么afterNodeAccess 方法就会被调用，该方法用于将最新访问的键值对移至链表的尾部，由于链表内结点位置的改变仅仅是修改几个引用即可，所以这个操作还是非常轻量级的\npublic V get(Object key) { Node\u0026lt;K,V\u0026gt; e; if ((e = getNode(hash(key), key)) == null) return null; if (accessOrder) afterNodeAccess(e); return e.value; } //当访问了结点 e 时调用 //结点 e 是最新访问的一个结点，此时就将结点 e 置为链表的尾结点 void afterNodeAccess(Node\u0026lt;K,V\u0026gt; e) { //last 用来指向链表的尾结点 LinkedHashMap.Entry\u0026lt;K,V\u0026gt; last; //只有当 last 和 e 不相等时才需要进行下一步，如果相等说明 e 已经在链表尾部了 if (accessOrder \u0026amp;\u0026amp; (last = tail) != e) { LinkedHashMap.Entry\u0026lt;K,V\u0026gt; p = (LinkedHashMap.Entry\u0026lt;K,V\u0026gt;)e, b = p.before, a = p.after; //因为结点 p 将成为尾结点，所以 after 置为null p.after = null; //如果 b == null ，说明结点 p 此时是链表的头结点，那 a 就会成为新的头结点 //如果 b != null ，则移除结点 b 对结点 p 的引用并和 a 串联起来 if (b == null) head = a; else b.after = a; //如果 a != null，说明结点 p 此时不是链表的尾结点，则移除结点 a 对结点 p 的引用并和 b 串联起来 //如果 a == null，则说明结点 p 此时是链表的尾结点，那 a 就会成为新的尾结点 if (a != null) a.before = b; else last = b; //如果 last == null，说明原链表为空，则此时头结点就是结点 p //如果 last != null，则 p 就会成为新的尾结点 if (last == null) head = p; else { p.before = last; last.after = p; } //最新一个引用到的结点就是 tail tail = p; ++modCount; } } 当 put 方法被调用时afterNodeInsertion 方法也会被调用，该方法用于判断是否移除最近最少使用的元素，依此可以来构建 LRUcache 缓存\n//在插入元素后调用，此方法可用于 LRUcache 算法中移除最近最少使用的元素 void afterNodeInsertion(boolean evict) { LinkedHashMap.Entry\u0026lt;K,V\u0026gt; first; if (evict \u0026amp;\u0026amp; (first = head) != null \u0026amp;\u0026amp; removeEldestEntry(first)) { K key = first.key; removeNode(hash(key), key, null, false, true); } } //此方法就用于决定是否移除最旧的缓存，默认返回 false //可以通过重写该方法来实现按照特定规则移除旧数据 protected boolean removeEldestEntry(Map.Entry\u0026lt;K,V\u0026gt; eldest) { return false; } 当 HashMap 内部移除了某个结点时，LinkedHashMap 也要通过 afterNodeRemoval 方法将对该结点的引用从维护的链表中移除\n//在移除结点 e 后调用 void afterNodeRemoval(Node\u0026lt;K,V\u0026gt; e) { LinkedHashMap.Entry\u0026lt;K,V\u0026gt; p = (LinkedHashMap.Entry\u0026lt;K,V\u0026gt;)e, b = p.before, a = p.after; //移除结点 p 对相邻结点的引用 p.before = p.after = null; //如果 b == null，说明结点 p 是链表的头结点，则 a 将成为新的头结点 //如果 b != null，则更新结点间的引用 if (b == null) head = a; else b.after = a; //如果 a == null，说明结点 a 是尾结点，则移除结点 p 后最新一个访问的结点就是原倒数第二的结点 //如果 a != null，则更新结点间的引用 if (a == null) tail = b; else a.before = b; } 6、LRUCache 在 Android 端的应用开发中，LRUCache 算法（最近最少使用算法）是很常见的，一种典型的用途就是用来在内存中缓存 Bitmap，因为从 IO 流中读取 Bitmap 的资源消耗较大，为了防止多次从磁盘中读取某张图片，所以通常会在内存中 Bitmap。但内存空间也是有限的，所以也不能每张图片都进行缓存，需要有选择性地缓存一定数量的图片，LRUCache 就是最常见的缓存方案之一\n这里利用 LinkedHashMap 可以按照元素使用顺序进行排列的特点，来实现一个 LRUCache 策略的缓存\npublic class LRUCache { private static class LRUCacheMap\u0026lt;K, V\u0026gt; extends LinkedHashMap\u0026lt;K, V\u0026gt; { //最大的缓存数量 private final int maxCacheSize; public LRUCacheMap(int maxCacheSize) { super(16, 0.75F, true); this.maxCacheSize = maxCacheSize; } @Override protected boolean removeEldestEntry(Map.Entry\u0026lt;K, V\u0026gt; eldest) { return size() \u0026gt; maxCacheSize; } } public static void main(String[] args) { //最大缓存数量是 5 LRUCacheMap\u0026lt;String, Integer\u0026gt; map = new LRUCacheMap\u0026lt;\u0026gt;(5); map.put(\u0026#34;Java\u0026#34;, 1); map.put(\u0026#34;Jetpack\u0026#34;, 2); map.put(\u0026#34;Kotlin\u0026#34;, 3); map.put(\u0026#34;业志陈\u0026#34;, 4); map.put(\u0026#34;字节数组\u0026#34;, 5); map.put(\u0026#34;leaveC\u0026#34;, 6); System.out.println(); Set\u0026lt;String\u0026gt; keySet = map.keySet(); //输出结果是：Jetpack Kotlin 业志陈 字节数组 leaveC keySet.forEach(key -\u0026gt; System.out.print(key + \u0026#34; \u0026#34;)); //获取链表的头结点的值，使之移动到链表尾部 map.get(\u0026#34;Jetpack\u0026#34;); System.out.println(); keySet = map.keySet(); //输出结果是：Kotlin 业志陈 字节数组 leaveC Jetpack keySet.forEach(key -\u0026gt; System.out.print(key + \u0026#34; \u0026#34;)); //向链表添加元素 map.put(\u0026#34;Dart\u0026#34;, 5); System.out.println(); //输出结果是：业志陈 字节数组 leaveC Jetpack Dart keySet.forEach(key -\u0026gt; System.out.print(key + \u0026#34; \u0026#34;)); } } 三、HashSet HashSet 实现了 Set 接口，不允许插入重复的元素，允许包含 null 元素，且不保证元素的迭代顺序，源码十分简单，去掉注释后不到两百行，因为其底层也是通过 HashMap 来实现的，看了上面关于 HashMap 源码的解析后再来看 HashSet 就会有一种“不过如此”的感觉了\n我们知道，当向 HashMap 中插入一个存在相同 key 的键值对时，HashMap 中旧 key 不会被改动到，但旧 value 可能会被新 value 所覆盖，HashSet 就依靠这个特性来实现自身的不可重复性。HashSet 中包含一个 HashMap，向 HashSet 添加的值都会被包装为一个键值对保存到 HashMap 中，key 即外部传入的值，value 则由 HashSet 来提供，当 key 不重复时则正常保存，当 key 重复时则也只会改动到 value，从而实现了 HashSet 元素不重复的特性\n在此就直接贴出源代码了\npublic class HashSet\u0026lt;E\u0026gt; extends AbstractSet\u0026lt;E\u0026gt; implements Set\u0026lt;E\u0026gt;, Cloneable, java.io.Serializable{ static final long serialVersionUID = -5024744406713321676L; //HashSet 底层用 HashMap 来存放数据 //Key 值由外部传入，Value 则由 HashSet 内部来维护 private transient HashMap\u0026lt;E,Object\u0026gt; map; //HashMap 中所有键值对都共享同一个值 //即所有存入 HashMap 的键值对都是使用这个对象作为值 private static final Object PRESENT = new Object(); public HashSet() { map = new HashMap\u0026lt;\u0026gt;(); } //使用默认的装载因子，并以此来计算 HashMap 的初始化大小 //+1 是为了弥补精度损失 public HashSet(Collection\u0026lt;? extends E\u0026gt; c) { map = new HashMap\u0026lt;\u0026gt;(Math.max((int) (c.size()/.75f) + 1, 16)); addAll(c); } public HashSet(int initialCapacity, float loadFactor) { map = new HashMap\u0026lt;\u0026gt;(initialCapacity, loadFactor); } public HashSet(int initialCapacity) { map = new HashMap\u0026lt;\u0026gt;(initialCapacity); } //此构造函数为包访问权限，只用于支持 LinkedHashSet HashSet(int initialCapacity, float loadFactor, boolean dummy) { map = new LinkedHashMap\u0026lt;\u0026gt;(initialCapacity, loadFactor); } //将对 HashSet 的迭代转换为对 HashMap 的 Key 值的迭代 public Iterator\u0026lt;E\u0026gt; iterator() { return map.keySet().iterator(); } public int size() { return map.size(); } public boolean isEmpty() { return map.isEmpty(); } public boolean contains(Object o) { return map.containsKey(o); } //如果 HashMap 中不包含 key 是 e 的键值对，则添加该元素并返回 true //如果包含则只会覆盖 value 而不会影响 key，同时返回 false //从而实现 HashSet key 不重复的特性 public boolean add(E e) { return map.put(e, PRESENT)==null; } public boolean remove(Object o) { return map.remove(o)==PRESENT; } public void clear() { map.clear(); } } 四、LinkedHashSet LinkedHashSet 其内部源码十分简单，简单到只有几十行代码，从其名字就可以猜出它是 HashSet 的子类，并且是依靠链表来实现有序的 HashSet\nHashSet 为 LinkedHashSet 预留了一个构造函数，其 dummy 参数并没有实际意义，只是为了和其它构造函数区分开。其它构造函数会将 map 变量初始化为 HashMap 类型，特意预留的构造函数则是会初始化为 LinkedHashMap 类型变量，从而通过 LinkedHashMap 内部的双向链表来实现 LinkedHashSet 自身存取有序，元素唯一的特性\npublic class HashSet\u0026lt;E\u0026gt; extends AbstractSet\u0026lt;E\u0026gt; implements Set\u0026lt;E\u0026gt;, Cloneable, java.io.Serializable { private transient HashMap\u0026lt;E,Object\u0026gt; map; HashSet(int initialCapacity, float loadFactor, boolean dummy) { map = new LinkedHashMap\u0026lt;\u0026gt;(initialCapacity, loadFactor); } } public class LinkedHashSet\u0026lt;E\u0026gt; extends HashSet\u0026lt;E\u0026gt; implements Set\u0026lt;E\u0026gt;, Cloneable, java.io.Serializable { private static final long serialVersionUID = -2851667679971038690L; public LinkedHashSet(int initialCapacity, float loadFactor) { super(initialCapacity, loadFactor, true); } public LinkedHashSet(int initialCapacity) { super(initialCapacity, .75f, true); } //使用默认的初始容量以及装载因子 public LinkedHashSet() { super(16, .75f, true); } public LinkedHashSet(Collection\u0026lt;? extends E\u0026gt; c) { super(Math.max(2*c.size(), 11), .75f, true); addAll(c); } @Override public Spliterator\u0026lt;E\u0026gt; spliterator() { return Spliterators.spliterator(this, Spliterator.DISTINCT | Spliterator.ORDERED); } } ","permalink":"http://localhost:1313/hugo-blog/public/post/kotlin/java--android-%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6%E9%A1%BB%E7%9F%A5%E9%A1%BB%E4%BC%9A2/","tags":[],"title":"Java \u0026 Android 集合框架须知须会（2）"},{"categories":[],"content":" 公众号：字节数组 希望对你有所帮助 🤣🤣\n本系列文章会陆续对 Java 和 Android 的集合框架（JDK 1.8，Android SDK 30）中的几个常见容器结合源码进行介绍，了解不同容器在数据结构、适用场景、优势点上的不同，希望对你有所帮助 🤣🤣\n本篇文章再来分析下 SparseArray 和 ArrayMap 这两个 Android 系统独有的集合框架类，这两个容器在使用上类似于 HashMap，都是用于存储键值对。由于 Android 系统对于内存比较敏感，所以 SparseArray 和 ArrayMap 在内存使用方面会比较克制，这里就来分析下其实现原理和优势点\n一、SparseArray 使用 Android Studio 的同学可能遇到过一个现象，就是如果在代码中声明了 Map\u0026lt;Integer,Object\u0026gt; 类型变量的话，Android Studio 会提示：Use new SparseArray\u0026lt;Object\u0026gt;(...) instead for better performance ...，即用 SparseArray\u0026lt; Object \u0026gt; 性能更优，可以用来替代 HashMap\n这里就来介绍下 SparseArray 的内部原理，看看它相比 HashMap 有什么性能优势\n1、基本概念 SparseArray 的使用方式：\nSparseArray\u0026lt;String\u0026gt; sparseArray = new SparseArray\u0026lt;\u0026gt;(); sparseArray.put(100,\u0026#34;leavesC\u0026#34;); sparseArray.remove(100); sparseArray.get(100); sparseArray.removeAt(29); SparseArray\u0026lt; E \u0026gt; 相当于 Map\u0026lt; Integer , E \u0026gt; ，key 值固定为 int 类型，在初始化时只需要声明 value 的数据类型即可，其内部用两个数组分别来存储 key 和 value：int[] mKeys ; Object[] mValues\nmKeys 和 mValues 按照如下规则对应起来：\n假设要向 SparseArray 存入 key 为 10，value 为 200 的键值对，则先将 10 存到 mKeys 中，假设 10 在 mKeys 中对应的索引值是 2，则将 value 存入 mValues[2] 中 mKeys 中的元素值按照递增的方法进行存储，每次存放新的键值对时都通过二分查找的方式将 key 插入到 mKeys 中 当要从 SparseArray 取值时，先通过二分查找法找到 key 在 mKeys 中对应的索引，然后根据该索引从 mValues 中取值 从以上可以看出来的一点就是：SparseArray 避免了 HashMap 每次存取值时的装箱拆箱操作，key 值保持为基本数据类型 int，减少了性能开销\n2、类声明 SparseArray 本身并没有直接继承于任何类，内部也没有使用到 Java 原生的集合框架，所以 SparseArray 是 Android 系统自己实现的一个集合容器类\npublic class SparseArray\u0026lt;E\u0026gt; implements Cloneable 3、全局变量 mGarbage 是 SparseArray 的一个优化点之一，用于标记当前是否有需要垃圾回收(GC)的元素，当该值被置为 true 时，意味着当前存在无效元素，需要进行垃圾回收，但回收操作并不会马上进行，而是在后续操作中再统一进行\n//键值对被移除后对应的 value 会变成此值，用来当做 GC 标记位 private static final Object DELETED = new Object(); //用于标记当前是否有待垃圾回收(GC)的元素 private boolean mGarbage = false; private int[] mKeys; private Object[] mValues; //当前集合元素的数量 //该值并不一定是时时处于正确状态，因为有可能出现只删除 key 和 value 两者之一的情况 //所以 size() 方法内都会先进行 GC private int mSize; 4、构造函数 key 数组和 value 数组的默认大小都是 10，如果在初始化时已知最终数据量的大小，则可以直接指定初始容量，这样可以避免后续的扩容操作\n//设置数组的默认初始容量为10 public SparseArray() { this(10); } public SparseArray(int initialCapacity) { if (initialCapacity == 0) { mKeys = EmptyArray.INT; mValues = EmptyArray.OBJECT; } else { mValues = ArrayUtils.newUnpaddedObjectArray(initialCapacity); mKeys = new int[mValues.length]; } mSize = 0; } 5、添加元素 添加元素的方法有几个，主要看 put(int key, E value) 方法就可以，该方法用于存入 key 和 value 组成的键值对\n按照前面所说的 SparseArray 存储键值对的规则，put 方法会先判断当前 mKeys 中是否已经有相同的 key 值，有的话就用 value 覆盖 mValues 中的旧值。如果不存在相同 key 值，在将 key 插入到 mKeys 后需要在 mValues 的相同索引位置插入 value。由于 mKeys 是按照大小对元素值进行排序存储的，所以将 key 插入到 mKeys 可能会导致元素重新排序，从而连锁导致 mValues 也需要重新排序\nput 方法从 mKeys 查找 key 用的是 ContainerHelpers 类提供的二分查找方法：binarySearch，用于获取 key 在 mKeys 中的当前索引（存在该 key 的话）或者是应该存放的位置的索引（不存在该 key），方法的返回值可以分为三种情况：\n如果 mKeys 中存在对应的 key，则直接返回对应的索引值 如果 mKeys 中不存在对应的 key 假设 mKeys 中存在\u0026quot;值比 key 大且大小与 key 最接近的值的索引\u0026quot;为 presentIndex，则此方法的返回值为 ~presentIndex 如果 mKeys 中不存在比 key 还要大的值的话，则返回值为 ~mKeys.length // This is Arrays.binarySearch(), but doesn\u0026#39;t do any argument validation. static int binarySearch(int[] array, int size, int value) { int lo = 0; int hi = size - 1; while (lo \u0026lt;= hi) { final int mid = (lo + hi) \u0026gt;\u0026gt;\u0026gt; 1; final int midVal = array[mid]; if (midVal \u0026lt; value) { lo = mid + 1; } else if (midVal \u0026gt; value) { hi = mid - 1; } else { return mid; // value found } } return ~lo; // value not present } 可以看到，如果 mKeys 存在目标 key，那么返回值即对应的索引位置。如果不存在目标 key，其返回值也指向了应该让 key 存入的位置，因为当不存在目标 key 时，将计算出的索引值进行 ~ 运算后返回值一定是负数，从而与“找得到目标 key 的情况（返回值大于等于0）”的情况区分开。从这里可以看出该方法的巧妙之处，单纯的一个返回值就可以区分出多种情况，且通过这种方式来存放数据可以使得 mKeys 的内部值一直是按照值递增的方式来排序的\n再来具体看看 put 方法的逻辑\npublic void put(int key, E value) { //用二分查找法查找指定 key 在 mKeys 中的索引值 int i = ContainerHelpers.binarySearch(mKeys, mSize, key); if (i \u0026gt;= 0) { //对应已经存在相同 key 的情况 mValues[i] = value; } else { //取反，拿到真实的索引位置 i = ~i; //如果目标位置还未赋值，则直接存入数据即可 if (i \u0026lt; mSize \u0026amp;\u0026amp; mValues[i] == DELETED) { mKeys[i] = key; mValues[i] = value; return; } //如果存在冗余数据，那么就先进行 GC if (mGarbage \u0026amp;\u0026amp; mSize \u0026gt;= mKeys.length) { gc(); //GC 后再次进行查找，因为值可能已经发生变化了 i = ~ContainerHelpers.binarySearch(mKeys, mSize, key); } //索引 i 位置已经用于存储其它数据了，此时就需要对数组元素进行迁移 //所以从索引 i 开始的所有数据都需要向后移动一位，并将 key 存到 mKeys[i] mKeys = GrowingArrayUtils.insert(mKeys, mSize, i, key); mValues = GrowingArrayUtils.insert(mValues, mSize, i, value); mSize++; } } //将索引 index 处的元素赋值为 value //知道目标位置的话可以直接向 mValues 赋值 public void setValueAt(int index, E value) { if (index \u0026gt;= mSize \u0026amp;\u0026amp; UtilConfig.sThrowExceptionForUpperArrayOutOfBounds) { // The array might be slightly bigger than mSize, in which case, indexing won\u0026#39;t fail. // Check if exception should be thrown outside of the critical path. throw new ArrayIndexOutOfBoundsException(index); } //如果需要则先进行垃圾回收 if (mGarbage) { gc(); } mValues[index] = value; } //和 put 方法类似 //但在存入数据前先对数据大小进行了判断，有利于减少对 mKeys 进行二分查找的次数 //所以在“存入的 key 比现有的 mKeys 值都大”的情况下会比 put 方法性能高 public void append(int key, E value) { if (mSize != 0 \u0026amp;\u0026amp; key \u0026lt;= mKeys[mSize - 1]) { put(key, value); return; } if (mGarbage \u0026amp;\u0026amp; mSize \u0026gt;= mKeys.length) { gc(); } mKeys = GrowingArrayUtils.append(mKeys, mSize, key); mValues = GrowingArrayUtils.append(mValues, mSize, value); mSize++; } 6、移除元素 上文说了，布尔变量 mGarbage 用于标记当前是否有待垃圾回收(GC)的元素，当该值被置为 true 时，即意味着当前状态需要进行垃圾回收，但回收操作并不马上进行，而是在后续操作中再完成\n以下几个方法在移除元素时，都只是切断了 mValues 对 value 的引用，而 mKeys 并没有进行回收，这个操作会留到 gc() 进行处理\npublic void delete(int key) { //用二分查找法查找指定 key 在 mKeys 中的索引值 int i = ContainerHelpers.binarySearch(mKeys, mSize, key); if (i \u0026gt;= 0) { if (mValues[i] != DELETED) { mValues[i] = DELETED; //标记当前需要进行垃圾回收 mGarbage = true; } } } public void remove(int key) { delete(key); } //和 delete 方法基本相同，差别在于会返回 key 对应的元素值 public E removeReturnOld(int key) { int i = ContainerHelpers.binarySearch(mKeys, mSize, key); if (i \u0026gt;= 0) { if (mValues[i] != DELETED) { final E old = (E) mValues[i]; mValues[i] = DELETED; mGarbage = true; return old; } } return null; } //删除指定索引对应的元素值 public void removeAt(int index) { if (index \u0026gt;= mSize \u0026amp;\u0026amp; UtilConfig.sThrowExceptionForUpperArrayOutOfBounds) { // The array might be slightly bigger than mSize, in which case, indexing won\u0026#39;t fail. // Check if exception should be thrown outside of the critical path. throw new ArrayIndexOutOfBoundsException(index); } if (mValues[index] != DELETED) { mValues[index] = DELETED; //标记当前需要进行垃圾回收 mGarbage = true; } } //删除从起始索引值 index 开始之后的 size 个元素值 public void removeAtRange(int index, int size) { //避免发生数组越界的情况 final int end = Math.min(mSize, index + size); for (int i = index; i \u0026lt; end; i++) { removeAt(i); } } //移除所有元素值 public void clear() { int n = mSize; Object[] values = mValues; for (int i = 0; i \u0026lt; n; i++) { values[i] = null; } mSize = 0; mGarbage = false; } 7、查找元素 查找元素的方法较多，逻辑都挺简单的\n//根据 key 查找相应的元素值，查找不到则返回默认值 @SuppressWarnings(\u0026#34;unchecked\u0026#34;) public E get(int key, E valueIfKeyNotFound) { //用二分查找法查找指定 key 在 mKeys 中的索引值 int i = ContainerHelpers.binarySearch(mKeys, mSize, key); //如果找不到该 key 或者该 key 尚未赋值，则返回默认值 if (i \u0026lt; 0 || mValues[i] == DELETED) { return valueIfKeyNotFound; } else { return (E) mValues[i]; } } //根据 key 查找相应的元素值，查找不到则返回 null public E get(int key) { return get(key, null); } //因为 mValues 中的元素值并非一定是连贯的，有可能掺杂着 DELETED //所以在遍历前需要先进行 GC，这样通过数组取出的值才是正确的 @SuppressWarnings(\u0026#34;unchecked\u0026#34;) public E valueAt(int index) { if (mGarbage) { gc(); } return (E) mValues[index]; } //根据索引值 index 查找对应的 key public int keyAt(int index) { if (mGarbage) { gc(); } return mKeys[index]; } //根据 key 对应的索引值 public int indexOfKey(int key) { if (mGarbage) { gc(); } return ContainerHelpers.binarySearch(mKeys, mSize, key); } //根据 value 查找对应的索引值 public int indexOfValue(E value) { if (mGarbage) { gc(); } for (int i = 0; i \u0026lt; mSize; i++) { if (mValues[i] == value) { return i; } } return -1; } //与 indexOfValue 方法类似，但 indexOfValue 方法是通过比较 == 来判断是否同个对象 //而此方法是通过 equals 方法来判断是否同个对象 public int indexOfValueByValue(E value) { if (mGarbage) { gc(); } for (int i = 0; i \u0026lt; mSize; i++) { if (value == null) { if (mValues[i] == null) { return i; } } else { if (value.equals(mValues[i])) { return i; } } } return -1; } 8、垃圾回收 因为 SparseArray 中会出现只移除 key 和 value 两者之一的情况，导致当前数组中的有效数据并不是全都紧挨着排列在一起的，即存在无效值，因此 gc() 方法会根据 mValues 中到底存在多少有效数据，将 mKeys 和 mValues 中的数据进行重新排列，将有意义的元素值紧挨着排序在一起\nprivate void gc() { int n = mSize; int o = 0; int[] keys = mKeys; Object[] values = mValues; for (int i = 0; i \u0026lt; n; i++) { Object val = values[i]; //val 非 DELETED ，说明该位置可能需要移动数据 if (val != DELETED) { //将索引 i 处的值赋值到索引 o 处 //所以如果 i == o ，则不需要执行代码了 if (i != o) { keys[o] = keys[i]; values[o] = val; values[i] = null; } o++; } } mGarbage = false; mSize = o; } 9、优劣势总结 从上文的介绍来看，SparseArray 的主要优势有以下几点：\n避免了基本数据类型 int 的装箱拆箱操作 和 HashMap 中每个存储结点都是一个类对象不同，SparseArray 不需要用于包装 key 的结构体，单个元素的存储成本更加低廉 在数据量不大的情况下，查找效率较高（二分查找法） 延迟了垃圾回收的时机，只在需要的时候才一次性进行 劣势有以下几点：\n具有特定的适用范围，key 只能是 int 类型 插入键值对时可能需要移动大量的数组元素 数据量较大时，查找效率（二分查找法）会明显降低，需要经过多次折半查找才能定位到目标数据。而 HashMap 在没有哈希冲突的情况下只需要进行一次哈希计算即可定位到目标元素，有哈希冲突时也只需要对比链表或者红黑树上的元素即可 10、关联类 SparseArray 属于泛型类，所以即使 value 是基本数据类型也会被装箱和拆箱，如果想再省去这一部分开销的话，可以使用 SparseBooleanArray、SparseIntArray 和 SparseLongArray 等三个容器类，这三个容器的实现原理和 SparseArray 相同，但是 value 还是属于基本数据类型\n此外，系统还提供了 LongSparseArray 这个容器类，其实现原理和 SparseArray 类似，但是 key 固定为 long 类型，value 通过泛型来声明，对于日常开发中比较有用的一点是可以用来根据 viewId 来存储 view 对象\n二、ArrayMap ArrayMap 属于泛型类，继承了 Map 接口，其使用方式和 HashMap 基本一样，但在内部逻辑上有着很大差异，所以需要了解其实现原理后才能明白 ArrayMap 到底适用于哪些场景\npublic final class ArrayMap\u0026lt;K, V\u0026gt; implements Map\u0026lt;K, V\u0026gt; 1、存储机制 ArrayMap 中包含以下两个数组。mHashes 用于存储键值对中 key 的哈希值，mArray 则用于存储 key 和 value，即每个键值对会一起被存入 mArray 中\n// Hashes are an implementation detail. Use public key/value API. int[] mHashes; // Storage is an implementation detail. Use public key/value API. Object[] mArray; 当向 ArrayMap 插入键值对时，会先计算出 key 的哈希值，将 keyHash 按照大小顺序存入 mHashes 中，拿到其位置索引 index。然后将 key 存入 mArray 的 index\u0026laquo;1 位置，将 value 存入 mArray 的 (index\u0026laquo;1 + 1) 位置，即 key 和 value 会存储在相邻的位置。从这个位置对应关系来看，mArray 的所需容量至少也需要是 mHashes 的两倍，且每个 key-value 的排列关系也是和 keyHash 的排列保持一致\n当要通过 key 对象向 ArrayMap 取值时，就先计算出 keyHash，然后通过二分查找法找到 keyHash 在 mHashes 中的位置索引 index，然后在 (index\u0026laquo;1 + 1)位置从 mArray 拿到 value\n2、添加元素 有几个用于添加元素的方法，当中重点看 put 方法即可，其它添加元素的方法都需要依靠该方法来实现。前文有讲到，key-value 最终是会相邻着存入 mArray 中的，而 key-value 在 mArray 中的位置是由 keyHash 和 mHashes 来共同决定的，put 方法的整体逻辑如下所述：\n根据二分查找法获取到 keyHash 在 mHashes 中的索引位置 index 如果 index 大于等于 0，说明在 mArray 中 key 已存在，那么直接覆盖旧值即可，结束流程 如果 index 小于 0，说明在 mArray 中 key 不存在，~index 此时代表的是 keyHash 按照递增顺序应该插入 mHashes 的位置 判断是否需要扩容，需要的话则进行扩容。如果符合缓存标准的话，则会缓存扩容前的数组 对最终的数组进行数据迁移，插入 key-value 和 keyHash @Override public V put(K key, V value) { final int osize = mSize; final int hash; int index; //第一步 if (key == null) { hash = 0; index = indexOfNull(); } else { hash = mIdentityHashCode ? System.identityHashCode(key) : key.hashCode(); index = indexOf(key, hash); } //第二步 if (index \u0026gt;= 0) { index = (index\u0026lt;\u0026lt;1) + 1; final V old = (V)mArray[index]; mArray[index] = value; return old; } //第三步 index = ~index; //第四步 if (osize \u0026gt;= mHashes.length) { //ArrayMap 的扩容机制相比 HashMap 会比较克制 //当数组长度已超出 BASE_SIZE*2 后，数组容量按照 1.5 倍来扩容 final int n = osize \u0026gt;= (BASE_SIZE*2) ? (osize+(osize\u0026gt;\u0026gt;1)) : (osize \u0026gt;= BASE_SIZE ? (BASE_SIZE*2) : BASE_SIZE); if (DEBUG) Log.d(TAG, \u0026#34;put: grow from \u0026#34; + mHashes.length + \u0026#34; to \u0026#34; + n); final int[] ohashes = mHashes; final Object[] oarray = mArray; allocArrays(n); if (CONCURRENT_MODIFICATION_EXCEPTIONS \u0026amp;\u0026amp; osize != mSize) { throw new ConcurrentModificationException(); } if (mHashes.length \u0026gt; 0) { if (DEBUG) Log.d(TAG, \u0026#34;put: copy 0-\u0026#34; + osize + \u0026#34; to 0\u0026#34;); System.arraycopy(ohashes, 0, mHashes, 0, ohashes.length); System.arraycopy(oarray, 0, mArray, 0, oarray.length); } freeArrays(ohashes, oarray, osize); } //第五步 if (index \u0026lt; osize) { if (DEBUG) Log.d(TAG, \u0026#34;put: move \u0026#34; + index + \u0026#34;-\u0026#34; + (osize-index) + \u0026#34; to \u0026#34; + (index+1)); System.arraycopy(mHashes, index, mHashes, index + 1, osize - index); System.arraycopy(mArray, index \u0026lt;\u0026lt; 1, mArray, (index + 1) \u0026lt;\u0026lt; 1, (mSize - index) \u0026lt;\u0026lt; 1); } if (CONCURRENT_MODIFICATION_EXCEPTIONS) { if (osize != mSize || index \u0026gt;= mHashes.length) { throw new ConcurrentModificationException(); } } mHashes[index] = hash; mArray[index\u0026lt;\u0026lt;1] = key; mArray[(index\u0026lt;\u0026lt;1)+1] = value; mSize++; return null; } append 方法也是用于添加元素的，带有一点“追加”的意思，如果外部可以确定本次插入的 key 的 hash 值比当前所有已有值都大的话，那么就可以直接向 mHashes 的尾部插入数据，从而节省了二分查找的过程。所以 append 方法会先和 mHashes 的最后一个元素值进行对比，如果 keyHash 比该值大的话就说明可以直接保存到尾部，校验不通过的话还是会调用 put 方法\npublic void append(K key, V value) { int index = mSize; final int hash = key == null ? 0 : (mIdentityHashCode ? System.identityHashCode(key) : key.hashCode()); if (index \u0026gt;= mHashes.length) { throw new IllegalStateException(\u0026#34;Array is full\u0026#34;); } //如果 mHashes 当前的最后一个值比 hash 大，hash 没法直接插到尾部，那么就还是需要调用 put 方法 if (index \u0026gt; 0 \u0026amp;\u0026amp; mHashes[index-1] \u0026gt; hash) { RuntimeException e = new RuntimeException(\u0026#34;here\u0026#34;); e.fillInStackTrace(); Log.w(TAG, \u0026#34;New hash \u0026#34; + hash + \u0026#34; is before end of array hash \u0026#34; + mHashes[index-1] + \u0026#34; at index \u0026#34; + index + \u0026#34; key \u0026#34; + key, e); put(key, value); return; } //将 key-value 直接插入到数组尾部 mSize = index+1; mHashes[index] = hash; index \u0026lt;\u0026lt;= 1; mArray[index] = key; mArray[index+1] = value; } 3、获取元素 获取元素的方法主要看 indexOf(Object key, int hash)方法即可，只要理解了该方法是如何获取 keyIndex 的，那么就能够对 ArrayMap 的存储结构有更明确的认知\nindexOf 方法用于获取和 key，hash 均能对应上的元素的哈希值在 mHashes 中的索引位置。我们知道，keyHash 是存储在 mHashes 中的，而 key-value 又是存储在 mArray 中的，但我们无法只根据 keyHash 就准确对应上 key-value，因为不同的 key 有可能有相同的 hash 值，即需要考虑哈希冲突的情况，所以 indexOf 方法除了需要对比 hash 值大小是否相等外还需要对比 key 的相等性\n通过二分查找法获取到 mHashes 中和 hash 相等的值的索引 index 如果 index 小于 0，说明不存在该 key，那么就返回 index，~index 就是 hash 插入 mHashes 后的位置索引。结束流程 index 大于等于 0，说明 key 有可能存在，之所以说可能，因为存在 key 不同但 hash 值相等的情况 判断 mArray 中 index\u0026laquo;1 位置的元素是否和 key 相等，如果相等说明已经找到了目标位置，返回 index。结束流程 此时可以确定发生了哈希冲突，那么就需要对 mArray 进行相等性对比了，而之所以要分为两个 for 循环也是为了减少遍历次数，因为相同 hash 值是会靠拢在一起的，所以分别向两侧进行遍历查找。如果 key 和 keyHash 的相等性均校验通过，那么就返回对应的索引。结束流程 会执行到这里，说明还是没有找到和 key 相等的元素值，那么就拿到 hash 应该存入 mHashes 后的索引，~ 运算后返回 int indexOf(Object key, int hash) { final int N = mSize; // Important fast case: if nothing is in here, nothing to look for. if (N == 0) { return ~0; } //第一步 int index = binarySearchHashes(mHashes, N, hash); // If the hash code wasn\u0026#39;t found, then we have no entry for this key. //第二步 if (index \u0026lt; 0) { return index; } // If the key at the returned index matches, that\u0026#39;s what we want. //第四步 if (key.equals(mArray[index\u0026lt;\u0026lt;1])) { return index; } //第五步 // Search for a matching key after the index. int end; for (end = index + 1; end \u0026lt; N \u0026amp;\u0026amp; mHashes[end] == hash; end++) { if (key.equals(mArray[end \u0026lt;\u0026lt; 1])) return end; } // Search for a matching key before the index. for (int i = index - 1; i \u0026gt;= 0 \u0026amp;\u0026amp; mHashes[i] == hash; i--) { if (key.equals(mArray[i \u0026lt;\u0026lt; 1])) return i; } // Key not found -- return negative value indicating where a // new entry for this key should go. We use the end of the // hash chain to reduce the number of array entries that will // need to be copied when inserting. //第六步 return ~end; } 4、缓存机制 ArrayMap 内部包含了对 mHashes 和 mArray 这两个数组进行缓存的机制，避免由于频繁创建数组而造成内存抖动，这一点还是比较有意义的。在 Android 系统中 Bundle 是使用得很频繁的一个类，其内部就通过 ArrayMap 来存储键值对，这可以从 Bundle 的父类 BaseBundle 看到。所以 ArrayMap 的数组缓存机制在我看来更多的是面对系统运行时的优化措施\npublic class BaseBundle { @UnsupportedAppUsage ArrayMap\u0026lt;String, Object\u0026gt; mMap = null; public void putBoolean(@Nullable String key, boolean value) { unparcel(); mMap.put(key, value); } void putByte(@Nullable String key, byte value) { unparcel(); mMap.put(key, value); } void putChar(@Nullable String key, char value) { unparcel(); mMap.put(key, value); } ··· } put 方法内部就使用到了数组的缓存和复用机制\n@Override public V put(K key, V value) { ··· if (osize \u0026gt;= mHashes.length) { final int n = osize \u0026gt;= (BASE_SIZE*2) ? (osize+(osize\u0026gt;\u0026gt;1)) : (osize \u0026gt;= BASE_SIZE ? (BASE_SIZE*2) : BASE_SIZE); if (DEBUG) Log.d(TAG, \u0026#34;put: grow from \u0026#34; + mHashes.length + \u0026#34; to \u0026#34; + n); final int[] ohashes = mHashes; final Object[] oarray = mArray; //尝试通过数组复用机制来初始化 mHashes 和 mArray allocArrays(n); if (CONCURRENT_MODIFICATION_EXCEPTIONS \u0026amp;\u0026amp; osize != mSize) { throw new ConcurrentModificationException(); } if (mHashes.length \u0026gt; 0) { if (DEBUG) Log.d(TAG, \u0026#34;put: copy 0-\u0026#34; + osize + \u0026#34; to 0\u0026#34;); System.arraycopy(ohashes, 0, mHashes, 0, ohashes.length); System.arraycopy(oarray, 0, mArray, 0, oarray.length); } //尝试回收 ohashes 和 oarray freeArrays(ohashes, oarray, osize); } ··· return null; } 缓存数组 实现数组缓存逻辑对应的是 freeArrays 方法，该方法就用于缓存 mHashes 和 mArray。每当 ArrayMap 完成数组扩容后就会调用此方法对扩容前的数组进行缓存，但也不是所有数组都会进行缓存，而是有着数组长度和缓存总数这两方面的限制\n首先，ArrayMap 包含了多个全局的静态变量和静态常量用于控制及实现数组缓存。从freeArrays方法可以看出来，if 和 else 语句块的逻辑是基本完全一样的，其区别只在于触发缓存的条件和使用的缓存池不一样\n例如，如果 hashes 的数组长度是 BASE_SIZE * 2，且当前缓存总数没有超出 CACHE_SIZE，那么缓存的数组就保存在 mTwiceBaseCache 所构造的的单向链表中。mTwiceBaseCache 采用单向链表的结构来串联多个数组，要缓存的 mArray 的第一个数组元素值会先指向 mTwiceBaseCache，第二个数组元素值会指向 mHashes，之后 mArray 会成为单向链表的新的头结点，即 mArray 成为了新的 mTwiceBaseCache。在这种缓存机制下，最终 mTwiceBaseCache 指向的其实是本次缓存的 mArray，mArray 的第一个元素值指向的又是上一次缓存的 mArray，第二个元素值指向的是本次缓存的 mHashes，从而形成了一个单向链表结构\n//用于缓存长度为 BASE_SIZE 的数组 static Object[] mBaseCache; //mBaseCache 已缓存的数组个数 static int mBaseCacheSize; //用于缓存长度为 BASE_SIZE * 2 的数组 static Object[] mTwiceBaseCache; //mTwiceBaseCache 已缓存的数组个数 static int mTwiceBaseCacheSize; private static final int BASE_SIZE = 4; //mBaseCacheSize 和 mTwiceBaseCacheSize 的最大缓存个数 private static final int CACHE_SIZE = 10; //用来当做同步锁 private static final Object sBaseCacheLock = new Object(); private static final Object sTwiceBaseCacheLock = new Object(); //缓存 hashes 和 array private static void freeArrays(final int[] hashes, final Object[] array, final int size) { if (hashes.length == (BASE_SIZE*2)) { synchronized (sTwiceBaseCacheLock) { if (mTwiceBaseCacheSize \u0026lt; CACHE_SIZE) { //第一个元素指向 mTwiceBaseCache array[0] = mTwiceBaseCache; //第二个元素指向 hashes array[1] = hashes; for (int i=(size\u0026lt;\u0026lt;1)-1; i\u0026gt;=2; i--) { //切除多余引用，避免内存泄漏，有利于 GC array[i] = null; } //array 成为单链表的头结点 mTwiceBaseCache = array; mTwiceBaseCacheSize++; if (DEBUG) Log.d(TAG, \u0026#34;Storing 2x cache \u0026#34; + array + \u0026#34; now have \u0026#34; + mTwiceBaseCacheSize + \u0026#34; entries\u0026#34;); } } } else if (hashes.length == BASE_SIZE) { synchronized (sBaseCacheLock) { if (mBaseCacheSize \u0026lt; CACHE_SIZE) { array[0] = mBaseCache; array[1] = hashes; for (int i=(size\u0026lt;\u0026lt;1)-1; i\u0026gt;=2; i--) { array[i] = null; } mBaseCache = array; mBaseCacheSize++; if (DEBUG) Log.d(TAG, \u0026#34;Storing 1x cache \u0026#34; + array + \u0026#34; now have \u0026#34; + mBaseCacheSize + \u0026#34; entries\u0026#34;); } } } } 复用数组 缓存数组的目的自然就是为了后续复用，数组的复用逻辑对应的是 allocArrays 方法，该方法用于为 mHashes 和 mArray 申请一个更大容量的数组空间，通过复用数组或者全新初始化来获得\n在进行数组缓存的时候会判断数组长度，只有当长度是 BASE_SIZE * 2 或 BASE_SIZE 时才会进行缓存，那么自然只有当数组的目标长度 size 是这两个值之一才符合复用条件了。allocArrays 方法取出缓存的逻辑也很简单，只需要取出单向链表的头结点赋值给 mHashes 和 mArray，同时使链表的第二个结点成为新的头结点即可。如果不符合复用条件或者复用失败，那么就还是需要重新构建两个新的数组对象\n//用于缓存长度为 BASE_SIZE 的数组 static Object[] mBaseCache; //mBaseCache 已缓存的数组个数 static int mBaseCacheSize; //用于缓存长度为 BASE_SIZE * 2 的数组 static Object[] mTwiceBaseCache; //mTwiceBaseCache 已缓存的数组个数 static int mTwiceBaseCacheSize; private static final int BASE_SIZE = 4; //mBaseCacheSize 和 mTwiceBaseCacheSize 的最大缓存个数 private static final int CACHE_SIZE = 10; //用来当做同步锁 private static final Object sBaseCacheLock = new Object(); private static final Object sTwiceBaseCacheLock = new Object(); private void allocArrays(final int size) { if (mHashes == EMPTY_IMMUTABLE_INTS) { throw new UnsupportedOperationException(\u0026#34;ArrayMap is immutable\u0026#34;); } if (size == (BASE_SIZE*2)) { synchronized (sTwiceBaseCacheLock) { if (mTwiceBaseCache != null) { final Object[] array = mTwiceBaseCache; mArray = array; try { //指向头结点的下一个结点，即原先的第二个结点将成为链表新的头结点 mTwiceBaseCache = (Object[]) array[0]; mHashes = (int[]) array[1]; if (mHashes != null) { //符合复用条件，切除多余引用 array[0] = array[1] = null; mTwiceBaseCacheSize--; if (DEBUG) { Log.d(TAG, \u0026#34;Retrieving 2x cache \u0026#34; + mHashes + \u0026#34; now have \u0026#34; + mTwiceBaseCacheSize + \u0026#34; entries\u0026#34;); } return; } } catch (ClassCastException e) { } // Whoops! Someone trampled the array (probably due to not protecting // their access with a lock). Our cache is corrupt; report and give up. Slog.wtf(TAG, \u0026#34;Found corrupt ArrayMap cache: [0]=\u0026#34; + array[0] + \u0026#34; [1]=\u0026#34; + array[1]); //会执行到这里，说明缓存机制发现问题，则弃用之前的所有缓存 mTwiceBaseCache = null; mTwiceBaseCacheSize = 0; } } } else if (size == BASE_SIZE) { synchronized (sBaseCacheLock) { if (mBaseCache != null) { final Object[] array = mBaseCache; mArray = array; try { mBaseCache = (Object[]) array[0]; mHashes = (int[]) array[1]; if (mHashes != null) { array[0] = array[1] = null; mBaseCacheSize--; if (DEBUG) { Log.d(TAG, \u0026#34;Retrieving 1x cache \u0026#34; + mHashes + \u0026#34; now have \u0026#34; + mBaseCacheSize + \u0026#34; entries\u0026#34;); } return; } } catch (ClassCastException e) { } // Whoops! Someone trampled the array (probably due to not protecting // their access with a lock). Our cache is corrupt; report and give up. Slog.wtf(TAG, \u0026#34;Found corrupt ArrayMap cache: [0]=\u0026#34; + array[0] + \u0026#34; [1]=\u0026#34; + array[1]); mBaseCache = null; mBaseCacheSize = 0; } } } mHashes = new int[size]; mArray = new Object[size\u0026lt;\u0026lt;1]; } 总结 上文说了，只有长度为 BASE_SIZE 或者 BASE_SIZE * 2 的数组才会被缓存复用，而 mHashes 和 mArray 的扩容操作也会尽量使得扩容后的数组长度就是这两个值之一，这可以从 put 方法计算扩容后容量的算法看出来\n@Override public V put(K key, V value) { final int osize = mSize; final int hash; ··· if (osize \u0026gt;= mHashes.length) { //计算数组扩容后的大小 final int n = osize \u0026gt;= (BASE_SIZE*2) ? (osize+(osize\u0026gt;\u0026gt;1)) : (osize \u0026gt;= BASE_SIZE ? (BASE_SIZE*2) : BASE_SIZE); if (DEBUG) Log.d(TAG, \u0026#34;put: grow from \u0026#34; + mHashes.length + \u0026#34; to \u0026#34; + n); final int[] ohashes = mHashes; final Object[] oarray = mArray; allocArrays(n); ··· freeArrays(ohashes, oarray, osize); } ··· return null; } 所以说，虽然 ArrayMap 的构造函数中并没有直接将 BASE_SIZE 作为数组的默认长度，但是在扩容过程中会尽量往 BASE_SIZE 和 BASE_SIZE * 2 这两个值靠拢，这就有利于尽量实现数组复用\n此外，ArrayMap 的扩容操作在申请内存时也显得比较克制，在数组长度超出 BASE_SIZE * 2 后，只是扩容到当前的 1.5 倍，且也只在 mHashes 容量不足时才会触发扩容机制。而 HashMap 在达到负载因子设定的比例后（此时数组未满）就会触发扩容机制，而且也是按照扩充到两倍容量的方式进行扩容。所以说，ArrayMap 对于内存空间的利用效率会更高一些\n5、优劣势总结 ArrayMap 的适用场景可以从它的缓存机制就看出来一些，它会缓存容量为 4 或者 8 的数组并进行后续复用，而这两个值可以说都是比较小的。Android 系统对于内存比较敏感，需要存储键值对时面对的往往是使用频率高但数据量小的场景。例如我们在跳转到 Activity 时往往是通过 Bundle 来存储跳转参数，但数据量一般都很少，所以 Bundle 内部就使用到了 ArrayMap 来存储键值对。ArrayMap 在内存申请时相比 HashMap 会比较克制，键值对会以更加紧密的数据结构存储在一起，对内存利用率会更高一些\n而相对的，ArrayMap 的这种存储结构也导致了其查找效率相比 HashMap 要低很多。在数据量大时，ArrayMap 可能需要通过多次二分查找才能定位到元素，而 HashMap 在没有哈希冲突的情况下只需要经过一次哈希计算即可定位到元素，即使有哈希冲突也只需要遍历发生冲突的部分元素即可\n所以说， ArrayMap 适用于数据量较小的场景，此时查找效率也不会受多大影响，而内存利用率能够显著提高。如果数据量较大，那就可以考虑使用 HashMap 来替代了\n6、关联类 系统还包含了一个用于存储不重复元素值的集合框架类：ArraySet，从名字就可以猜到 ArraySet 实现了 Set 接口。ArraySet 内部一样使用两个数组来存储 hash 和 value，即 mHashes 和 mArray，在实现逻辑上基本和 ArrayMap 一样，只是会在存值的时候判断 value 是否重复而已，这里就不再赘述了\n","permalink":"http://localhost:1313/hugo-blog/public/post/kotlin/java--android-%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6%E9%A1%BB%E7%9F%A5%E9%A1%BB%E4%BC%9A3/","tags":[],"title":"Java \u0026 Android 集合框架须知须会（3）"},{"categories":[],"content":" 公众号：字节数组 希望对你有所帮助 🤣🤣\n目前，多线程编程可以说是在大部分平台和应用上都需要实现的一个基本需求。本系列文章就来对 Java 平台下的多线程编程知识进行讲解，从概念入门、底层实现到上层应用都会涉及到，预计一共会有五篇文章，希望对你有所帮助 😎😎\n本篇文章是第一篇，先来介绍下 Java 多线程的基础概念以及需要面对的挑战，是后续文章的敲门砖\n一、多线程编程 假设存在三个事件（事件A、事件B、事件C）需要我们完成，每个事件均包含一定的前置处理时间和等待完成时间，即每个事件均需要先处理一定时间，处理完成后再等待一段时间，等待过后该事件就算作已完成了。那么，我们就可以采用三种不同的方式来完成这三个事件：\n串行。按照顺序依次来处理三个事件，待某个事件处理且等待结束后再处理下一个事件。这种方式需要消耗一个人力 并发。先处理事件 A，当事件 A 的前置处理完成后，转而来处理事件 B，当事件 B 的前置处理完成后，转而来处理事件 C，最后就只要等待三个事件结束即可。这种方式需要消耗一个人力 并行。三个事件分别转交由三个人进行同时处理。这种方式需要消耗三个人力 从直观上看，串行的处理效率最低，耗时最长，在每次等待事件完成的时间段内人力都被白白消耗了。并行的处理效率最高，耗时最短，理论上总的所需耗时取决于用时最长的那个事件，但其需要的人力成本也最高。并发的处理效率和耗时长短均介于串行和并行之间，需要的人力成本和串行持平（均低于并行）\n从以上假设的情景映射到软件世界\n并发就是在一段时间内以交替的方式来完成多个任务，使用多个线程来分别处理不同的任务，即使在单个处理器的情况下也可以通过时间片切换的技术来实现在一个时间段内运行多个线程，因此即使只有一个处理器也可以实现并发 并行就是以同时处理的方式来完成多个任务，使用多个线程来分别处理不同的任务，然后将多个线程分别转交给不同的处理器进行运行，因此并行需要有多个处理器才可以实现 而在现实情况下，程序需要同时执行的线程数量往往是远多于处理器的数量，并发才是我们的主要实现目标。因此，我们可以这么理解：实现多线程编程的过程就是将任务的执行方式由串行改为并发的过程，即实现并发化，以此来尽量提高程序和硬件的运行效率 那使用多线程有什么好处呢？\n对于计算机来说，其处理器的运算速度相比存储和通信子系统要快了几个数量级，如果只采用单线程，那么当线程在处理磁盘 I/O、数据库访问等任务时，处理器就被闲置着没有活干了，这就造成了很大的性能浪费。此时就可以通过采用多线程来使处理器尽量处于运转状态，尽量利用到其运算能力\n此处，对于一个服务端，衡量其性能高低好坏的一个重要标准之一是每秒事务处理数（TPS）的大小，它代表着一秒内服务端平均能响应的请求总数。服务端可能会在极小的时间段内收到多个请求，服务端的 TPS 就和程序的并发能力（即同时处理多项任务的能力）有着密切关联\n再比如，在 Android 应用开发中，系统规定了只有 main 线程才可以进行 UI 绘制和刷新，如果不将耗时操作（IO读写、网络请求等）放到子线程进行处理，那么用户对应用的 UI 操作行为（点击屏幕、滑动列表等）很大可能就会由于无法及时被 main 线程处理，导致应用似乎被卡住了，最终用户可能就会放弃使用该应用了\n所以，使用多线程编程可以最大限度地利用系统提供的处理能力，提高程序的吞吐率和响应性，避免性能浪费。但使用多线程就一定就能提高效率吗？这不一定\n采用多线程后，各个线程间可能会相互竞争系统资源，例如处理器时间片、排他锁、带宽、硬盘读写等，而资源往往是有限且每次只能由一个线程使用的，并发编程的最终效益就往往受限于资源的有限分配，多个线程争用同一个排他性资源就会带来线程上下文切换甚至死锁等问题 例如，当采用多个线程来分段下载某个网络文件以此来希望减少下载耗时。由于带宽大小是固定的，使用多个线程同时进行下载首先就会拉低每个线程的平均可用带宽大小，每个线程下载到的单份资源也需要通过硬盘读写合并成一个完整的文件，每段资源的合并需要通过调度程度来按顺序写入，维护调度顺序的过程也是有着性能的消耗，多个线程进行 IO 读写也会加大发生线程上下文切换的次数。因此，某些情况下采用多线程可能会显得“并不那么值得”，需要我们根据实际情况来衡量使用 二、进程与线程 程序（Program）是对指令、数据及其组织形式的描述，是一种静态的概念 进程（Process）是程序的运行实例，每个被启动的程序就对应运行于操作系统上的一个进程，是一种动态的概念。进程是程序向操作系统申请资源（内存空间、文件句柄等）的基本单位，也是操作系统进行资源调度和资源分配的基本单位。运行一个 Java 程序实质上就是启动了一个 Java 虚拟机进程 线程（Thread）是进程中可独立执行的最小单位，也是操作系统能够进行运算调度的最小单位，也被称为轻量级进程。每个线程总是包含于特定的进程内，一个进程可以包含多个线程且至少包含一个线程，线程是进程中的实际运行单位。同一个进程中的所有线程共享该进程中的资源（内存空间、文件句柄等） 任务（Task）即线程所要完成的逻辑计算。线程在创建之初的目的就是为了让其来执行特定的逻辑计算，其所要完成的工作就称为该线程的任务 多线程编程是一种以线程为基本抽象单位的编程范式（Praadigm）。现代计算机操作系统几乎都支持多任务处理，多任务处理有两种不同的类型：基于进程的多任务处理和基于线程的多任务处理\n基于进程的多任务处理指操作系统支持同时运行多个程序，进程是调度程序能够调度的最小代码单元。进程是重量级的任务，每个进程需要有自己的地址空间，进程间通信开销很大而且有很多限制，从一个进程上下文切换到另一个进程上下文的开销也很大 基于线程的多任务处理意味着单个进程可以同时执行多个任务，线程是调度程序能够调度的最小代码单元。基于线程的多任务处理需要的开销要比基于进程的多任务处理小得多。线程是轻量级的任务，它们共享同个进程下的资源，线程间通信的开销不大，并且同个进程下的不同线程上下文间的切换所需要的的开销要比不同进程上下文间的切换小得多 基于进程的多任务处理是由操作系统来实现并管理的，一般的程序开发接触不到这个层面。而基于线程的多任务处理则可以由程序开发者自己来实现并进行管理。可以说，多线程编程的一个目的就是为了实现基于线程的多任务处理\nJava 对多线程提供了内置支持。Java 标准类库中的 java.lang.Thread 类就是对线程这个概念的抽象实现，提供了在不同的硬件和操作系统平台上对线程操作的统一处理，屏蔽了不同的硬件和操作系统的差异性\nJava 本身是一个多线程的平台，即使开发者没有主动创建线程，此时进程内还是使用到了多个线程（例如，还存在 GC 线程）。所谓的单线程编程往往指的是在程序中开发者没有主动创建线程\n三、Thread Java 标准类库 java.lang.Thread 是 Java 平台对线程这个概念的抽象实现，Thread 类或者其子类的一个实例就是一个线程\n1、线程的属性 属性 含义 编号（ID） long。用于标识不同的线程，不同的线程拥有不同的编号，在 Java 虚拟机的单次生命周期内具有唯一性 名称（Name） String。用于区分不同的线程，方便开发和调试时定位问题，在 Java 虚拟机的单次生命周期内可以重复 类别（Daemon） boolean。值为 true 表示该线程为守护线程，否则为用户线程 优先级（Priority） int。Java 定义了 1~10 的 10 个优先级，默认值为 5 按照线程是否会阻止 Java 虚拟机正常停止，Java 中的线程分为用户线程和守护线程。用户线程会阻止 Java 虚拟机的正常停止，即一个 Java 虚拟机只有在其所有用户线程都运行结束的情况下才能正常停止。而守护线程不会影响 Java 虚拟机的正常停止，即使应用程序中还有守护线程在运行也不影响 Java 虚拟机的正常停止。因此，守护线程适合用于执行一些重要性不是很高的任务。但如果 Java 虚拟机是被强制停止或者由于异常被停止的话，用户线程也无法阻止 Java 虚拟机的停止\nJava 线程的优先级属性本质上只是一个给线程调度器的提示信息，以便于线程调度器决定优先调度哪些线程运行，优先级高的线程理论上会获得更多的处理器使用时间，但线程调度器并不保证一定按照线程优先级的高低来调度线程。此外， JVM 所在的操作系统可能会忽略甚至主动来修改我们对线程的优先级配置，且如果线程的优先级设置不当，甚至有可能导致线程永远无法得到运行，即产生线程饥饿\n如果在线程 A 中创建了线程 B，那么线程 B 就称为线程 A 的子线程，线程 A 就称为线程 B 的父线程。由于 Java 虚拟机创建的 main 线程（主线程）负责执行 Java 程序的入口方法 main() 方法，因此 main 方法中创建的线程都是 main 线程的子线程或间接子线程。此外，一个线程是否是守护线程默认与其父线程相同，线程优先级的默认值也与其父线程的优先级相同。需要注意的是，虽然线程间具有这类父子关系，但是它们并不会相互影响对方的生命周期，一方线程生命周期的结束（不管是正常结束还是异常停止）并不影响另一个线程继续运行\n2、线程的方法 方法 说明 static Thread currentThread() 返回当前的执行线程对象 static void yield() 使当前线程主动放弃其处理器的占用，但不一定会使当前线程暂停 static void sleep(long) 使当前线程休眠指定时间 void start() 启动线程 void join() 若线程 A 调用线程 B 的 join() 方法，则线程 A 会暂停运行，直到线程 B 运行结束 void suspend() 暂停线程，进入睡眠状态（已废弃） void resume() 唤醒线程，和 suspend() 成对使用（已废弃） void stop() 停止线程（已废弃） Thread.suspend() 和 Thread.resume() 是 Thread 类提供的用于暂停和唤醒线程的方法，用于在某些运行条件不满足的时候暂停执行任务，后续在运行条件满足的时候唤醒线程继续执行任务，但现在均已废弃\n3、线程的状态 线程在它的整个生命周期内会先后处于不同状态，也可能会在多个状态间来回切换。对于给定的线程实例，可以使用 Thread.getState() 方法获取线程的状态，该方法返回 Thread.State 枚举类型值，用于标明在调用该方法时线程所处的当前状态，返回值包含以下几种可能：\n值 状态 NEW 线程处于新建状态，还没有调用 start() 方法 RUNNABLE 线程要么当前正在执行，要么在获得处理器时间片之后就可以执行 BLOCKED 线程因为发起了阻塞式操作，或者正在等待需要的资源时被挂起 WAITING 线程因为等待某些动作而挂起执行。例如，因为调用了 wait() 或 join() 方法所以处于这种状态，这种状态下的线程需要由外部其它线程来唤醒自身 TIMED_WAITING 线程挂起一段指定的时间，当达到指定的时间到达后，线程就会转为 RUNNABLE 状态。例如当调用 sleep(long) 、wait(long) 、 join(long) 等方法时就会处于这种状态 TERMINATED 已经运行结束的线程就处于此状态 可以用更加通俗的语言来描述线程的生命周期：\n新建状态-NEW\n使用 new 关键字建立一个线程对象后，线程就处于新建状态，一个已创建但还未启动的线程就处于此状态。线程会保持这个状态直到被调用 Thread.start() 方法\n就绪状态-RUNNABLE\n当线程对象调用了 start() 方法之后，线程就会进入就绪状态。该状态可以看成一个复合状态，它包含两个子状态：READY 和 RUNNING。前者表示线程处于就绪队列中，当被线程调度器选中调度后就可以正式运行，变为 RUNNING 状态。后者表示线程正处于运行中，其 run() 方法对应的指令正在由处理器执行。当执行线程的 yiedId() 方法时，其状态可能会由 RUNNING 切换为 READY\n阻塞状态-BLOCKED\n当线程发起一个阻塞式的 IO 操作或者是在申请一个由其它线程持有的独占资源时，该线程就会处于此状态。处理 BLOCKED 状态的线程不会占用 CPU 资源。当其目标行为或者是目标资源被满足后，就可以切换为 RUNNABLE 状态\n无限期等待状态-WAITING\n当线程的运行需要满足某些执行条件而当前并不满足时，通常就会通过让该线程主动调用 Object.wait()、Thread.join() 等类似方法将线程切换为 WAITING 状态。当前状态是 WAITING 的线程处于暂停运行的状态，需要外部其它线程通过 Object.notify() 等方法来主动唤醒该线程\n限期等待状态-TIMED_WAITING\nTIMED_WAITING 状态和 WAITING 状态类似。区别在于 TIMED_WAITING 状态并非是线程本身完全无限制地进行等待，其等待行为带有指定时间范围的限制，当在指定时间内没有完成该线程所期望的特定操作时，该线程就会转为 RUNNABLE 状态。可以通过 Object.wait(long) 方法来使线程切换为 TIMED_WAITING 状态\n终止状态-TERMINATED\n当一个线程完成自身任务或者由于其它原因被迫终止时，线程就会切换到终止状态，至此线程的整个生命周期就结束了\n由于一个线程在其整个生命周期内只能被启动一次，所以线程也只会处于一次 NEW 状态和一次 TERMINATED 状态。对于一个多线程系统来说，最理想的情况就是所有已启动且未结束的线程能一直处于 RUNNING 状态，但这是不可能实现的。在现实场景下线程会在多个状态间来回切换，且线程从 RUNNABLE 状态转换为 BLOCKED、WAITING 和 TIMED_WAITING 这几个状态中的任何一个时都意味着发生了线程上下文切换\n4、ThreadGroup 线程组（ThreadGroup）用来表示一组相关联的线程，它是 Thread 类包含的一个内部属性，可以通过 Thread.getThreadGroup()来获取该值。线程与线程组之间的关系类似于文件系统中文件与文件夹之间的关系，一个线程组可以包含多个线程以及其它线程组\n如果在创建线程时没有显示指定线程所属的线程组的话，在默认情况下线程就被归类于其父线程所属的线程组下。从 Thread 类的以下方法就可以看出来：\nprivate void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc, boolean inheritThreadLocals) { ···· Thread parent = currentThread(); SecurityManager security = System.getSecurityManager(); if (g == null) { /* Determine if it\u0026#39;s an applet or not */ /* If there is a security manager, ask the security manager what to do. */ if (security != null) { //默认也是返回 Thread.currentThread().getThreadGroup() g = security.getThreadGroup(); } /* If the security doesn\u0026#39;t have a strong opinion of the matter use the parent thread group. */ if (g == null) { g = parent.getThreadGroup(); } } ···· } Java 虚拟机在创建 main 线程（所有线程的父线程）的时候会为其自动指定一个线程组，因此任何一个线程都有一个线程组与之相关联。且一个线程组的父线程组默认是在声明该线程组时所在线程的线程组，但并非所有线程组均有父线程组，最顶层线程组就不包含父线程组\n/** * @Author: leavesCZY * @Github：https://github.com/leavesCZY */ fun main() { val mainThreadGroup = Thread.currentThread().threadGroup println(mainThreadGroup) println(\u0026#34;mainThreadGroup.parent: \u0026#34; + mainThreadGroup.parent) println(\u0026#34;mainThreadGroup.parent.parent: \u0026#34; + mainThreadGroup.parent.parent) val thread = Thread() println(thread.threadGroup) val thread2 = Thread(ThreadGroup(\u0026#34;otherThreadGroup\u0026#34;), \u0026#34;thread\u0026#34;) println(thread2.threadGroup) // java.lang.ThreadGroup[name=main,maxpri=10] // mainThreadGroup.parent: java.lang.ThreadGroup[name=system,maxpri=10] // mainThreadGroup.parent.parent: null // java.lang.ThreadGroup[name=main,maxpri=10] // java.lang.ThreadGroup[name=otherThreadGroup,maxpri=10] } ThreadGroup 本身存在设计缺陷问题，目前的使用场景有限，日常开发中可以无需理会\n5、线程异常捕获 在很多时候，我们会通过创建一个线程池来执行任务，而当某个任务由于抛出异常导致其执行线程异常终止时，我们就需要对这种异常情况进行上报以便后续分析。要实现这个效果，就需要能够收到线程被异常终止时的事件通知，这就需要用到 Thread.setUncaughtExceptionHandler(UncaughtExceptionHandler) 方法\n通过该方法我们可以在异常发生时且线程被停止前获取到相应的 Thread 对象和 Throwable 实例\n/** * @Author: leavesCZY * @Github：https://github.com/leavesCZY */ fun main() { val runnable = Runnable { for (i in 4 downTo 0) { println(100 % i) Thread.sleep(100) } } val thread = Thread(runnable, \u0026#34;otherName\u0026#34;) thread.setUncaughtExceptionHandler { t, e -\u0026gt; println(\u0026#34;threadName: \u0026#34; + t.name) println(\u0026#34;exc: $e\u0026#34;) } thread.start() } 0 1 4 2 4 0 0 1 0 0 threadName: otherName exc: java.lang.ArithmeticException: / by zero ThreadGroup 本身也实现了 UncaughtExceptionHandler 接口，所以如果 Thread 对象不包含关联的 UncaughtExceptionHandler 实例的话，则会将异常交由 ThreadGroup 来进行处理\n从 Thread 类的以下逻辑就可以看出来\npublic class Thread implements Runnable { private ThreadGroup group; private volatile UncaughtExceptionHandler uncaughtExceptionHandler; private void dispatchUncaughtException(Throwable e) { getUncaughtExceptionHandler().uncaughtException(this, e); } public UncaughtExceptionHandler getUncaughtExceptionHandler() { return uncaughtExceptionHandler != null ? uncaughtExceptionHandler : group; } } ThreadGroup 默认情况下会将异常交由其父线程组进行处理，而对于不包含父线程组的线程组对象（顶层线程组），则会将异常交由 Thread 类的 defaultUncaughtExceptionHandler 进行处理。所以，我们可以通过 Thread 的静态方法 setDefaultUncaughtExceptionHandler 方法来为程序设置一个全局的默认异常处理器\npublic class ThreadGroup implements Thread.UncaughtExceptionHandler { public void uncaughtException(Thread t, Throwable e) { if (parent != null) { //当有父线程组时，则将异常交由父线程组来处理 parent.uncaughtException(t, e); } else { //当父线程组不存在时，则尝试将异常交由 DefaultUncaughtExceptionHandler 来处理 Thread.UncaughtExceptionHandler ueh = Thread.getDefaultUncaughtExceptionHandler(); if (ueh != null) { ueh.uncaughtException(t, e); } else if (!(e instanceof ThreadDeath)) { System.err.print(\u0026#34;Exception in thread \\\u0026#34;\u0026#34; + t.getName() + \u0026#34;\\\u0026#34; \u0026#34;); e.printStackTrace(System.err); } } } } public class Thread implements Runnable { private static volatile UncaughtExceptionHandler defaultUncaughtExceptionHandler; public static UncaughtExceptionHandler getDefaultUncaughtExceptionHandler(){ return defaultUncaughtExceptionHandler; } //设置全局默认的异常处理器 public static void setDefaultUncaughtExceptionHandler(UncaughtExceptionHandler eh) { SecurityManager sm = System.getSecurityManager(); if (sm != null) { sm.checkPermission( new RuntimePermission(\u0026#34;setDefaultUncaughtExceptionHandler\u0026#34;) ); } defaultUncaughtExceptionHandler = eh; } } 所以，当线程由于异常而终止时，UncaughtExceptionHandler 实例的选择优先级从高到低分别是：\nThread.uncaughtExceptionHandler ThreadGroup.uncaughtExceptionHandler Thread.defaultUncaughtExceptionHandler 6、ThreadFactory 在项目中先后需要使用到多个线程是一个普遍的需求，而如果每次均简单的通过 new Thread() 来创建线程的话，在出现问题时就很难定位问题所在。所以 Java 标准库也提供了创建线程的工厂方法，即 ThreadFactory 接口\npublic interface ThreadFactory { Thread newThread(Runnable r); } ThreadFactory 提供了将要执行的任务 Runnable 与要创建的 Thread 相关联的方法，即我们可以通过 ThreadFactory 来标明 Thread 要执行的具体任务、为 Thread 设置一个有具体含义的名字、设置 Thread 的运行优先级等\n例如，Executors 内部就包含了一个 DefaultThreadFactory，通过 threadNumber 自增的方式为每一个创建的线程设置了特定的线程名、确保线程是用户线程、确保线程的优先级为正常级别\nstatic class DefaultThreadFactory implements ThreadFactory { private static final AtomicInteger poolNumber = new AtomicInteger(1); private final ThreadGroup group; private final AtomicInteger threadNumber = new AtomicInteger(1); private final String namePrefix; DefaultThreadFactory() { SecurityManager s = System.getSecurityManager(); group = (s != null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); namePrefix = \u0026#34;pool-\u0026#34; + poolNumber.getAndIncrement() + \u0026#34;-thread-\u0026#34;; } public Thread newThread(Runnable r) { Thread t = new Thread(group, r, namePrefix + threadNumber.getAndIncrement(), 0); if (t.isDaemon()) t.setDaemon(false); if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); return t; } } 而对于我们项目自己定义的线程池，使用 ThreadFactory 的一个比较有意义的用处是：为线程设置关联的 UncaughtExceptionHandler，这在提高系统的健壮性方面是很有好处的\n7、线程的执行时机 我们可以简单地理解为运行一个线程就是要求 Java 虚拟机来调用 Runnable 对象的 run() 方法，从而使得线程的任务处理逻辑得以被执行。但我们通过 Thread.start() 启动一个线程并不意味着线程就能够马上被执行，线程的具体执行时机由线程调度器来决定，执行时机具有不确定性，甚至可能会由于线程活性故障而永远无法运行。此外，由于 run() 方法是 public 的，所以它也可以由外部主动来调用执行，但此时其任务就是由当前的运行线程来执行，这在大多数时候都是没有实际意义的\n而不管是通过什么方式来创建线程，当线程的 run() 方法执行结束时（不管是正常结束还是由于异常而中断运行），线程的生命周期也就走到末尾了，其占用的资源会在后续被 Java 虚拟机垃圾回收。而且，线程是一次性资源，我们无法通过再次调用 start() 方法来重新启动线程，当多次调用该方法时会抛出 IllegalThreadStateException\n四、多线程安全 实现多线程编程不是简单地声明多个 Thread 对象并启动就可以的了，在现实场景中，多个线程间往往是需要完成数据交换和行为交互等各种复杂操作的，而不是简单地“各行其是”。相比单线程，使用多线程会带来许多在单线程下不存在或者根本不用考虑的问题\n1、竞态 先来看一个简单的例子。假设存在一个商店 Shop，其初始商店数量为零。存在四十个生产者 Producer 为其生产商品，每个 Producer 会各自为商店提供一个商品。那么，理论上当所有 Producer 生产完毕后，Shop 的商品数量 goodsCount 应该是四十\n可是，运行以下代码后你会发现实际数量大概率是会少于四十\n/** * @Author: leavesCZY * @Github：https://github.com/leavesCZY */ class Shop(var goodsCount: Int) { fun produce() { goodsCount++ } } class Producer(private val shop: Shop) : Thread() { override fun run() { sleep(100) if (shop.goodsCount \u0026lt; 40) { shop.produce() } println(\u0026#34;over\u0026#34;) } } fun main() { val shop = Shop(0) val threads = mutableListOf\u0026lt;Thread\u0026gt;() for (i in 1..40) { threads.add(Producer(shop)) } threads.forEach { it.start() } //保证所有 Producer Thread 都执行完毕会再执行之后的语句 threads.forEach { it.join() } println(\u0026#34;shop.goodsCount: \u0026#34; + shop.goodsCount) } 以上代码就使用到了多个线程，单个 Producer 线程的行为逻辑是独立的，而多个 Producer 线程的行为逻辑对于 Shop 来说是互相交错且先后顺序不确定的，这就有可能导致一种情况：两个 Producer 同时判断到当前商品数量是十，然后同时为商店生产第十一件商品（shop.goodsCount++），最终就导致某个 Producer 生产的第十一号商品被另一个 Producer 覆盖了，两个 Producer 只生产了一件商品，即数据更新无效/更新丢失\nshop.goodsCount++ 这条语句虽然看起来像是一个不可分割的操作（原子操作），但它实际上相当于如下伪代码所表示的三个指令的组合：\nload(shop.goodsCount , r1) //指令1，将变量 shop.goodsCount 的值从内存读到寄存器 r1 increment(r1) //指令2，将寄存器 r1 的值加1 store(shop.goodsCount , r1) //指令3，将寄存器 r1 的内容写入变量 shop.goodsCount 所对应的内存空间 多个 Producer 线程可能会同时各自执行上述指令。例如，假设当前 goodsCount 是十，Producer1 和 Producer2 同时执行到指令1，两个线程将 goodsCount 读到各自处理器的寄存器上，即每个线程会各自拥有一份副本数据，然后对各自寄存器的值进行自增加一的操作，当执行到指令三时，由于 goodsCount 所在的内存空间是特定的，所以两个 Producer 线程对内存空间上 goodsCount 的值的回传会存在相互覆盖的情况。即原本最终结果应该是递增加二的行为最终却只有递增加一\n以上是多线程编程中经常会遇到的一个现象，即竞态。竞态是指计算的正确性依赖于相对时间顺序或者线程的交错。竞态并不一定就会导致计算结果不正确，它只是不排除计算结果时而正确时而错误的可能\n从上述代码中可以总结出竞态的两种模式：read-modify-write（读-改-写）、check-then-act（检测后行动）\nread-modify-write 的步骤即：读取一个共享变量的值，然后根据该值进行一些计算、接着根据计算结果更新共享变量的值。例如，上述代码中的 goodsCount++ 就是这种模式，相当于如下伪代码所表示的三个指令的组合\nload(shop.goodsCount , r1) //指令1，将变量 shop.goodsCount 的值从内存读到寄存器 r1 increment(r1) //指令2，将寄存器 r1 的值加1 store(shop.goodsCount , r1) //指令3，将寄存器 r1 的内容写入变量 shop.goodsCount 所对应的内存空间 线程 A 在执行完指令1，开始执行或者正在执行指令2时，线程 B 可能已经执行完了指令3，这使得线程 A 当前持有的共享变量 shop.goodsCount 是旧值，当线程 A 执行完指令3时，这就使得线程 B 对共享变量的更新被覆盖了，即造成了更新丢失\ncheck-then-act 的步骤即：读取一个共享变量的值，根据该变量的值决定下一步的动作是什么。例如，以下代码就是这种模式\nif (shop.goodsCount \u0026lt; 40) { //操作1 shop.produce() //操作2 } 线程 A 在执行完操作1，开始执行操作2之前，线程 B 可能已经更新了共享变量 shop.goodsCount 的值导致 if 语句中的条件变为不成立，可此时线程 A 依然会执行操作2，这是因为线程 A 此时并不知道共享变量已经被更新且导致运行条件不成立了\n从上述分析中我们可以总结出竞态产生的一般条件。设 Q1 和 Q2 是并发访问共享变量 V 的两个操作，这两个操作并非都是读操作。如果一个线程在执行 Q1 期间另外一个线程同时执行 Q2，那么无论 Q2 是读操作还是写操作都会导致竞态。从这个角度来看，竞态可以看做是由于访问（读取、更新）同一组共享变量的多个线程所执行的操作被相互交错而导致的。而上述代码中遇到的更新丢失和读到脏数据问题就是由于竞态的存在而导致的\n需要注意的是，竞态的产生前提是涉及到了多个线程和共享变量。如果系统仅包含单个线程，或者不涉及共享变量，那么就不会产生竞态。对于局部变量（包括形式参数和方法体内定义的变量），由于不同的线程访问的是各自的那一份局部变量，因此局部变量的使用不会导致竞态\n2、线程安全性 如果一个类在单线程环境下能够正常运行，并且在多线程环境下也不需要考虑运行时环境下的调度和交替执行，使用方也不必为其做多任何操作也能正常运行，那么我们就说该类是线程安全的，即这个类具有线程安全性。反之，如果一个类在单线程环境下正常运行而在多线程环境下无法正常运行，那么这个类就是非线程安全的。所以，只有非线程安全的类才会导致竞态\n如果一个类不是线程安全的，我们就说它在多线程环境下存在多线程安全问题。以上定义也适用于多个线程间的共享数据\n多线程安全问题概括来说表现为三个方面：原子性、可见性、有序性\n原子性 原子的字面意思即不可分割。对于涉及共享变量访问的操作，若该操作从其执行线程以外的其它任意线程来看是不可分割的，那么该操作就是原子操作，相应的就称该操作具有原子性。所谓“不可分割”，是指访问（读、写）某个共享变量的操作从其执行线程以外的任何线程来看，该操作要么已经完成，要么尚未发生，其它线程不会看到该操作执行了一部分的中间效果\n例如，假设存在一个共享的全局变量 Shop 对象，其存在一个 update() 方法。当线程 A 执行 update() 方法时，在线程 A 执行完语句1之后而未执行语句2之前，此时线程 B 就会看到 goodsCount 已递增加一而 clerk 还未递增加一的这样一个中间效果。此时，我们就说 update() 方法作为一个整体不具备原子性\nclass Shop(var goodsCount: Int, var clerk: Int) { fun update() { goodsCount++ //语句1 clerk++ //语句2 } } 理解原子操作这个概念还需要注意以下两点：\n原子操作是针对共享变量的操作而言的，仅涉及局部变量访问的操作无所谓是否是原子性，或者可以直接将其看作成原子操作 原子操作是从该操作的执行线程以外的其它线程的视角来描述的，也就是说它只在多线程环境下才有意义，所以可以将单线程环境下的所有操作均当做原子操作 总的来说，Java 中有两种方式来提供原子性：\n第一种是使用锁（Lock）。锁具有排他性，它能够保障共享变量在任意一个时刻只能够被一个线程访问。这就排除了多个线程在同一时刻访问同一个共享变量而导致干扰与冲突的可能，从而消除了竞态 第二种是利用处理器提供的 CAS 指令。CAS 指令实现原子性的方式与锁在本质上是相同的，差别在于锁通常是在软件这一层面实现的，而 CAS 是直接在硬件（处理器和内存）这一层次实现的，可以被看做“硬件锁” Java 语言规范规定了：在 Java 语言中，64 位以外的任何类型的变量的读写操作都是原子操作。而对于 long 和 double 等 64 位的数据类型的读写操作并不强制规定 Java 虚拟机必须保证其原子性，可以由 Java 虚拟机自己选择是否要实现。因此在多线程并发读写同一 long/double 型共享变量的情况下，一个线程可能会读取到其它线程更新该变量的“中间结果”。而之所以会有中间结果，是因为对于 64 位的存储空间的写操作，虚拟机可能会将其拆解为两个步骤来实现，比如先写低 32 位再写高 32 位，从而导致外部线程读取到一个中间结果值。但这个问题也不需要特意关注，因为目前商用 Java 虚拟机几乎都选择将 64 位数据的读写操作实现为原子操作。此外，Java 语言规范也特别规定了用 volatile 关键字修饰的 long/double 型变量的读写操作具有原子性。\n需要注意的是， volatile 关键字仅能保障变量读写操作的原子性，但并不能保障其它操作（例如 read-modify-write 、check-then-act）的原子性\n可见性 在多线程环境下，一个线程对某个共享变量进行更新之后，后续访问该变量的其它线程可能无法立即读取到这个更新的结果，甚至永远也无法读取到，这体现了多线程安全性问题中的一个：可见性。可见性是指一个线程对共享变量的更新结果对于其它读取相应共享变量的线程而言是否可见的问题。多线程程序在可见性方面存在问题意味着某些线程读取到了旧数据，而这往往会导致我们的程序出现意想不到的问题\n会存在可见性问题。一方面是由于 JIT 编译器可能出于提高代码运行效率考虑而自动对代码进行一些“优化”，使得共享变量更新失效。一方面是由于处理器并不是直接对主内存中的共享变量进行访问，而是会各自在自己的高速缓存上保留着对共享变量的一份副本，处理器直接访问的是副本数据，对副本数据的修改需要同步回主内存后才可以对其它处理器可见。所以一个处理器对共享变量的更新结果并不一定能立即同步到其它处理器上，这就导致了可见性问题的出现\n对于同一个共享变量而言，一个线程更新了该变量的值之后，如果其它线程能够读取到这个更新后的值，那么这个值就被称为该变量的相对新值。如果读取这个共享变量的线程在读取并使用该变量的时候其它线程无法更新该变量的值，那么该线程读取到的值就被称为该变量的最新值。可见性的保障仅仅意味着一个线程能够读取到共享变量的相对新值，而并不意味着线程能够读取到相应变量的最新值\n可见性问题是由于使用了多线程所导致的，它与当前是单核处理器还是多核处理器无关。在单核处理器下，多线程并发是通过时间片分配技术来实现的，此时虽然多个线程都是运行在同个处理器上，但是由于在上下文切换的时候，一个线程对共享变量的修改会被当做其上下文信息保存起来，这也会导致另外一个线程无法立即读取到该线程对共享变量的修改\n有序性 在说有序性之前，需要先介绍下重排序\n顺序结构是结构化编程中的一种基本结构，它表示我们希望某个操作必须先于另外一个操作得以执行，但是在多核处理器环境下，这种操作执行顺序可能是没有保障的。编译器和处理器可以在保证不影响单线程执行结果的前提下，对源代码的指令进行重新排序执行，处理器可能不是完全依照程序的目标代码所指定的顺序来执行指令。另外，一个处理器上执行的多个操作，从其它处理器的角度来看其顺序可能与目标代码所指定的顺序不一致。这种现象就叫做重排序。重排序是对内存访问有关的操作（读和写）所做的一种优化，它可以在不影响单线程程序正确性的情况下提升程序的性能。但是，它可能对多线程程序的正确性产生影响，即它可能导致线程安全问题\n重排序分为以下几种：\n编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序 指令级并行的重排序。现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序 内存系统的重排序。由于处理器使用缓存和读／写缓冲区，这使得加载和存储操作看上去可能是在乱序执行 有序性指的就是在什么情况下一个处理器上运行的线程所执行的内存访问顺序在另外一个处理器上运行的其它线程看来是乱序的。所谓乱序，是指内存访问操作的顺序看起来是发生了变化\n3、不安全的线程安全类 上文有提到如何定义一个类是否是线程安全的，Java 也提供了很多被称为线程安全的类，例如 java.util.Vector。Vector 类内部的 add()、removeAt() 和 size() 等很多方法都使用了 synchronize 进行修饰，保证了在多线程环境下的安全性，但这种同步保障也无法阻止开发者在逻辑层面上写出不安全的代码\n例如，对于以下代码。即使 add() 和 removeAt() 两个方法由于 Vector 类内部的同步处理，保障了两个方法一定是串行执行的，但由于方法调用端缺少了额外的同步处理，导致调用端可能会读取到一个过时的 vector.size 值，最终导致索引越界抛出 ArrayIndexOutOfBoundsException\n所以说，线程安全类可能只是保障了其自身单次操作行为的线程安全性，使得我们在调用的时候不需要进行额外的同步保障。但对于使用方的一些特定顺序的连续调用，就还是需要在外部实现额外的同步手段来保证调用的正确性，否则就有可能用线程安全类写出不安全的代码\n/** * @Author: leavesCZY * @Github：https://github.com/leavesCZY */ private val vector = Vector\u0026lt;Int\u0026gt;() private val threadNum = 5 fun main() { val addThreadList = mutableListOf\u0026lt;Thread\u0026gt;() for (i in 1..threadNum) { val thread = object : Thread() { override fun run() { for (item in 1..10) { vector.add(item) } } } addThreadList.add(thread) } val printThreadList = mutableListOf\u0026lt;Thread\u0026gt;() for (i in 1..threadNum) { val thread = object : Thread() { override fun run() { for (index in 1..vector.size) { vector.removeAt(i) } } } printThreadList.add(thread) } addThreadList.forEach { it.start() } printThreadList.forEach { it.start() } addThreadList.forEach { it.join() } printThreadList.forEach { it.join() } } 4、上下文切换 并发的实现和是否拥有多个处理器无关，即使只有单个处理器也能够通过处理器时间片分配技术来实现并发。操作系统通过给每个线程分配一小段占有处理器使用权的时间来供其运行，然后在每个线程的运行时间结束后又快速切换到下一个线程来运行，多个线程以这种断断续续的方式来实现并发并完成各自的任务。一个线程被剥夺处理器的使用权并暂停运行的过程就被称为切出，被线程调度器选中来占用处理器并运行的过程就被称为切入\n操作系统会分出一个个时间片，每个线程每次运行会分配到若干个时间片，时间片决定了一个线程可以连续占用处理器运行的时间长度，一般是只有几十毫秒，单处理器上的多线程就是通过这种时间片分配的方式来实现并发。当一个进程中的一个线程由于其时间片用完或者由于其自身的原因被迫或者主动暂停其运行时，另外一个线程（当前进程中的线程或者其它进程中的线程）就可以被线程调度器选中来占用处理器并开始运行。这种一个线程被剥夺处理器的使用权并暂停运行，另外一个线程被赋予处理器的使用权并开始运行的过程就称为线程上下文切换\n线程上下文切换是处理器个数远小于系统所需要支持的并发线程数的现实场景下的必然产物。这也意味着在线程切出和切入的时候操作系统需要保存和恢复相应线程的进度信息，即需要保存切入和切出那一刻相应线程所执行的指令进行到什么哪一步了。这个进度信息就被称为上下文\n线程的生命周期状态在 RUNNABLE 状态与非 RUNNABLE 状态之间切换的过程就是上下文切换的过程。当被暂停的线程被操作系统选中获得继续运行的机会时，操作系统会恢复之前为该线程保存的上下文，以便其在此基础上继续完成其任务\n按照导致上下文切换的因素来划分，可以将上下文切换划分为自发性上下文切换和非自发性上下文切换\n自发性上下文切换。这种情况是线程由于其自身原因导致的切出。从 Java 平台的角度来看，一个线程在其运行过程中执行了以下任何一个操作都会引起自发性上下文切换 Thread.sleep() Object.wait() Thread.yieid() Thread.join() LockSupport.park() I/O 操作 等待被其它线程持有的锁 非自发性上下文切换。指线程由于线程调度器的原因被迫切出。这种情况往往是由于被切出的线程的时间片用完，或者有一个比被切出线程更高优先级的线程需要运行。此外，Java 虚拟机的垃圾回收动作也可能导致非自发性上下文切换，这是因为垃圾回收器在执行 GC 的过程中可能需要暂停所有应用线程才能完成 系统在一段时间内产生的上下文切换次数越多，由此导致的处理器资源消耗也就越多，相应的这段时间内真正能够用于执行目标代码的处理器资源就越少，因此我们也需要考虑尽量减少上下文切换的次数，这在后续文章中会介绍\n五、线程调度 线程调度是指操作系统为线程分配处理器使用权的过程。主要的调度方式有两种：\n协同式线程调度。在这种策略下，线程的执行时机由线程本身来决定，线程通过主动通知系统切换到另一个线程的方式来让出处理器的使用权。该策略的优点是实现简单，可以通过精准控制线程的执行顺序来避免线程安全性问题。缺点是可能会由于单个线程的代码缺陷问题导致无法切换到下一个线程，最终导致进程被阻塞 抢占式线程调度。这也是 Java 平台使用的线程调度策略。在这种策略下，由操作系统来决定当前处理器时间片交由哪个线程来使用，线程无法决定具体的运行时机和运行顺序。虽然我们可以通过 Thread.yieid() 方法来让出时间片，但是无法主动抢夺时间片，且虽然 Thread 类也提供了设置线程优先级的方法，但线程的具体执行顺序还是取决于其运行系统。该策略的优点是不会由于一个线程的问题导致整个进程被阻塞，且提高了并发性。缺点是实现较为复杂，且会带来多线程安全性问题 六、资源争用和资源调度 1、资源争用 一次只能被一个线程占用的资源称为排他性资源。常见的排他性资源包括锁、处理器、文件等。由于资源的稀缺性或者资源本身的特性，我们往往需要在多个线程间共享同一个排他性资源。当一个线程占用一个排他性资源而未释放其对资源的所有权时，存在其它线程同时试图访问该资源的现象就被称为资源争用，简称争用。显然，争用是在并发环境下产生的一种现象，同时试图访问一个已经被其它线程占用的排他性资源的线程数量越多，争用的程度就越高，反之争用的程度就越低。相应的争用就被称为高争用和低争用\n同一时间段内，处于运行状态的线程数量越多，我们就称并发的程度越高，简称高并发。虽然高并发加大了争用的可能性，但是高并发未必就意味着高争用，因为线程并非就是一定会在某个时刻来一起申请资源，资源的申请操作对于多个线程来说可能是交错开的，或者每个线程持有排他性资源的时间很短。多线程编程的理想情况就是高并发、低争用\n2、资源调度 当多个线程同时申请同一个排他性资源，申请资源失败的线程往往是会存入一个等待队列中，当后续资源被其持有线程释放时，如果刚好有一个活跃线程来申请资源，此时选择哪一个线程来获取资源的独占权就是一个资源调度的过程，资源调度策略的一个重要属性就是能否保证公平性。所谓公平性，是指资源的申请者是否严格按照申请顺序而被授予资源的独占权。如果资源的任何一个先申请者总是能够被比任何一个后申请者先获得资源的独占权，那么该策略就被称为公平调度策略。如果资源的后申请者可能比先申请者先获得资源的独占权，那么该策略就被称为非公平调度策略。注意，非公平调度策略往往只是不保证资源调度的公平性，即它只是允许不公平的资源调度现象，而不是表示它刻意造就不公平的资源调度\n公平的资源调度策略不允许插队现象的出现，资源申请者总是按照先来后到的顺序获得资源的独占权。如果当前等待队列为空，则来申请资源的线程可以直接获得资源的独占权。如果等待队列不为空，那么每个新到来的线程就被插入等待队列的队尾。公平的资源调度策略的优点是：每个资源申请者从开始申请资源到获得相应资源的独占权所需时间的偏差会比较小，即每个申请者成功申请到资源所需的时间基本相同，且可以避免出现线程饥饿现象。缺点是吞吐率较低，为了保证 FIFO 加大了发生线程上下文切换的可能性\n非公平的资源调度策略则允许插队现象。新到来的线程会直接尝试申请资源，只有当申请失败时才会将线程插入等待队列的队尾。假设两种多个线程一起竞争同一个排他性资源的场景：\n当资源被释放时，如果刚好有一个活跃线程来申请资源，该线程就可以直接抢占到资源，而无需去唤醒等待队列中的线程。这种场景相对公平调度策略就少了将新到来的线程暂停和将等待队列队头的线程唤醒的两个操作，而资源也一样有被得到使用 即使等待队列中的某个线程已经被唤醒来试图抢占资源的独占权，如果新到来的活跃线程占用资源的时间不长的话，那么就有可能在被唤醒的线程开始申请资源之前，新到来的活跃线程已经释放了对资源的独占权，从而不妨碍被唤醒的线程申请资源。这种场景也一样避免了将新到来的线程暂停这么一个操作 因此，非公平调度策略的优点主要有两点：\n吞吐率一般来说会比公平调度策略高，即单位时间内它可以为更多的申请者调配资源 降低了发生上下文切换的概率 非公平调度策略的缺点主要有两点：\n由于允许插队现象，极端情况下可能导致等待队列中的线程永远也无法获得其所需的资源，即出现线程饥饿的活性故障现象 每个资源申请者从开始申请资源到获得相应资源的独占权所需时间的偏差可能较大，即有的线程可能很快就能申请到资源，而有的线程则要经历若干次暂停与唤醒才能成功申请到资源 综上所诉，公平调度策略适用于资源被持有的时间较长或者线程申请资源的平均时间间隔较长的情形，或者要求申请资源所需的时间偏差较小的情况。总的来说，使用公平调度策略的开销会比使用非公平调度策略的开销要大，因此在没有特别需求的情况下，应该默认使用非公平调度策略\n七、参考的书籍 《Java 多线程编程实战指南（核心篇）》\n《深入理解 Java 虚拟机》\n《Java 并发编程的艺术》\n","permalink":"http://localhost:1313/hugo-blog/public/post/kotlin/java-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%BC%80%E5%8F%911%E4%BB%80%E4%B9%88%E6%98%AF%E5%A4%9A%E7%BA%BF%E7%A8%8B/","tags":[],"title":"Java 多线程开发（1）什么是多线程"},{"categories":[],"content":" 公众号：字节数组 希望对你有所帮助 🤣🤣\n目前，多线程编程可以说是在大部分平台和应用上都需要实现的一个基本需求。本系列文章就来对 Java 平台下的多线程编程知识进行讲解，从概念入门、底层实现到上层应用都会涉及到，预计一共会有五篇文章，希望对你有所帮助 😎😎\n本篇文章是第二篇，介绍实现多线程同步的各类方案，涉及多种多线程同步机制，是开发者在语言层面上对多线程运行所做的规则设定\n一、线程同步机制 前面的文章有介绍到，多线程安全问题概括来说表现为三个方面：原子性、可见性、有序性。多线程安全问题的产生前提是存在多个线程并发访问（不全是读）同一份共享数据，而会产生多线程安全问题的根本原因是多个线程间缺少一套用于协调各个线程间的数据访问和行为交互的机制，即缺少线程同步机制\n多线程为程序引入了异步行为，相应的就必须提供一种线程同步机制来保障在需要时能够强制多线程同步的方法。当多个线程间存在共享资源时，需要以某种方式来确保每次只有一个线程能够使用资源。例如，如果希望两个线程进行通信并共享某个复杂的数据结构（例如链表），就需要以某种方式来确保它们相互之间不会发生冲突。也就是说，当一个线程正在读取该数据结构时，必须阻止另外一个线程向该数据结构写入数据\nJava 为同步提供了语言级的支持，同步的关键是监视器，监视器是用作互斥锁的对象。在给定时刻，只有一个线程可以拥有监视器。当线程取得锁时，也就是进入了监视器。其它所有企图进入加锁监视器的线程都会被挂起，直到持有监视器的线程退出监视器\n从广义上来说，Java 平台提供的线程同步机制包括：锁、volatile、final、static 以及一些 API（Object.wait()、Object.notify() 等）\n二、锁的分类 既然线程安全问题的产生前提是存在多个线程并发访问（不全是读）共享数据，那么为了保障线程安全，我们就可以通过将多个线程对共享数据的并发访问转换为串行访问，从而来避免线程安全问题。将多个线程对共享数据的访问限制为串行访问，即限制共享数据一次只能被一个线程访问，该线程访问结束后其它线程才能对其进行访问\nJava 就是通过这种思路提供了锁(Lock) 这种线程同步机制来保障线程安全。锁具有排他性，一次只能被一个线程持有（这里所说的锁不包含读写锁这类共享锁），这种锁就被称为排他锁或者互斥锁。锁的持有线程可以对锁保护的共享数据进行访问，访问结束后持有线程就必须释放锁，以便其它线程能够后续对共享数据进行访问。锁的持有线程在其获得锁之后和释放锁之前这段时间内所执行的代码被称为临界区。因此，临界区一次只能被一个线程执行，共享数据只允许在临界区内进行访问\n按照 Java 虚拟机对锁的实现方式的划分，Java 平台中的锁包括内部锁和显式锁。内部锁是通过 synchronize 关键字实现的。显式锁是通过 java.util.concurrent.locks.Lock 接口的实现类来实现的。内部锁仅支持非公平调度策略，显式锁既支持公平调度策略也支持非公平调度策略\n锁能够保护共享数据以实现线程安全，起的作用包括保障原子性、保障可见性和保障有序性\n锁通过互斥来保障原子性。锁保证了临界区代码一次只能被一个线程执行，临界区代码被执行期间其它线程无法访问相应的共享数据，从而排除了多个线程同时访问共享变量从而导致竞态的可能性，这使得临界区所执行的操作具备了原子性。虽然实现并发是多线程编程的目标，但是这种并发往往是带有局部串行 可见性的保障是通过写线程冲刷处理器缓存和读线程刷新处理器缓存这两个动作实现的。在 Java 平台。锁的获得隐含着刷新处理器缓存这个动作，这使得读线程在获得锁之后且执行临界区代码之前，可以将写线程对共享变量所做的更新同步到该线程执行处理器的高速缓存中；而锁的释放隐含着冲刷处理器缓存这个动作，这使得写线程对共享变量所做的更新能够被推送到该线程执行处理器的高速缓存中，从而对读线程可见。因此，锁能够保障可见性 锁能够保障有序性。由于锁对原子性和可见性的保障，使得锁的持有线程对临界区内对各个共享数据的更新同时对外部线程可见，相当于临界区中执行的一系列操作在外部线程看来就是完全按照源代码顺序执行的，即外部线程对这些操作的感知顺序与源代码顺序一致，所以说锁保障了临界区的有序性。尽管锁能够保障有序性，但临界区内依然可能存在重排序，但临界区代码不会被重排序到临界区之外，而临界区之外的代码有可能被重排序到临界区之内 锁的原子性及对可见性的保障合在一起，可保障临界区内的代码能够读取到共享数据的相对新值。再由于锁的互斥性，同一个锁所保护的共享数据一次只能被一个线程访问，因此线程在临界区中所读取到的共享数据的相对新值同时也是最新值\n需要注意的是，锁对可见性、原子性和有序性的保障是有条件的，需要同时满足以下两个条件，否则就还是会存在线程安全问题\n多个线程在访问同一组共享数据的时候必须使用同一个锁 即使是对共享数据进行只读操作，其执行线程也必须持有相应的锁 之所以需要保障以上两个要求，是由于一旦某个线程进入了一个锁句柄引导的同步方法/同步代码块，其它线程就都无法再进入同个锁句柄引导的任何同步方法/同步代码块，但是仍然可以继续调用其它非同步方法/非同步代码块，而如果非同步方法/非同步代码块也对共享数据进行了访问，那么此时依然会存在竞态\n1、内部锁 Java 平台中的任何一个对象都有一个唯一与之关联的锁，被称为监视器或者内部锁。内部锁是通过关键字 synchronize 实现的，可用来修饰实例方法、静态方法、代码块等\nsynchronize 关键字修饰的方法就被称为同步方法，同步方法的整个方法体就是一个临界区。用 synchronize 修饰的实例方法和静态方法就分别称为同步实例方法和同步静态方法\npublic class Test { //同步静态方法 public synchronized static void funName1() { } //同步方法 public synchronized void funName2() { } } synchronize 关键字修饰的代码块就被称为同步块。当中，lock被称为锁句柄。锁句柄是对一个对象的引用，锁句柄对应的监视器就称为相应同步块的引导锁\npublic class Test { private final Object lock = new Object(); public void funName1() { //同步块 synchronized (lock) { } } } 锁句柄如果为当前对象（this），那就相当于同步实例方法，如下两个同步方法是等价的\npublic class Test { public void funName1() { synchronized (this) { } } public synchronized void funName2() { } } 同步静态方法则相当于以当前类对象为引导锁的同步块，如下两个同步方法是等价的\npublic class Test { public synchronized static void funName1() { } public void funName2() { synchronized (Test.class) { } } } 作为锁句柄的变量通常使用 private final修饰，这是因为锁句柄的变量一旦被改变，会导致执行同一个同步块的多个线程实际上使用不同的锁，从而导致竞态\n对于内部锁来说，线程在执行临界区内代码之前必须获得该临界区的引导锁，执行完后就会自动释放引导锁，引导锁的申请和释放是由 Java 虚拟机代为执行的，这也是 synchronized被称为内部锁的原因。且由于 Java 编译器对同步块代码的特殊处理，即使临界区抛出异常，内部锁也会被自动释放，所以内部锁不会导致锁泄漏\n2、显式锁 显式锁从 JDK 1.5 开始被引入 ，其作用与内部锁相同，但相比内部锁其功能会丰富很多。显式锁由 java.concurrent.locks.Lock 接口来定义，默认实现类是 java.util.concurrent.locks.ReentrantLock\nLock 的使用方式较为灵活，可以在方法 A 内申请锁，在方法 B 再进行释放。其基本使用方式如下所示\nprivate Lock lock = new ReentrantLock(false); private void funName() { //申请锁 lock.lock(); try { //action } finally { //释放锁 lock.unlock(); } } ReentrantLock 既支持公平调度策略也支持非公平调度策略，通过其一个参数的构造函数来指定，传值为 true 表示公平锁，false 表示非公平锁， 默认使用非公平调度策略。此外，由于虚拟机并不会自动为我们释放锁，所以为了避免锁泄漏，一般会将 Lock.unlock()方法放在 finally 中执行，以保证临界区内的代码不管是正常结束还是异常退出，相应的锁释放操作都会被执行\n3、内部锁和显式锁的比较 内部锁是基于代码块的锁\n其缺点主要有以下几点：\n使用上缺少灵活性。锁的申请和释放操作被限制在一个代码块或者方法体内部 功能有限。例如，当一个线程申请某个正被其它线程持有的内部锁时，该线程只能被暂停，等待锁被释放后再次申请，而无法取消申请或者是限时申请，且不支持线程中断 仅支持非公平调度策略 其优点主要有以下几点：\n使用简单 由于 Java 编译器的保障，所以使用时不会造成锁泄露，保障了安全性 显式锁是基于对象的锁\n其缺点主要有以下几点：\n需要开发者自己来保障不会发生锁泄露 其优点主要有以下几点：\n相对内部锁在使用上更具灵活性，可以跨方法来完成锁的申请和释放操作 功能相对内部锁要丰富许多。例如，可以通过 Lock.isLocked()判断当前线程是否已经持有该锁、通过 Lock.tryLock() 尝试申请锁以避免由于锁被其它线程持有而导致当前线程被暂停、通过 Lock.tryLock(long,TimeUnit) 在指定时间范围内尝试申请锁、Lock.lockInterruptibly() 支持线程中断 同时支持公平调度策略和非公平调度策略 4、读写锁 锁的排他性使得多个线程无法以线程安全的方式在同一时刻对共享数据进行只读取而不更新的操作，这在共享数据读取频繁但更新频率较低的情况下降低了系统的并发性，读写锁就是为了应对这种问题而诞生的。读写锁（Read/Wirte Lock）是一种改进型的排他锁，也被称为共享/排他锁。读写锁允许多个线程同时读取共享变量，但是一次只允许一个线程对共享变量进行更新。任何线程读取共享变量的时候，其它线程无法更新这些变量；一个线程更新共享变量的时候，其它线程都无法读取和更新这些变量\nJava 平台的读写锁由 java.util.concurrent.locks.ReadWriteLock 接口来定义，其默认实现类是 java.util.concurrent.locks.ReentrantReadWriteLock\nReadWriteLock 接口定义了两个方法，分别用来获取读锁（ReadLock）和写锁（WriteLock）\npublic interface ReadWriteLock { /** * Returns the lock used for reading. * * @return the lock used for reading */ Lock readLock(); /** * Returns the lock used for writing. * * @return the lock used for writing */ Lock writeLock(); } 读线程在访问共享变量的时候必须持有读锁，读锁是可以共享的，它可以同时被多个线程持有，提高了只读操作的并发性。写线程在访问共享变量的时候必须持有写锁，写锁是排他的，即一个线程持有写锁的时候其它线程无法获得同个读写锁的读锁和写锁\n读写锁的使用方式与显式锁相似，也需要由开发者自己来保障避免锁泄露\npublic class Test { private final ReadWriteLock readWriteLock = new ReentrantReadWriteLock(); private final Lock readLock = readWriteLock.readLock(); private final Lock writeLock = readWriteLock.writeLock(); public void reader() { readLock.lock(); try { //在此区域读取共享变量 } finally { readLock.unlock(); } } public void writer() { writeLock.lock(); try { //在此区域更新共享变量 } finally { writeLock.unlock(); } } } 读写锁在原子性、可见性和有序性保障方面，它所起的作用和普通的排他锁是一样的，但由于读写锁内部实现比内部锁和其它显式锁要复杂很多，因此读写锁适合于在以下条件同时得以满足的场景下使用：\n只读操作比写操作要频繁得多 读线程持有锁的时间比较长 只有同时满足以上两个条件的时候读写锁才是比较适合的，否则可能反而会比普通排他锁增大性能开销\n此外，ReentrantReadWriteLock 支持锁的降级，即一个线程持有写锁的同时可以继续获得相应的读锁。但 ReentrantReadWriteLock 不支持锁的升级，即无法在持有读锁的同时获得相应的写锁\n5、内部锁和读写锁的性能比较 这里，我们以一个简单的例子来比较下内部锁和读写锁之间的性能差异。假设存在数量相等的读线程和写线程，读线程负责打印出共享变量整数值 index 的当前值大小，写线程负责对共享变量整数值 index 进行递增加一。读线程和写线程各自有多个，每个线程间的行为是互相独立的。这里分别通过使用“内部锁”和“读写锁”来规范每个线程的行为必须是串行的，通过比较不同方式下所需的时间耗时来对比两种锁之间的性能高低\n首先，Printer 接口定义了读线程和写线程需要做的行为操作，ReadWriteLockPrinter 类是读写锁方式的实现，SynchronizedPrinter 类是内部锁方式的实现\n/** * @Author: leavesCZY * @Github：https://github.com/leavesCZY */ interface Printer { fun read() fun write() fun sleep() { Thread.sleep(200) } } /** * @Author: leavesCZY * @Github：https://github.com/leavesCZY */ class ReadWriteLockPrinter : Printer { private val readWriteLock = ReentrantReadWriteLock(true) private val readLock = readWriteLock.readLock() private val writeLock = readWriteLock.writeLock() private var index = 0 override fun read() { readLock.lock() try { sleep() } finally { println(\u0026#34;读取到数据： $index\u0026#34; + \u0026#34;，time: \u0026#34; + System.currentTimeMillis()) readLock.unlock() } } override fun write() { writeLock.lock() try { sleep() index++ } finally { println(\u0026#34;写入数据： $index\u0026#34; + \u0026#34;，time: \u0026#34; + System.currentTimeMillis()) writeLock.unlock() } } } /** * @Author: leavesCZY * @Github：https://github.com/leavesCZY */ class SynchronizedPrinter : Printer { private var index = 0 @Synchronized override fun read() { sleep() println(\u0026#34;读取到数据： $index\u0026#34; + \u0026#34;，time: \u0026#34; + System.currentTimeMillis()) } @Synchronized override fun write() { sleep() index++ println(\u0026#34;写入数据： $index\u0026#34; + \u0026#34;，time: \u0026#34; + System.currentTimeMillis()) } } 再来定义读线程和写线程，两种线程使用的是同个 Printer 对象\n/** * @Author: leavesCZY * @Github：https://github.com/leavesCZY */ class PrinterReadThread(private val printer: Printer) : Thread() { override fun run() { printer.read() } } class PrinterWriteThread(private val printer: Printer) : Thread() { override fun run() { printer.write() } } 通过切换不同的 Printer 实现即可大致对比不同的锁的性能高低\n/** * @Author: leavesCZY * @Github：https://github.com/leavesCZY */ fun main() { val printer: Printer = SynchronizedPrinter() //val printer: Printer = ReadWriteLockPrinter() val threadNum = 10 val writeThreadList = mutableListOf\u0026lt;Thread\u0026gt;() for (i in 1..threadNum) { writeThreadList.add(PrinterWriteThread(printer)) } val readThreadList = mutableListOf\u0026lt;Thread\u0026gt;() for (i in 1..threadNum) { readThreadList.add(PrinterReadThread(printer)) } //启动所有读线程和所有写线程 writeThreadList.forEach { it.start() } readThreadList.forEach { it.start() } } 最后的日志输出类似如下所示。虽然即使多次运行来取平均值也不具备严格的对比意义，但是也可以大致对比出不同锁之间的性能高低。从日志也可以看出，当使用读写锁时多个读线程读取数据所需要的总耗时几乎是零\n# 内部锁 消耗 3801 毫秒 写入数据： 1，time: 1597151018862 读取到数据： 1，time: 1597151019062 读取到数据： 1，time: 1597151019262 读取到数据： 1，time: 1597151019462 读取到数据： 1，time: 1597151019662 读取到数据： 1，time: 1597151019862 读取到数据： 1，time: 1597151020062 读取到数据： 1，time: 1597151020262 读取到数据： 1，time: 1597151020462 读取到数据： 1，time: 1597151020662 读取到数据： 1，time: 1597151020862 写入数据： 2，time: 1597151021062 写入数据： 3，time: 1597151021262 写入数据： 4，time: 1597151021462 写入数据： 5，time: 1597151021663 写入数据： 6，time: 1597151021863 写入数据： 7，time: 1597151022063 写入数据： 8，time: 1597151022263 写入数据： 9，time: 1597151022463 写入数据： 10，time: 1597151022663 # 读写锁 消耗 2000 毫秒 写入数据： 1，time: 1597151078704 写入数据： 2，time: 1597151078904 写入数据： 3，time: 1597151079104 写入数据： 4，time: 1597151079304 写入数据： 5，time: 1597151079504 写入数据： 6，time: 1597151079704 写入数据： 7，time: 1597151079904 写入数据： 8，time: 1597151080104 写入数据： 9，time: 1597151080304 写入数据： 10，time: 1597151080504 读取到数据： 10，time: 1597151080704 读取到数据： 10，time: 1597151080704 读取到数据： 10，time: 1597151080704 读取到数据： 10，time: 1597151080704 读取到数据： 10，time: 1597151080704 读取到数据： 10，time: 1597151080704 读取到数据： 10，time: 1597151080704 读取到数据： 10，time: 1597151080704 读取到数据： 10，time: 1597151080704 读取到数据： 10，time: 1597151080704 6、锁的开销 锁的开销主要包含几点：\n上下文切换与线程调度开销。一个线程在申请已经被其它线程持有的锁时，该线程就有可能会被暂停运行，直到锁被释放后被该线程申请到，也有可能不会被暂停运行，而是采用忙等策略直到锁被释放。如果申请锁的线程被暂停，Java 虚拟机就需要为被暂停的线程维护一个等待队列，以便后续锁的持有线程释放锁时将这些线程唤醒。线程的暂停与唤醒就是一个上下文切换的过程，并且 Java 虚拟机维护等待队列也是有着一定消耗。如果是非争用锁则不会产生上下文切换和等待队列的开销 内存同步、编译器优化受限的开销。锁的底层实现需要使用到内存屏障，而内部屏障会产生直接和间接的开销。直接开销是内存屏障所的冲刷写处理器、清空无效化队列等行为所导致的开销。间接开销包含：禁止部分代码重排序从而阻碍编译器优化。无论是争用锁还是非争用锁都会产生这部分开销，但如果非争用锁最终可以被采用锁消除技术进行优化的话，那么就可以消除掉这个锁带来的开销 限制可伸缩性。采用锁的目的是使得多个线程间的并发改为带有局部串行的并发，实现这个目的后带来的副作用就是使得系统的局部计算行为（同步代码块）的吞吐率降低，限制系统的可伸缩性，导致处理器资源的浪费 三、wait / notify 在单线程编程中，如果程序要执行的操作需要满足一定的运行条件后才可以执行，那么我们可以将目标操作放到一个 if 语句中，让目标操作只有在运行条件得以满足时才会被执行\n而在多线程编程中，目标操作的运行条件可能涉及到多个线程间的共享变量，即运行条件可能是由多个线程来共同决定的。对于目标操作的执行线程来说，运行条件可能只是暂时未满足的，其它线程可能在稍后就会更新运行条件涉及的共享变量从而使得运行条件成立。因此，我们可以选择将当前线程暂停，等待其它线程更新了共享变量使得运行条件成立后，再由其它线程来将被暂停的线程唤醒以便让其执行目标操作\n当中，一个线程因为要执行的目标动作所需的保护条件未满足而被暂停的过程就被称为等待（wait）。一个线程更新了共享变量，使得其它线程所需的保护条件得以满足并唤醒那些被暂停的线程的过程就被称为通知（notify）\n在 Java 平台上，以下两类方法可用于实现等待和通知，Object 可以是任何对象。由于等待线程和通知线程在实现等待和通知的时候必须是调用同一个对象的 wait、notify 方法，且其执行线程必须持有该对象的内部锁，所以等待线程和通知线程是同步在同一个对象上的两种线程\nObject.wait()/Object.wait(long)。这两个方法的作用是使其执行线程暂停，生命周期变为 WAITING，可用于实现等待。其执行线程就被称为等待线程 Object.notify()/Object.notifyAll()。这两个方法的作用是唤醒一个或多个被暂停的线程，可用于实现通知。其执行线程就被称为通知线程 1、wait 使用 Object.wait() 实现等待，其代码模板如以下伪代码所示：\n//在调用 wait 方法前获得相应对象的内部锁 synchronized(someObject){ while (保护条件不成立) { //调用 wait 方法暂停当前线程，并同时释放已持有的锁 someObject.wait() } //能执行到这里说明保护条件已经满足 //执行目标动作 doAction() } 当中，保护条件是一个包含共享变量的布尔表达式\n当保护条件不成立时，因执行 someObject.wait() 而被暂停的线程就被称为对象 someObject 上的等待线程。由于一个对象的 wait() 方法可以被多个线程执行，因此一个对象可能存在多个等待线程。此外，由于一个线程只有在持有一个对象的内部锁的情况下才能够调用该对象的 wait() 方法，因此 Object.wait() 总是放在相应对象所引导的临界区之中。someObject.wait() 会以原子操作的方式使其执行线程（即等待线程）暂停并使该线程释放其持有的 someObject 对应的内部锁。当等待线程被暂停的时候其对 someObject.wait() 方法的调用并不会返回，只有当等待线程被通知线程唤醒且重新申请到 someObject 对应的内部锁时，才会继续执行 someObject.wait() 内部剩余的指令，这时 wait() 才会返回\n当等待线程被唤醒时，等待线程在其被唤醒继续运行到其再次申请到相应对象的内部锁的这段时间内，其它线程有可能会抢先获得相应的内部锁并更新了相关共享变量导致保护条件再次不成立，因此 someObject.wait() 调用返回之后我们需要再次判断此时保护条件是否成立。所以，对保护条件的判断以及 someObject.wait() 的调用应该放在循环语句之中，以确保目标动作一定只在保护条件成立的情况下才会被执行\n此外，等待线程对保护条件的判断以及目标动作的执行必须是原子操作，否则可能产生竞态，即目标动作被执行前的那一刻其它线程可能对共享变量进行了更新又使得保护条件重新不成立。因此，保护条件的判断、目标动作的执行、Object.wait() 的调用都必须放在同一个对象所引导的临界区中\n2、notify 使用 Object.notify() 实现通知，其代码模板如以下伪代码所示：\nsynchronized(someObject){ //更新等待线程的保护条件涉及的共享变量 updateSharedState() //唤醒等待线程 someObject.notify() } 由于只有在持有一个对象的内部锁的情况下才能够执行该对象的 notify() 方法，所以 Object.notify() 方法也总是放在相应对象内部锁所引导的临界区之内。也正因为如此， Object.wait() 在暂停其执行线程的同时也必须释放 Object 的内部锁，否则通知线程就永远也无法来唤醒等待线程。和 Object.wait() 不同，Object.notify() 方法本身并不会释放内部锁，只有在其所在的临界区代码执行结束后才会被释放。因此，为了使得等待线程在被唤醒后能够尽快获得相应的内部锁，我们要尽量将 Object.notify() 代码放在靠近临界区结束的地方，否则如果 Object.notify()唤醒了等待线程而通知线程又迟迟不释放内部锁，就有可能导致等待线程再次经历上下文切换，从而浪费系统资源\n调用 Object.notify() 所唤醒的线程仅是 Object 对象上的任意一个等待线程，所以被唤醒的线程有可能并不是我们真正想要唤醒的线程。因此，有时我们需要改用 Object.notifyAll() 方法，该方法可以唤醒 Object 上的所有等待线程。被唤醒的线程就都有了抢夺相应 Object 对象的内部锁的机会。而如果被唤醒的线程在占用处理器继续运行后且申请到内部锁之前，有其它线程（被唤醒的等待线程之一或者是新到来的线程）先持有了内部锁，那么这个被唤醒的线程可能又会再次被暂停，等待再次被唤醒的机会，而这个过程会导致上下文切换\nwait/notify 机制也被应用于 Thread 类内部。例如，Thread.join() 方法提供了在某个线程运行结束前暂停该方法调用者线程的功能，内部也使用到 wait() 方法来暂停调用者线程，等到线程终止后 JVM 内部就会通过 notifyAll()方法来唤醒所有等待线程\npublic final synchronized void join(long millis) throws InterruptedException { ··· if (millis == 0) { while (isAlive()) { wait(0); } } else { ··· } } 3、wait / notify 存在的问题 用 wait / notify 实现的等待和通知可能会遇到以下两个问题：\n过早唤醒。假设存在多个等待线程同步在对象 someObject 上，每个等待线程的运行保护条件并不完成相同。当通知线程更新了某个等待线程的运行保护条件涉及的共享变量并使之成立时，由于 someObject.notify() 方法具体会唤醒哪个线程对于开发者来说是不可预知的，所以我们只能使用 someObject.notifyAll() 方法，此时就会导致那些运行条件还不成立的等待线程也被唤醒，这种现象就叫做过早唤醒。过早唤醒会使得那些运行条件还不满足的等待线程也被唤醒运行，当这些线程再次判断到当前运行条件不满足时又会再次调用 someObject.wait() 方法暂停 多次的线程上下文切换。对于一次完整的 wait 和 notify 过程，等待线程执行 someObject.wait() 方法至少会导致等待线程对相应内部锁的两次申请和两次释放，通知线程执行 someObject.notify() 方法则会导致通知线程对相应内部锁的一次申请和一次释放。每个线程每次锁的申请与释放操作都对应着一次线程上下文切换 4、生产者与消费者 wait 和 notify 两个方法的协作可以通过一个经典的问题来展示：生产者与消费者问题。对于一家商店来说，其能承载的商品最大数是固定的，最多为 MAX_COUNT。存在多个生产者为商店生产商品，生产者生产商品不能使得商店内的商品数量超出 MAX_COUNT。存在多个消费者从商店消费商品，消费者消费过后最低使商店的商品总数变为零。生产者只有当商店内的商品总数小于 MAX_COUNT 时才能继续生产，消费者只有当商店内的商品总数大于零时才能进行消费。因此，当商店内的商品总数小于 MAX_COUNT 时需要通知生产者开始生产，否则需要暂停生产。当商店内的商品总数大于零时需要通知消费者来消费，否则需要暂停消费\n上述的生产者与消费者分别对应多个线程，商店就相当于多个线程间的共享数据。生产者线程的运行保护条件是：当前商品总数不能大于等于 MAX_COUNT。消费者线程的运行保护条件是：当前商品总数要大于 0\n/** * @Author: leavesCZY * @Github：https://github.com/leavesCZY */ private val LOCK = Object() private const val MAX_COUNT = 10 class Shop(var goodsCount: Int) fun main() { val shop = Shop(0) val producerSize = 4 val consumerSize = 8 for (i in 1..producerSize) { Producer(shop, \u0026#34;生产者-${i}\u0026#34;).apply { start() } } for (i in 1..consumerSize) { Consumer(shop, \u0026#34;消费者-${i}\u0026#34;).apply { start() } } } class Producer(private val shop: Shop, name: String) : Thread(name) { override fun run() { while (true) { Tools.randomSleep() synchronized(LOCK) { while (shop.goodsCount \u0026gt;= MAX_COUNT) { println(\u0026#34;${name}-商品总数已达到最大数量，停止生产\u0026#34;) LOCK.wait() } val number = Tools.randomInt(1, MAX_COUNT - shop.goodsCount) shop.goodsCount = shop.goodsCount + number println(\u0026#34;$name ===== 新增了 $number 件商品，当前剩余: ${shop.goodsCount}\u0026#34;) LOCK.notifyAll() } } } } class Consumer(private val shop: Shop, name: String) : Thread(name) { override fun run() { while (true) { Tools.randomSleep() synchronized(LOCK) { while (shop.goodsCount \u0026lt;= 0) { println(\u0026#34;${name}-商品已经被消费光了，停止消费\u0026#34;) LOCK.wait() } val number = Tools.randomInt(1, shop.goodsCount) shop.goodsCount = shop.goodsCount - number println(\u0026#34;$name ---- 消费了 $number 件商品，当前剩余: ${shop.goodsCount}\u0026#34;) LOCK.notifyAll() } } } } 其运行结果类似于如下所示\n生产者-2 ===== 新增了 7 件商品，当前剩余: 7 消费者-7 ---- 消费了 4 件商品，当前剩余: 3 消费者-7 ---- 消费了 2 件商品，当前剩余: 1 消费者-8 ---- 消费了 1 件商品，当前剩余: 0 生产者-4 ===== 新增了 2 件商品，当前剩余: 2 消费者-2 ---- 消费了 1 件商品，当前剩余: 1 生产者-1 ===== 新增了 8 件商品，当前剩余: 9 消费者-1 ---- 消费了 3 件商品，当前剩余: 6 消费者-1 ---- 消费了 2 件商品，当前剩余: 4 消费者-3 ---- 消费了 1 件商品，当前剩余: 3 消费者-1 ---- 消费了 2 件商品，当前剩余: 1 消费者-5 ---- 消费了 1 件商品，当前剩余: 0 消费者-8-商品已经被消费光了，停止消费 消费者-7-商品已经被消费光了，停止消费 生产者-3 ===== 新增了 1 件商品，当前剩余: 1 消费者-7 ---- 消费了 1 件商品，当前剩余: 0 消费者-8-商品已经被消费光了，停止消费 消费者-2-商品已经被消费光了，停止消费 生产者-2 ===== 新增了 3 件商品，当前剩余: 3 消费者-2 ---- 消费了 2 件商品，当前剩余: 1 消费者-8 ---- 消费了 1 件商品，当前剩余: 0 消费者-6-商品已经被消费光了，停止消费 ······ 四、线程同步工具类 1、Condition wait/notify 存在过早唤醒、可能多次线程上下文切换次数、无法区分 Obejct.wait(long) 方法在返回时是由于超时还是由于线程被唤醒等一系列问题，可以使用 JDK 1.5 开始引入的 java.util.concurrent.locks.Condition 接口来解决这些问题\nCondition 接口定义的 await()、singal()、singalAll() 等方法相当于 Object.wait()、Object.notify()、Object.notifyAll()。Object.wait()/notify() 方法要求其执行线程必须持有相应对象的内部锁，类似的，Condition.await()/singal() 也要求其执行线程必须持有创建该 Condition 实例的显式锁\n使用 Condition 实现等待和通知，其代码模板如以下伪代码所示。Lock.newCondition() 方法的返回值就是一个 Condition 实例。每个 Condition 实例内部都维护了一个用于存储等待线程的队列，Condition.await() 方法的执行线程会被暂停并存入等待队列中。Condition.notify() 方法会分别使等待队列中的一个线程被唤醒，而用同一个 Lock 创建的其它 Condition 实例中的等待线程并不会收到影响。这就使得我们可以精准唤醒目标线程，避免过早唤醒，减少线程上下文切换的次数\nclass ConditionDemo { private val lock = ReentrantLock() private val conditionA = lock.newCondition() private val conditionB = lock.newCondition() fun waitA() { lock.lock() try { while (运行保护条件A不成立) { conditionA.await() } //执行目标操作 doAction() } finally { lock.unlock() } } fun notifyA() { lock.lock() try { //更新等待线程的保护条件涉及的共享变量 updateSharedStateA() //唤醒等待线程 conditionA.signal() } finally { lock.unlock() } } fun waitB() { lock.lock() try { while (运行保护条件B不成立) { conditionB.await() } //执行目标操作 doAction() } finally { lock.unlock() } } fun notifyB() { lock.lock() try { //更新等待线程的保护条件涉及的共享变量 updateSharedStateB() //唤醒等待线程 conditionB.signal() } finally { lock.unlock() } } } 这里通过设计一个简单的阻塞队列来演示下 Condition 的用法\n在 Queue 中，Lock 保障了 put 操作和 take 操作的线程安全性，两个不同的 Condition 实例又保障了 putThread 和 takeThread 在各自运行保护条件成立时，可以只唤醒相应的线程\nclass Queue\u0026lt;T\u0026gt; constructor(private val size: Int) { private val lock = ReentrantLock() //当队列已满时，put thread 就成为 notFull 上的等待线程 private val notFull = lock.newCondition() //当队列为空时，take thread 就成为 notEmpty 上的等待线程 private val notEmpty = lock.newCondition() private val items = mutableListOf\u0026lt;T\u0026gt;() fun put(x: T) { lock.lock() try { while (items.size == size) { println(\u0026#34;当前队列已满，暂停 put 操作...\u0026#34;) notFull.await() } println(\u0026#34;当前队列未满，执行 put 操作...\u0026#34;) items.add(x) //唤醒 TakeThread notEmpty.signal() } finally { lock.unlock() } } fun take(): T { lock.lock() try { while (items.size == 0) { println(\u0026#34;当前队列为空，暂停 take 操作...\u0026#34;) notEmpty.await() } println(\u0026#34;当前队列不为空，执行 take 操作...\u0026#34;) val x = items[0] items.removeAt(0) //唤醒 PutThread notFull.signal() return x } finally { lock.unlock() } } } PutThread 负责循环向阻塞队列存入八条数据，TakeThread 负责循环从阻塞队列获取九条数据，TakeThread 随机休眠的时间相对 PutThread 会更长，而阻塞队列的队长为四，那么在程序运行过程中大概率可以看到由于阻塞队列已满从而导致 PutThread 被暂停的现象，且程序运行到最后 TakeThread 会为了获取第九条数据而一直处于等待状态\nclass PutThread(private val intQueue: Queue\u0026lt;Int\u0026gt;) : Thread() { override fun run() { for (i in 1..8) { sleep(Random.nextLong(1, 50)) intQueue.put(i) } } } class TakeThread(private val intQueue: Queue\u0026lt;Int\u0026gt;) : Thread() { override fun run() { for (i in 1..9) { sleep(Random.nextLong(10, 100)) println(\u0026#34;TakeThread get value: \u0026#34; + intQueue.take()) } } } /** * @Author: leavesCZY * @Github：https://github.com/leavesCZY */ fun main() { val intQueue = Queue\u0026lt;Int\u0026gt;(4) val putThread = PutThread(intQueue) val takeThread = TakeThread(intQueue) putThread.start() takeThread.start() } 从程序的输出结果可以看到 TakeThread 最终将一直处于等待状态\n当前队列未满，执行 put 操作... 当前队列未满，执行 put 操作... 当前队列未满，执行 put 操作... 当前队列不为空，执行 take 操作... TakeThread get value : 1 当前队列未满，执行 put 操作... 当前队列未满，执行 put 操作... 当前队列已满，暂停 put 操作... 当前队列不为空，执行 take 操作... TakeThread get value : 2 当前队列未满，执行 put 操作... 当前队列不为空，执行 take 操作... TakeThread get value : 3 当前队列未满，执行 put 操作... 当前队列不为空，执行 take 操作... TakeThread get value : 4 当前队列未满，执行 put 操作... 当前队列不为空，执行 take 操作... TakeThread get value : 5 当前队列不为空，执行 take 操作... TakeThread get value : 6 当前队列不为空，执行 take 操作... TakeThread get value : 7 当前队列不为空，执行 take 操作... TakeThread get value : 8 当前队列为空，暂停 take 操作... 2、CountDownLatch 有时候会存在某个线程需要等待其它线程完成特定操作后才能继续运行的需求，此时使用 Object.wait() 和 Object.notify()也可以满足需求，但是使用上会比较繁琐，此时可以考虑通过 CountDownLatch 来实现\nCountDownLatch 可用来实现一个或多个线程等待其它线程完成特定操作后才继续运行的功能，这组操作被称为先决条件。CountDownLatch 内部会维护一个用于标记需要等待完成的先决条件的数量的计数器，当每个先决条件完成时，先决条件的执行线程就通过调用 CountDownLatch.countDown() 来使计算器减一。而 CountDownLatch.await() 就相当于一个受保护方法，其保护条件为“计算器值为零”，当计算器值不为零时，调用了 CountDownLatch.await() 方法的执行线程都会被暂停。当所有先决条件都完成时，即当“计算器值为零”的保护条件成立时，CountDownLatch 上的所有等待线程就都会被唤醒，继续运行\n当计数器的值达到 0 之后，该计数器的值就不再发生变化，后续继续调用 CountDownLatch.countDown() 也不会导致抛出异常，且再次调用 CountDownLatch.await() 方法也不会导致线程被暂停。因此，一个 CountDownLatch 实例只能用来实现一次等待和一次通知\n来看一个简单的例子。假设在程序启动时需要确保三个基础服务（ServiceA、ServiceB、ServiceC）先被初始化完成，且为了加快初始化速度，每个基础服务均交由一个工作者线程来完成初始化任务。此时就可以通过 CountDownLatch 来保证 main 线程一直处于等待状态直到所有的工作者线程的任务均结束（不管初始化成功还是失败）\n/** * @Author: leavesCZY * @Github：https://github.com/leavesCZY */ fun main() { val serviceManager = ServicesManager() serviceManager.startServices() println(\u0026#34;等待所有 Services 执行完毕\u0026#34;) val allSuccess = serviceManager.checkState() println(\u0026#34;执行结果： $allSuccess\u0026#34;) } class ServicesManager { private val countDownLatch = CountDownLatch(3) private val serviceList = mutableListOf\u0026lt;AbstractService\u0026gt;() init { serviceList.add(ServiceA(\u0026#34;ServiceA\u0026#34;, countDownLatch)) serviceList.add(ServiceB(\u0026#34;ServiceB\u0026#34;, countDownLatch)) serviceList.add(ServiceC(\u0026#34;ServiceC\u0026#34;, countDownLatch)) } fun startServices() { serviceList.forEach { it.start() } } fun checkState(): Boolean { countDownLatch.await() return serviceList.find { !it.checkState() } == null } } abstract class AbstractService(private val countDownLatch: CountDownLatch) { private var success = false abstract fun doTask(): Boolean fun start() { thread { try { success = doTask() } finally { countDownLatch.countDown() } } } fun checkState(): Boolean { return success } } class ServiceA(private val serviceName: String, countDownLatch: CountDownLatch) : AbstractService(countDownLatch) { override fun doTask(): Boolean { Thread.sleep(2000) println(\u0026#34;${serviceName}执行完毕\u0026#34;) return true } } class ServiceB(private val serviceName: String, countDownLatch: CountDownLatch) : AbstractService(countDownLatch) { override fun doTask(): Boolean { Thread.sleep(4000) println(\u0026#34;${serviceName}执行完毕\u0026#34;) return true } } class ServiceC(private val serviceName: String, countDownLatch: CountDownLatch) : AbstractService(countDownLatch) { override fun doTask(): Boolean { Thread.sleep(3000) if (Random.nextBoolean()) { throw RuntimeException(\u0026#34;$serviceName failed\u0026#34;) } else { println(\u0026#34;${serviceName}执行完毕\u0026#34;) } return true } } ServiceC 会随机抛出异常，所以程序的运行结果会分为以下两种可能。且为了保证当任务失败时 main 线程也可以收到唤醒通知，需要确保 CountDownLatch.countDown() 是放在 finally 代码块中\n# 成功的情况 等待所有 Services 执行完毕 ServiceA执行完毕 ServiceC执行完毕 ServiceB执行完毕 执行结果： true # 失败的情况 等待所有 Services 执行完毕 ServiceA执行完毕 Exception in thread \u0026#34;Thread-2\u0026#34; java.lang.RuntimeException: ServiceC failed at thread.ServiceC.doTask(CountDownLatchTest.kt:93) at thread.AbstractService$start$1.invoke(CountDownLatchTest.kt:55) at thread.AbstractService$start$1.invoke(CountDownLatchTest.kt:46) at kotlin.concurrent.ThreadsKt$thread$thread$1.run(Thread.kt:30) ServiceB执行完毕 执行结果： false 3、CyclicBarrier JDK 1.5 引入了 java.util.concurrent.CyclicBarrier 类用于实现多个线程间的相互等待。CyclicBarrier 可用于这么一种场景：假设存在一个集合点，在所有线程均执行到集合点之前，每个执行到指定集合点的线程均会被暂停。当所有线程均执行到指定集合点时，即当最后一个线程执行到集合点时，所有被暂停的线程都会自动被唤醒并继续执行\nCyclicBarrier 的字面意思可以理解为：可循环使用的屏障。而集合点就相当于一个“屏障”，除非所有线程都抵达到了屏障，否则每个到达的线程都会被拒之门外（即被暂停运行）。而当最后一个线程到来时，“屏障”就会自动消失，即最后一个到来的线程不会被暂停，而是继续向下执行代码，同时唤醒所有其它之前被暂停的线程\nCyclicBarrier 类涉及到的线程数量可以通过其构造参数 parties 来指定，CyclicBarrier.await() 方法就用于标记当前线程执行到了指定集合点。在功能上 CyclicBarrier 与 CountDownLatch 相似，但 CyclicBarrier 实例是可以重复使用的，在所有线程都被唤醒之后，任何线程再次执行 CyclicBarrier.await() 方法又会被暂停，直到最后一个线程也执行了该方法。所以，CyclicBarrier.await() 方法既是等待方法也是通知方法，最后一个执行线程就相当于通知线程，其它线程就相当于等待线程，线程的具体类别由其运行时序来动态区分，而非靠调用方法的不同\n再来看一个简单的例子。存在三个输出不同字符串内容的 PrintThread 线程，每个线程每输出一次，均需要等待其它线程也输出一次后才能再次输出，但三个线程每次的输出先后顺序可以随意\nclass PrintThread(private val cyclicBarrier: CyclicBarrier, private val content: String) : Thread() { override fun run() { while (true) { sleep(Random.nextLong(300, 1000)) println(\u0026#34;打印完成：${content}\u0026#34;) if (cyclicBarrier.parties == cyclicBarrier.numberWaiting + 1) { println() } cyclicBarrier.await() } } } fun main() { val threadNum = 3 val cyclicBarrier = CyclicBarrier(threadNum) val threadList = mutableListOf\u0026lt;Thread\u0026gt;() for (i in 1..threadNum) { threadList.add(PrintThread(cyclicBarrier, \u0026#34;index_$i\u0026#34;)) } threadList.forEach { it.start() } } 程序的输出结果类似如下所示。每一轮输出的三条数据先后顺序并不固定，但每一轮的内容一定不会重复\n打印完成：index_2 打印完成：index_1 打印完成：index_3 打印完成：index_2 打印完成：index_1 打印完成：index_3 打印完成：index_2 打印完成：index_1 打印完成：index_3 打印完成：index_3 打印完成：index_1 打印完成：index_2 打印完成：index_1 打印完成：index_3 打印完成：index_2 ... 4、Semaphore Semaphore 可用于实现互斥以及流量控制，在某些资源有限的场景下限制可以同时访问资源的最大线程数。例如，假设当前有几十上百个线程需要连接数据库进行数据存取，而数据库支持的最大连接数只有十个，此时就可以通过 Semaphore 来限制线程的最大并发数，当已经有十个线程连接到了数据库时，多余的请求线程就会被暂停\n看个简单的例子。对于以下代码，线程池同时发起的请求有三十个，而 Semaphore 限制了最大线程并发数是四个，所以最终的输出结果就是会每隔两秒输出四行内容\nfun main() { val threadNum = 30 val threadPool = Executors.newFixedThreadPool(threadNum) val semaphore = Semaphore(4) for (index in 1..threadNum) { threadPool.execute { semaphore.acquire() try { Thread.sleep(2000) println(\u0026#34;over $index\u0026#34;) } finally { semaphore.release() } } } } 5、Exchanger Exchanger 可用于实现在两个线程之间交换数据的功能。当线程 A 先通过 Exchanger 发起交换数据的请求时，线程 A 会被暂停运行直到线程 B 也发起交换数据的请求，当数据交换完成后，两个线程就会各自继续运行\nfun main() { val exchanger = Exchanger\u0026lt;String\u0026gt;() val threadA = object : Thread() { override fun run() { sleep(2000) val result = exchanger.exchange(\u0026#34;A\u0026#34;) println(\u0026#34;Thread A: $result\u0026#34;) } } val threadB = object : Thread() { override fun run() { sleep(2000) val result = exchanger.exchange(\u0026#34;B\u0026#34;) println(\u0026#34;Thread B: $result\u0026#34;) } } threadA.start() threadB.start() } Thread B: A Thread A: B 五、ThreadLocal 以上介绍的几个线程同步工具类，目的都是为了在多个线程之间实现一种等待机制，即在线程 A 完成目标行为前，线程 B 能够依靠这些线程同步工具类进行等待，直到线程 A 完成\nThreadLocal 不太一样，ThreadLocal 也是用于多线程环境，但其实现的目的是为了进行数据隔离，为每一个线程维护一个独有的全局变量，从而解决共享变量的并发安全问题\n例如，以下代码中 mainThread 可以获取到值但 subThread 获取到的是 null，因为 mainThread 进行了赋值操作而 subThread 没有，每个线程只会获取到自己对 ThreadLocal 的赋值结果\npublic static void main(String[] args) throws InterruptedException { ThreadLocal\u0026lt;String\u0026gt; threadLocal = new ThreadLocal\u0026lt;\u0026gt;(); threadLocal.set(\u0026#34;业志陈\u0026#34;); Thread subThread = new Thread() { @Override public void run() { System.out.println(\u0026#34;subThread :\u0026#34; + threadLocal.get()); } }; subThread.start(); subThread.join(); System.out.println(\u0026#34;mainThread: \u0026#34; + threadLocal.get()); } subThread :null mainThread: 业志陈 这里来简单看下 ThreadLocal 的源码实现\nThreadLocal 是一个泛型类，其对外部开放的方法主要就是 get()、set(T)、remove()、initialValue() 四个方法\nget() 方法用于获取 ThreadLocal 保存的值，该方法会根据当前线程获取到一个 ThreadLocalMap，从名字上就可以看出 ThreadLocalMap 具有存储键值对的特性（虽然并没有实现 Map 接口），会以当前 ThreadLocal 对象作为 key 来进行取值。可以看到，该 ThreadLocalMap 就保存在当前线程所代表的 Thread 对象中，即 threadLocals，所以不同线程间会维护单独一份数据，从而实现数据隔离\n如果 ThreadLocal 还未赋值过，则会调用 setInitialValue() 方法来进行初始化，所以我们可以通过重写 initialValue() 方法来设置 ThreadLocal 对所有线程的默认初始值\npublic T get() { Thread t = Thread . currentThread (); ThreadLocalMap map = getMap (t); if (map != null) { ThreadLocalMap.Entry e = map . getEntry (this); if (e != null) { @SuppressWarnings(\u0026#34;unchecked\u0026#34;) T result =(T) e . value; return result; } } return setInitialValue(); } private T setInitialValue() { T value = initialValue (); Thread t = Thread . currentThread (); ThreadLocalMap map = getMap (t); if (map != null) map.set(this, value); else createMap(t, value); return value; } protected T initialValue() { return null; } ThreadLocalMap getMap(Thread t) { return t.threadLocals; } void createMap(Thread t, T firstValue) { t.threadLocals = new ThreadLocalMap (this, firstValue); } set(T) 和 remove()两个方法也是以当前 ThreadLocal 作为 key，对 ThreadLocalMap 进行赋值操作和移除操作\npublic void set(T value) { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); } public void remove() { ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this); } 可以看到，ThreadLocal 的主要实现逻辑还是在于 ThreadLocalMap，每个 Thread 都有自己单独的一个 ThreadLocalMap 对象，ThreadLocal 就以自身作为 key 来存储在 ThreadLocalMap 中，每个 ThreadLocal 就用于为本线程维护一个特定的值，从而使得不同线程间即使是使用同个 ThreadLocal 对象也可以单独维护一个特定的值\npublic class Thread implements Runnable { ThreadLocal.ThreadLocalMap threadLocals = null; } 由于一个线程可以关联多个 ThreadLocal，所以 ThreadLocalMap 就以数组的形式 Entry[] 来存储 ThreadLocal\nstatic class ThreadLocalMap { static class Entry extends WeakReference\u0026lt;ThreadLocal\u0026lt;?\u0026gt;\u0026gt; { /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal\u0026lt;?\u0026gt; k, Object v) { super(k); value = v; } } private static final int INITIAL_CAPACITY = 16; private Entry[] table; private int size = 0; ThreadLocalMap(ThreadLocal\u0026lt;?\u0026gt; firstKey, Object firstValue) { table = new Entry[INITIAL_CAPACITY]; int i = firstKey.threadLocalHashCode \u0026amp; (INITIAL_CAPACITY - 1); table[i] = new Entry(firstKey, firstValue); size = 1; setThreshold(INITIAL_CAPACITY); } ··· } ThreadLocal 和关联的 value 会被包装为一个 Entry 对象，Entry 以弱引用的方式来保存 ThreadLocal。ThreadLocalMap 的一个重要知识点就是考察为什么要以弱引用的方式来保存 ThreadLocal\n想象这么一个场景，就能明白为什么不使用强引用的方式\n假设创建 ThreadLocal 变量的是线程 A，线程 B 访问了 ThreadLocal 后就会将其保存到自身的 ThreadLocalMap 中。当线程 A 结束运行，由于使用了弱引用，ThreadLocal 在没有外部强引用时一进行 GC 就会被回收，避免了内存泄漏，这种情况就是最理想的了。如果使用强引用，那么就需要等到线程 B 也结束运行后 ThreadLocal 才能被回收，而这可能需要一段比较长的时间，即使在这个过程中线程 B 都没有再次使用 ThreadLocal\n但依靠弱引用也无法完全避免内存泄漏问题，因为线程 A 可能是线程池中的某个线程，可以不断被复用，此时即使 ThreadLocal 被回收了，其对应的 value 却会一直被保留着，这就造成了 ThreadLocalMap 会保留着 key 为 null 但 value 不为 null 的 Entry 对象，value 无法被回收，此时就一样会造成内存泄漏。为了解决该问题，就需要在线程 A 不再需要使用到 ThreadLocal 时主动调用 remove() 方法移除掉 Entry 对象\n六、线程中断机制 以上介绍的几种线程间协作方法的使用初衷都是希望线程完成各自操作后能互相通知。可是还存在这么一种情况：一个线程请求另外一个线程停止其正在执行的任务。例如，对于一个地图应用来说，当用户退出应用时，就需要停止后台线程正在执行的定位任务，因为此时该任务对于用户来说是不需要的了\n一个线程向另一个线程发起请求，希望其停止任务的机制就称为线程中断机制。中断（interrupt）是由发起线程向目标线程发送的一种指示，该指示用于表示发起线程希望目标线程停止其正在执行的任务。发起线程的中断请求并不是一个强制性的行为，目标线程可能会在收到中断指示时停止任务，也可能完全不做任何响应，这取决于目标线程对中断请求的处理逻辑\nJava 平台会为每个线程维护一个被称为中断标记的布尔型变量来表示相应线程是否收到了中断，值为 true 则表示收到了中断请求。Thread 类包含以下几个和中断相关的方法\npublic class Thread implements Runnable { //向此线程发起中断请求 public void interrupt() { ... } //在获取中断标记的同时将中断标记置为 false public static boolean interrupted() { ... } //获取中断标记 public boolean isInterrupted() { ... } } 目标线程收到中断请求后所执行的操作，被称为目标线程对中断的响应，简称中断响应。目标线程对中断的响应类型一般包括：\n无影响。例如，ReentrantLock.lock() 或者内部锁申请等操作时，都不会对中断进行响应，即不会停止当前正在执行的操作 取消任务的运行。例如，目标线程可以在每次执行任务前均检查中断标记，当中断标记为 true 时则取消当前任务，但还是会继续处理其他任务 停止线程。即令目标线程放弃执行所有任务，生命周期状态变更为 TERMINATED Java 标准库中的许多阻塞方法对中断的响应都是抛出 InterruptedException 等异常。能够响应中断的方法通常是在执行阻塞操作前判断中断标记，若中断标记为 true 则直接抛出 InterruptedException。例如，ReentrantLock.lockInterruptibly() 方法会在执行申请锁这个阻塞操作前检查当前线程的中断标记，当中断标记为 true 时则会抛出 InterruptedException。而按照惯例，抛出 InterruptedException 异常的方法一般都会在抛出该异常之前将当前线程的中断标记重置为 false。例如，ReentrantLock.lockInterruptibly() 方法会通过在 acquireInterruptibly() 方法里调用 Thread.interrupted() 来获取并重置中断标记\npublic final void acquireInterruptibly(int arg) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) doAcquireInterruptibly(arg); } 如果目标线程在收到中断请求的时候已经由于执行了一些阻塞操作而处于暂停状态，那么 Java 虚拟机可能会将目标线程唤醒，从而使得目标线程被唤醒后继续执行的代码可以再次得到响应中断的机会\n七、如何实现单例模式 单例模式是 GOF 设计模式中比较容易理解且应用非常广泛的一种设计模式，但是实现一个能够在多线程环境下正常运行且兼顾到性能的单例模式却不是一个简单的事情，这需要我们同时运用到锁、volatile 变量、原子性、可见性、有序性等多方面的知识\n1、单线程环境 在单线程环境下，我们无需考虑原子性、可见性、有序性等问题，所以仅需要做到懒加载即可\npublic final class Singleton { private static Singleton instance = null; private Singleton() { } public static Singleton getInstance() { if (instance == null) { //操作1 instance = new Singleton(); //操作2 } return instance; } } 2、双重检查锁定 对于上述的在单线程环境下可以正常使用的单例模式，在多线程环境下就很容易出现问题。getInstance()方法本身是基于 check-then-act 操作来判断是否需要初始化共享变量的，该操作并不是一个原子操作。在 instance 还为 null 时，假设有两个线程 T1 和 T2 同时执行到操作1，接着在 T1 执行操作2之前 T2 已经执行完操作2，在下一时刻，当 T1 执行到操作2的时候，即使 instance 当前已经不为 null，但是 T1 此时依然会多创建一个实例，这就导致了多个实例的创建\n首先，我们最先想到的可能是通过加锁来避免这种情况\npublic static Singleton getInstance() { synchronized (Singleton.class) { if (instance == null) { instance = new Singleton(); } } return instance; } 上述方式实现的单例模式固然是线程安全的，但是这也意味着 getInstance()方法的任何一个执行线程都需要申请锁，为了避免无谓的锁开销，人们又想到以下这种方法，即双重检查锁定。在执行临界区代码前先判断 instance 是否为 null，如果不为 null ，则直接返回 instance 变量，否则才执行临界区代码来完成 instance 变量的初始化\npublic static Singleton getInstance() { if (instance == null) { //操作1 synchronized (Singleton.class) { if (instance == null) { //操作2 instance = new Singleton(); //操作3 } } } return instance; } 上述代码表现出来的初始化逻辑可以分为两种情况，这两种情况的前置前提是：存在两个线程 T1 和 T2 ，线程 T1 执行到了操作1，线程 T2 执行到了临界区\n当线程 T1 执行到操作1的时候线程 T2 已经执行完了操作3，发现此时 instance 不为 null，直接返回 instance 变量，避免了锁的开销 当线程 T1 执行到操作1的时候发现 instance 为 null，此时线程 T2 还处于执行操作3之前，那么当线程 T2 执行临界区结束之前，线程 T1 均会处于等待状态。当线程 T2 执行完毕，线程 T1 进入临界区后，由于此时线程 T1 是在临界区内读取共享变量 instance 的，因此 T1 可以发现此刻 instance 不为 null，于是 T1 不会执行操作3，从而避免了再次创建一个实例 上述代码看起来似乎避免了锁的开销又保障了线程安全，但还是有着一些逻辑缺陷，因为该方法仅考虑到了可见性，而没有考虑到发生重排序的情况\n操作3可以分解为以下三条伪指令所代表的子操作\nobjRef = allocate(Singleton.class) //子操作1，分配对象所需的存储空间 invokeConstructor(objRef) //子操作2，初始化 objRef 引用的对象 instance = objRef //子操作3，将对象引用写入共享变量 由于临界区内的代码是有可能被重排序的，因此，JIT 编译器可能将上述的子操作重排序为：子操作1 -\u0026gt; 子操作3 -\u0026gt; 子操作2。即在初始化对象之前将对象的引用写入实例变量 instance。由于锁对有序性的保障是有条件的，而线程 T1 在临界区之外检查 instance 是否为 null 的时候并没有加锁，因此上述重排序对于线程 T1 来说是有影响的，这会使得线程 T1 得到一个不为 null 但内部还未完全初始化完毕的 instance 变量，从而造成一些意想不到的错误\n在分析清楚问题的原因后，解决方法也就不难想到：只要将 instance 变量采用 volatile 修饰即可，这实际上是利用了 volatile 关键字的以下两个作用：\n保障可见性。一个线程通过执行 instance = new Singleton() 修改了 instance 变量值，其它线程可以读取到相应的值 保障有序性。由于 volatile 能够禁止 volatile 变量写操作与该操作之前的任何读、写操作进行重排序，因此，用 volatile 修饰 instance 相当于禁止 JIT 编译器以及处理器将子操作2重排序到子操作3之后，这保障了一个线程读取到 instance 变量所引用的实例时该实例已经初始化完毕 因此，双重检查锁定的单例模式其正确的实现方式如下所示\npublic final class Singleton { private static volatile Singleton instance = null; private Singleton() { } public static Singleton getInstance() { if (instance == null) { synchronized (Singleton.class) { if (instance == null) { instance = new Singleton(); } } } return instance; } public static void main(String[] args) { Singleton singleton = Singleton.getInstance(); } } 3、静态内部类 类的静态变量被初次访问时会触发 Java 虚拟机对该类进行初始化，即该类的静态变量的值会变为其初始值而不再是默认值（例如，引用型变量的默认值是 null，int 的默认值是 0）。因此，静态方法 getInstance() 被调用的时候 Java 虚拟机会初始化这个方法所访问的内部静态类 InstanceHolder。这使得 InstanceHolder 的静态变量 INSTANCE 被初始化，从而使得 Singleton 类的唯一实例得以创建。由于类的静态变量只会创建一次，因此 Singleton 也只会有一个实例变量\npublic final class Singleton { private Singleton() { } private final static class InstanceHolder { final static Singleton INSTANCE = new Singleton(); } public static Singleton getInstance() { return InstanceHolder.INSTANCE; } public static void main(String[] args) { Singleton singleton = Singleton.getInstance(); } } 4、枚举类 枚举类 Singleton 相当于一个单例类，其字段 INSTANCE 相当于该类的唯一实例。这个实例是在 Singleton.INSTANCE 初次被引用的时候才会被初始化的。仅访问 Singleton 本身（例如 Singleton.class.getName() ）并不会导致 Singleton 的唯一实例被初始化\npublic class SingletonExample { public static void main(String[] args) { Singleton.INSTANCE.doSomething(); } public enum Singleton { INSTANCE; void doSomething() { } } } ","permalink":"http://localhost:1313/hugo-blog/public/post/kotlin/java-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%BC%80%E5%8F%912%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5/","tags":[],"title":"Java 多线程开发（2）怎么实现多线程同步"},{"categories":[],"content":" 公众号：字节数组 希望对你有所帮助 🤣🤣\n目前，多线程编程可以说是在大部分平台和应用上都需要实现的一个基本需求。本系列文章就来对 Java 平台下的多线程编程知识进行讲解，从概念入门、底层实现到上层应用都会涉及到，预计一共会有五篇文章，希望对你有所帮助 😎😎\n本篇文章是第三篇，来介绍四种不同类型的线程活性故障现象，这是开发者所必须应对的异常情况\n线程活性故障是由于资源稀缺性或者程序自身的问题导致线程一直处于非 Runnable 状态，或者线程虽然处于 Runnable 状态但是其要执行的任务一直无法取得进展的一种故障现象\n下面就来介绍几种常见类型的线程活性故障：\n死锁\n锁死\n线程饥饿\n活锁\n一、死锁 如果多个线程因互相等待对方而被永远暂停（生命周期状态为 Blocked 或者 Waiting），那么就称这些线程产生了死锁（Deadlock）。由于产生死锁的线程的生命周期状态永远是非运行状态，所以如果没有外力作用，这些线程所要执行的任务就永远也无法取得进展\n例如，线程 A 在持有锁 L1 的情况下申请锁 L2，同时线程 B 在持有锁 L2 的情况下在申请锁 L1，而线程 A 和线程 B 各自要求只有在取得对方的锁后才能释放持有的锁，这就导致了两个锁都将处于无限等待的状态，此时死锁就发生了\n有关死锁的一个经典问题是哲学家就餐问题。五位哲学家围着一张圆桌，每位哲学家之间均放着一根筷子，即一共有五根筷子。每位哲学家要么处于思考状态，要么是在吃饭。吃饭前，每位哲学家均会先拿起左手边的筷子，再拿起右手边的筷子，只有当手上持有了一双筷子时哲学家才能够吃饭，且除非本次吃饭行为完成，否则哲学家不会放下手中已持有的筷子。哲学家吃完饭后就会放下手中的筷子，再次思考一段时间后再进行吃饭\n在这个问题中，每位哲学家就相当于一个线程，每根筷子就相当于多条线程间的共享资源。且筷子明显是一个排他性资源，因为每根筷子每次只能由一位哲学家持有，因此哲学家在拿起筷子前需要先取得筷子对应的锁。由于筷子和哲学家的数量相等，而每位哲学家需要的筷子数量是现有的两倍，所以发生死锁的可能性还是很大的\n我们可以用一段程序来模拟并验证上述的情况\n先对筷子 Chopstick 进行定义，其能被操作的行为只有两种，即：拿起和放下\nenum class ChopstickStatus { UP, Down } data class Chopstick(val id: Int) { var status = ChopstickStatus.Down private set fun pickUp() { status = ChopstickStatus.UP } fun putDown() { status = ChopstickStatus.Down } } 每位哲学家 Philosopher 均对应一个唯一的标识 id，一根左手边的筷子 left，一根右手边的筷子 right。会不间断地进行“思考”和“吃饭”两种行为，每种行为均包含一段随机的时间间隔（随机的线程休眠）\nprivate object Tools { fun randomSleep(max: Long = 30) { val realMax = max.coerceAtLeast(1) ThreadLocalRandom.current().nextLong(if (realMax == 1L) 0 else 1, max + 1) } } data class Philosopher(val id: Int, val left: Chopstick, val right: Chopstick) : Thread(\u0026#34;Philosopher-$id\u0026#34;) { override fun run() { while (true) { think() eat() } } private fun eat() { synchronized(left) { println(\u0026#34;$name 拿起了左边的筷子: \u0026#34; + left.id) left.pickUp() synchronized(right) { println(\u0026#34;$name 拿起了右边的筷子: \u0026#34; + right.id) right.pickUp() println(\u0026#34;$name 开始吃饭.....\u0026#34;) Tools.randomSleep(10) println(\u0026#34;$name 吃饭结束!!!!!!!!!!\u0026#34;) right.putDown() } left.putDown() } } private fun think() { println(\u0026#34;$name 思考中....\u0026#34;) Tools.randomSleep(100) } } 然后，我们创建五根筷子，并将每根筷子按顺序分配给每位哲学家，然后就启动哲学家的思考和吃饭行为（启动线程）\n/** * @Author: leavesCZY * @Github：https://github.com/leavesCZY */ fun main() { val philosopherNumber = 5 val chopstickList = mutableListOf\u0026lt;Chopstick\u0026gt;() for (i in 0 until philosopherNumber) { chopstickList.add(Chopstick(i)) } val philosopherList = mutableListOf\u0026lt;Philosopher\u0026gt;() for (index in 0 until philosopherNumber) { val left = chopstickList[index] val right = chopstickList.getOrNull(index - 1) ?: chopstickList.last() philosopherList.add(Philosopher(index, left, right)) } philosopherList.forEach { println(it.name + \u0026#34; 左手边的筷子是：\u0026#34; + it.left + \u0026#34; 右手边的筷子是：\u0026#34; + it.right) } philosopherList.forEach { it.start() } } 最后，运行程序后，只要我们为哲学家设定每次思考和吃饭的耗时时间不要太长，那么应该就能很快看到程序没有继续输出日志了，似乎被卡住了，此时即发生了死锁\nPhilosopher-0 左手边的筷子是：Chopstick(id=0) 右手边的筷子是：Chopstick(id=4) Philosopher-1 左手边的筷子是：Chopstick(id=1) 右手边的筷子是：Chopstick(id=0) Philosopher-2 左手边的筷子是：Chopstick(id=2) 右手边的筷子是：Chopstick(id=1) Philosopher-3 左手边的筷子是：Chopstick(id=3) 右手边的筷子是：Chopstick(id=2) Philosopher-4 左手边的筷子是：Chopstick(id=4) 右手边的筷子是：Chopstick(id=3) Philosopher-0 思考中.... Philosopher-1 思考中.... Philosopher-2 思考中.... Philosopher-3 思考中.... Philosopher-4 思考中.... Philosopher-0 拿起了左边的筷子: 0 Philosopher-2 拿起了左边的筷子: 2 Philosopher-3 拿起了左边的筷子: 3 Philosopher-0 拿起了右边的筷子: 4 Philosopher-0 开始吃饭..... Philosopher-0 吃饭结束!!!!!!!!!! Philosopher-2 拿起了右边的筷子: 1 Philosopher-2 开始吃饭..... Philosopher-2 吃饭结束!!!!!!!!!! Philosopher-0 思考中.... Philosopher-0 拿起了左边的筷子: 0 Philosopher-4 拿起了左边的筷子: 4 Philosopher-3 拿起了右边的筷子: 2 Philosopher-3 开始吃饭..... Philosopher-3 吃饭结束!!!!!!!!!! Philosopher-3 思考中.... Philosopher-4 拿起了右边的筷子: 3 Philosopher-4 开始吃饭..... Philosopher-4 吃饭结束!!!!!!!!!! Philosopher-2 思考中.... Philosopher-4 思考中.... Philosopher-1 拿起了左边的筷子: 1 Philosopher-2 拿起了左边的筷子: 2 Philosopher-3 拿起了左边的筷子: 3 Philosopher-0 拿起了右边的筷子: 4 Philosopher-0 开始吃饭..... Philosopher-0 吃饭结束!!!!!!!!!! Philosopher-0 思考中.... Philosopher-0 拿起了左边的筷子: 0 Philosopher-4 拿起了左边的筷子: 4 根据输出日志可以分析出，最后每位哲学家均拿到了其左手边的筷子，且均在等待右手边的筷子被放下，但此时由于筷子是独占资源，所以每位哲学家都只能干瞪着眼无法吃饭，最终导致了死锁\n二、死锁的产生条件 哲学家就餐问题反映了发生死锁的必要条件，线程一旦发生死锁，那么这些线程及相关的共享资源就一定同时满足以下条件：\n资源互斥。涉及的资源必须是排他性资源，即每个资源每次只能由一个线程持有 资源不可抢夺。涉及的资源只能由其持有线程主动释放，其它线程无法从持有线程中主动夺得 占用并等待其它资源。涉及的线程当前至少已经持有了一个排他性资源，并在申请其它资源，而这些资源同时又被其它线程所持有。在这个资源等待过程中，线程不会主动释放持有的现有资源 循环等待资源。在涉及到的所有线程列表内部，每个线程均在互相等待其它线程释放持有的资源，形成了互相等待的圆形依赖关系。即存在一个处于等待状态的线程集合 {T1, T2, \u0026hellip;, Tn}，其中 Ti 等待的资源被 T(i+1) 占有（i 大于等于 1 小于 n），Tn 等待的资源被 T1 占有 以上条件是死锁产生的必要条件而非充分条件，即只要产生了死锁，以上条件就一定同时成立，但是上诉条件即使同时成立也未必就一定能产生死锁。例如，对于上诉的第四点，如果线程 T1 等待的资源数大于一，除了等待 T2 主动释放持有的一份资源外，T1 还可以通过获取循环圈外的多余资源来打破线程间的循环等待关系，从而避免造成死锁\n三、规避死锁 如果把 Java 平台下的锁（Lock）当做一种资源，那么这种资源就正好符合“资源互斥”和“资源不可抢夺”的要求，在这种情况下，产生死锁的代码特征就是在持有一个锁的情况下去申请另外一个锁，这通常意味着锁的嵌套。但是，一个线程在已经持有一个锁的情况下再次申请这个锁并不会导致死锁，这是因为 Java 中的锁都是可重入的（Reentrant），这种情形下线程重复申请某个锁是可以成功的\n从上诉的四个发生死锁的必要条件来反推，我们只要消除死锁产生的任意一个必要条件就可以规避死锁了。由于锁具有排他性且只能由其持有线程来主动释放，因此由锁导致的死锁只能从消除“占用并等待资源”和消除“循环等待资源”这两个方向入手。以下就来介绍基于这两个思路来规避死锁的方法\n1、粗锁法 粗锁法即使用粗粒度的锁来代替多个锁。“占用并等待资源”这个条件隐含的情况即：线程在持有一个锁的同时还去申请另一个锁。那么，只要采用一个粒度较粗的锁来替代原先粒度较细的锁，使得涉及的资源都只需要申请一个锁就可以获得，那么就可以避免死锁\n对应上诉的哲学家就餐问题，只要将 Philosopher 拿左手边筷子和拿右手边筷子的行为统一放到同个锁内，就可以消除“占用并等待资源”和“循环等待资源”这两个条件了\ndata class Philosopher(val id: Int, val left: Chopstick, val right: Chopstick) : Thread(\u0026#34;Philosopher-$id\u0026#34;) { companion object { private val LOCK = Object() } override fun run() { while (true) { think() eat() } } private fun eat() { synchronized(LOCK) { println(\u0026#34;$name 拿起了左边的筷子: \u0026#34; + left.id) left.pickUp() println(\u0026#34;$name 拿起了右边的筷子: \u0026#34; + right.id) right.pickUp() println(\u0026#34;$name 开始吃饭.....\u0026#34;) Tools.randomSleep(10) println(\u0026#34;$name 吃饭结束!!!!!!!!!!\u0026#34;) right.putDown() left.putDown() } } private fun think() { println(\u0026#34;$name 思考中....\u0026#34;) Tools.randomSleep(100) } } 粗锁法的缺点就是它明显降低了并发性并可能导致资源浪费。修改过后的代码，每次只有一位哲学家能够吃饭。如果每位哲学家吃饭的耗时相对其思考的时间要长得多，那么在持有筷子的哲学家吃饭结束前，有可能其他哲学家都已经处于等待筷子的状态了（即锁的争用程度比较高，多个线程由于申请不到锁而被暂停，每次锁的争夺可能会经历多次线程上下文切换）。而如果每位哲学家吃饭的耗时相对其思考的时间要短得多，那么就有可能在非持有筷子的哲学家结束思考前，持有筷子的哲学家就已经吃饭结束了（即锁的争用比较低，每次只有一个线程来申请锁，此时就不会由于申请锁而导致线程上下文切换）\n即使锁的争用程度比较低，一位哲学家在吃饭的时候也仅需要占用两根筷子，剩下的三根筷子本来还可以提供给另外一位哲学家使用，此时采用粗锁法就明显导致了资源的浪费。因此，粗锁法的适用范围较为有限\n2、锁排序法 锁排序法的思路是：对所有锁按照一定规则进行排序，所有线程在申请锁之前均按照先后顺序进行申请，以此来消除“循环等待资源”这个条件，从而来规避死锁\n例如，对上诉的哲学家问题进行简单化。假设哲学家的数量是 2。哲学家1的左手边是筷子2，右手边是筷子1；哲学家2的左手边是筷子1，右手边是筷子2。当两位哲学家同时拿起左手边的筷子时，此时就会发生死锁。而如果对筷子的申请顺序进行要求，要求哲学家需要先拿起 ID 较小的筷子才能去申请 ID 较大的筷子，那么此时先拿到筷子1的哲学家就可以无竞争地拿到筷子2，从而避免了“循环等待资源”的情况\ndata class Philosopher(val id: Int, val left: Chopstick, val right: Chopstick) : Thread(\u0026#34;Philosopher-$id\u0026#34;) { private val one: Chopstick private val theOther: Chopstick init { //每位哲学家都对其左右两边的筷子进行排序 //都按照“先取ID小的筷子再取ID大的筷子”的这种规则来拿筷子 if (left.id \u0026lt; right.id) { one = left theOther = right } else { one = right theOther = left } } override fun run() { while (true) { think() eat() } } private fun eat() { synchronized(one) { println(\u0026#34;$name 拿起了左边的筷子: \u0026#34; + left.id) left.pickUp() synchronized(theOther) { println(\u0026#34;$name 拿起了右边的筷子: \u0026#34; + right.id) right.pickUp() println(\u0026#34;$name 开始吃饭.....\u0026#34;) Tools.randomSleep(10) println(\u0026#34;$name 吃饭结束!!!!!!!!!!\u0026#34;) right.putDown() left.putDown() } } } private fun think() { println(\u0026#34;$name 思考中....\u0026#34;) Tools.randomSleep(100) } } 3、资源限时申请 避免死锁的另一种方法是在申请资源时设定一个超时时间，避免无限制地等待资源，从而消除“占用并等待资源”这种情况。当等待时间超出既定的限制时，释放已持有的资源（哲学家放下左手边的筷子转而去继续思考）先给其它线程使用，待后续再重新申请资源\ndata class Philosopher(val id: Int, val left: Chopstick, val right: Chopstick) : Thread(\u0026#34;Philosopher-$id\u0026#34;) { companion object { private val LOCK_MAP = ConcurrentHashMap\u0026lt;Chopstick, ReentrantLock\u0026gt;() } init { LOCK_MAP.putIfAbsent(left, ReentrantLock()) LOCK_MAP.putIfAbsent(right, ReentrantLock()) } override fun run() { while (true) { think() eat() } } private fun eat() { val leftLock = LOCK_MAP[left]!! val leftLockAcquired = leftLock.tryLock(10, TimeUnit.MILLISECONDS) if (!leftLockAcquired) { return } val rightLock = LOCK_MAP[right]!! val rightLockAcquired = rightLock.tryLock(10, TimeUnit.MILLISECONDS) if (!rightLockAcquired) { leftLock.unlock() return } println(\u0026#34;$name 拿起了左边的筷子: \u0026#34; + left.id) left.pickUp() println(\u0026#34;$name 拿起了右边的筷子: \u0026#34; + right.id) right.pickUp() println(\u0026#34;$name 开始吃饭.....\u0026#34;) Tools.randomSleep(10) println(\u0026#34;$name 吃饭结束!!!!!!!!!!\u0026#34;) right.putDown() left.putDown() leftLock.unlock() rightLock.unlock() } private fun think() { println(\u0026#34;$name 思考中....\u0026#34;) Tools.randomSleep(100) } } 四、死锁的恢复 死锁的恢复有着一定难度，原因主要有以下几点\n如果代码中使用的是内部锁，或者使用的是显式锁的 Lock.lock() 方法，那么这些锁导致的死锁是无法恢复的，此时只能通过重启 Java 虚拟机来停止程序 可以通过定义一个工作者线程专门用于检测和恢复死锁。该线程定时检测系统中是否存在死锁，如果存在，则选择一个死锁线程向其发送中断。该中断使得相应的死锁线程被唤醒并抛出 InterruptedException 异常，死锁线程捕获到 InterruptedException 异常后主动释放已持有的资源，从而“消除并等待资源”这个条件。如果该死锁线程释放已持有的线程后依然存在死锁，工作者线程就继续选择一个死锁线程进行中断处理，直到消除死锁。这种方法依赖于发生死锁的线程能够响应中断，而能响应中断的同时并释放已持有的资源就意味着在一开始我们就考虑到了可能会发生死锁，那么我们应该在一开始就做好死锁的预防，而不是使死锁线程支持死锁的恢复处理 即使死锁线程能够在响应中断的同时并释放已持有的资源，那么检测死锁的工作者线程应该按照什么顺序来中断死锁线程依然是个问题，且被中断的死锁线程可能会丢失其之前已经完成的计算任务，从而导致各种意想不到的情况 这里根据第一节内容中会发生死锁的哲学家问题，来尝试恢复死锁\n定义一个死锁检测线程 DeadlockDetector，它会每隔一段时间定时检测当前系统是否发生了死锁，如果发生了的话，则从涉及到死锁的所有线程中选择一个线程向其发送中断请求，被中断的线程内部需要捕获中断异常，然后自动释放其持有的资源，尝试将资源让给其它线程使用，从而打破占用并等待其它资源和资源循环等待两个条件\n/** * @Author: leavesCZY * @Github：https://github.com/leavesCZY */ class DeadlockDetector(monitorInterval: Long) : Thread(\u0026#34;DeadlockDetector\u0026#34;) { companion object { private val tmb = ManagementFactory.getThreadMXBean() //获取发生死锁时涉及到的所有线程 fun findDeadlockedThreads(): Array\u0026lt;ThreadInfo\u0026gt; { val ids = tmb.findDeadlockedThreads() return if (tmb.findDeadlockedThreads() == null) arrayOf() else tmb.getThreadInfo(ids) ?: arrayOf() } fun findThreadById(threadId: Long): Thread? { for (thread in getAllStackTraces().keys) { if (thread.id == threadId) { return thread } } return null } //向线程发送中断 fun interruptThread(threadId: Long): Boolean { val thread = findThreadById(threadId) if (thread != null) { thread.interrupt() return true } return false } } //检测周期，单位为毫秒 private val monitorInterval: Long init { isDaemon = true this.monitorInterval = monitorInterval } override fun run() { var threadInfoList: Array\u0026lt;ThreadInfo\u0026gt; var ti: ThreadInfo? var i = 0 try { while (true) { threadInfoList = findDeadlockedThreads() if (threadInfoList.isNotEmpty()) { ti = threadInfoList[i++ % threadInfoList.size] interruptThread(ti.threadId) continue } else { i = 0 } sleep(monitorInterval) } } catch (e: InterruptedException) { e.printStackTrace() } } } Philosopher 通过 Lock.lockInterruptibly() 方法来申请锁，该方法可以响应中断。此时就可以在捕获到中断异常时自动释放已持有的资源\ndata class Philosopher(val id: Int, val left: Chopstick, val right: Chopstick) : Thread(\u0026#34;Philosopher-$id\u0026#34;) { companion object { private val LOCK_MAP = ConcurrentHashMap\u0026lt;Chopstick, ReentrantLock\u0026gt;() } init { LOCK_MAP.putIfAbsent(left, ReentrantLock()) LOCK_MAP.putIfAbsent(right, ReentrantLock()) } override fun run() { while (true) { think() eat() } } private fun eat() { val leftLock = LOCK_MAP[left]!! try { leftLock.lockInterruptibly() } catch (e: InterruptedException) { e.printStackTrace() println(\u0026#34;$name ==========放弃等待左边的筷子: \u0026#34; + left.id) return } println(\u0026#34;$name 拿起了左边的筷子: \u0026#34; + left.id) left.pickUp() val rightLock = LOCK_MAP[right]!! try { rightLock.lockInterruptibly() } catch (e: InterruptedException) { e.printStackTrace() println(\u0026#34;$name ==========放弃等待右边的筷子: \u0026#34; + right.id) left.putDown() println(\u0026#34;$name ====================放下已持有的左边的筷子: \u0026#34; + left.id) leftLock.unlock() return } println(\u0026#34;$name 拿起了右边的筷子: \u0026#34; + right.id) right.pickUp() println(\u0026#34;$name 开始吃饭.....\u0026#34;) Tools.randomSleep(10) println(\u0026#34;$name 吃饭结束!!!!!!!!!!\u0026#34;) left.putDown() right.putDown() leftLock.unlock() rightLock.unlock() } private fun think() { println(\u0026#34;$name 思考中....\u0026#34;) Tools.randomSleep(100) } } /** * @Author: leavesCZY * @Github：https://github.com/leavesCZY */ fun main() { val philosopherNumber = 5 val chopstickList = mutableListOf\u0026lt;Chopstick\u0026gt;() for (i in 0 until philosopherNumber) { chopstickList.add(Chopstick(i)) } val philosopherList = mutableListOf\u0026lt;Philosopher\u0026gt;() for (index in 0 until philosopherNumber) { val left = chopstickList[index] val right = chopstickList.getOrNull(index - 1) ?: chopstickList.last() philosopherList.add(Philosopher(index, left, right)) } philosopherList.forEach { println(it.name + \u0026#34; 左手边的筷子是：\u0026#34; + it.left + \u0026#34; 右手边的筷子是：\u0026#34; + it.right) } philosopherList.forEach { it.start() } DeadlockDetector(2000).start() } 从日志输出可以看出来，线程 Philosopher-4 在收到中断请求时释放了其持有的资源，但很快又发生了死锁，因为线程 Philosopher-4 释放的资源可以由所有需要的线程进行抢夺，可能在 线程 Philosopher-4 刚释放了持有的资源时又马上自己抢占到了该资源。最极端的情况就是：每次收到中断的线程均释放了其持有的资源，但随后又马上自己抢占到了该资源，接着该线程（或者其它线程）又收到中断请求，又释放持有的资源，又自己抢占到该资源……如此循环往复。这种情况下所有线程依然无法获得依赖的目标资源，反而由于反复的锁申请和锁释放操作造成多次的线程上下文切换。且释放锁可能会导致线程之前的任务被无效化。所以说，死锁的恢复实际意义不大\nPhilosopher-0 左手边的筷子是：Chopstick(id=0) 右手边的筷子是：Chopstick(id=4) Philosopher-1 左手边的筷子是：Chopstick(id=1) 右手边的筷子是：Chopstick(id=0) Philosopher-2 左手边的筷子是：Chopstick(id=2) 右手边的筷子是：Chopstick(id=1) Philosopher-3 左手边的筷子是：Chopstick(id=3) 右手边的筷子是：Chopstick(id=2) Philosopher-4 左手边的筷子是：Chopstick(id=4) 右手边的筷子是：Chopstick(id=3) Philosopher-0 思考中.... Philosopher-1 思考中.... Philosopher-2 思考中.... Philosopher-3 思考中.... Philosopher-4 思考中.... Philosopher-2 拿起了左边的筷子: 2 Philosopher-3 拿起了左边的筷子: 3 Philosopher-4 拿起了左边的筷子: 4 Philosopher-0 拿起了左边的筷子: 0 Philosopher-2 拿起了右边的筷子: 1 Philosopher-2 开始吃饭..... Philosopher-2 吃饭结束!!!!!!!!!! Philosopher-2 思考中.... Philosopher-1 拿起了左边的筷子: 1 Philosopher-3 拿起了右边的筷子: 2 Philosopher-3 开始吃饭..... Philosopher-3 吃饭结束!!!!!!!!!! Philosopher-3 思考中.... Philosopher-2 拿起了左边的筷子: 2 Philosopher-3 拿起了左边的筷子: 3 java.lang.InterruptedException at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireInterruptibly(AbstractQueuedSynchronizer.java:898) at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1222) at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:335) at thread.Philosopher.eat(DeadLockDemo.kt:71) at thread.Philosopher.run(DeadLockDemo.kt:52) Philosopher-4 ==========放弃等待右边的筷子: 3 Philosopher-4 ====================放下已持有的左边的筷子: 4 Philosopher-4 思考中.... Philosopher-0 拿起了右边的筷子: 4 Philosopher-0 开始吃饭..... Philosopher-0 吃饭结束!!!!!!!!!! Philosopher-0 思考中.... Philosopher-1 拿起了右边的筷子: 0 Philosopher-1 开始吃饭..... Philosopher-4 拿起了左边的筷子: 4 Philosopher-1 吃饭结束!!!!!!!!!! Philosopher-1 思考中.... Philosopher-0 拿起了左边的筷子: 0 Philosopher-2 拿起了右边的筷子: 1 Philosopher-2 开始吃饭..... Philosopher-2 吃饭结束!!!!!!!!!! Philosopher-2 思考中.... Philosopher-3 拿起了右边的筷子: 2 Philosopher-1 拿起了左边的筷子: 1 Philosopher-3 开始吃饭..... Philosopher-3 吃饭结束!!!!!!!!!! Philosopher-3 思考中.... Philosopher-2 拿起了左边的筷子: 2 Philosopher-3 拿起了左边的筷子: 3 java.lang.InterruptedException at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireInterruptibly(AbstractQueuedSynchronizer.java:898) at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1222) at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:335) at thread.Philosopher.eat(DeadLockDemo.kt:71) at thread.Philosopher.run(DeadLockDemo.kt:52) Philosopher-4 ==========放弃等待右边的筷子: 3 Philosopher-4 ====================放下已持有的左边的筷子: 4 Philosopher-4 思考中.... Philosopher-0 拿起了右边的筷子: 4 Philosopher-0 开始吃饭..... Philosopher-0 吃饭结束!!!!!!!!!! Philosopher-0 思考中.... Philosopher-4 拿起了左边的筷子: 4 Philosopher-0 拿起了左边的筷子: 0 java.lang.InterruptedException at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireInterruptibly(AbstractQueuedSynchronizer.java:898) at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1222) at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:335) at thread.Philosopher.eat(DeadLockDemo.kt:71) at thread.Philosopher.run(DeadLockDemo.kt:52) Philosopher-4 ==========放弃等待右边的筷子: 3 Philosopher-4 ====================放下已持有的左边的筷子: 4 Philosopher-4 思考中.... Philosopher-0 拿起了右边的筷子: 4 Philosopher-0 开始吃饭..... Philosopher-0 吃饭结束!!!!!!!!!! Philosopher-0 思考中.... Philosopher-0 拿起了左边的筷子: 0 Philosopher-0 拿起了右边的筷子: 4 Philosopher-0 开始吃饭..... Philosopher-0 吃饭结束!!!!!!!!!! Philosopher-0 思考中.... Philosopher-0 拿起了左边的筷子: 0 Philosopher-0 拿起了右边的筷子: 4 Philosopher-0 开始吃饭..... Philosopher-0 吃饭结束!!!!!!!!!! Philosopher-0 思考中.... Philosopher-0 拿起了左边的筷子: 0 Philosopher-0 拿起了右边的筷子: 4 Philosopher-0 开始吃饭..... Philosopher-0 吃饭结束!!!!!!!!!! Philosopher-0 思考中.... Philosopher-0 拿起了左边的筷子: 0 Philosopher-4 拿起了左边的筷子: 4 java.lang.InterruptedException at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireInterruptibly(AbstractQueuedSynchronizer.java:898) at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1222) at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:335) at thread.Philosopher.eat(DeadLockDemo.kt:71) at thread.Philosopher.run(DeadLockDemo.kt:52) Philosopher-4 ==========放弃等待右边的筷子: 3 Philosopher-4 ====================放下已持有的左边的筷子: 4 Philosopher-4 思考中.... Philosopher-4 拿起了左边的筷子: 4 ···· 五、锁死 等待线程由于唤醒其所需的条件永远无法成立，或者是其它线程无法唤醒这个线程导致其一直处于非运行状态（线程并未终止）从而任务一直取得进展，那么我们称这个线程被锁死\n锁死和死锁之间有着共同的外在表现：故障线程一直处于非运行状态而使得其任务无法进展。死锁针对的是多个线程，而锁死可能只是作用在一个线程上。例如，一个调用了 Object.wait() 处于等待状态的线程，由于发生异常或者是代码缺陷，导致一直没有外部线程调用 Object.notify() 方法来唤醒等待线程，使得线程一直处于等待状态无法运行，此时就可以说该线程被锁死\n锁死和死锁的产生条件是不同的，即便是在产生死锁的所有必要条件都不成立的情况下（此时死锁不可能发生），锁死仍可能出现。因此应对死锁的办法未必能够用来避免锁死现象的发生。按照锁死产生的条件来分，锁死包括信号丢失锁死和嵌套监视器锁死\n1、信号丢失锁死 信号丢失锁死是由于没有相应的通知线程来唤醒等待线程而使等待线程一直处于等待状态的一种活性故障\n例如，某个等待线程在执行 Object.wait() 前没有对保护条件进行判断，而此时保护条件实际上已经成立了，然而此后可能并无其他线程会来唤醒等待线程，因为在等待线程获得 Object 内部锁之前保护条件已经是处于成立状态了，这就使得等待线程一直处于等待状态，其任务一直无法取得进展\n信号丢失锁死的另外一个常见例子是由于 CountDownLatch.countDown() 没有放在 finally 块中，而如果 CountDownLatch.countDown() 的执行线程运行时抛出未捕获的异常时， CountDownLatch.await() 的执行线程就会一直处于等待状态从而任务一直无法取得进展\n例如，对于以下代码，当 ServiceB 抛出异常时，main 线程就会由于一直无法收到唤醒通知从而一直处于等待状态\n/** * @Author: leavesCZY * @Github：https://github.com/leavesCZY */ fun main() { val serviceManager = ServicesManager() serviceManager.startServices() println(\u0026#34;等待所有 Services 执行完毕\u0026#34;) val allSuccess = serviceManager.checkState() println(\u0026#34;执行结果： $allSuccess\u0026#34;) } class ServicesManager { private val countDownLatch = CountDownLatch(2) private val serviceList = mutableListOf\u0026lt;AbstractService\u0026gt;() init { serviceList.add(ServiceA(\u0026#34;ServiceA\u0026#34;, countDownLatch)) serviceList.add(ServiceB(\u0026#34;ServiceB\u0026#34;, countDownLatch)) } fun startServices() { serviceList.forEach { it.start() } } fun checkState(): Boolean { countDownLatch.await() return serviceList.find { !it.checkState() } == null } } abstract class AbstractService(private val countDownLatch: CountDownLatch) { private var success = false abstract fun doTask(): Boolean fun start() { thread { // try { // success = doTask() // } finally { // countDownLatch.countDown() // } success = doTask() countDownLatch.countDown() } } fun checkState(): Boolean { return success } } class ServiceA(private val serviceName: String, countDownLatch: CountDownLatch) : AbstractService(countDownLatch) { override fun doTask(): Boolean { Thread.sleep(2000) println(\u0026#34;${serviceName}执行完毕\u0026#34;) return true } } class ServiceB(private val serviceName: String, countDownLatch: CountDownLatch) : AbstractService(countDownLatch) { override fun doTask(): Boolean { Thread.sleep(3000) if (Random.nextBoolean()) { throw RuntimeException(\u0026#34;$serviceName failed\u0026#34;) } else { println(\u0026#34;${serviceName}执行完毕\u0026#34;) } return true } } 2、嵌套监视器锁死 嵌套监视器锁死是嵌套锁导致等待线程永远无法被唤醒的一种活性故障\n来看以下伪代码。假设存在一个等待线程，其先后持有了 monitorX 和 monitorY 两个不同的锁，当等待线程监测到当前执行条件不成立时，调用了 monitorY.wait() 等待通知线程来唤醒自身，并同时释放了锁 monitorY\nsynchronized(monitorX) { //... synchronized(monitorY) { while (!somethingOk) { monitorY.wait() } //执行目标行为 } } 相应的通知线程其伪代码如下所示。通知线程需要持有了 monitorX 和 monitorY 两个锁才能执行到 monitorY.notifyAll() 这行代码来唤醒等待线程。而等待线程执行 monitorY.wait() 时仅会释放 monitorY，而不会释放 monitorX。这使得通知线程由于一直获得 monitorX， 从而导致等待线程一直无法被唤醒而一直处于 BLOCKED 状态\nsynchronized(monitorX) { //... synchronized(monitorY) { //... somethingOk = true monitorY.notifyAll() //... } } 这种由于嵌套锁导致通知线程始终无法唤醒等待线程的活性故障就被称为嵌套监视器锁死\n六、线程饥饿 线程饥饿是指线程一直无法获得所需资源从而导致任务无法取得进展的一种活性故障现象\n产生线程饥饿的一种情况是：线程一直没有被分配到处理器时间片。这种情况一般是由于处理器时间片一直被高优先级的线程抢占，低优先级的线程一直无法获得运行机会，此时即发生了线程饥饿现象。Thread 类提供了修改线程优先级的成员方法setPriority(Int)，定义了整数一到十之间的十个优先级级别。不同的操作系统会有不同的线程优先级等级，JVM 会把这 Thread 类的十个优先级级别映射到具体的操作系统所定义的线程优先级关系上。但是我们所设置的线程优先级对线程调度器来说只是一个建议，当我们将一个线程设置为高优先级时，既可能会被线程调度器忽略，也可能会使该线程过度优先执行而别的线程一直得不到处理器时间片，从而导致线程饥饿。因此我们应该尽量避免修改线程的优先级\n把锁看做一种资源，那么死锁也是一种线程饥饿。死锁的结果是所有故障线程都无法获得其所需的全部锁，从而使得其任务一直无法取得进展，这就相当于线程无法获得所需的全部资源从而导致任务无法取得进展，即产生了线程饥饿\n发生线程饥饿并不一定同时存在死锁。因为线程饥饿可能只发生在一个线程上（例如上述的低优先级线程无法获得时间片），且即使是同时发生在多个线程上，也可能并不满足死锁发生的必要条件之一：循环等待资源，因为此时涉及到的多个线程所等待的资源可能并没有相互依赖关系\n七、活锁 活锁指的是任务和任务的执行线程均没有被阻塞，但由于某些条件没有满足，导致线程一直在重复尝试—失败—尝试的过程，任务一直无法取得进展。也就是说，产生活锁的线程虽然处于 Runnable 状态，但是一直在做无用功\n例如，对于上述的哲学家问题，假设某位哲学家“比较有礼貌”，当其拿起了左手边的筷子时，如果恰好有其他哲学家需要这根筷子，有礼貌的哲学家就主动放下筷子，让给其他哲学家使用。在最极端的情况下，每当有礼貌的哲学家一想要吃饭并拿起左手边的筷子时，就有其他哲学家需要这根筷子，此时有礼貌的哲学就会一直处于拿起筷子-放下筷子-拿起筷子这样一个循环过程中，导致一直无法吃饭。此时并没有发生死锁，但对于有礼貌的哲学家所代表的线程来说就是发生了活锁\n","permalink":"http://localhost:1313/hugo-blog/public/post/kotlin/java-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%BC%80%E5%8F%913%E7%BA%BF%E7%A8%8B%E6%B4%BB%E6%80%A7%E6%95%85%E9%9A%9C%E6%9C%89%E5%93%AA%E4%BA%9B/","tags":[],"title":"Java 多线程开发（3）线程活性故障有哪些"},{"categories":[],"content":" 公众号：字节数组 希望对你有所帮助 🤣🤣\n目前，多线程编程可以说是在大部分平台和应用上都需要实现的一个基本需求。本系列文章就来对 Java 平台下的多线程编程知识进行讲解，从概念入门、底层实现到上层应用都会涉及到，预计一共会有五篇文章，希望对你有所帮助 😎😎\n本篇文章是第四篇，来介绍 Java 平台下的锁机制，锁是 Java 开发者实现线程同步最为简单的一种方式\n锁是 Java 开发者实现线程同步最为简单的一种方式，最简单的情形下我们只需要添加一个 synchronized 关键字就可以实现线程同步，但锁的分类细数下来也不少，JVM 自动为代码中的锁所做的优化措施也有很多，这里来对其详细讲一讲\n一、悲观锁、乐观锁 悲观锁与乐观锁两者体现了多个线程在对共享数据进行并发操作时的不同看法\n对于多个线程间的共享数据，悲观锁认为自己在使用数据的时候很有可能会有其它线程也刚好前来修改数据，因为在使用数据前都会加上锁，确保在使用过程中数据不会被其它线程修改。synchronized 关键字和 Lock 接口的实现类都属于悲观锁\n乐观锁则认为在使用数据的过程中其它线程也刚好前来修改数据的可能性很低，所以在使用数据前不会加锁，而只是在更新数据的时候判断数据之前是否有被别的线程更新了。如果数据没有被更新，当前线程就可以将自己修改后的数据成功写入。而如果数据已经被其它线程更新过了，则根据不同的实现方式来执行不同的补救操作（报错或者重复尝试）。乐观锁在 Java 中是通过使用无锁编程来实现的，最常采用的是 CAS 算法，java.util.concurrent 包中的原子类就是通过 CAS 自旋来实现的\n总的来说，悲观锁适合写操作较多的场景，加锁可以保证执行写操作时数据的正确性。乐观锁适合读操作较多的场景，不加锁能够使读操作的性能大幅度提升\nsynchronized 关键字和 Lock 接口所代表的悲观锁比较常见，这里主要来看下乐观锁\n乐观锁采用的 CAS 算法全称是 Compare And Swap（比较与交换），是一种无锁算法，在不使用锁（所以也不会导致线程被阻塞）的情况下实现在多线程之间的变量同步\nCAS 算法涉及到三个操作数：\n需要读写的内存值 V 进行比较的值 A 要写入的新值 B 当且仅当 V 的值等于 A 时，CAS 才会用新值 B 来更新 V 的值，且保证了**“比较+更新”**这整个操作的原子性。当 V 的值不等于 A 时则不会执行任何操作。一般情况下，“更新”是一个会不断重试的操作\n这里来看下 AtomicInteger 类的用于自增加一的方法 incrementAndGet() 是如何实现的。\npublic class AtomicInteger extends Number implements java.io.Serializable { private static final Unsafe unsafe = Unsafe.getUnsafe(); /** * Atomically increments by one the current value. * * @return the updated value */ public final int incrementAndGet() { return unsafe.getAndAddInt(this, valueOffset, 1) + 1; } } incrementAndGet() 方法是通过 unsafe.getAndAddInt() 来实现的。getAndAddInt() 方法会循环获取给定对象 o 中的偏移量 offset 处的值 v，然后判断内存值是否等于 v。如果相等则将内存值修改为 v + delta，否则就继续整个循环进行重复尝试，直到修改成功才退出循环，并且将旧值返回。整个“比较+更新”操作封装在 compareAndSwapInt() 方法中，在 JNI 里是借助于一个 CPU 指令完成的，属于原子操作，可以保证多个线程都能够看到同一个变量的修改值\npublic final int getAndAddInt(Object o, long offset, int delta) { int v; do { v = getIntVolatile(o, offset); } while (!compareAndSwapInt(o, offset, v, v + delta)); return v; } public native int getIntVolatile(Object var1, long var2); public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5); CAS 虽然很高效，但是也存在ABA问题，且如果 CAS 操作长时间不成功的话，会导致其一直自旋，给处理器带来非常大的开销\n二、可重入锁、非可重入锁 锁是否可重入表示的是这么一种特性：锁的持有线程在不释放锁的前提下，是否能够再次申请到同一个锁。例如，如果 synchronized 是可重入锁，那么 doSomething1() 是可以正常执行的。如果 synchronized 是不可重入锁，那么 doSomething1() 就会导致死锁。而在现实情况下，Java 中 synchronized 和 ReentrantLock 都是可重入锁\nprivate synchronized void doSomething1() { doSomething2(); } private synchronized void doSomething2() { } 这里也以 ReentrantLock 作为例子来从看下其重入流程\n我们知道，在使用 ReentrantLock 时，我们调用了 Lock.lock() N 次后就要相应调用 Lock.unlock() N 次才可以使得持有线程真正地释放了锁，那么这里自然就需要有个状态值来记录 ReentrantLock 申请了几次锁（即重入了几次）。ReentrantLock 包含一个内部类 Sync，Sync 继承自 AQS（AbstractQueuedSynchronizer）\nAQS 中维护了一个 int 类型的同步状态值 status，其初始值为 0，在不同的场景下具有不同的含义，对于 ReentrantLock 来说就是用来标记重入次数。当线程尝试获取锁时，ReentrantLock 就会尝试获取并更新 status 值\n如果 status 等于 0。表示锁没有被其它线程抢占，则把 status 置为 1，同时当前线程成功抢占到锁 如果 status 不等于 0。判断当前线程是否是该锁的持有线程，如果是的话则执行 status + 1，表示当前线程再次重入了一次。如果当前线程不是该锁的持有线程，则意味着抢占失败 当持有线程释放锁时，ReentrantLock 同样会先获取当前 status 值。如果 status - 1 等于 0，表示当前线程已经撤销了所有的申请操作，此时线程才会真正释放锁，否则持有线程就还是依然占用着锁\n三、公平锁、非公平锁 当多个线程同时申请同一个排他性资源，申请资源失败的线程往往是会存入一个等待队列中，当后续资源被其持有线程释放时，如果刚好有一个活跃线程来申请资源，此时选择哪一个线程来获取资源的独占权就是一个资源调度的过程，资源调度策略的一个重要属性就是能否保证公平性。所谓公平性，是指资源的申请者是否严格按照申请顺序而被授予资源的独占权。如果资源的任何一个先申请者总是能够被比任何一个后申请者先获得资源的独占权，那么该策略就被称为公平调度策略。如果资源的后申请者可能比先申请者先获得资源的独占权，那么该策略就被称为非公平调度策略。注意，非公平调度策略往往只是不保证资源调度的公平性，即它只是允许不公平的资源调度现象，而不是表示它刻意造就不公平的资源调度\n公平的资源调度策略不允许插队现象的出现，资源申请者总是按照先来后到的顺序获得资源的独占权。如果当前等待队列为空，则来申请资源的线程可以直接获得资源的独占权。如果等待队列不为空，那么每个新到来的线程就被插入等待队列的队尾。公平的资源调度策略的优点是：每个资源申请者从开始申请资源到获得相应资源的独占权所需时间的偏差会比较小，即每个申请者成功申请到资源所需的时间基本相同，且可以避免出现线程饥饿现象。缺点是吞吐率较低，为了保证 FIFO 加大了发生线程上下文切换的可能性\n非公平的资源调度策略则允许插队现象。新到来的线程会直接尝试申请资源，只有当申请失败时才会将线程插入等待队列的队尾。假设两种多个线程一起竞争同一个排他性资源的场景：\n当资源被释放时，如果刚好有一个活跃线程来申请资源，该线程就可以直接抢占到资源，而无需去唤醒等待队列中的线程。这种场景相对公平调度策略就少了将新到来的线程暂停和将等待队列队头的线程唤醒的两个操作，而资源也一样有被得到使用 即使等待队列中的某个线程已经被唤醒来试图抢占资源的独占权，如果新到来的活跃线程占用资源的时间不长的话，那么就有可能在被唤醒的线程开始申请资源之前，新到来的活跃线程已经释放了对资源的独占权，从而不妨碍被唤醒的线程申请资源。这种场景也一样避免了将新到来的线程暂停这么一个操作 因此，非公平调度策略的优点主要有两点：\n吞吐率一般来说会比公平调度策略高，即单位时间内它可以为更多的申请者调配资源 降低了发生上下文切换的概率 非公平调度策略的缺点主要有两点：\n由于允许插队现象，极端情况下可能导致等待队列中的线程永远也无法获得其所需的资源，即出现线程饥饿的活性故障现象 每个资源申请者从开始申请资源到获得相应资源的独占权所需时间的偏差可能较大，即有的线程可能很快就能申请到资源，而有的线程则要经历若干次暂停与唤醒才能成功申请到资源 综上所诉，公平调度策略适用于资源被持有的时间较长或者线程申请资源的平均时间间隔较长的情形，或者要求申请资源所需的时间偏差较小的情况。总的来说使用公平调度策略的开销会比使用非公平调度策略的开销要大，因此在没有特别需求的情况下，应该默认使用非公平调度策略\n公平锁就是指采用了公平调度策略的锁，非公平锁就是指采用了非公平调度策略的锁。Java 中的 synchronized 就是非公平锁；而 ReentrantLock 既支持公平调度策略也支持非公平调度策略，且默认使用的也是非公平调度策略\n这里来简单看下 ReentrantLock 的源码来了解下公平锁和非公平锁的实现区别\nReentrantLock 申请和释放锁的大部分逻辑都是在其内部类 Sync 里实现的。Sync 包含公平锁 FairSync 和非公平锁 NonfairSync 两个不同的子类实现，ReentrantLock 默认使用的是 NonfairSync\nFairSync 和 NonfairSync 在申请锁时的会分别调用以下两个方法，两者的唯一的区别只在于公平锁在获取同步状态时多了一个限制条件：hasQueuedPredecessors()\nhasQueuedPredecessors() 方法用于判断等待队列中是否有排在当前线程之前的线程，如果有返回 true，否则返回 false。所以说，ReentrantLock 的公平调度策略只有在等待队列为空时才允许当前的活跃线程执行申请锁的操作，而非公平调度策略则是直接就进行申请\n四、互斥锁、共享锁 互斥锁也称为排他锁，是指该锁一次只能被一个线程持有，当某个线程已经在持有锁的时候其它来申请同个锁实例的线程只能进行等待，以此来保证临界区内共享数据的安全性。Java 中的 synchronized 和 java.util.concurrent.locks.Lock 接口的实现类就属于互斥锁\n互斥锁使得多个线程无法以线程安全的方式在同一时刻对共享数据进行只读取而不更新的操作，这在共享数据读取频繁但更新频率较低的情况下降低了系统的并发性，共享锁就是为了应对这种问题而诞生的。共享锁是一种改进型的排他锁，也称为共享/排他锁。共享锁允许多个线程同时读取共享变量，但是一次只允许一个线程对共享变量进行更新。任何线程读取共享变量的时候，其它线程无法更新这些变量；一个线程更新共享变量的时候，其它线程都无法读取和更新这些变量\nJava 平台中的读写锁就是对共享锁这个概念的实现，由 java.util.concurrent.locks.ReadWriteLock 接口来定义，其默认实现类是 java.util.concurrent.locks.ReentrantReadWriteLock\nReadWriteLock 接口定义了两个方法，分别用来获取读锁（ReadLock）和写锁（WriteLock）。ReadLock 是共享的，WriteLock 是排他的，ReadLock 和 WriteLock 的操作最终都要转交由内部类 Sync 来完成\n上面在讲“可重入锁与非可重入锁”这一节内容的时候，有提到：AQS 中维护了一个 int 类型的同步状态值 status，其初始值为 0，在不同的场景下具有不同的含义。对于 ReentrantReadWriteLock 来说，status 就用来标记当前持有读锁和写锁的线程分别是多少\n而为了在一个 32 位的 int 类型整数上来存储两种不同含义的数据，就需要将 status 进行分段切割，高 16 位用来存储读锁当前被获取的次数，低 16 位用来存储写锁当前被获取的次数\nSync 类内部就提供了两个分别用来计算读线程和写线程个数的方法\n1、共享流程 这里先来看下线程在获取读锁时的申请流程，这里主要是要先前置判断下读写锁的写锁是否已经被持有了\nprotected final int tryAcquireShared(int unused) { Thread current = Thread.currentThread(); int c = getState(); if (exclusiveCount(c) != 0 \u0026amp;\u0026amp; getExclusiveOwnerThread() != current) //如果当前已经有线程持有了写锁，且该线程并非当前线程 //则返回 -1，表示读锁获取失败 //这里之所以要判断线程是否相等，是因为 ReentrantReadWriteLock 支持锁的降级，可以在已经持有写锁的时候申请读锁 return -1; //下面就是多个线程前来申请读锁或者是同个线程多次申请读锁的流程了 int r = sharedCount(c); if (!readerShouldBlock() \u0026amp;\u0026amp; r \u0026lt; MAX_COUNT \u0026amp;\u0026amp; compareAndSetState(c, c + SHARED_UNIT)) { if (r == 0) { firstReader = current; firstReaderHoldCount = 1; } else if (firstReader == current) { firstReaderHoldCount++; } else { HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; } return 1; } return fullTryAcquireShared(current); } 而线程在释放读锁时，主要就是更新 state 值，将读线程数量减一，写线程数量不做改动\nprotected final boolean tryReleaseShared(int unused) { Thread current = Thread.currentThread(); if (firstReader == current) { // assert firstReaderHoldCount \u0026gt; 0; if (firstReaderHoldCount == 1) firstReader = null; else firstReaderHoldCount--; } else { HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) rh = readHolds.get(); int count = rh.count; if (count \u0026lt;= 1) { readHolds.remove(); if (count \u0026lt;= 0) throw unmatchedUnlockException(); } --rh.count; } for (;;) { int c = getState(); //SHARED_UNIT 等于 1 \u0026lt;\u0026lt; 16 //c - SHARED_UNIT 就想当于 c 的高16位减1，低16位保持不变 //从而使得读线程数量减1，写线程数量不变 int nextc = c - SHARED_UNIT; //通过 CAS 来更新 state if (compareAndSetState(c, nextc)) // Releasing the read lock has no effect on readers, // but it may allow waiting writers to proceed if // both read and write locks are now free. return nextc == 0; } } 2、互斥流程 再来看下线程在获取写锁时的流程。主要是要考虑写锁的可重入性以及读写锁的公平性与否\nprotected final boolean tryAcquire(int acquires) { /* * Walkthrough: * 1. If read count nonzero or write count nonzero * and owner is a different thread, fail. * 2. If count would saturate, fail. (This can only * happen if count is already nonzero.) * 3. Otherwise, this thread is eligible for lock if * it is either a reentrant acquire or * queue policy allows it. If so, update state * and set owner. */ Thread current = Thread.currentThread(); int c = getState(); int w = exclusiveCount(c); //获取当前写线程数量 if (c != 0) { // (Note: if c != 0 and w == 0 then shared count != 0) //1. 如果 c != 0 \u0026amp;\u0026amp; w == 0 成立，说明当前存在读线程，返回 false，写锁获取失败 //2. 如果 c != 0 \u0026amp;\u0026amp; w != 0 \u0026amp;\u0026amp; current != getExclusiveOwnerThread() 成立 //说明当前写锁已经被持有了，且持有写锁的线程并非当前线程，返回 false，写锁获取失败 if (w == 0 || current != getExclusiveOwnerThread()) return false; if (w + exclusiveCount(acquires) \u0026gt; MAX_COUNT) throw new Error(\u0026#34;Maximum lock count exceeded\u0026#34;); // Reentrant acquire //能走到这一步，说明当前线程已经持有了写锁，由于写锁是可重入的 //所以这里这里更新下写锁被持有的次数后就返回了 true setState(c + acquires); return true; } //能走到这一步，说明当前写锁还未被持有，则根据读写锁的公平性与否来完成写锁的申请 if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; setExclusiveOwnerThread(current); return true; } 线程在释放写锁时，由于 state 值的高 16 位肯定全是 0 （即读线程数量为 0），而低 16 位肯定不全是 0，所以主要就是来更新当前写锁被持有的次数\nprotected final boolean tryRelease(int releases) { if (!isHeldExclusively()) //如果当前线程并非写锁的持有线程，则抛出异常 throw new IllegalMonitorStateException(); int nextc = getState() - releases; //由于写锁是可重入的，所以这里也要判断线程是否已经撤销了所有的申请操作 boolean free = exclusiveCount(nextc) == 0; if (free) //只有在写锁已经撤销了所有的申请操作后才会真正释放锁 setExclusiveOwnerThread(null); setState(nextc); return free; } 五、自旋锁、适应性自旋锁 在一个排他锁已经被持有且锁的持有线程只会占用锁一小段时间的情况下，如果此时将来申请同个锁实例的线程均进行暂停运行处理的话，锁在暂停和后续唤醒过程中所需的时间耗时甚至可能会长于锁被占用的时间，此时暂停线程就显得很不值得了。而自旋锁的实现出发点就基于这么一种观测结果：在很多时候锁的持有线程只需要占用锁一小段时间\n自旋锁的实现前提是当前物理机器包含一个以上的处理器，即支持同时运行一个以上的线程，此时就可以让后面来申请锁的线程不放弃处理器时间片而是稍微“等一等”，看看锁是否很快就会被释放。让线程“等一等”，就是通过让线程反复执行忙循环（也称自旋，可以理解为执行空操作，实现原理也是 CAS）来实现的。如果锁被占用的时间很短，此时采用自旋锁的效果就会非常好，不会导致上下文切换。而如果锁被占用的时间比较长，自旋锁就会浪费很多处理器时间，因此也必须为自旋操作限定一个最大次数，当达到限定的最大次数后如果仍然没有获得锁的话就还是需要将线程进行暂停运行处理\n因此，自旋锁适用于绝大多数线程对锁的持有时间比较短的情况，这样能够避免上下文切换的资源开销和过多的处理器时间开销。而对于系统中绝大多数线程对锁的持有时间比较长的情况，就还是采用直接暂停线程的策略比较适合\n在自旋锁出现的一开始，只能对 JVM 中的所有锁设定一个固定的最大自旋次数。而在后续也引入了适应性自旋锁。适应性意味着自旋的时间（次数）不再是固定的，而是由前一次在该锁上的自旋时间及其当前持有线程的状态来决定。对于某个锁，如果其当前正在被某个已经通过自旋成功获得锁的线程持有的话，那么 JVM 就会认为其它来申请同个锁的线程再次使用自旋也很能再次成功，进而将允许自旋等待相对更长的时间。如果对于某个锁自旋很少成功获得过，那么在以后尝试获取这个锁时将可能省略掉自旋过程，而是直接阻塞线程，避免浪费处理器资源\n总的来说，通过采用自旋锁，锁的申请就并不一定会导致上下文切换了，自旋锁的自适应性也进一步降低了发生线程上下文切换的概率\n六、偏向锁、轻量级锁、重量级锁 偏向锁、轻量级锁、重量级锁可以看做是三种状态值或者说是操作手段，用于描述 synchronized 所对应的内部锁所处的状态，在不同的状态下获取内部锁的实现步骤也各不相同，在理解这三种状态前需要先了解下什么是对象头\n1、对象头 在 HotSpot 虚拟机里，对象在堆内存中的存储布局可以划分为三个部分：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding） 。当中，对象头包含着对象自身的运行时数据，如 HashCode、GC 分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等，这部分数据的长度在 32 位和 64 位的虚拟机（未开启压缩指针）中分别为 32 个比特和 64 个比特，官方称它为“Mark Word”，它是实现偏向锁和轻量级锁的关键。Mark Word 被设计成一个有着动态定义的数据结构，在运行期间 Mark Word 里存储的数据会随着锁标志位的变化而变化，即在不同的状态下会分别存储具有不同含义的数据\n例如，在 32 位的 HotSpot 虚拟机中，如果对象处于未被锁定状态，Mark Word 的 32 个比特存储空间中的 25 个比特会用于存储对象哈希码，4 个比特用于存储对象分代年龄，1个比特固定为 0，2 个比特用于存储锁标志位\n我们在使用 synchronized 时会显式或隐式地指定关联的同步对象（实例变量或者是 Class 对象），而 Java 平台中的任何一个对象都有一个唯一与之关联的锁，被称为监视器（Monitor）或者内部锁。同步对象的对象头所包含的运行时数据的变化过程，就是其内部锁在偏向锁、轻量级锁、重量级锁这四种状态下的切换过程\n2、偏向锁 JVM 在实现 monitorenter（申请锁） 和 monitorexit（释放锁） 这两个字节码指令时需要借助一个原子操作（CAS 操作），这个操作代价相对来说比较昂贵。而如果在一段时间内一个锁实例先后只会由同一个线程来申请并使用的话，那么该线程每次申请和释放锁的代价就会被放大，显得很不值得了。而偏向锁的实现出发点就基于这么一种观测结果：大多数锁并没有被争用，并且在其整个生命周期内总是同一个线程来进行申请\n偏向锁的执行流程是这样的：\n当某个锁第一次被线程申请到时，JVM 会把同步对象的 Mark Word 中的标志位设置为“01”，偏向模式设置为“1”，表示该锁进入了偏向模式。同时使用 CAS 操作把当前线程的 ID 记录在对象的 Mark Word 之中，如果 CAS 操作成功，该线程就会被记录为同步对象的偏好线程（Biased Thread），然后执行步骤 4。如果 CAS 操作失败，则直接步骤 3 当又有线程前来申请锁时，如果判断到偏向锁指向的 Thread ID 即为当前线程，则直接执行步骤 4，即偏向线程以后每次进入这个锁相关的同步块时，都不用再进行任何加锁操作。如果偏向锁指向的 Thread ID 并非当前线程，说明当前系统存在多个线程竞争偏向锁，则通过 CAS 来竞争锁。如果竞争成功，则将Mark Word 中的线程 ID 设置为当前线程 ID，然后执行步骤 4；如果竞争失败，则执行步骤 3 因为线程不会主动去释放偏向锁，所以如果 CAS 获取偏向锁失败，则表示当前存在多个线程一个竞争偏向锁。当到达全局安全点（safepoint）时，会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着（因为持有偏向锁的线程可能已经执行完毕，但该线程并不会主动去释放偏向锁），如果线程不处于活动状态，则将对象头设置成无锁状态（标志位为“01”），然后重新偏向新的线程；如果线程仍然活跃，则撤销偏向锁，将其升级到轻量级锁状态（标志位变为“00”），此时轻量级锁由原持有偏向锁的线程继续持有，让其继续执行同步代码，而正在申请锁的线程则通过自旋等待获得该轻量级锁 执行同步代码 引入偏向锁是为了提高带有 synchronized 同步操作但实际上无争用的代码块的性能，因为偏向线程在获取到偏向锁之后，每次进入这个锁相关的同步块时，都不用再进行任何同步操作（例如加锁、解锁及对 Mark Word 的更新操作等）。而且轻量级锁的获取及释放依赖多次 CAS 原子指令，而偏向锁只需要在置换 Thread ID 的时候执行一次 CAS 原子指令即可\n偏向锁适用于存在相当大一部分锁并没有被争用的系统，如果系统中存在大量被争用的锁而没有被争用的锁仅占小部分，那么就可以考虑关闭偏向锁\n3、轻量级锁 轻量级锁是 JDK 6 时加入的新型锁机制。当某个锁是偏向锁时，如果该锁被其它线程访问了，此时偏向锁就会升级为轻量级锁，其它线程会通过自旋的方式来尝试获取锁，此时该线程不会阻塞，从而提高了性能\n在线程进入同步块的时候，如果同步对象锁没有被锁定（锁标志位为“01”），JVM 首先会在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，然后拷贝对象头中的 Mark Word 到锁记录中。拷贝完成后，JVM 将使用 CAS 操作尝试将对象的 Mark Word 值更新为指向 Lock Record 的指针，并将 Lock Record 里的 owner 指针指向对象的 Mark Word。如果这个更新动作成功了，即代表这个线程拥有了该对象锁，并且 Mark Word 的锁标志位将变更为为 “00”，表示此对象处于轻量级锁定状态。如果这个更新操作失败了，那就意味着至少存在一个线程与当前线程竞争获取该对象锁。JVM 会先检查对象的 Mark Word 是否指向当前线程的栈帧，如果是，说明当前线程已经拥有了这个对象的锁，那直接进入同步块继续执行就可以了，否则就说明这个锁对象已经被其他线程抢占了。如果出现两个以上的线程争用同一个锁的情况，那轻量级锁就不再有效，必须要升级为重量级锁，锁标志的状态值变为“10”，此时 Mark Word 中存储的就是指向重量级锁（互斥量）的指针，此后等待锁的线程也必须进入阻塞状态\n轻量级锁的实现出发点是基于这么一种观测结果：大多数锁在整个同步周期内都是不存在竞争的。这里需要和偏向锁区分开，偏向锁的理论基础是：大多数锁总是在其整个生命周期内被同一个线程所使用。而轻量级锁的理论基础是：锁可能会先后被多个线程使用，但由于线程间的交叉使用，所以大多数线程在使用同步资源时是不存在竞争的。偏向锁相对轻量级锁会更加“乐观”，所以轻量级锁就需要比偏向锁多出更多的“安全保障措施”\n如果没有竞争，轻量级锁便通过 CAS 操作成功避免了使用互斥量的开销；但如果确实存在锁竞争，除了互斥量的本身开销外，还额外产生了 CAS 操作的开销。因此在有竞争的情况下轻量级锁会比传统的重量级锁更加消耗资源\n4、重量级锁 升级为重量级锁时，Mark Word 中前 30 位存储的是指向重量级锁（互斥量）的指针，锁标志的状态值变为“10”，此后等待锁的线程就必须进入阻塞状态。重量级锁是实现锁申请操作最为消耗资源的一种做法\n5、概述 综上，偏向锁通过对比 Mark Word 解决了加锁问题，避免执行 CAS 操作。而轻量级锁是通过用 CAS 操作和自旋来解决加锁问题，避免线程阻塞和唤醒而影响性能。重量级锁则是直接将除了拥有锁的线程以外的线程都阻塞\n七、锁消除 锁消除是 JIT 编译器对内部锁的具体实现所做的一种优化。在动态编译同步块的时候，编译器会借助逃逸分析技术来判断同步块所使用的锁对象是否只会被一个线程使用。如果判断出该锁对象的确只能被一个线程访问，编译器在编译这个同步块的时候就不会生成 synchronize 所表示的 monitorenter 和 monitorexit 两个机器码，而仅生成临界区内的代码所对应的机器码，从而消除了锁的使用。这种优化措施就称为锁消除，锁消除使得在特定情况下可以完全消除锁的开销\n例如，对于以下方法。StringBuffer 类本身是线程安全的，其内部多个方法（例如，append 方法）都使用到了内部锁，而在toJson()方法里 StringBuffer 是作为一个局部变量存在的，并不会存在多个线程同时访问的情况，此时 append 方法所使用到的内部锁就成了一种无谓的消耗。所以，编译器在编译 toJson 方法的时候就会将其调用的 StringBuffer.append 方法内联到该方法之中，相当于把 StringBuffer.append 方法的方法体中的指令复制到 toJson 方法体中，此时就可以避免 append 方法所声明的内部锁所带来的消耗\npublic String toJson() { StringBuffer stringBuffer = new StringBuffer(); stringBuffer.append(\u0026#34;xxx\u0026#34;); return stringBuffer.toString(); } 锁消除不一定会被编译器实施，这和同步代码块是否能被内联有关，所以虽然锁消除技术可以使得编译器为我们消除一部分的锁开销，但是这也不意味着开发者就可以随意使用内部锁了\n八、锁粗化 锁粗化是指 JIT 编译器会将相邻的几个同步代码块合并为一个大的同步代码块的一种优化措施。通过锁粗化，可以避免一个线程反复申请和释放同一个锁所导致的开销，相应的也会导致一个线程持有一个锁的时间变长，从而使得锁的等待线程申请锁所需要的时间也相应变长\n例如，对于以下代码。通过锁粗化技术就可以将多个同步代码块合并为一个，且同步代码块之间的代码也会被合并在一起，使得临界区的长度变长。而原本在锁 lockX 的持有线程执行完第一个同步代码块之后（即释放 lockX 后），其它等待线程是有机会获得 lockX 的，但是经过锁粗化后使得 lockX 的持有线程只有执行完全部同步代码块之后才会释放 lockX，使得等待线程申请 lockX 的时间相应变长了。因此，为了避免一个线程持有锁的时间过长，锁粗化不会被应用到循环体内的相邻同步代码块\n//锁粗化前 public void test() { synchronized (lockX) { doSomethind1(); } x = 10; synchronized (lockX) { doSomethind2(); } y = 10; synchronized (lockX) { doSomethind3(); } } //锁粗化后 public void test() { synchronized (lockX) { doSomethind1(); x = 10; doSomethind2(); y = 10; doSomethind3(); } } 九、优化对锁的使用 以上所讲的大部分优化措施都是在编译器这个层次实施的，这一节再来介绍下如何在代码层次对锁进行优化\n1、降低锁的争用程度 在之前的文章中有介绍过使用锁带来的主要开销，而如果必须使用锁且锁带来的开销很难避免，那么要降低锁的开销的思路之一就是降低锁的争用程度。锁的争用程度和程序中需要同时使用到该锁实例的线程数量有关，如果可以尽量降低每个线程来申请锁时该锁实例还被其它线程持有的情况，那么就可以降低锁的争用程度。降低锁的争用程度可以用两种方式来实现：减少锁被持有的时间和降低锁的申请频率\n减少锁被持有的时间即让每个线程持有锁的时间尽量短，从而减少当某个线程申请锁时而锁的持有线程还未执行完临界区代码的情况，而且也有利于 Java 虚拟机的适应性锁发挥作用。可以通过减少临界区长度来缩减锁被持有的时间，例如：将不会导致竞态的代码（局部变量的访问等）放到临界区之外执行，使得每个线程在持有锁的过程中需要执行的指令尽量少。此外，也需要避免在临界区中执行阻塞式 IO 等阻塞操作，阻塞操作会导致线程被暂停和上下文切换，而在线程被暂停的过程中其持有的锁也不会被释放，这样会增大锁被争用的可能性\n降低锁的申请频率可以通过减小锁的粒度来实现。例如，多个线程间存在多个共享变量，而共享变量之间并没有特定的关联关系，此时就可以分别使用不同的锁对象来保障不同的共享变量在多个线程间的线程安全性。假设多个线程间存在两个共享变量 A 和 B，如果变量 A 和变量 B 之间并没有关联关系，那么在访问共享变量的时候就可以使用不同的锁，线程 A 在访问变量 A 的时候可以使用 Lock A 来保障安全性，而在线程 A 持有 Lock A 的过程中也不妨碍线程 B 申请 Lock B 对变量 B 进行访问。通过这种使用不同的锁来保障不同共享数据的安全性，从而减少锁的争用程度。但如果锁的粒度过细也会增加锁调度的开销，需要在实际开发中衡量使用\n2、使用可参数化锁 如果一个方法或者类的内部所使用的锁实例可以由其使用者来指定的话，那么就可以说这个锁是可参数化的，相应的这个锁就被称为可参数化的锁。使用可参数化锁有助于减少线程需要申请的锁实例的个数，从而减少锁的开销\n例如，对于以下例子。假设 Printer 类是由第三方提供的工具类，其内部需要保障自身的线程安全性，所以使用到了内部锁，其锁实例默认是其本身变量实例（即 this） 。LogPrinter 类作为客户端/使用者，其内部也需要保障自身的线程安全性（例如：line++; ），所以也使用到了内部锁。但由于 Printer 的所有方法均由 LogPrinter 已经保障了线程安全性的方法进行调用，此时 Printer 内部使用到的内部锁就成了多余配置，增加了无谓的锁开销\n由于 Java 平台中的锁都是可重入的，且锁的持有线程在未释放锁的情况下重复申请该锁的开销时所需要的开销比较小，所以此时就可以依靠 Printer 类提供的可参数化锁配置，将 LogPrinter 声明的锁实例 lock 作为构造参数传给 Printer，从而减少了锁开销\nclass Printer { private final Object lock; public Printer(Object lock) { this.lock = lock; } public Printer() { this.lock = this; } public void print(String msg) { synchronized (lock) { System.out.println(msg); } } } class LogPrinter { private final Object lock = new Object(); private final Printer printer = new Printer(lock); private int line; public void print(String msg) { synchronized (lock) { line++; printer.print(msg); } } } 十、参考资料 不可不说的Java“锁”事 ","permalink":"http://localhost:1313/hugo-blog/public/post/kotlin/java-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%BC%80%E5%8F%914%E9%94%81%E7%9A%84%E5%88%86%E7%B1%BB%E6%9C%89%E8%BF%99%E4%B9%88%E5%A4%9A/","tags":[],"title":"Java 多线程开发（4）锁的分类有这么多"},{"categories":[],"content":" 公众号：字节数组 希望对你有所帮助 🤣🤣\n目前，多线程编程可以说是在大部分平台和应用上都需要实现的一个基本需求。本系列文章就来对 Java 平台下的多线程编程知识进行讲解，从概念入门、底层实现到上层应用都会涉及到，预计一共会有五篇文章，希望对你有所帮助 😎😎\n本篇文章是第五篇，应该也是最后一篇了，从现实需求出发到源码介绍，一步步理清楚线程池的作用和优势\n线程池（ThreadPool）面对的是外部复杂多变的多线程环境，既需要保证多线程环境下的状态同步，也需要最大化对每个线程的利用率，还需要留给子类足够多的余地来实现功能扩展。所以说，线程池的难点在于如何实现，而在概念上其实还是挺简单的。在 Java 中，线程池这个概念一般都认为对应的是 JDK 中的 ThreadPoolExecutor 类及其各种衍生类，本篇文章就从实现思路出发，探索 ThreadPoolExecutor 的源码到底是如何实现的以及为什么这么实现\n一、线程池 线程是一种昂贵的系统资源，其“昂贵”不仅在于创建线程所需要的资源开销，还在于使用过程中带来的资源消耗。一个系统能够支持同时运行的线程总数受限于该系统所拥有的处理器数目和内存大小等硬件条件，线程的运行需要占用处理器时间片，系统中处于运行状态的线程越多，每个线程单位时间内能分配到的时间片就会越少，线程调度带来的上下文切换的次数就会越多，最终导致处理器真正用于运算的时间就会越少。此外，在现实场景中一个程序在其整个生命周期内需要交由线程执行的任务数量往往是远多于系统所能支持同时运行的最大线程数。基于以上原因，为每个任务都创建一个线程来负责执行是不太现实的。那么，我们最直接的一个想法就是要考虑怎么来实现线程的复用了\n线程池就是实现线程复用的一种有效方式。线程池的思想可以看做是对资源是有限的而需要处理的任务几乎是无限的这样一个现状的应对措施。线程池的一般实现思路是：线程池内部预先创建或者是先后创建一定数量的线程，外部将需要执行的任务作为一个对象提交给线程池，由线程池选择某条空闲线程来负责执行。如果所有线程都处于工作状态且线程总数已经达到限制条件了，则先将任务缓存到任务队列中，线程再不断从任务队列中取出任务并执行。因此，线程池可以看做是基于生产者-消费者模式的一种服务，内部维护的多个线程相当于消费者，提交的任务相当于产品，提交任务的外部就相当于生产者\n二、思考下 好了，既然已经对线程池这个概念有了基本的了解，那么就再来思考下线程池应该具备的功能以及应该如何来实现线程池\n线程池中的线程最大数量应该如何限定？ 既然我们不可能无限制地创建线程，那么在创建线程池前就需要为其设定一个最大数量，我们称之为最大线程池大小（maximumPoolSize），当线程池中的当前线程总数达到 maximumPoolSize 后就不应该再创建线程了。在开发中，我们需要根据运行设备的硬件条件和任务类型（I/O 密集型或者 CPU 密集型）来实际衡量该数值的大小，但任务的提交频率和任务的所需执行时间是不固定的，所以线程池的 maximumPoolSize 也应该支持动态调整\n线程池中的线程应该在什么时候被创建呢？ 一般来说，如果线程池中的线程数量还没有达到 maximumPoolSize 时，我们可以等到当外部提交了任务时再来创建线程进行处理。但是，线程从被创建到被调度器选中运行，之间也是有着一定时间间隔的。从提高任务的处理响应速度这方面考虑，我们也可以选择预先就创建一批线程进行等待\n线程池中的线程可以一直存活着吗？ 程序运行过程中可能只是偶发性地大批量提交任务，而大部分时间只是比较零散地提交少量任务，这就导致线程池中的线程可能会在一段时间内处于空闲状态。如果线程池中的线程只要创建了就可以一直存活着的话，那么线程池的“性价比”就显得没那么高了。所以，当线程处于空闲状态的时间超出允许的最大空闲时间（keepAliveTime）后，我们就应该将其回收，避免白白浪费系统资源。而又为了避免频繁地创建和销毁线程，线程池需要缓存一定数量的线程，即使其处于空闲状态也不会进行回收，这类线程我们就称之为核心线程，相应的线程数量就称之为核心线程池大小（corePoolSize）。大于 corePoolSize 而小于等于 maximumPoolSize 的那一部分线程，就称之为非核心线程\n如何实现线程的复用？ 我们知道，当 Thread.run() 方法执行结束后线程就会被回收了，那么想要实现线程的复用，那么就要考虑如何避免退出 Thread.run() 了。这里，我们可以通过循环向任务队列取值的方式来实现。上面有提到，如果外部提交的任务过多，那么任务就需要被缓存到任务队列中。那么，我们就可以考虑使用一个阻塞队列来存放任务。线程循环从任务队列中取任务，如果队列不为空，那么就可以马上拿到任务进行执行；如果队列为空，那么就让线程一直阻塞等待，直到外部提交了任务被该线程拿到或者由于超时退出循环。通过这种循环获取+阻塞等待的方式，就可以实现线程复用的目的\n如何尽量实现线程的复用？ 这个问题和“如何实现线程的复用”不太一样，“如何实现线程的复用”针对的是单个线程的复用流程，本问题针对的是整个线程池范围的复用。线程池中需要使用到任务队列进行缓存，那么任务队列的使用时机可以有以下几种：\n当线程数已经达到 maximumPoolSize ，且所有线程均处于工作状态时，此后外部提交的任务才被缓存到任务队列中 当核心线程都已经被创建了时，此后外部提交的任务就被缓存到任务队列中，当任务队列满了后才创建非核心线程来循环处理任务 很明显的，第二种方案会更加优秀。由于核心线程一般情况下是会被长久保留的，核心线程的存在保证了外部提交的任务一直有在被循环处理。如果外部提交的大部分都是耗时较短的任务或者任务的提交频率比较低的话，那么任务队列就可能没那么容易满，第二种方案就可以尽量避免去创建非核心线程。而且对于“偶发性地大批量提交任务，而大部分时间只是比较零散地提交少量任务”这种情况，第二种方案也会更加合适。当然，在任务的处理速度方面，第一种方案就会高一些，但是如果想要尽量提高第二种方案的任务处理速度的话，也可以通过将任务队列的容量调小的方式来实现\n当任务队列满了后该如何处理？ 如果线程池实在“忙不过来”的话，那么任务队列也是有可能满的，那么就需要为这种情况指定处理策略。当然，我们也可以选择使用一个无界队列来缓存任务，但是无界队列容易掩盖掉一些程序异常。因为有界队列之所以会满，可能是由于发生线程池死锁或者依赖的某个基础服务失效导致的，从而令线程池中的任务一直迟迟得不到解决。如果使用的是无界队列的话，就可能使得当系统发生异常时程序还是看起来运转正常，从而降低了系统健壮性。所以，最常用的还是有界队列\n现实需求是多样化的，在实现线程池时就需要留有交由外部自定义处理策略的余地。例如，当队列满了后，我们可以选择直接抛出异常来向外部“告知”这一异常情况。对于重要程度较低的任务，可以选择直接抛弃该任务，也可以选择抛弃队列头的任务而尝试接纳新到来的任务。如果任务必须被执行的话，也可以直接就在提交任务的线程上进行执行\n以上就是线程池在实现过程中需要主要考虑的几个点，下面就来看下 Java 实际上是怎么实现线程池的\n三、ThreadPoolExecutor java.util.concurrent.ThreadPoolExecutor 类就是 Java 对线程池的默认实现，下文如果没有特别说明的话，所说的线程池就是指 ThreadPoolExecutor\nThreadPoolExecutor 的继承关系如下图所示\nThreadPoolExecutor 实现的最顶层接口是 Executor。Executor 提供了一种将任务的提交和任务的执行两个操作进行解耦的思路：客户端无需关注执行任务的线程是如何创建、运行和回收的，只需要将任务的执行逻辑包装为一个 Runnable 对象传递进来即可，由 Executor 的实现类自己来完成最复杂的执行逻辑\nExecutorService 接口在 Executor 的基础上扩展了一些功能：\n扩展执行任务的能力。例如：获取任务的执行结果、取消任务等功能 提供了关闭线程池、停止线程池，以及阻塞等待线程池完全终止的方法 AbstractExecutorService 则是上层的抽象类，负责将任务的执行流程串联起来，从而使得下层的实现类 ThreadPoolExecutor 只需要实现一个执行任务的方法即可\n也正如上文所说的那样，ThreadPoolExecutor 可以看做是基于生产者-消费者模式的一种服务，内部维护的多个线程相当于消费者，提交的任务相当于产品，提交任务的外部就相当于生产者。其整个运行流程如下图所示\n而在线程池的整个生命周期中，以下三个关于线程数量的统计结果也影响着线程池的流程走向\n当前线程池大小（currentPoolSize）。表示当前实时状态下线程池中线程的数量 最大线程池大小（maximumPoolSize）。表示线程池中允许存在的线程的数量上限 核心线程池大小（corePoolSize）。表示一个不大于 maximumPoolSize 的线程数量上限 三者之间的关系如下：\n当前线程池大小 ≤ 核心线程池大小 ≤ 最大线程池大小 or 核心线程池大小 ≤ 当前线程池大小 ≤ 最大线程池大小 当中，除了“当前线程池大小”是对线程池现有的工作者线程进行实时计数的结果，其它两个值都是对线程池配置的参数值。三个值的作用在上文也都已经介绍了\nThreadPoolExecutor 中参数最多的一个构造函数的声明如下所示：\npublic ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue\u0026lt;Runnable\u0026gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { if (corePoolSize \u0026lt; 0 || maximumPoolSize \u0026lt;= 0 || maximumPoolSize \u0026lt; corePoolSize || keepAliveTime \u0026lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; } corePoolSize ：用于指定线程池的核心线程数大小 maximumPoolSize：用于指定最大线程池大小 keepAliveTime、unit ：一起用于指定线程池中空闲线程的最大存活时间 workQueue ：任务队列，相当于生产者-消费者模式中的传输管道，用于存放待处理的任务 threadFactory：用于指定创建线程的线程工厂 handler：用于指定当任务队列已满且线程数量达到 maximumPoolSize 时任务的处理策略 下面就以点见面，从细节处来把握整个线程池的流程走向\n1、线程池的状态如何保存 这里所说的“状态”指的是一个复合数据，包含“线程池生命周期状态”和“线程池当前线程数量”这两项。线程池从启动到最终终止，其内部需要记录其当前状态来决定流程走向。而线程池的当前线程数量，也关乎着线程是否需要进行回收以及是否需要执行任务的拒绝策略\n线程池一共包含以下五种生命周期状态，涵盖了线程池从启动到终止的这整个范围。线程池的生命周期状态可以按顺序跃迁，但无法反向回转，每个状态的数值大小也是逐步递增的\n//运行状态，线程池正处于运行中 private static final int RUNNING = -1 \u0026lt;\u0026lt; COUNT_BITS; //关闭状态，当调用 shutdown() 方法后处于这个状态，任务队列中的任务会继续处理，但不再接受新任务， private static final int SHUTDOWN = 0 \u0026lt;\u0026lt; COUNT_BITS; //停止状态，当调用 shutdownNow() 方法后处于这个状态 //任务队列中的任务也不再处理且作为方法返回值返回，此后不再接受新任务 private static final int STOP = 1 \u0026lt;\u0026lt; COUNT_BITS; //TERMINATED 之前的临时状态，当线程都被回收且任务队列已清空后就会处于这个状态 private static final int TIDYING = 2 \u0026lt;\u0026lt; COUNT_BITS; //终止状态，在处于 TIDYING 状态后会立即调用 terminated() 方法，调用完成就会马上转到此状态 private static final int TERMINATED = 3 \u0026lt;\u0026lt; COUNT_BITS; 在日常开发中，如果我们想要用一个 int 类型的 state 变量来表示这五种状态的话，那么就可能是通过让 state 分别取值 1，2，3，4，5 来进行标识，而 state 作为一个 int 类型是一共有三十二位的，那其实上仅需要占用三位就足够标识了，即 2 x 2 x 2 = 8 种可能。那还剩下 29 位可以用来存放其它数据\n实际上 ThreadPoolExecutor 就是通过将一个 32 位的 int 类型变量分割为两段，高 3 位用来表示线程池的当前生命周期状态，低 29 位就拿来表示线程池的当前线程数量，从而做到用一个变量值来维护两份数据，这个变量值就是 ctl。从 ctl 的初始值就可以知道线程池的初始生命周期状态( runState )是 RUNNING，初始线程数量 ( workerCount )是 0。这种用一个变量去存储两个值的做法，可以避免在做相关决策时出现不一致的情况，且不必为了维护两者的一致而使用锁，后续需要获取线程池的当前生命周期状态和线程数量的时候，也可以直接采用位运算的方式获取，在速度上相比基本运算会快很多\nprivate final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); ThreadPoolExecutor 还声明了以下两个常量用来参与位运算\n//用来表示线程数量的位数，即 29 private static final int COUNT_BITS = Integer.SIZE - 3; //线程池所能表达的最大线程数，即一个“高3位全是0，低29位全是1”的数值 private static final int CAPACITY = (1 \u0026lt;\u0026lt; COUNT_BITS) - 1; 相应的，那么就需要有几个方法可以来分别取“生命周期状态”和“线程数”这两个值，以及将这两个值合并保存的方法，这几个方法都使用到了位运算\n// Packing and unpacking ctl //通过按位取反 + 按位与运算，将 c 的高3位保留，舍弃低29位，从而得到线程池状态 private static int runStateOf(int c) { return c \u0026amp; ~CAPACITY; } //通过按位与运算，将 c 的高3位舍弃，保留低29位，从而得到工作线程数 private static int workerCountOf(int c) { return c \u0026amp; CAPACITY; } //rs，即 runState，线程池的生命周期状态 //wc，即 workerCount，工作线程数量 //通过按位或运算来合并值 private static int ctlOf(int rs, int wc) { return rs | wc; } private static boolean runStateLessThan(int c, int s) { return c \u0026lt; s; } private static boolean runStateAtLeast(int c, int s) { return c \u0026gt;= s; } //用于判断线程池是否处于 RUNNING 状态 //由于五个状态值的大小是依次递增的，所以只需要和 SHUTDOWN 比较即可 private static boolean isRunning(int c) { return c \u0026lt; SHUTDOWN; } public boolean isShutdown() { return !isRunning(ctl.get()); } //用于判断当前状态是否处于 SHUTDOWN、STOP、TIDYING 三者中的一个 public boolean isTerminating() { int c = ctl.get(); return !isRunning(c) \u0026amp;\u0026amp; runStateLessThan(c, TERMINATED); } //用于判断当前状态是否处于 TERMINATED public boolean isTerminated() { return runStateAtLeast(ctl.get(), TERMINATED); } 2、线程的创建流程 在初始状态下，客户端每提交一个任务，线程池就会通过 threadFactory 创建线程来处理该任务，如果开发者没有指定 threadFactory 的话，则会使用 Executors.DefaultThreadFactory。线程池在最先开始创建的线程属于核心线程，线程数量在大于 corePoolSize 而小于等于 maximumPoolSize 这个范围内的线程属于非核心线程。需要注意的是，核心线程和非核心线程并非是两种不同类型的线程对象，这两个概念只是对不同数量范围内的线程进行的区分，实质上这两者指向的都是同一类型\n线程的创建流程可以通过任务的提交流程来了解，任务的提交流程图如下所示\n线程池开放了多个让外部提交任务的方法，这里主要看 execute(Runnable command) 方法。该方法需要先后多次校验状态值，因为线程池面对的调用方可以来自于多个不同的线程。可能在当前线程提交任务的同时，其它线程就刚好关闭了线程池或者是调整了线程池的线程大小参数，需要考虑当前的线程数量是否已经达到限制了\npublic void execute(Runnable command) { if (command == null) throw new NullPointerException(); int c = ctl.get(); if (workerCountOf(c) \u0026lt; corePoolSize) { //如果当前线程数还未达到 corePoolSize，则尝试创建一个核心线程来处理任务 //addWorker 可能会因为线程池被关闭了、线程数量超出限制等原因返回 false if (addWorker(command, true)) return; c = ctl.get(); } if (isRunning(c) \u0026amp;\u0026amp; workQueue.offer(command)) { //线程池还处于运行状态且成功添加任务到任务队列 //需要重新检查下运行状态 //因为等执行到这里时，线程池可能被其它线程关闭了 int recheck = ctl.get(); //1、如果线程池已经处于非运行状态了 //1.1、如果移除 command 成功，则走拒绝策略 //1.2、如果移除 command 失败（因为 command 可能已经被其它线程拿去执行了），则走第 3 步 //2、如果线程池还处于运行状态，则走第 3 步 //3、如果当前线程数量为 0，则创建线程进行处理 //第 3 步的意义在于：corePoolSize 可以被设为 0，所以这里需要检查下，在需要的时候创建一个非核心线程 if (! isRunning(recheck) \u0026amp;\u0026amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); } //如果线程池处于非运行状态了，或者是处于运行状态但队列已满了，此时就会走到这里 //在这里尝试创建一个非核心线程 //如果线程创建失败，说明要么是线程池当前状态大于等于 STOP，或者是任务队列已满且线程总数达到 maximumPoolSize 了 //此时就走拒绝策略 else if (!addWorker(command, false)) reject(command); } 当中，addWorker(Runnable firstTask, boolean core) 方法用于尝试创建并启动线程，同时将线程保存到 workers。第一个参数用于指定线程启动时需要执行的第一个任务，可以为 null。第二个参数用于指定要创建的是否是核心线程，这个参数会关系到线程是否能被成功创建\n该方法在实际创建线程前，都需要先通过 CAS 来更新（递增加一）当前的线程总数，通过 for 循环来不断进行重试。当 CAS 成功后，则会再来实际进行线程的创建操作。但在这时候线程也未必能够创建成功，因为在 CAS 成功后线程池可能被关闭了，或者是在创建线程时抛出异常了，此时就需要回滚对 workerCount 的修改\n该方法如果返回 true，意味着新创建了一个 Worker 线程，同时线程也被启动了\n该方法如果返回 false，则可能是由于以下情况：\n生命周期状态大于等于 STOP 生命周期状态等于 SHUTDOWN，但 firstTask 不为 null，或者任务队列为空 当前线程数已经超出限制 符合创建线程的条件，但创建过程中或启动线程的过程中抛出了异常 private boolean addWorker(Runnable firstTask, boolean core) { //下面的 for 主要逻辑： //在创建线程前通过 CAS 原子性地将“工作者线程数量递增加一” //由于 CAS 可能会失败，所以将之放到 for 循环中进行循环重试 //每次循环前后都需要检查下当前状态是否允许创建线程 retry: for (;;) { int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs \u0026gt;= SHUTDOWN \u0026amp;\u0026amp; ! (rs == SHUTDOWN \u0026amp;\u0026amp; firstTask == null \u0026amp;\u0026amp; ! workQueue.isEmpty())) //当外部调用 shutdown() 方法后，线程池状态会变迁为 SHUTDOWN //此时依然允许创建线程来对队列中的任务进行处理，但是不会再接受新任务 //除这种情况之外不允许在非 RUNNING 的时候还创建线程 return false; for (;;) { int wc = workerCountOf(c); if (wc \u0026gt;= CAPACITY || wc \u0026gt;= (core ? corePoolSize : maximumPoolSize)) //当前线程数已经超出最大限制 return false; if (compareAndIncrementWorkerCount(c)) //通过 CAS 更新工作者线程数成功后就跳出循环，去实际创建线程 break retry; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) //循环过程中线程池状态被改变了，重新循环 continue retry; // else CAS failed due to workerCount change; retry inner loop } } boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try { w = new Worker(firstTask); final Thread t = w.thread; if (t != null) { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); if (rs \u0026lt; SHUTDOWN || (rs == SHUTDOWN \u0026amp;\u0026amp; firstTask == null)) { if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); //更新线程池曾经达到的最大线程数 int s = workers.size(); if (s \u0026gt; largestPoolSize) largestPoolSize = s; workerAdded = true; } } finally { mainLock.unlock(); } if (workerAdded) { t.start(); workerStarted = true; } } } finally { //如果线程没有被成功启动，则需要将该任务从队列中移除并重新更新工作者线程数 if (! workerStarted) addWorkerFailed(w); } return workerStarted; } 3、线程的执行流程 上面所讲的线程其实指的是 ThreadPoolExecutor 的内部类 Worker ，Worker 内部包含了一个 Thread 对象，所以本文就把 Worker 实例也看做线程来对待\nWorker 继承于 AbstractQueuedSynchronizer，意味着 Worker 就相当于一个锁。之没有使用 synchronized 或者 ReentrantLock，是因为它们都是可重入锁，Worker 继承于 AQS 为的就是自定义实现不可重入的特性来辅助判断线程是否处于执行任务的状态：在开始执行任务前进行加锁，在任务执行结束后解锁，以便在后续通过判断 Worker 是否处于锁定状态来得知其是否处于执行阶段\nWorker 在开始执行任务前会执行 Worker.lock() ，表明线程正在执行任务 如果 Worker 处于锁定状态，则不应该对其进行中断，避免任务执行一半就被打断 如果 Worker 处于非锁定状态，说明其当前是处于阻塞获取任务的状态，此时才允许对其进行中断 线程池在执行 shutdown() 方法或 shutdownNow() 方法时会调用 interruptIdleWorkers() 方法来回收空闲的线程，interruptIdleWorkers() 方法会使用Worker.tryLock() 方法来尝试获取锁，由于 Worker 是不可重入锁，所以如果锁获取成功就说明线程处于空闲状态，此时才可以进行回收 Worker 同时也是 Runnable 类型，thread 是通过 getThreadFactory().newThread(this) 来创建的，即将 Worker 本身作为构造参数传给 Thread 进行初始化，所以在 thread 启动的时候 Worker 的 run() 方法就会被执行\nprivate final class Worker extends AbstractQueuedSynchronizer implements Runnable { /** * This class will never be serialized, but we provide a * serialVersionUID to suppress a javac warning. */ private static final long serialVersionUID = 6138294804551838833L; /** Thread this worker is running in. Null if factory fails. */ final Thread thread; //线程要执行的第一个任务，可能为 null /** Initial task to run. Possibly null. */ Runnable firstTask; //用于标记 Worker 执行过的任务数（不管成功与否都记录） /** Per-thread task counter */ volatile long completedTasks; /** * Creates with given first task and thread from ThreadFactory. * @param firstTask the first task (null if none) */ Worker(Runnable firstTask) { setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); } /** Delegates main run loop to outer runWorker */ public void run() { runWorker(this); } // Lock methods // // The value 0 represents the unlocked state. // The value 1 represents the locked state. protected boolean isHeldExclusively() { return getState() != 0; } //只有在 state 值为 0 的时候才能获取到锁，以此实现不可重入的特性 protected boolean tryAcquire(int unused) { if (compareAndSetState(0, 1)) { setExclusiveOwnerThread(Thread.currentThread()); return true; } return false; } protected boolean tryRelease(int unused) { setExclusiveOwnerThread(null); setState(0); return true; } public void lock() { acquire(1); } public boolean tryLock() { return tryAcquire(1); } public void unlock() { release(1); } public boolean isLocked() { return isHeldExclusively(); } //向线程发起中断请求 void interruptIfStarted() { Thread t; if (getState() \u0026gt;= 0 \u0026amp;\u0026amp; (t = thread) != null \u0026amp;\u0026amp; !t.isInterrupted()) { try { t.interrupt(); } catch (SecurityException ignore) { } } } } runWorker(Worker) 方法就是线程正式进行任务执行的地方。该方法通过 while 循环不断从任务队列中取出任务来进行执行，如果 getTask()方法返回了 null，那此时就需要将此线程进行回收。如果在任务执行过程中抛出了异常，那也需要回收此线程\nfinal void runWorker(Worker w) { Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; //因为 Worker 的默认值是 -1，而 Worker 的 interruptIfStarted() 方法只有在 state \u0026gt;=0 的时候才允许进行中断 //所以这里调用 unlock() 并不是为了解锁，而是为了让 Worker 的 state 值变为 0，让 Worker 允许外部进行中断 //所以，即使客户端调用了 shutdown 或者 shutdownNow 方法，在 Worker 线程还未执行到这里前，无法在 interruptWorkers() 方法里发起中断请求 w.unlock(); // allow interrupts //用于标记是否由于被打断而非正常结束导致的线程终止 //为 true 表示非正常结束 boolean completedAbruptly = true; try { // 如果 getTask() 为 null，说明线程池已经被停止或者需要进行线程回收 while (task != null || (task = getTask()) != null) { //在开始执行任务前进行加锁，在任务执行结束后解锁 //以便在后续通过判断 Worker 是否处于锁定状态来得知其是否处于执行阶段 w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt //确保当状态值大于等于 STOP 时有向线程发起过中断请求 if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() \u0026amp;\u0026amp; runStateAtLeast(ctl.get(), STOP))) \u0026amp;\u0026amp; !wt.isInterrupted()) wt.interrupt(); try { beforeExecute(wt, task); Throwable thrown = null; try { task.run(); } catch (RuntimeException x) { thrown = x; throw x; } catch (Error x) { thrown = x; throw x; } catch (Throwable x) { thrown = x; throw new Error(x); } finally { afterExecute(task, thrown); } } finally { task = null; w.completedTasks++; w.unlock(); } } completedAbruptly = false; } finally { //回收此线程 processWorkerExit(w, completedAbruptly); } } private Runnable getTask() { boolean timedOut = false; // Did the last poll() time out? for (; ; ) { int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. //如何当前状态大于等于 STOP，则返回 null //如何当前状态是 SHUTDOWN 且任务队列为空，则返回 null if (rs \u0026gt;= SHUTDOWN \u0026amp;\u0026amp; (rs \u0026gt;= STOP || workQueue.isEmpty())) { decrementWorkerCount(); return null; } int wc = workerCountOf(c); // Are workers subject to culling? //timed 用于标记从任务队列中取任务时是否需要进行超时控制 //如果允许回收空闲核心线程或者是当前的线程总数已经超出 corePoolSize 了，那么就需要进行超时控制 boolean timed = allowCoreThreadTimeOut || wc \u0026gt; corePoolSize; //1. 线程总数超出 maximumPoolSize //2. 允许回收核心线程，且核心线程的空闲时间已达到限制了 //如果以上两种情况之一有一个满足，且当前线程数大于 1 或者任务队列为空时就返回 null（如果 CAS 更新 WorkerCount 成功的话） //避免在任务队列不为空且只有一个线程时还回收线程导致任务没人处理 if ((wc \u0026gt; maximumPoolSize || (timed \u0026amp;\u0026amp; timedOut)) \u0026amp;\u0026amp; (wc \u0026gt; 1 || workQueue.isEmpty())) { if (compareAndDecrementWorkerCount(c)) return null; continue; } try { Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; //如果 r 为 null，说明是由于超时导致 poll 返回了 null //在下一次循环时将判断是否回收此线程 timedOut = true; } catch (InterruptedException retry) { timedOut = false; } } } getTask() 方法获取任务的流程图如下所示：\n4、线程的回收流程 当外部调用了线程池的以下几个方法之一时，就会触发到线程的回收机制：\n允许回收核心线程：allowCoreThreadTimeOut() 重置核心线程池大小：setCorePoolSize() 重置最大线程池大小：setMaximumPoolSize() 重置线程最大空闲时间：setKeepAliveTime() 关闭线程池：shutdown() 停止线程池：shutdownNow() /** * 用于控制核心线程是否可以由于空闲时间超时而被回收 * 超时时间和非核心线程一样由 keepAliveTime 来指定 * * @param value */ public void allowCoreThreadTimeOut(boolean value) { if (value \u0026amp;\u0026amp; keepAliveTime \u0026lt;= 0) throw new IllegalArgumentException(\u0026#34;Core threads must have nonzero keep alive times\u0026#34;); if (value != allowCoreThreadTimeOut) { allowCoreThreadTimeOut = value; if (value) //回收掉空闲线程 interruptIdleWorkers(); } } /** * 重置 corePoolSize * * @param corePoolSize */ public void setCorePoolSize(int corePoolSize) { if (corePoolSize \u0026lt; 0) throw new IllegalArgumentException(); int delta = corePoolSize - this.corePoolSize; this.corePoolSize = corePoolSize; if (workerCountOf(ctl.get()) \u0026gt; corePoolSize) //如果当前的线程总数已经超出新的 corePoolSize 的话那就进行线程回收 interruptIdleWorkers(); else if (delta \u0026gt; 0) { //会走进这里，说明新的 corePoolSize 比原先的大，但当前线程总数还小于等于新的 corePoolSize //此时如果任务队列不为空的话，那么就需要创建一批新的核心线程来处理任务 //delta 和 workQueueSize 中的最小值就是需要启动的线程数 //而如果在创建过程中任务队列已经空了（被其它线程拿去处理了），那就不再创建线程 int k = Math.min(delta, workQueue.size()); while (k-- \u0026gt; 0 \u0026amp;\u0026amp; addWorker(null, true)) { if (workQueue.isEmpty()) break; } } } /** * 用于设置线程池允许存在的最大活跃线程数 * * @param maximumPoolSize */ public void setMaximumPoolSize(int maximumPoolSize) { if (maximumPoolSize \u0026lt;= 0 || maximumPoolSize \u0026lt; corePoolSize) throw new IllegalArgumentException(); this.maximumPoolSize = maximumPoolSize; if (workerCountOf(ctl.get()) \u0026gt; maximumPoolSize) //回收掉空闲线程 interruptIdleWorkers(); } /** * 用于设置非核心线程在空闲状态能够存活的时间 * * @param time * @param unit */ public void setKeepAliveTime(long time, TimeUnit unit) { if (time \u0026lt; 0) throw new IllegalArgumentException(); //为了避免频繁创建线程，核心线程如果允许超时回收的话，超时时间不能为 0 if (time == 0 \u0026amp;\u0026amp; allowsCoreThreadTimeOut()) throw new IllegalArgumentException(\u0026#34;Core threads must have nonzero keep alive times\u0026#34;); long keepAliveTime = unit.toNanos(time); long delta = keepAliveTime - this.keepAliveTime; this.keepAliveTime = keepAliveTime; if (delta \u0026lt; 0) //如果新设置的值比原先的超时时间小的话，那就需要去回收掉空闲线程 interruptIdleWorkers(); } /** * 关闭线程池 */ public void shutdown() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { checkShutdownAccess(); //将当前状态设置为 SHUTDOWN advanceRunState(SHUTDOWN); //回收掉空闲线程 interruptIdleWorkers(); onShutdown(); // hook for ScheduledThreadPoolExecutor } finally { mainLock.unlock(); } //尝试看是否能把线程池状态置为 TERMINATED tryTerminate(); } /** * 停止线程池 * * @return 任务队列中缓存的所有任务 */ public List\u0026lt;Runnable\u0026gt; shutdownNow() { List\u0026lt;Runnable\u0026gt; tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { checkShutdownAccess(); //将当前状态设置为 STOP advanceRunState(STOP); //回收掉空闲线程 interruptWorkers(); //获取任务队列中缓存的所有任务 tasks = drainQueue(); } finally { mainLock.unlock(); } //尝试看是否能把线程池状态置为 TERMINATED tryTerminate(); return tasks; } 上述的几个方法最终都会调用 interruptIdleWorkers(boolean onlyOne) 方法来回收空闲线程。该方法通过向线程发起中断请求来使 Worker 退出 runWorker(Worker w) 方法，最终会调用 processWorkerExit(Worker w, boolean completedAbruptly) 方法来完成实际的线程回收操作\nprivate void interruptIdleWorkers() { interruptIdleWorkers(false); } private void interruptIdleWorkers(boolean onlyOne) { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { for (Worker w : workers) { Thread t = w.thread; //仅在线程的中断标记为 false 时才发起中断，避免重复发起中断请求 //且仅在 w.tryLock() 能成功（即 Worker 并非处于执行任务的阶段）才发起中断，避免任务还未执行完就被打断 if (!t.isInterrupted() \u0026amp;\u0026amp; w.tryLock()) { try { t.interrupt(); } catch (SecurityException ignore) { } finally { w.unlock(); } } if (onlyOne) break; } } finally { mainLock.unlock(); } } /** * 回收线程 * * @param w Worker * @param completedAbruptly 是否是由于任务执行过程抛出异常导致需要来回收线程 * true：由于任务抛出异常 * false：由于线程空闲时间达到限制条件 */ private void processWorkerExit(Worker w, boolean completedAbruptly) { if (completedAbruptly) // If abrupt, then workerCount wasn\u0026#39;t adjusted decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { //更新线程池总共处理过的任务数 completedTaskCount += w.completedTasks; //移除此线程 workers.remove(w); } finally { mainLock.unlock(); } tryTerminate(); int c = ctl.get(); if (runStateLessThan(c, STOP)) { //在任务队列不为空的时候，需要确保至少有一个线程可以来处理任务，否则就还是需要再创建一个新线程 if (!completedAbruptly) { int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 \u0026amp;\u0026amp; !workQueue.isEmpty()) min = 1; if (workerCountOf(c) \u0026gt;= min) return; // replacement not needed } addWorker(null, false); } } 除了上述几个方法会主动触发到线程回收机制外，当线程池满足以下几种情况之一时，也会进行线程的回收：\n非核心线程的空闲时间超出了 keepAliveTime allowCoreThreadTimeOut 为 true 且核心线程的空闲时间超出了 keepAliveTime 以上几种情况其触发时机主要看 getTask() 方法就可以。在向任务队列 workQueue 获取任务前，通过判断当前线程池的 allowCoreThreadTimeOut、corePoolSize、workerCount 等参数来决定是否需要对“从任务队列获取任务”这个操作进行限时。如果需要进行限时且获取任务的时间超出 keepAliveTime 的话，那就说明此线程的空闲时间已经达到限制了，需要对其进行回收\nprivate Runnable getTask() { boolean timedOut = false; // Did the last poll() time out? for (; ; ) { int c = ctl.get(); int rs = runStateOf(c); if (rs \u0026gt;= SHUTDOWN \u0026amp;\u0026amp; (rs \u0026gt;= STOP || workQueue.isEmpty())) { decrementWorkerCount(); return null; } int wc = workerCountOf(c); // Are workers subject to culling? //timed 用于标记从任务队列中取任务时是否需要进行超时控制 //如果允许回收空闲核心线程或者是当前的线程总数已经超出 corePoolSize 了，那么就需要进行超时控制 boolean timed = allowCoreThreadTimeOut || wc \u0026gt; corePoolSize; //1. 线程总数超出 maximumPoolSize //2. 允许回收核心线程，且核心线程的空闲时间已达到限制了 //如果以上两种情况之一有一个满足，且当前线程数大于 1 或者任务队列为空时就返回 null（如果 CAS 更新 WorkerCount 成功的话） //避免在任务队列不为空且只有一个线程时还回收线程导致任务没人处理 if ((wc \u0026gt; maximumPoolSize || (timed \u0026amp;\u0026amp; timedOut)) \u0026amp;\u0026amp; (wc \u0026gt; 1 || workQueue.isEmpty())) { if (compareAndDecrementWorkerCount(c)) return null; continue; } try { Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true; //如果能执行到 timedOut = true 说明是由于超时导致 poll 返回了 null //之所以不在判断到 r 不为 null 的时候就直接 return 出去 //是因为可能在获取任务的过程中外部又重新修改了 allowCoreThreadTimeOut 和 corePoolSize 等配置 //导致此时又不需要回收此线程了，所以就在下一次循环时再判断是否回收此线程 } catch (InterruptedException retry) { timedOut = false; } } } 以上就是线程池基本所有的线程回收流程。线程回收机制有助于节约系统资源，但如果 corePoolSize、keepAliveTime 等参数设置得和系统的实际运行情况不符的话，反而会导致线程频繁地被创建和回收，反而加大了资源开销\n5、线程池的关闭流程 shutdown() 和 shutdownNow() 方法可以用来关闭和停止线程池\nshutdown()。使用该方法，已提交的任务会被继续执行，而后续新提交的任务则会走拒绝策略。该方法返回时，线程池可能尚未走向终止状态 TERMINATED，即线程池中可能还有线程还在执行任务 shutdownNow()。使用该方法，正在运行的线程会尝试停止，任务队列中的任务也不会执行而是作为方法返回值返回。由于该方法是通过调用 Thread.interrupt() 方法来停止正在执行的任务的，因此某些无法响应中断的任务可能需要等到任务完成后才能停止线程 由于这两个方法调用过后线程池都不会再接收新任务了，所以在回收空闲线程后，还需要检查下线程是否都已经回收完毕了，是的话则需要将线程池的生命周期状态向 TIDYING 和 TERMINATED 迁移\nfinal void tryTerminate() { for (;;) { int c = ctl.get(); //在以下几种情况不需要终止线程池： //1.还处于运行状态 //2.已经处于 TIDYING 或 TERMINATED 状态 //3.处于 SHUTDOWN 状态且还有待处理的任务 if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateOf(c) == SHUTDOWN \u0026amp;\u0026amp; ! workQueue.isEmpty())) return; //在达到 TIDYING 状态前需要确保所有线程都被关闭了 if (workerCountOf(c) != 0) { // Eligible to terminate interruptIdleWorkers(ONLY_ONE); return; } final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) { try { //terminated() 方法执行完毕后，线程池状态就从 TIDYING 转为 TERMINATED 了，此时线程池就走向终止了 terminated(); } finally { ctl.set(ctlOf(TERMINATED, 0)); //唤醒所有在等待线程池 TERMINATED 的线程 termination.signalAll(); } return; } } finally { mainLock.unlock(); } // else retry on failed CAS } } 6、任务队列的选择 阻塞队列(BlockingQueue)是一个支持两个附加操作的队列。这两个附加的操作是：在队列为空时，获取数据的线程会阻塞等待直到从队列获取到任务。当队列已满时，存储数据的线程会阻塞等待直到队列空出位置可以存入数据。阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加数据的线程，消费者是从队列里取出数据的线程。阻塞队列就是生产者存放数据的容器，而消费者也只从容器里取数据\n线程池实现解耦的关键就是有了 任务队列/阻塞队列 的存在。线程池中是以生产者消费者模式+阻塞队列来实现的，任务队列负责缓存外部提交的任务，线程负责从任务队列取出任务，这样客户端提交的任务就避免了和线程直接关联\n选择不同的阻塞队列可以实现不一样的任务存取策略：\n7、任务的拒绝策略 随着客户端不断地提交任务，当前线程池大小也会不断增加。在当前线程池大小达到 corePoolSize 的时候，新提交的任务会被缓存到任务队列之中，由线程后续不断从队列中取出任务并执行。当任务队列满了之后，线程池就会创建非核心线程。当线程总数达到 maximumPoolSize 且所有线程都处于工作状态，同时任务队列也满了后，客户端再次提交任务时就会被拒绝。而被拒绝的任务具体的处理策略则由 RejectedExecutionHandler 来进行定义\npublic interface RejectedExecutionHandler { void rejectedExecution(Runnable r, ThreadPoolExecutor executor); } 当客户端提交的任务被拒绝时，线程池关联的 RejectedExecutionHandler 对象的 rejectedExecution 方法就会被调用，相应的拒绝策略可以由客户端来指定\nThreadPoolExecutor 提供了以下几种拒绝策略，默认使用的是 AbortPolicy\n实现类 策略 AbortPolicy 直接抛出异常，是 ThreadPoolExecutor 的默认策略 DiscardPolicy 直接丢弃该任务，不做任何响应也不会抛出异常 DiscardOldestPolicy 如果线程池未被停止，则将工作队列中最老的任务丢弃，然后尝试接纳该任务 CallerRunsPolicy 如果线程池未被停止，则直接在客户端线程上执行该任务 任务的拒绝策略只会在提交任务的时候被触发，即只在 execute(Runnable command) 方法中被触发到。execute(Runnable command) 方法会判断当前状态是否允许接受该任务，如果不允许的话则会走拒绝任务的流程\npublic void execute(Runnable command) { if (command == null) throw new NullPointerException(); int c = ctl.get(); if (workerCountOf(c) \u0026lt; corePoolSize) { if (addWorker(command, true)) return; c = ctl.get(); } if (isRunning(c) \u0026amp;\u0026amp; workQueue.offer(command)) { //线程池还处于运行状态且成功添加任务到任务队列 //需要重新检查下运行状态 //因为等执行到这里时，线程池可能被其它线程关闭了 int recheck = ctl.get(); //1、如果线程池已经处于非运行状态了 //1.1、如果移除 command 成功，则走拒绝策略 //1.2、如果移除 command 失败（因为 command 可能已经被其它线程拿去执行了），则走第 3 步 //2、如果线程池还处于运行状态，则走第 3 步 //3、如果当前线程数量为 0，则创建线程进行处理 //第 3 步的意义在于：corePoolSize 可以被设为 0，所以这里需要检查下，在需要的时候创建一个非核心线程 if (! isRunning(recheck) \u0026amp;\u0026amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); } //如果线程池处于非运行状态了，或者是处于运行状态但队列已满了，此时就会走到这里 //在这里尝试创建一个非核心线程 //如果线程创建失败，说明要么是线程池当前状态大于等于 STOP，或者是任务队列已满且线程总数达到 maximumPoolSize 了 //此时就走拒绝策略 else if (!addWorker(command, false)) reject(command); } final void reject(Runnable command) { handler.rejectedExecution(command, this); } 8、监控线程池的运行状态 ThreadPoolExecutor 提供了多个配置参数以便满足多种不同的需求，这些配置参数包含：corePoolSize、maximumPoolSize、keepAliveTime、allowCoreThreadTimeOut 等。但很多时候我们一开始使用线程池时并不知道该如何配置参数才最为适应当前需求，那么就只能通过监控线程池的运行状态来进行考察，最终得到一份最合理的配置参数\n可以通过 ThreadPoolExecutor 的以下几个属性来监控线程池的运行状态：\ntaskCount：线程池已执行结束（不管成功与否）的任务数加上任务队列中目前包含的任务数 completedTaskCount：线程池已执行结束（不管成功与否）的任务数，小于等于 taskCount largestPoolSize：线程池曾经创建过的最大线程数量。如果该数值等于 maximumPoolSize 那就说明线程池曾经满过 getPoolSize()：获取当前线程总数 getActiveCount()：获取当前正在执行任务的线程总数 此外，ThreadPoolExecutor 也预留了几个钩子方法可以由子类去实现。通过以下几个方法，就可以实现每个任务开始执行前和执行后，以及线程池走向终止时插入一些自定义的监控代码，以此来实现：计算任务的平均执行时间、最小执行时间和最大执行时间等功能\nprotected void beforeExecute(Thread t, Runnable r) { } protected void afterExecute(Runnable r, Throwable t) { } protected void terminated() { } 四、Executors Executors 是 JDK 提供的一个线程池创建工具类，封装了很多个创建 ExecutorService 实例的方法，这里就来介绍下这几个方法，这些线程池的差别主要都是由于选择了不同的任务队列导致的，读者需要先认识下以下几种任务队列\nnewFixedThreadPool方法创建的线程池，核心线程数和最大线程数都是 nThreads，所以线程池在任何时候最多也只会有 nThreads 个线程在同时运行，且在停止线程池前所有线程都不会被回收。LinkedBlockingQueue 的默认容量是 Integer.MAX_VALUE，近乎无限，在线程繁忙的情况下有可能导致等待处理的任务持续堆积，使得系统频繁 GC，最终导致 OOM\n此类线程池适合用于希望所有任务都能够被执行的情况\npublic static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026lt;Runnable\u0026gt;()); } public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026lt;Runnable\u0026gt;(), threadFactory); } newSingleThreadExecutor方法创建的线程池，核心线程数和最大线程数都是 1，所以线程池在任何时候最多也只会有 1 个线程在同时运行，且在停止线程池前所有线程都不会被回收。由于使用了 LinkedBlockingQueue，所以在极端情况下也是有发生 OOM 的可能\n此类线程池适合用于执行需要串行处理的任务，或者是任务的提交间隔比任务的执行时间长的情况\npublic static ExecutorService newSingleThreadExecutor() { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026lt;Runnable\u0026gt;())); } public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026lt;Runnable\u0026gt;(), threadFactory)); } newCachedThreadPool方法创建的线程池，核心线程数是 0，最大线程数是 Integer.MAX_VALUE，所以允许同时运行的线程数量近乎无限。再加上 SynchronousQueue 是一个不储存元素的阻塞队列，每当有新任务到来时，如果当前没有空闲线程的话就会马上启动一个新线程来执行任务，这使得任务总是能够很快被执行，提升了响应速度，但同时也存在由于要执行的任务过多导致一直创建线程的可能性，这在任务耗时过长且任务量过多的情况下也可能导致 OOM\n此类线程池适合用于对任务的处理速度要求比较高的情况\npublic static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue\u0026lt;Runnable\u0026gt;()); } public static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue\u0026lt;Runnable\u0026gt;(), threadFactory); } newScheduledThreadPool方法创建的线程池对应的是 ScheduledThreadPoolExecutor，其继承于 ThreadPoolExecutor 并实现了 ScheduledExecutorService 接口，在线程池的基础上扩展实现了执行定时任务的能力。ScheduledThreadPoolExecutor 的核心线程数由入参 corePoolSize 决定，最大线程数是 Integer.MAX_VALUE，keepAliveTime 是 0 秒，所以该线程池可能同时运行近乎无限的线程，但一旦当前没有待执行的任务的话，线程就会马上被回收\n此类线程池适合用于需要定时多次执行特定任务的情况\npublic static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) { return new ScheduledThreadPoolExecutor(corePoolSize); } public static ScheduledExecutorService newScheduledThreadPool( int corePoolSize, ThreadFactory threadFactory) { return new ScheduledThreadPoolExecutor(corePoolSize, threadFactory); } newSingleThreadScheduledExecutor方法 newScheduledThreadPool 方法基本一样，只是直接指定了核心线程数为 1\npublic static ScheduledExecutorService newSingleThreadScheduledExecutor() { return new DelegatedScheduledExecutorService (new ScheduledThreadPoolExecutor(1)); } public static ScheduledExecutorService newSingleThreadScheduledExecutor(ThreadFactory threadFactory) { return new DelegatedScheduledExecutorService (new ScheduledThreadPoolExecutor(1, threadFactory)); } 五、线程池故障 1、线程池死锁 多个线程会因为循环等待对方持有的排他性资源而导致死锁，线程池也可能会因为多个任务间的相互依赖而导致线程池死锁。例如，如果在线程池中执行的任务 A 在其执行过程中又向同个线程池提交了任务 B，且任务 A 的执行结束又依赖于任务 B 的执行结果，那么就可能出现这样的一种极端情形：线程池中的所有正在执行任务的线程都在等待其它任务的处理结果，而这些任务均在任务队列中处于待执行状态，且由于线程总数已经达到线程池的最大线程数量限制，所以任务队列中的任务就会一直无法被执行，最终导致所有任务都无法完成，从而形成线程池死锁\n因此，提交给同一个线程池的任务必须是没有互相依赖关系的。对于有依赖关系的任务，应该提交给不同的线程池，以此来避免死锁的发生\n2、线程泄漏 线程泄漏指由于某种原因导致线程池中实际可用的线程变少的一种异常情况。如果线程泄漏持续存在，那么线程池中的线程会越来越少，最终使得线程池再也无法处理任务。导致线程泄露的原因可能有两种：由于线程异常自动终止或者由于程序缺陷导致线程处于非有效运行状态。前者通常是由于 Thread.run() 方法中没有捕获到任务抛出的 Exception 或者 Error 导致的，使得相应线程被提前终止而没有相应更新线程池当前的线程数量，ThreadPoolExecutor 内部已经对这种情形进行了预防。后者可能是由于客户端提交的任务包含阻塞操作（Object.wait() 等操作），而该操作又没有相应的时间或者条件方面的限制，那么就有可能导致线程一直处于等待状态而无法执行其它任务，这样最终也是形成了线程泄漏\n六、总结 线程池通过复用一定数量的线程来执行不断被提交的任务，除了可以节约线程这种有限而昂贵的资源外，还包含以下好处：\n提高响应速度。ThreadPoolExecutor 提供了预先创建一定数量的线程的功能，使得后续提交的任务可以立即被执行而无须等待线程被创建，从而提高了系统的响应速度 抵消线程创建的开销。一个线程可以先后用于执行多个任务，那创建线程带来的成本（资源和时间）就可以看做是被平摊到其执行的所有任务中。一个线程执行的任务越多，那么创建该线程的“性价比”就越高 封装了任务的具体执行过程。线程池封装了每个线程在创建、管理、复用、回收等各个阶段的逻辑，使得客户端代码只需要提交任务和获取任务的执行结果，而无须关心任务的具体执行过程。即使后续想要将任务的执行方式从并发改为串行，往往也只需要修改线程池内部的处理逻辑即可，而无需修改客户端代码 减少销毁线程的开销。JVM 在销毁一个已经停止的线程时也有着资源和时间方面的开销，采用线程池可以避免频繁地创建线程，从而减少了销毁线程的次数，减少了相应开销 七、参考资料 Java线程池实现原理及其在美团业务中的实践 ","permalink":"http://localhost:1313/hugo-blog/public/post/kotlin/java-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%BC%80%E5%8F%915%E8%B6%85%E8%AF%A6%E7%BB%86%E7%9A%84-threadpoolexecutor-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/","tags":[],"title":"Java 多线程开发（5）超详细的 ThreadPoolExecutor 源码解析"},{"categories":[],"content":"一、什么是连接池 连接池是应用程序与数据库之间的一个缓冲区，它存储了一定数量的空闲数据库连接，当应用程序需要连接数据库时，可以从连接池中获取一个可用连接，使用完毕后再将连接归还给连接池，从而避免了每次连接都需要创建和销毁连接的开销，提高了应用程序的性能和可伸缩性。连接池也可以控制数据库连接的数量和复用，从而减少了数据库的负担。\n简单理解的话就是将连接放到自己家抽屉里，需要用的时候就去拿，不用了就放回去，减少了连接的时间，不用去远处去拿。\n二、连接池的好处 连接池的好处可以总结为以下几点：\n1. 提高性能 数据库连接是资源密集型操作，每次建立连接都需要进行TCP握手，验证用户身份等操作。连接池缓存了一定数量的已经建立的连接，可以更快速地获取和释放连接，减少了连接建立和关闭的时间，提高了应用程序的性能。\n2. 稳定性 当并发量较高时，如果每个请求都建立一个新的数据库连接，可能会导致数据库服务器过载。使用连接池可以控制连接的数量，避免过多的连接导致数据库服务器崩溃。\n3. 节省资源 使用连接池可以重复利用已有的数据库连接，避免了频繁创建和关闭连接的开销，从而节省了资源。\n4. 提高可靠性 连接池可以监控数据库连接的状态，并在连接出现问题时自动重置连接。这对于保持应用程序的可靠性和稳定性非常重要。\n有四种连接池c3p0、driuid、HikariCP、DBCP\n三、导入jar包 因为所有导入jar包步骤都是一致的，所以单拎出来写\n因为需要测试连接池连接数据库是否成功，我们这里使用的是MySql\nMySql.jar包：https://dev.mysql.com/downloads/connector/j/ 下载MySqljar包 导入jar包 将下载好的jar包复制到项目中，建议大家建一个文件专门用来放置jar包。 复制进去就是这样，接下来添加为库\n添加为库 右击jar包添加为库 根据需求选择级别之后直接确定 所有jar包都是这样导入。\n四、c3p0连接池 下载jar包 C3P0jar包：https://sourceforge.net/projects/c3p0/ 创建配置文件 创建c3p0-config.xml\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;c3p0-config\u0026gt; \u0026lt;!--默认配置--\u0026gt; \u0026lt;default-config\u0026gt; \u0026lt;!--数据库驱动--\u0026gt; \u0026lt;property name=\u0026#34;driverClass\u0026#34;\u0026gt;com.mysql.cj.jdbc.Driver\u0026lt;/property\u0026gt; \u0026lt;!--数据库的url--\u0026gt; \u0026lt;property name=\u0026#34;jdbcUrl\u0026#34;\u0026gt;jdbc:mysql://localhost:3306/vehicleUpkeepDB\u0026lt;/property\u0026gt; \u0026lt;!--用户名写自己的--\u0026gt; \u0026lt;property name=\u0026#34;user\u0026#34;\u0026gt;root\u0026lt;/property\u0026gt; \u0026lt;!--密码写自己的--\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34;\u0026gt;sasa\u0026lt;/property\u0026gt; \u0026lt;!--初始连接数--\u0026gt; \u0026lt;property name=\u0026#34;initialPoolSize\u0026#34;\u0026gt;10\u0026lt;/property\u0026gt; \u0026lt;!--最大连接数--\u0026gt; \u0026lt;property name=\u0026#34;maxPoolSize\u0026#34;\u0026gt;100\u0026lt;/property\u0026gt; \u0026lt;!--最小连接数--\u0026gt; \u0026lt;property name=\u0026#34;minPoolSize\u0026#34;\u0026gt;10\u0026lt;/property\u0026gt; \u0026lt;/default-config\u0026gt; \u0026lt;/c3p0-config\u0026gt; 测试连接 // 创建 ComboPooledDataSource 对象，该对象间接实现了 java 官方提供的 DataSource 接口 ComboPooledDataSource dataSource = new ComboPooledDataSource(); //获取连接，这里会有个异常可能连接不成功，你可以抛出或者处理 Connection connection = dataSource.getConnection(); //执行sql语句，这里会有个异常sql语句可能出错，你可以抛出或者处理 ResultSet resultSet = connection.prepareStatement(\u0026#34;select count(0) from user \u0026#34;).executeQuery(); //处理结果 if(resultSet.next()){ System.out.println(resultSet.getInt(1)); } //释放资源 resultSet.close(); connection.close(); 结果会有很多事务的东西，需要手动去关闭 这样就是连接成功了！\n五、driuid连接池 下载jar包 driuid.jar包:https://repo1.maven.org/maven2/com/alibaba/druid/1.2.0/ 导入项目，所有步骤都是一样的，不会就看上面c3p0\n创建配置文件 创建driuid.properties\n# 驱动名称(连接Mysql) driverClassName = com.mysql.cj.jdbc.Driver # 参数?rewriteBatchedStatements=True表示支持批处理机制 url = jdbc:mysql://localhost:3306/cinemaDB?useServerPrepStmts=true # 用户名,注意这里是按\u0026#34;userName\u0026#34;来读取的 userName = root # 用户密码(自己改) password = sasa # 初始化连接数量 initialSize = 10 # 最小连接数量 minIdle = 10 # 最大连接数量 maxActive = 50 # 超时时间5000ms (在等待队列中的最长等待时间,若超时,) maxWait = 5000 测试连接 //加载配置文件,会报错，可能找不到文件，可以选择抛出或者处理 Properties properties = new Properties(); properties.load(Files.newInputStream(Paths.get(\u0026#34;src\\\\driuid.properties\u0026#34;))); //在工厂中创建一个数据源,数据源的连接信息来源于properties配置文件中 DataSource dataSource = DruidDataSourceFactory.createDataSource(properties); //从连接池,获取连接对象 Connection connection = dataSource.getConnection(); //对sql语句进行预处理 PreparedStatement preparedStatement = connection.prepareStatement(\u0026#34;select count(0) from user \u0026#34;); //执行命令 ResultSet resultSet = preparedStatement.executeQuery(); //处理结果 if(resultSet.next()){ System.out.println(resultSet.getInt(1)); } //释放资源 resultSet.close(); connection.close(); 结果 这样就是连接成功了！\n六、HikariCP连接池 HikariCP需要下载三个jar包\nHiariCP.jar包：https://repo1.maven.org/maven2/com/zaxxer/HikariCP/4.0.3/ slf4j.jar包：https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.25/ log4j12.jar包：https://repo1.maven.org/maven2/org/slf4j/slf4j-log4j12/1.7.25/ 下载jar包 三个jar包都是找到**.jar**的后缀 创建配置文件 创建HikariCP.properties\n# 驱动参数 jdbcUrl=jdbc:mysql://localhost:3306/vehicleUpkeepDB?characterEncoding=utf8\u0026amp;serverTimezone=GMT%2B8 #驱动名称(连接MySql) DriverClassName = com.mysql.cj.jdbc.Driver #账号 username=root #密码 password=sasa 上面的都是必须要的，下面都有默认参数一般不用配置 #常用的参数 # 从池中借出的连接是否默认自动提交事务 # 默认 true autoCommit=true # 当我从池中借出连接时，愿意等待多长时间。如果超时，将抛出 SQLException # 默认 30000 ms，最小值 250 ms。支持 JMX 动态修改 connectionTimeout=30000 # 一个连接在池里闲置多久时会被抛弃 # 当 minimumIdle \u0026lt; maximumPoolSize 才生效 # 默认值 600000 ms，最小值为 10000 ms，0表示禁用该功能。支持 JMX 动态修改 idleTimeout=600000 # 多久检查一次连接的活性 # 检查时会先把连接从池中拿出来（空闲的话），然后调用isValid()或执行connectionTestQuery来校验活性，如果通过校验，则放回池里。 # 默认 0 （不启用），最小值为 30000 ms，必须小于 maxLifetime。支持 JMX 动态修改 keepaliveTime=0 # 当一个连接存活了足够久，HikariCP 将会在它空闲时把它抛弃 # 默认 1800000 ms，最小值为 30000 ms，0 表示禁用该功能。支持 JMX 动态修改 maxLifetime=1800000 # 用来检查连接活性的 sql，要求是一个查询语句，常用select \u0026#39;x\u0026#39; # 如果驱动支持 JDBC4.0，建议不设置，这时默认会调用 Connection.isValid() 来检查，该方式会更高效一些 # 默认为空 # connectionTestQuery= # 池中至少要有多少空闲连接。 # 当空闲连接 \u0026lt; minimumIdle，总连接 \u0026lt; maximumPoolSize 时，将新增连接 # 默认等于 maximumPoolSize。支持 JMX 动态修改 minimumIdle=5 # 池中最多容纳多少连接（包括空闲的和在用的） # 默认为 10。支持 JMX 动态修改 maximumPoolSize=10 # 用于记录连接池各项指标的 MetricRegistry 实现类 # 默认为空，只能通过代码设置 # metricRegistry= # 用于报告连接池健康状态的 HealthCheckRegistry 实现类 # 默认为空，只能通过代码设置 # healthCheckRegistry= # 连接池名称。 # 默认自动生成 poolName=zzsCP #少用的参数 # 如果启动连接池时不能成功初始化连接，是否快速失败 TODO # \u0026gt;0 时，会尝试获取连接。如果获取时间超过指定时长，不会开启连接池，并抛出异常 # =0 时，会尝试获取并验证连接。如果获取成功但验证失败则不开启池，但是如果获取失败还是会开启池 # \u0026lt;0 时，不管是否获取或校验成功都会开启池。 # 默认为 1 initializationFailTimeout=1 # 是否在事务中隔离 HikariCP 自己的查询。 # autoCommit 为 false 时才生效 # 默认 false isolateInternalQueries=false # 是否允许通过 JMX 挂起和恢复连接池 # 默认为 false allowPoolSuspension=false # 当连接从池中取出时是否设置为只读 # 默认值 false readOnly=false # 是否开启 JMX # 默认 false registerMbeans=true # 数据库 catalog # 默认由驱动决定 # catalog= # 在每个连接创建后、放入池前，需要执行的初始化语句 # 如果执行失败，该连接会被丢弃 # 默认为空 # connectionInitSql= # JDBC 驱动使用的 Driver 实现类 # 一般根据 jdbcUrl 判断就行，报错说找不到驱动时才需要加 # 默认为空 # driverClassName= # 连接的默认事务隔离级别 # 默认值为空，由驱动决定 # transactionIsolation= # 校验连接活性允许的超时时间 # 默认 5000 ms，最小值为 250 ms，要求小于 connectionTimeout。支持 JMX 动态修改 validationTimeout=5000 # 连接对象可以被借出多久 # 默认 0（不开启），最小允许值为 2000 ms。支持 JMX 动态修改 leakDetectionThreshold=0 # 直接指定 DataSource 实例，而不是通过 dataSourceClassName 来反射构造 # 默认为空，只能通过代码设置 # dataSource= # 数据库 schema # 默认由驱动决定 # schema= # 指定连接池获取线程的 ThreadFactory 实例 # 默认为空，只能通过代码设置 # threadFactory= # 指定连接池开启定时任务的 ScheduledExecutorService 实例（建议设置setRemoveOnCancelPolicy(true)） # 默认为空，只能通过代码设置 # scheduledExecutor= # JNDI 配置的数据源名 # 默认为空 # dataSourceJndiName=null 测试连接 //加载配置文件 HikariConfig hikariConfig = new HikariConfig(\u0026#34;src\\\\HikariCP.properties\u0026#34;); //在工厂中创建一个数据源,数据源的连接信息来源于hikariConfig配置文件中 HikariDataSource ds = new HikariDataSource(hikariConfig); //获取连接 Connection conn = ds.getConnection(); //执行sql语句 ResultSet rs = conn.prepareStatement(\u0026#34;select count(*) from user\u0026#34;).executeQuery(); //处理结果 while (rs.next()) { System.out.println(rs.getInt(1)); } //释放资源 conn.close(); rs.close(); 结果 这样就是连接成功了！\n七、DBCP连接池 DBCP需要下载两个jar包\nDBCP.jar包：https://commons.apache.org/proper/commons-dbcp/download_dbcp.cgi pool.jar包：https://commons.apache.org/proper/commons-pool/download_pool.cgi 下载jar包 两个都是这个位置 配置文件 创建DBCP.properties\n#数据库连接地址 #url=jdbc:mysql://localhost:3306/数据库名（?配置参数） url=jdbc:mysql://localhost:3306/vehicleUpkeepDB?useUnicode=true\u0026amp;characterEncoding=utf-8 #数据库驱动类的全名 #driverClassName=com.mysql.jdbc.Driver #数据库帐号 username=root #数据库密码 等于号后面直接填密码，不需要引号，密码为空时可以不填或 \u0026#34;\u0026#34; password=sasa #初始化连接池时,创建的连接数量 initialSize=5 #连接池的最大连接容量，连接使用完后不释放会很容易达到最大值，导致之后的连接被卡住 maxActive=20 #空闲时允许保留的最大连接数量 maxIdle=5 #空闲时允许保留的最小连接数量 minIdle=5 #排队等候的超时时间(毫秒) maxWait=3000 测试连接 //文件输入流 InputStream is = DBCP_Demo.class.getClassLoader().getResourceAsStream(\u0026#34;DBCP.properties\u0026#34;); //将配置文件,转换为Properties对象 Properties ppt = new Properties(); ppt.load(is); //通过连接池的工厂类(DruidDataSourceFactory)的创建连接池的方法(createDataSource()) DataSource ds = BasicDataSourceFactory.createDataSource(ppt); //从连接池,获取连接对象 Connection con = ds.getConnection(); //对sql语句进行预处理 PreparedStatement ps = con.prepareStatement(\u0026#34;select count(*) from user\u0026#34;); //执行命令 ResultSet re = ps.executeQuery(); //处理结果 if(re.next()){ int anInt = re.getInt(1); System.out.println(anInt); } //释放资源 re.close(); ps.close(); con.close(); 结果： 可能遇到的问题 NoClassDefFoundError 错误\nException in thread \u0026#34;main\u0026#34; java.lang.NoClassDefFoundError: Could not initialize class lesson04.utils.JDBCUtils_DBCP 原因：DBCP2之后的版本需要 logging 包官网下载：https://commons.apache.org/proper/commons-logging/download_logging.cgi 按照上面的步骤导入 IDEA 中即可\n","permalink":"http://localhost:1313/hugo-blog/public/post/dev-log/java%E4%B8%ADc3p0druidhikaricp-dbcp%E8%BF%9E%E6%8E%A5%E6%B1%A0%E7%9A%84jar%E5%8C%85%E4%B8%8B%E8%BD%BD%E4%B8%8Eidea%E9%85%8D%E7%BD%AE/","tags":[],"title":"java中C3P0、Druid、HikariCP 、DBCP连接池的jar包下载与IDEA配置"},{"categories":[],"content":"JVM整体结构 本文主要说的是HotSpot虚拟机，\nJVM 全称是 Java Virtual Machine，中文译名：Java虚拟机\n简化一下：\nJava字节码文件 Class文件本质上是一个以8位字节为基础单位的二进制流，各个数据项目严格按照顺序紧凑的排列在Class文件中，JVM根据其特定的规则解析该二进制数据，从而得到相关信息\nClass文件采用一种伪结构来存储数据，它有两种类型：无符号数和表\n首先从整体上看一下Java字节码文件所包含的内容：\n初识Class文件、基础信息 package com.zixieqing; public class KnowClass { static int a = 0; public static void main(String[] args) { int b = a++; System.out.println(\u0026#34;b = \u0026#34; + b); } } 通过以下命令, 可以在当前所在路径下生成一个 .Class 文件\njavac KnowClass.java 使用NotePad++的十六进制插件（HEX-Editor）打开编译后的Class文件，部分截图如下：\n其中：\n左边Address这一列：是当前文件中的地址 中间部分：是整个十六进制数据 右边Dump这一列：是编码之后的结果 对于中间部分数据：\n文件开头的4个字节（“cafe babe”）就是所谓的“magic魔数”。唯有以\u0026quot;cafe babe\u0026quot;开头的Class文件方可被虚拟机所接受，这4个字节就是字节码文件的身份识别 文件是无法通过文件扩展名来确定文件类型的，文件扩展名可以随意修改，不影响文件的内容\n软件使用文件的头几个字节（文件头）去校验文件的类型，如果软件不支持该种类型就会出错\nJava字节码文件中，将文件头称为magic魔数\n0000是编译器JDK版本的次版本号0，0034转化为十进制是52，是主版本号 主次版本号指的是编译字节码文件的JDK版本号\n主版本号用来标识大版本号\nJDK1.0-1.1使用了45.0-45.3，JDK1.2是46之后每升级一个大版本就加1；副版本号是当主版本号相同时作为区分不同版本的标识，一般只需要关心主版本号\n1.2之后大版本号计算方法就是：主版本号 – 44 比如主版本号52就是52 - 44 = 8，即JDK8 以前用的 Java -version 命令也就可以验证 PS C:\\Users\\zixq\\Desktop\u0026gt; java -version java version \u0026#34;1.8.0_221\u0026#34; Java(TM) SE Runtime Environment (build 1.8.0_221-b11) Java HotSpot(TM) 64-Bit Server VM (build 25.221-b11, mixed mode) 版本号的作用主要是判断当前字节码的版本和运行时的JDK是否兼容\n主版本号不兼容导致的错误的两种解决方案： 1.升级JDK版本\t（容易引发其他的兼容性问题，并且需要大量的测试） 2.将第三方依赖的版本号降低或者更换依赖，以满足JDK版本的要求\t√ 建议采用 反编译Class文件 使用Java内置的一个反编译工具Javap可以反编译字节码文件, 用法: Javap \u0026lt;options\u0026gt; \u0026lt;Classes\u0026gt;\n其中\u0026lt;options\u0026gt;选项包括:\n-help --help -? 输出此用法消息 -version 版本信息 -v -verbose 输出附加信息 -l 输出行号和本地变量表 -public 仅显示公共类和成员 -protected 显示受保护的/公共类和成员 -package 显示程序包/受保护的/公共类和成员 (默认) -p -private 显示所有类和成员 -c 对代码进行反汇编 -s 输出内部类型签名 -sysinfo 显示正在处理的类的系统信息 (路径, 大小, 日期, MD5 散列) -constants 显示最终常量 -Classpath \u0026lt;path\u0026gt; 指定查找用户类文件的位置 -cp \u0026lt;path\u0026gt; 指定查找用户类文件的位置 -bootClasspath \u0026lt;path\u0026gt; 覆盖引导类文件的位置 输入命令Javap -verbose -p KnowClass.Class查看输出内容:\nClassfile /E:/Study/JVM-Demo/out/production/JVM-Demo/com/zixieqing/KnowClass.class\t// Class文件当前所在位置 Last modified 2023-10-31; size 862 bytes\t// 最后修改时间、文件大小 MD5 checksum 1b6100d02bb70d920adceac139839609\t// MD5值 Compiled from \u0026#34;KnowClass.java\u0026#34;\t// 编译自哪个文件 public class com.zixieqing.KnowClass\t// 类全限定名 minor version: 0\t// 次版本号 major version: 52\t// 主版本号 flags: ACC_PUBLIC, ACC_SUPER\t// 该类的访问标志\t一会儿单独说明有哪些 Constant pool:\t// 常量池 #1 = Methodref #12.#30 // java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V #2 = Fieldref #11.#31 // com/zixieqing/KnowClass.a:I #3 = Fieldref #32.#33 // java/lang/System.out:Ljava/io/PrintStream; #4 = Class #34 // java/lang/StringBuilder #5 = Methodref #4.#30 // java/lang/StringBuilder.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V #6 = String #35 // b = #7 = Methodref #4.#36 // java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; #8 = Methodref #4.#37 // java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder; #9 = Methodref #4.#38 // java/lang/StringBuilder.toString:()Ljava/lang/String; #10 = Methodref #39.#40 // java/io/PrintStream.println:(Ljava/lang/String;)V #11 = Class #41 // com/zixieqing/KnowClass #12 = Class #42 // java/lang/Object #13 = Utf8 a #14 = Utf8 I #15 = Utf8 \u0026lt;init\u0026gt; #16 = Utf8 ()V #17 = Utf8 Code #18 = Utf8 LineNumberTable #19 = Utf8 LocalVariableTable #20 = Utf8 this #21 = Utf8 Lcom/zixieqing/KnowClass; #22 = Utf8 main #23 = Utf8 ([Ljava/lang/String;)V #24 = Utf8 args #25 = Utf8 [Ljava/lang/String; #26 = Utf8 b #27 = Utf8 \u0026lt;clinit\u0026gt; #28 = Utf8 SourceFile #29 = Utf8 KnowClass.java #30 = NameAndType #15:#16 // \u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V #31 = NameAndType #13:#14 // a:I #32 = Class #43 // java/lang/System #33 = NameAndType #44:#45 // out:Ljava/io/PrintStream; #34 = Utf8 java/lang/StringBuilder #35 = Utf8 b = #36 = NameAndType #46:#47 // append:(Ljava/lang/String;)Ljava/lang/StringBuilder; #37 = NameAndType #46:#48 // append:(I)Ljava/lang/StringBuilder; #38 = NameAndType #49:#50 // toString:()Ljava/lang/String; #39 = Class #51 // java/io/PrintStream #40 = NameAndType #52:#53 // println:(Ljava/lang/String;)V #41 = Utf8 com/zixieqing/KnowClass #42 = Utf8 java/lang/Object #43 = Utf8 java/lang/System #44 = Utf8 out #45 = Utf8 Ljava/io/PrintStream; #46 = Utf8 append #47 = Utf8 (Ljava/lang/String;)Ljava/lang/StringBuilder; #48 = Utf8 (I)Ljava/lang/StringBuilder; #49 = Utf8 toString #50 = Utf8 ()Ljava/lang/String; #51 = Utf8 java/io/PrintStream #52 = Utf8 println #53 = Utf8 (Ljava/lang/String;)V { static int a; descriptor: I flags: ACC_STATIC public com.zixieqing.KnowClass();\t// 方法表集合，就是前面看Class整体中说的“方法” descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V 4: return LineNumberTable: line 12: 0 LocalVariableTable: Start Length Slot Name Signature 0 5 0 this Lcom/zixieqing/KnowClass; public static void main(java.lang.String[]);\t// 方法表集合\t一会儿说明 descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=3, locals=2, args_size=1 0: getstatic #2 // Field a:I 3: dup 4: iconst_1 5: iadd 6: putstatic #2 // Field a:I 9: istore_1 10: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 13: new #4 // class java/lang/StringBuilder 16: dup 17: invokespecial #5 // Method java/lang/StringBuilder.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V 20: ldc #6 // String b = 22: invokevirtual #7 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 25: iload_1 26: invokevirtual #8 // Method java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder; 29: invokevirtual #9 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 32: invokevirtual #10 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 35: return LineNumberTable: line 16: 0 line 18: 10 line 19: 35 LocalVariableTable: Start Length Slot Name Signature 0 36 0 args [Ljava/lang/String; 10 26 1 b I static {}; descriptor: ()V flags: ACC_STATIC Code: stack=1, locals=0, args_size=0 0: iconst_0 1: putstatic #2 // Field a:I 4: return LineNumberTable: line 13: 0 } SourceFile: \u0026#34;KnowClass.java\u0026#34;\t// 资源文件名\t即源代码的文件名 上面提到了类的访问标志：ACC_PUBLIC, ACC_SUPER，访问标志的含义如下:\n标志名称 标志值 含义 ACC_PUBLIC 0x0001 是否为Public类型 ACC_FINAL 0x0010 是否被声明为final，只有类可以设置 ACC_SUPER 0x0020 是否允许使用invokespecial字节码指令的新语义． ACC_INTERFACE 0x0200 标志这是一个接口 ACC_ABSTRACT 0x0400 是否为abstract类型，对于接口或者抽象类来说，次标志值为真，其他类型为假 ACC_SYNTHETIC 0x1000 标志这个类并非由用户代码产生 ACC_ANNOTATION 0x2000 标志这是一个注解 ACC_ENUM 0x4000 标志这是一个枚举 常量池 Constant pool意为常量池\n常量池中的数据都有一个编号，编号从1开始。在字段或者字节码指令中通过编号可以快速的找到对应的数据\n字节码指令中通过编号引用到常量池的过程称之为“符号引用”\n常量池可以理解成Class文件中的资源仓库，主要存放的是两大类常量：字面量(Literal)和符号引用(Symbolic References)，字面量类似于Java中的常量概念，如文本字符串，final常量等，而符号引用则属于编译原理方面的概念，包括以下三种:\n类和接口的全限定名(Fully Qualified Name) 字段的名称和描述符号(Descriptor) 方法的名称和描述符 不同于C/C++,，JVM是在加载Class文件的时候才进行的动态链接，也就是说这些字段和方法符号引用只有在运行期转换后才能获得真正的内存入口地址，当虚拟机运行时，需要从常量池获得对应的符号引用，再在类创建或运行时解析并翻译到具体的内存地址中。如上一节反编译的文件中的常量池：\nConstant pool:\t// 常量池 #1 = Methodref #12.#30 // java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V #2 = Fieldref #11.#31 // com/zixieqing/KnowClass.a:I #3 = Fieldref #32.#33 // java/lang/System.out:Ljava/io/PrintStream; #4 = Class #34 // java/lang/StringBuilder #5 = Methodref #4.#30 // java/lang/StringBuilder.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V #6 = String #35 // b = #7 = Methodref #4.#36 // java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; #8 = Methodref #4.#37 // java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder; #9 = Methodref #4.#38 // java/lang/StringBuilder.toString:()Ljava/lang/String; #10 = Methodref #39.#40 // java/io/PrintStream.println:(Ljava/lang/String;)V #11 = Class #41 // com/zixieqing/KnowClass #12 = Class #42 // java/lang/Object #13 = Utf8 a #14 = Utf8 I #15 = Utf8 \u0026lt;init\u0026gt; #16 = Utf8 ()V #17 = Utf8 Code #18 = Utf8 LineNumberTable #19 = Utf8 LocalVariableTable #20 = Utf8 this #21 = Utf8 Lcom/zixieqing/KnowClass; #22 = Utf8 main #23 = Utf8 ([Ljava/lang/String;)V #24 = Utf8 args #25 = Utf8 [Ljava/lang/String; #26 = Utf8 b #27 = Utf8 \u0026lt;clinit\u0026gt; #28 = Utf8 SourceFile #29 = Utf8 KnowClass.java #30 = NameAndType #15:#16 // \u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V #31 = NameAndType #13:#14 // a:I #32 = Class #43 // java/lang/System #33 = NameAndType #44:#45 // out:Ljava/io/PrintStream; #34 = Utf8 java/lang/StringBuilder #35 = Utf8 b = #36 = NameAndType #46:#47 // append:(Ljava/lang/String;)Ljava/lang/StringBuilder; #37 = NameAndType #46:#48 // append:(I)Ljava/lang/StringBuilder; #38 = NameAndType #49:#50 // toString:()Ljava/lang/String; #39 = Class #51 // java/io/PrintStream #40 = NameAndType #52:#53 // println:(Ljava/lang/String;)V #41 = Utf8 com/zixieqing/KnowClass #42 = Utf8 java/lang/Object #43 = Utf8 java/lang/System #44 = Utf8 out #45 = Utf8 Ljava/io/PrintStream; #46 = Utf8 append #47 = Utf8 (Ljava/lang/String;)Ljava/lang/StringBuilder; #48 = Utf8 (I)Ljava/lang/StringBuilder; #49 = Utf8 toString #50 = Utf8 ()Ljava/lang/String; #51 = Utf8 java/io/PrintStream #52 = Utf8 println #53 = Utf8 (Ljava/lang/String;)V 第一个常量是一个方法定义，指向了第12和第30个常量。以此类推查看第12和第30个常量最后可以拼接成第一个常量右侧的注释内容:\n// java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V 这段可以理解为该类的实例构造器的声明，由于Main类没有重写构造方法，所以调用的是父类的构造方法。此处也说明了Main类的直接父类是Object，该方法默认返回值是V, 也就是void，无返回值\n第二个常量同理可得:\n#2 = Fieldref #11.#31 // com/zixieqing/KnowClass.a:I #11 = Class #41 // com/zixieqing/KnowClass #13 = Utf8 a #14 = Utf8 I #41 = Utf8 com/zixieqing/KnowClass #31 = NameAndType #13:#14 // a:I 此处声明了一个字段a，类型为I，I即为int类型。关于字节码的类型对应如下：\n标识字符 含义 备注 B 基本类型byte C 基本类型char D 基本类型double F 基本类型float I 基本类型int J 基本类型long 特殊记 S 基本类型short Z 基本类型boolean 特殊记 V 特殊类型void L 对象类型，以分号结尾，如LJava/lang/Object; 特殊记 对于数组类型，每一位使用一个前置的[字符来描述，如定义一个Java.lang.String[][]类型的二维数组，将被记录为[[LJava/lang/String;\n方法表集合 在常量池之后的是对类内部的方法描述，在字节码中以表的集合形式表现，暂且不管字节码文件的16进制文件内容如何，我们直接看反编译后的内容\nstatic int a; descriptor: I flags: ACC_STATIC 此处声明了一个static的变量a，类型为int\npublic com.zixieqing.KnowClass();\t// 方法表集合，就是前面看Class整体中说的“方法” descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V 4: return LineNumberTable: line 12: 0 LocalVariableTable: Start Length Slot Name Signature 0 5 0 this Lcom/zixieqing/KnowClass; 这里是构造方法：KnowClass()，返回值为void, 权限修饰符为public\ncode内的主要属性为:\nstack:：最大操作数栈，JVM运行时会根据这个值来分配栈帧(Frame)中的操作栈深度,此处为1 locals:：局部变量所需的存储空间，单位为Slot, Slot是虚拟机为局部变量分配内存时所使用的最小单位，为4个字节大小，方法参数(包括实例方法中的隐藏参数this)，显示异常处理器的参数(try catch中的catch块所定义的异常)，方法体中定义的局部变量都需要使用局部变量表来存放。值得一提的是，locals的大小并不一定等于所有局部变量所占的Slot之和，因为局部变量中的Slot是可以重用的 args_size:：方法参数的个数，这里是1，因为每个实例方法都会有一个隐藏参数this attribute_info:：方法体内容，0,1,4为字节码\u0026quot;行号\u0026quot;，该段代码的意思是将第一个引用类型本地变量推送至栈顶，然后执行该类型的实例方法，也就是常量池存放的第一个变量，也就是注释里的Java/lang/Object.\u0026quot;\u0026quot;:()V, 然后执行返回语句，结束方法 LineNumberTable:：该属性的作用是描述源码行号与字节码行号(字节码偏移量)之间的对应关系。可以使用 -g:none 或-g:lines 选项来取消或要求生成这项信息，如果选择不生成LineNumberTable，当程序运行异常时将无法获取到发生异常的源码行号，也无法按照源码的行数来调试程序 LocalVariableTable：该属性的作用是描述帧栈中局部变量与源码中定义的变量之间的关系。可以使用 -g:none 或 -g:vars 来取消或生成这项信息，如果没有生成这项信息，那么当别人引用这个方法时，将无法获取到参数名称，取而代之的是arg0, arg1这样的占位符 start\t表示该局部变量在哪一行开始可见 length\t表示可见行数\tstart和length也可以称之为变量的作用域。从字节码的start 到 length行这个作用域里该变量一直有效/可见 Slot\t代表所在帧栈位置/变量槽的索引 Name\t变量名称 Signature\t类型签名/变量类型\t就是前面“常量池”中说的字节码的类型 上面Code中有一个小东西：0: aload_0，这里的 aload_0 叫做虚拟机字节码指令\n关于更多虚拟机字节码指令，也可以在《深入理解Java虚拟机 ：JVM高级特性与最佳实践-附录B》中获取：深入理解Java虚拟机 ：JVM高级特性与最佳实践_周志明_V3 下载 这里说几个最基本的虚拟机字节码指令：\n再来个示例：\n字节码常用工具 javap命令 这个命令前面已经玩过\njavap是JDK自带的反编译工具，可以通过控制台查看字节码文件的内容。适合在服务器上查看字节码文件内容\n直接输入javap查看所有参数\n输入 javap -v 字节码文件名称 查看具体的字节码信息。（jar包需要先使用 jar –xvf 命令解压）\njclasslib工具 exe方式安装：https://github.com/ingokegel/jclasslib IDEA集成插件：直接在IDEA的plugins中搜索jclasslib即可 **注意点：**源代码改变之后需要重编译，然后刷新jclasslib，否则看到的就是旧的class文件\n附加：遇到不会的虚拟机字节码指令时，可以通过jclasslib中右键对应指令，跳入官方文档查看描述\n阿里Arthas Arthas 是一款线上监控诊断产品，通过全局视角实时查看应用 load、内存、gc、线程的状态信息，并能在不修改应用代码的情况下，对业务问题进行诊断，大大提升线上问题排查效率\n官网：https://arthas.aliyun.com/doc/ 下载jar包，运行jar包：本地查看就下载jar包到本地，Linux中查看线上代码就丢在Linux中即可 java -jar xxx.jar 进入后使用示例：更多命令参考官网 https://arthas.aliyun.com/doc/commands.html dump 类的全限定名\t命令含义：dump已加载类的字节码文件到特定目录 场景：线上查看Class文件，就可选择将此Class文件整到自己规定的目录中去 jad 类的全限定名\t命令含义：反编译已加载类的源码\t场景：BUG修复，然后上线，但BUG还在，就可选择此命令将Class文件反编译为源代码（即xxxx.java文件） 然后看部署的是修复好BUG的代码 还是 旧代码 字节码增强技术 声明：本章节内容转载于 https://www.pdai.tech/md/java/jvm/java-jvm-class-enhancer.html 字节码增强技术 在上文中，着重介绍了字节码的结构，这为我们了解字节码增强技术的实现打下了基础。字节码增强技术就是一类对现有字节码进行修改或者动态生成全新字节码文件的技术。接下来，我们将从最直接操纵字节码的实现方式开始深入进行剖析\nASM 对于需要手动操纵字节码的需求，可以使用ASM，它可以直接生产 .Class字节码文件，也可以在类被加载入JVM之前动态修改类行为（如下图所示）ASM的应用场景有AOP（Cglib就是基于ASM）、热部署、修改其他jar包中的类等。当然，涉及到如此底层的步骤，实现起来也比较麻烦。接下来，本文将介绍ASM的两种API，并用ASM来实现一个比较粗糙的AOP。但在此之前，为了让大家更快地理解ASM的处理流程，强烈建议读者先对访问者模式进行了解。简单来说，访问者模式主要用于修改或操作一些数据结构比较稳定的数据，而通过第一章，我们知道字节码文件的结构是由JVM固定的，所以很适合利用访问者模式对字节码文件进行修改\nASM API 核心API ASM Core API可以类比解析XML文件中的SAX方式，不需要把这个类的整个结构读取进来，就可以用流式的方法来处理字节码文件，好处是非常节约内存，但是编程难度较大。然而出于性能考虑，一般情况下编程都使用Core AP。I在Core API中有以下几个关键类：\nClassReader：用于读取已经编译好的.Class文件 ClassWriter：用于重新构建编译后的类，如修改类名、属性以及方法，也可以生成新的类的字节码文件 各种Visitor类：如上所述，Core API根据字节码从上到下依次处理，对于字节码文件中不同的区域有不同的Visitor，比如用于访问方法的MethodVisitor、用于访问类变量的FieldVisitor、用于访问注解的AnnotationVisitor等。为了实现AOP，重点要使用的是MethodVisitor 树形API ASM Tree API可以类比解析XML文件中的DOM方式，把整个类的结构读取到内存中，缺点是消耗内存多，但是编程比较简单。Tree Api不同于Core API，Tree API通过各种Node类来映射字节码的各个区域，类比DOM节点，就可以很好地理解这种编程方式\n直接利用ASM实现AOP 利用ASM的Core API来增强类，这里不纠结于AOP的专业名词如切片、通知，只实现在方法调用前、后增加逻辑，通俗易懂且方便理解，首先定义需要被增强的Base类：其中只包含一个process()方法，方法内输出一行“process”。增强后，我们期望的是，方法执行前输出“start”，之后输出”end”\npublic Class Base { public void process(){ System.out.println(\u0026#34;process\u0026#34;); } } 为了利用ASM实现AOP，需要定义两个类：一个是MyClassVisitor类，用于对字节码的visit以及修改；另一个是Generator类，在这个类中定义ClassReader和ClassWriter，其中的逻辑是，ClassReader读取字节码，然后交给MyClassVisitor类处理，处理完成后由ClassWriter写字节码并将旧的字节码替换掉，Generator类较简单，我们先看一下它的实现，如下所示，然后重点解释MyClassVisitor类\nimport org.objectweb.asm.ClassReader; import org.objectweb.asm.ClassVisitor; import org.objectweb.asm.ClassWriter; public Class Generator { public static void main(String[] args) throws Exception { // 读取 ClassReader ClassReader = new ClassReader(\u0026#34;meituan/bytecode/asm/Base\u0026#34;); ClassWriter ClassWriter = new ClassWriter(ClassWriter.COMPUTE_MAXS); // 处理 ClassVisitor ClassVisitor = new MyClassVisitor(ClassWriter); ClassReader.accept(ClassVisitor, ClassReader.SKIP_DEBUG); byte[] data = ClassWriter.toByteArray(); // 输出 File f = new File(\u0026#34;operation-server/target/Classes/meituan/bytecode/asm/Base.Class\u0026#34;); FileOutputStream fout = new FileOutputStream(f); fout.write(data); fout.close(); System.out.println(\u0026#34;now generator cc success!!!!!\u0026#34;); } } MyClassVisitor继承自ClassVisitor，用于对字节码的观察，它还包含一个内部类MyMethodVisitor，继承自MethodVisitor，用于对类内方法的观察，它的整体代码如下：\nimport org.objectweb.asm.ClassVisitor; import org.objectweb.asm.MethodVisitor; import org.objectweb.asm.Opcodes; public Class MyClassVisitor extends ClassVisitor implements Opcodes { public MyClassVisitor(ClassVisitor cv) { super(ASM5, cv); } @Override public void visit(int version, int access, String name, String signature, String superName, String[] interfaces) { cv.visit(version, access, name, signature, superName, interfaces); } @Override public MethodVisitor visitMethod(int access, String name, String desc, String signature, String[] exceptions) { MethodVisitor mv = cv.visitMethod(access, name, desc, signature,exceptions); // Base类中有两个方法：无参构造以及process方法，这里不增强构造方法 if (!name.equals(\u0026#34;\u0026lt;init\u0026gt;\u0026#34;) \u0026amp;\u0026amp; mv != null) { mv = new MyMethodVisitor(mv); } return mv; } Class MyMethodVisitor extends MethodVisitor implements Opcodes { public MyMethodVisitor(MethodVisitor mv) { super(Opcodes.ASM5, mv); } @Override public void visitCode() { super.visitCode(); mv.visitFieldInsn(GETSTATIC, \u0026#34;Java/lang/System\u0026#34;, \u0026#34;out\u0026#34;, \u0026#34;LJava/io/PrintStream;\u0026#34;); mv.visitLdcInsn(\u0026#34;start\u0026#34;); mv.visitMethodInsn(INVOKEVIRTUAL, \u0026#34;Java/io/PrintStream\u0026#34;, \u0026#34;println\u0026#34;, \u0026#34;(LJava/lang/String;)V\u0026#34;, false); } @Override public void visitInsn(int opcode) { if ((opcode \u0026gt;= Opcodes.IRETURN \u0026amp;\u0026amp; opcode \u0026lt;= Opcodes.RETURN) || opcode == Opcodes.ATHROW) { // 方法在返回之前，打印\u0026#34;end\u0026#34; mv.visitFieldInsn(GETSTATIC, \u0026#34;Java/lang/System\u0026#34;, \u0026#34;out\u0026#34;, \u0026#34;LJava/io/PrintStream;\u0026#34;); mv.visitLdcInsn(\u0026#34;end\u0026#34;); mv.visitMethodInsn(INVOKEVIRTUAL, \u0026#34;Java/io/PrintStream\u0026#34;, \u0026#34;println\u0026#34;, \u0026#34;(LJava/lang/String;)V\u0026#34;, false); } mv.visitInsn(opcode); } } } 利用这个类就可以实现对字节码的修改详细解读其中的代码，对字节码做修改的步骤是：\n首先通过MyClassVisitor类中的visitMethod方法，判断当前字节码读到哪一个方法了跳过构造方法 \u0026lt;init\u0026gt; 后，将需要被增强的方法交给内部类MyMethodVisitor来进行处理 接下来，进入内部类MyMethodVisitor中的visitCode方法，它会在ASM开始访问某一个方法的Code区时被调用，重写visitCode方法，将AOP中的前置逻辑就放在这里，MyMethodVisitor继续读取字节码指令，每当ASM访问到无参数指令时，都会调用MyMethodVisitor中的visitInsn方法，我们判断了当前指令是否为无参数的“return”指令，如果是就在它的前面添加一些指令，也就是将AOP的后置逻辑放在该方法中 综上，重写MyMethodVisitor中的两个方法，就可以实现AOP了，而重写方法时就需要用ASM的写法，手动写入或者修改字节码，通过调用methodVisitor的visitXXXXInsn()方法就可以实现字节码的插入，XXXX对应相应的操作码助记符类型，比如mv.visitLdcInsn(“end”)对应的操作码就是ldc “end”，即将字符串“end”压入栈 完成这两个visitor类后，运行Generator中的main方法完成对Base类的字节码增强，增强后的结果可以在编译后的target文件夹中找到Base.Class文件进行查看，可以看到反编译后的代码已经改变了然后写一个测试类MyTest，在其中new Base()，并调用base.process()方法，可以看到下图右侧所示的AOP实现效果： ASM工具 利用ASM手写字节码时，需要利用一系列visitXXXXInsn()方法来写对应的助记符，所以需要先将每一行源代码转化为一个个的助记符，然后通过ASM的语法转换为visitXXXXInsn()，这种写法第一步将源码转化为助记符就已经够麻烦了，不熟悉字节码操作集合的话，需要我们将代码编译后再反编译，才能得到源代码对应的助记符；第二步利用ASM写字节码时，如何传参也很令人头疼，ASM社区也知道这两个问题，所以提供了工具ASM Byte Code Outline 安装后，右键选择“Show Bytecode Outline”，在新标签页中选择“ASMified”这个tab，如下图所示，就可以看到这个类中的代码对应的ASM写法了，图中上下两个红框分别对应AOP中的前置逻辑与后置逻辑，将这两块直接复制到visitor中的visitMethod()以及visitInsn()方法中，就可以了\nJavassist ASM是在指令层次上操作字节码的，阅读上文后，我们的直观感受是在指令层次上操作字节码的框架实现起来比较晦涩，故除此之外，我们再简单介绍另外一类框架：强调源代码层次操作字节码的框架Javassist\n利用Javassist实现字节码增强时，可以无须关注字节码刻板的结构，其优点就在于编程简单直接使用Java编码的形式，而不需要了解虚拟机指令，就能动态改变类的结构或者动态生成类，其中最重要的是ClassPool、CtClass、CtMethod、CtField这四个类：\nCtClass（compile-time Class）：编译时类信息，它是一个Class文件在代码中的抽象表现形式，可以通过一个类的全限定名来获取一个CtClass对象，用来表示这个类文件 ClassPool：从开发视角来看，ClassPool是一张保存CtClass信息的HashTable，key为类名，value为类名对应的CtClass对象，当我们需要对某个类进行修改时，就是通过pool.getCtClass(“ClassName”)方法从pool中获取到相应的CtClass CtMethod、CtField：这两个比较好理解，对应的是类中的方法和属性 了解这四个类后，我们可以写一个小Demo来展示Javassist简单、快速的特点，我们依然是对Base中的process()方法做增强，在方法调用前后分别输出”start”和”end”，实现代码如下，我们需要做的就是从pool中获取到相应的CtClass对象和其中的方法，然后执行method.insertBefore和insertAfter方法，参数为要插入的Java代码，再以字符串的形式传入即可，实现起来也极为简单\nimport com.meituan.mtrace.agent.Javassist.*; public Class JavassistTest { public static void main(String[] args) throws NotFoundException, CannotCompileException, IllegalAccessException, InstantiationException, IOException { ClassPool cp = ClassPool.getDefault(); CtClass cc = cp.get(\u0026#34;meituan.bytecode.Javassist.Base\u0026#34;); CtMethod m = cc.getDeclaredMethod(\u0026#34;process\u0026#34;); m.insertBefore(\u0026#34;{ System.out.println(\\\u0026#34;start\\\u0026#34;); }\u0026#34;); m.insertAfter(\u0026#34;{ System.out.println(\\\u0026#34;end\\\u0026#34;); }\u0026#34;); Class c = cc.toClass(); cc.writeFile(\u0026#34;/Users/zen/projects\u0026#34;); Base h = (Base)c.newInstance(); h.process(); } } 运行时类的重载 问题引出 上一章重点介绍了两种不同类型的字节码操作框架，且都利用它们实现了较为粗糙的AOP。其实，为了方便大家理解字节码增强技术，在上文中我们避重就轻将ASM实现AOP的过程分为了两个main方法：第一个是利用MyClassVisitor对已编译好的Class文件进行修改，第二个是new对象并调用，这期间并不涉及到JVM运行时对类的重加载，而是在第一个main方法中，通过ASM对已编译类的字节码进行替换，在第二个main方法中，直接使用已替换好的新类信息，另外在Javassist的实现中，我们也只加载了一次Base类，也不涉及到运行时重加载类\n如果我们在一个JVM中，先加载了一个类，然后又对其进行字节码增强并重新加载会发生什么呢？模拟这种情况，只需要我们在上文中Javassist的Demo中main()方法的第一行添加Base b=new Base()，即在增强前就先让JVM加载Base类，然后在执行到c.toClass()方法时会抛出错误，如下图20所示跟进c.toClass()方法中，我们会发现它是在最后调用了ClassLoader的native方法defineClass()时报错，也就是说，JVM是不允许在运行时动态重载一个类的\n显然，如果只能在类加载前对类进行强化，那字节码增强技术的使用场景就变得很窄了。我们期望的效果是：在一个持续运行并已经加载了所有类的JVM中，还能利用字节码增强技术对其中的类行为做替换并重新加载，为了模拟这种情况，我们将Base类做改写，在其中编写main方法，每五秒调用一次process()方法，在process()方法中输出一行“process”\n我们的目的就是，在JVM运行中的时候，将process()方法做替换，在其前后分别打印“start”和“end”，也就是在运行中时，每五秒打印的内容由”process”变为打印”start process end”。那如何解决JVM不允许运行时重加载类信息的问题呢？为了达到这个目的，我们接下来一一来介绍需要借助的Java类库\nimport Java.lang.management.ManagementFactory; public Class Base { public static void main(String[] args) { String name = ManagementFactory.getRuntimeMXBean().getName(); String s = name.split(\u0026#34;@\u0026#34;)[0]; // 打印当前Pid System.out.println(\u0026#34;pid:\u0026#34;+s); while (true) { try { Thread.sleep(5000L); } catch (Exception e) { break; } process(); } } public static void process() { System.out.println(\u0026#34;process\u0026#34;); } } Instrument instrument是JVM提供的一个可以修改已加载类的类库，专门为Java语言编写的插桩服务，提供支持它需要依赖JVMTI的Attach API机制实现，JVMTI这一部分，我们将在下一小节进行介绍，在JDK 1.6以前，instrument只能在JVM刚启动开始加载类时生效，而在JDK 1.6之后，instrument支持了在运行时对类定义的修改，要使用instrument的类修改功能，我们需要实现它提供的ClassFileTransformer接口，定义一个类文件转换器，接口中的transform()方法会在类文件被加载时调用，而在transform方法里，我们可以利用上文中的ASM或Javassist对传入的字节码进行改写或替换，生成新的字节码数组后返回\n我们定义一个实现了ClassFileTransformer接口的类TestTransformer，依然在其中利用Javassist对Base类中的process()方法进行增强，在前后分别打印“start”和“end”，代码如下：\nimport Java.lang.instrument.ClassFileTransformer; public Class TestTransformer implements ClassFileTransformer { @Override public byte[] transform(ClassLoader loader, String ClassName, Class\u0026lt;?\u0026gt; ClassBeingRedefined, ProtectionDomain protectionDomain, byte[] ClassfileBuffer) { System.out.println(\u0026#34;Transforming \u0026#34; + ClassName); try { ClassPool cp = ClassPool.getDefault(); CtClass cc = cp.get(\u0026#34;meituan.bytecode.JVMti.Base\u0026#34;); CtMethod m = cc.getDeclaredMethod(\u0026#34;process\u0026#34;); m.insertBefore(\u0026#34;{ System.out.println(\\\u0026#34;start\\\u0026#34;); }\u0026#34;); m.insertAfter(\u0026#34;{ System.out.println(\\\u0026#34;end\\\u0026#34;); }\u0026#34;); return cc.toBytecode(); } catch (Exception e) { e.printStackTrace(); } return null; } } 现在有了Transformer，那么它要如何注入到正在运行的JVM呢？还需要定义一个Agent，借助Agent的能力将Instrument注入到JVM中，我们将在下一小节介绍Agent，现在要介绍的是Agent中用到的另一个类Instrumentation，在JDK 1.6之后，Instrumentation可以做启动后的Instrument、本地代码（Native Code）的Instrument，以及动态改变Classpath等等。我们可以向Instrumentation中添加上文中定义的Transformer，并指定要被重加载的类，代码如下所示这样，当Agent被Attach到一个JVM中时，就会执行类字节码替换并重载入JVM的操作\nimport Java.lang.instrument.Instrumentation; public Class TestAgent { public static void agentmain(String args, Instrumentation inst) { //指定我们自己定义的Transformer，在其中利用Javassist做字节码替换 inst.addTransformer(new TestTransformer(), true); try { //重定义类并载入新的字节码 inst.retransformClasses(Base.Class); System.out.println(\u0026#34;Agent Load Done.\u0026#34;); } catch (Exception e) { System.out.println(\u0026#34;agent load failed!\u0026#34;); } } } JVMTI \u0026amp; Agent \u0026amp; Attach API 上一小节中，我们给出了Agent类的代码，追根溯源需要先介绍JPDA（Java Platform Debugger Architecture）如果JVM启动时开启了JPDA，那么类是允许被重新加载的，在这种情况下，已被加载的旧版本类信息可以被卸载，然后重新加载新版本的类。正如JDPA名称中的Debugger，JDPA其实是一套用于调试Java程序的标准，任何JDK都必须实现该标准\nJPDA定义了一整套完整的体系，它将调试体系分为三部分，并规定了三者之间的通信接口，三部分由低到高分别是Java 虚拟机工具接口（JVMTI），Java 调试协议（JDWP）以及 Java 调试接口（JDI），三者之间的关系如下图所示：\n现在回到正题，我们可以借助JVMTI的一部分能力，帮助动态重载类信息JVM TI（JVM TOOL INTERFACE，JVM工具接口）是JVM提供的一套对JVM进行操作的工具接口通过JVMTI，可以实现对JVM的多种操作，它通过接口注册各种事件勾子，在JVM事件触发时，同时触发预定义的勾子，以实现对各个JVM事件的响应，事件包括类文件加载、异常产生与捕获、线程启动和结束、进入和退出临界区、成员变量修改、GC开始和结束、方法调用进入和退出、临界区竞争与等待、VM启动与退出等等\n而Agent就是JVMTI的一种实现，Agent有两种启动方式，一是随Java进程启动而启动，经常见到的Java -agentlib就是这种方式；二是运行时载入，通过attach API，将模块（jar包）动态地Attach到指定进程id的Java进程内\nAttach API 的作用是提供JVM进程间通信的能力，比如说我们为了让另外一个JVM进程把线上服务的线程Dump出来，会运行jstack或jmap的进程，并传递pid的参数，告诉它要对哪个进程进行线程Dump，这就是Attach API做的事情在下面，我们将通过Attach API的loadAgent()方法，将打包好的Agent jar包动态Attach到目标JVM上具体实现起来的步骤如下：\n定义Agent，并在其中实现AgentMain方法，如上一小节中定义的代码块7中的TestAgent类； 然后将TestAgent类打成一个包含MANIFEST.MF的jar包，其中MANIFEST.MF文件中将Agent-Class属性指定为TestAgent的全限定名，如下图所示； 最后利用Attach API，将我们打包好的jar包Attach到指定的JVM pid上，代码如下： import com.sun.tools.attach.VirtualMachine; public Class Attacher { public static void main(String[] args) throws AttachNotSupportedException, IOException, AgentLoadException, AgentInitializationException { // 传入目标 JVM pid VirtualMachine vm = VirtualMachine.attach(\u0026#34;39333\u0026#34;); vm.loadAgent(\u0026#34;/Users/zen/operation_server_jar/operation-server.jar\u0026#34;); } } 由于在MANIFEST.MF中指定了Agent-Class，所以在Attach后，目标JVM在运行时会走到TestAgent类中定义的agentmain()方法，而在这个方法中，我们利用Instrumentation，将指定类的字节码通过定义的类转化器TestTransformer做了Base类的字节码替换（通过Javassist），并完成了类的重新加载由此，我们达成了“在JVM运行时，改变类的字节码并重新载入类信息”的目的 以下为运行时重新载入类的效果：先运行Base中的main()方法，启动一个JVM，可以在控制台看到每隔五秒输出一次”process”接着执行Attacher中的main()方法，并将上一个JVM的pid传入此时回到上一个main()方法的控制台，可以看到现在每隔五秒输出”process”前后会分别输出”start”和”end”，也就是说完成了运行时的字节码增强，并重新载入了这个类\n使用场景 至此，字节码增强技术的可使用范围就不再局限于JVM加载类前了。通过上述几个类库，我们可以在运行时对JVM中的类进行修改并重载了。通过这种手段，可以做的事情就变得很多了：\n热部署：不部署服务而对线上服务做修改，可以做打点、增加日志等操作 Mock：测试时候对某些服务做Mock 性能诊断工具：比如bTrace就是利用Instrument，实现无侵入地跟踪一个正在运行的JVM，监控到类和方法级别的状态信息 总结 字节码增强技术相当于是一把打开运行时JVM的钥匙，利用它可以动态地对运行中的程序做修改，也可以跟踪JVM运行中程序的状态。此外，我们平时使用的动态代理、AOP也与字节码增强密切相关，它们实质上还是利用各种手段生成符合规范的字节码文件。综上所述，掌握字节码增强后可以高效地定位并快速修复一些棘手的问题（如线上性能问题、方法出现不可控的出入参需要紧急加日志等问题），也可以在开发中减少冗余代码，大大提高开发效率\n类的生命周期 整个流程如下：\n注意：加载、验证、准备和初始化这四个阶段发生的顺序是确定的，而解析阶段则不一定，它在某些情况下可以在初始化阶段之后开始，这是为了支持Java语言的运行时绑定(也称为动态绑定或晚期绑定)。另外：这里的几个阶段是按顺序开始，而不是按顺序进行或完成，因为这些阶段通常都是互相交叉地混合进行的，通常在一个阶段执行的过程中调用或激活另一个阶段\n加载：查找并加载类的二进制数据 加载是类加载过程的第一个阶段，在加载阶段，虚拟机需要完成以下三件事情:\n类加载器根据类的全限定名通过不同的渠道以二进制流的方式获取字节码信息。如下列的不同渠道： 从本地系统中直接加载 通过网络下载.Class文件 从zip，jar等归档文件中加载.Class文件 从专有数据库中提取.Class文件 将Java源文件动态编译为.Class文件 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构，生成一个InstanceKlass对象，保存类的所有信息，里边还包含实现特定功能比如多态的信息。 Java虚拟机会在堆中生成一份与方法区中数据“类似”的java.lang.Class对象，作为对方法区中相关数据的访问入口。 作用：在Java代码中去获取类的信息以及存储静态字段的数据（这里的静态字段是说的JDK8及之后的Java虚拟机的设计）\nPS：堆中生成的java.lang.Class对象信息是方法区中生成的InstanceKlass对象信息的浓缩版，也就是将方法区InstanceKlass中程序员不需要的信息剔除就成为堆中的java.lang.Class对象信息\n对于开发者来说，只需要访问堆中的Class对象而不需要访问方法区中所有信息。这样Java虚拟机就能很好地控制开发者访问数据的范围\n**注意：**类加载器并不需要等到某个类被“首次主动使用”时再加载它，JVM规范允许类加载器在预料某个类将要被使用时就预先加载它，如果在预先加载的过程中遇到了 .Class文件 缺失或存在错误，类加载器必须在程序首次主动使用该类时才报告错误(LinkageError错误)，如果这个类一直没有被程序主动使用，那么类加载器就不会报告错误\n既然要加载类，那是怎么加载的就得了解了，而这就不得不了解“JVM类加载机制”了\nJVM类加载机制 类加载器的分类 类加载器（ClassLoader）是Java虚拟机提供给应用程序去实现获取类和接口字节码数据的技术。\n类加载器只参与加载过程中的字节码获取并加载到内存这一部分。\n类加载器分为两类，一类是Java代码中实现的，一类是Java虚拟机底层源码实现的。\n类加载器的设计JDK8和8之后的版本差别较大，JDK8及之前的版本中默认的类加载器有如下几种：\n查找类加载器 Arthas关于中类加载器的详细信息的查看方式。Arthas之classloader命令官网说明 classloader\t# 查看 classloader 的继承树，urls，类加载信息，使用 classloader 去获取资源 参数说明：\n参数名称 参数说明 [l] 按类加载实例进行统计 [t] 打印所有 ClassLoader 的继承树 [a] 列出所有 ClassLoader 加载的类，请谨慎使用 [c:] ClassLoader 的 hashcode [classLoaderClass:] 指定执行表达式的 ClassLoader 的 class name [c: r:] 用 ClassLoader 去查找 resource [c: load:] 用 ClassLoader 去加载指定的类 示例：\nPS：下图那些数量指的是我进入的当前这个线程相关的，不是说所有的数量就是那些，根据进程会发生改变\n另外：Arthas也可以查看 JVM 已加载的”某个类“的类信息，Arthas之sc命令官网说明 sc命令，即“Search-Class” 的简写，这个命令能搜索出所有已经加载到 JVM 中的 Class 信息，这个命令支持的参数有 [d]、[E]、[f] 和 [x:]，参数说明如下：\n参数名称 参数说明 class-pattern 类名表达式匹配 method-pattern 方法名表达式匹配 [d] 输出当前类的详细信息，包括这个类所加载的原始文件来源、类的声明、加载的 ClassLoader 等详细信息。 如果一个类被多个 ClassLoader 所加载，则会出现多次 [E] 开启正则表达式匹配，默认为通配符匹配 [f] 输出当前类的成员变量信息（需要配合参数-d 一起使用） [x:] 指定输出静态变量时属性的遍历深度，默认为 0，即直接使用 toString 输出 [c:] 指定 class 的 ClassLoader 的 hashcode [classLoaderClass:] 指定执行表达式的 ClassLoader 的 class name [n:] 具有详细信息的匹配类的最大数量（默认为 100） [cs \u0026lt;arg\u0026gt;] 指定 class 的 ClassLoader#toString() 返回值。长格式[classLoaderStr \u0026lt;arg\u0026gt;] 示例：\n自己写代码查看 package com.zixieqing; import java.io.IOException; /** * \u0026lt;p\u0026gt; * 查找类加载器 * \u0026lt;/p\u0026gt; * * \u0026lt;p\u0026gt;@author : ZiXieqing\u0026lt;/p\u0026gt; */ public class FindClassLoader { public static void main(String[] args) throws IOException { // 获取当前类的类加载器 即应用程序类加载器 ClassLoader classLoader = FindClassLoader.class.getClassLoader(); System.out.println(\u0026#34;classLoader = \u0026#34; + classLoader); // 获取父类加载器 即扩展类加载器 ClassLoader parentclassLoader = classLoader.getParent(); System.out.println(\u0026#34;parentclassLoader = \u0026#34; + parentclassLoader); // 获取启动类加载器 C语言实现，所以结果为 null\t目的：出于安安全考虑，所以不许操作此类加载器 ClassLoader loader = parentclassLoader.getParent(); System.out.println(\u0026#34;loader = \u0026#34; + loader); System.in.read(); } } 还有几种获取类加载器的方式：\n// 获取当前 ClassLoader clazz.getClassLoader(); // 获取当前线程上下文的 ClassLoader Thread.currentThread().getContextClassLoader(); // 获取系统的 ClassLoader ClassLoader.getSystemClassLoader(); // 获取调用者的 ClassLoader DriverManager.getCallerClassLoader(); 通过这个代码查看之后，也可以说三个类加载器的层次关系长下面这个鸟样儿：\n**注：**这几个类加载器并不是继承关系，而是组合，或者可说是层级/上下级关系，只是源码中用的是ClassLoader类型的Parent字段来实现“双亲委派机制”（后续会上源码）。\n启动类加载器 启动类加载器（Bootstrap ClassLoader）是由Hotspot虚拟机提供的、使用C++编写的类加载器。\n启动类加载器是无法被Java程序直接引用的。\n默认加载Java安装目录/jre/lib下的类文件，比如rt.jar（Java的核心类库，如java.lang.String），tools.jar，resources.jar等。\n启动类加载器加载用户jar包的方式 放入 JDK安装目录/jre/lib 下进行扩展。 不推荐 尽可能不要去更改JDK安装目录中的内容，会出现即使放进去由于文件名不匹配的问题也不会正常地被加载\n使用虚拟机参数 -Xbootclasspath/a:jar包目录/jar包名 命令扩展。推荐 PS：此命令中有一个 “a” 即add的意思，意为添加一个“jar包目录/jar包名”的jar包\nIDEA中示例：\n-Xbootclasspath/a:E:/Study/JVM-Demo/jar/FindClassLoader.jar 扩展 与 应用程序类加载器 扩展类加载器和应用程序类加载器都是JDK中提供的、使用Java编写的类加载器。\n它们的源码都位于sun.misc.Launcher中，是一个静态内部类。继承自URLClassLoader。具备通过目录或者指定jar包将字节码文件加载到内存中。\n扩展类加载器：加载 Java安装目录/jre/lib/ext 下的类文件\n应用程序类加载器：加载 classpath 下的类文件，此classpath包括“自己项目中编写的类或接口中的文件 和 第三方jar包中的类或接口中的文件（如：maven依赖中的）”\nArthas验证上述目录：\nclassloader -l\t# 查看所有类加载器的hash码 classloader –c 类加载器的hash码\t# 查看当前类加载器的加载路径 扩展类加载器加载用户jar包的方式 放入 JDK安装目录/jre/lib/ext 下进行扩展。不推荐 尽可能不要去更改JDK安装目录中的内容\n使用虚拟机参数 -Djava.ext.dirs=jar包目录 进行扩展。推荐 注意：此种方式会覆盖掉扩展类加载器原始加载的目录。Windows可以使用;分号，macos/Linux可以使用:冒号隔开，从而将原始目录添加在后面\n# Windows中示例 -Djava.ext.dirs=E:/Study/JVM-Demo/jar/ext;D:/Install/JDK/JDK8/jre/lib/ext 双亲委派机制 若是前面查看了应用程序类加载器的加载路径的话，会发现一个有意思的地方：\n查看应用程序类加载器的加载路径，发现启动类加载器的加载路径也有，为什么？\n要搞清楚这个问题，就需要知道“双亲委派机制”了。\n双亲委派机制：\n当一个类加载器加载某个类的时候，会自底向上查找是否加载过；若加载过直接返回，若一直到最顶层的类加载器都没有加载，再自顶向下进行加载。 应用程序类加载器的父类加载器是扩展类加载器，扩展类加载器的父类加载器是启动类加载器。 PS：严谨点来说，扩展类加载器没有父类加载器，只是会“委派”给启动类加载器，即如果类加载的parent为null，则会提交给启动类加载器处理。 双亲委派机制的好处：一是避免恶意代码替换JDK中的核心类库（如：java.lang.String），确保核心类库得到完整性和安全性；二是避免一个类重复被加载 双亲委派机制的作用：\n避免类被重复加载：若一个类重复出现在三个类加载器的加载位置，应该由谁加载？ 启动类加载器加载，根据双亲委派机制，它的优先级是最高的。\n双亲委派机制可以避免同一个类被多次加载，上层的类加载器如果加载过该类，就会直接返回该类，避免重复加载。\n保证类加载的安全性：如在自己的项目中创建一个java.lang.String类，会被加载吗？ 不能，会交由启动类加载器加载在rt.jar包中的String类。\n通过双亲委派机制，让顶层的类加载器去加载核心类，避免恶意代码替换JDK中的核心类库（这个也叫沙箱安全机制），如：上述的java.lang.String，确保核心类库的完整性和安全性。\n同时底层源码中建包“禁止”以java.开头\n上面定义中第一点说“类加载器加载某个类的时候”，那在Java中怎么加载一个类？这就需要知道Java中类加载的方式了。\nJava中类加载的方式 在Java中如何使用代码的方式去主动加载一个类？Java中类加载有两种方式：\n通过 Class.forName() 方法动态加载\n通过 ClassLoader.loadClass() 方法动态加载\npublic Class loaderTest { public static void main(String[] args) throws ClassNotFoundException { ClassLoader loader = HelloWorld.Class.getClassLoader(); System.out.println(loader); // 使用ClassLoader.loadClass()来加载类，不会执行初始化块 loader.loadClass(\u0026#34;Test2\u0026#34;); // 使用Class.forName()来加载类，默认会执行初始化块 // Class.forName(\u0026#34;Test2\u0026#34;); // 使用Class.forName()来加载类，并指定ClassLoader，初始化时不执行静态块 // Class.forName(\u0026#34;Test2\u0026#34;, false, loader); } } public Class Test2 { static { System.out.println(\u0026#34;静态初始化块执行了！\u0026#34;); } } 分别切换加载方式，会有不同的输出结果\nClass.forName() 和 ClassLoader.loadClass()区别?\nClass.forName():：将类的.Class文件加载到JVM中之外，还会对类进行解释，执行类中的static块； ClassLoader.loadClass():：只干一件事情，就是将.Class文件加载到JVM中，不会执行static中的内容,只有在newInstance才会去执行static块 Class.forName(name, initialize, loader)带参函数也可控制是否加载static块并且只有调用了newInstance()方法采用调用构造函数，创建类的对象 Java中查看双亲委派机制的实现 package java.lang; public abstract class ClassLoader { // 每个Java实现的类加载器中保存了一个成员变量叫“父”（Parent）类加载器，可以理解为它的上级，并不是继承关系 private final ClassLoader parent; public Class\u0026lt;?\u0026gt; loadClass(String name) throws ClassNotFoundException { // 第二个参数 会决定着是否要开始类的生命周期的解析阶段，实质执行的是\u0026#34;类生命周期中的连接阶段\u0026#34; return loadClass(name, false); } protected Class\u0026lt;?\u0026gt; loadClass(String name, boolean resolve) throws ClassNotFoundException { synchronized (getClassLoadingLock(name)) { // 首先判断该类型是否已经被加载 Class\u0026lt;?\u0026gt; c = findLoadedClass(name); if (c == null) { long t0 = System.nanoTime(); try { // 如果没有被加载，就委托给父类加载或者委派给启动类加载器加载 if (parent != null) { // 如果存在父类加载器，就委派给父类加载器加载 c = parent.loadClass(name, false); } else { // 如果不存在父类加载器，就检查是否是由启动类加载器加载的类， // 通过调用本地方法native Class findBootstrapClass(String name) c = findBootstrapClassOrNull(name); } } catch (ClassNotFoundException e) { // ClassNotFoundException thrown if class not found // from the non-null parent class loader } // 如果父类加载器和启动类加载器都不能完成加载任务 if (c == null) { // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); // 调用自身的加载功能 c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); } } // 是否开始解析，此处resolve = false if (resolve) { // 最终调用 private native void resolveClass0(Class\u0026lt;?\u0026gt; c); resolveClass(c); } return c; } } } 自定义类加载器 通常情况下，我们都是直接使用系统类加载器，但是，有的时候，我们也需要自定义类加载器，比如应用是通过网络来传输 Java 类的字节码，为保证安全性，这些字节码经过了加密处理，这时系统类加载器就无法对其进行加载，此时就需要我们自定义类加载器。\n而需要自定义类加载器，就需要了解几个API：\npackage java.lang; public abstract class ClassLoader { /** * 类加载的入口，提供双亲委派机制，调用了 findClass(String name) */ protected Class\u0026lt;?\u0026gt; loadClass(String name, boolean resolve) { // ............. } /** * 由类加载器子类实现获取二进制数据， * 调用 defineClass(String name, byte[] b, int off, int len) * 如：URLClassLoader 会根据文件路径获取类文件中的二进制数据 */ protected Class\u0026lt;?\u0026gt; findClass(String name) { throw new ClassNotFoundException(name); } } /** * 做一些类名的校验，然后调用虚拟机底层的方法将字节码信息加载到虚拟机内存中 */ protected final Class\u0026lt;?\u0026gt; defineClass(String name, byte[] b, int off, int len){ // ......... } /** * 执行类生命周期中的连接阶段 */ protected final void resolveClass(Class\u0026lt;?\u0026gt; c){ // ......... } 从上对 loadClass 方法分析来看：想要自定义类加载器，那么继承 ClassLoader 类，重写 findClass() 即可，示例如下：\nJDK1.2之前是重写 loadClass()，但JDK1.2之后就建议自定义类加载器最好重写 findClass() 而不要重写 loadClass() ，因为这样容易破坏双亲委托模式。\npackage com.zixieqing; import java.io.*; /** * \u0026lt;p\u0026gt; * 自定义类加载器：核心在于对字节码文件的获取 * \u0026lt;/p\u0026gt; * * \u0026lt;p\u0026gt;@author : ZiXieqing\u0026lt;/p\u0026gt; */ public class MyClassLoader extends ClassLoader { private String root; @Override protected Class\u0026lt;?\u0026gt; findClass(String name) throws ClassNotFoundException { // 获取二进制数据 byte[] ClassData = loadClassData(name); if (ClassData == null) { throw new ClassNotFoundException(); } else { // 校验，将字节码信息加载进虚拟机内存 return defineClass(name, ClassData, 0, ClassData.length); } } /** * 加载二进制数据 * @param className Class全限定名 */ private byte[] loadClassData(String className) { // 得到Class字节码文件名 String fileName = root + File.separatorChar + className.replace(\u0026#39;.\u0026#39;, File.separatorChar) + \u0026#34;.Class\u0026#34;; try { InputStream ins = new FileInputStream(fileName); ByteArrayOutputStream baos = new ByteArrayOutputStream(); int bufferSize = 1024; byte[] buffer = new byte[bufferSize]; int length = 0; while ((length = ins.read(buffer)) != -1) { baos.write(buffer, 0, length); } return baos.toByteArray(); } catch (IOException e) { e.printStackTrace(); } return null; } public void setRoot(String root) { this.root = root; } public static void main(String[] args) throws ClassNotFoundException { MyClassLoader myClassLoader = new MyClassLoader(); // 设置此类加载器的加载目录 myClassLoader.setRoot(\u0026#34;E:\\\\lib\\\\\u0026#34;); // 要加载哪个类 // 传递的文件名是类的全限定名，以 \u0026#34;.\u0026#34; 隔开，因为 defineClass() 是按这种格式进行处理的 Class\u0026lt;?\u0026gt; testClass = myClassLoader.loadClass(\u0026#34;com.zixq.FindClassLoader\u0026#34;); System.out.println(testClass.getClassLoader()); System.out.println(testClass.getClassLoader().getParent()); } } 结果如下：\nom.zixieqing.MyClassLoader@1b6d3586 sun.misc.Launcher$AppClassLoader@18b4aac2 问题：自定义类加载器父类怎么是AppClassLoader？ 以Jdk8为例，ClassLoader类中提供了构造方法设置parent的内容：\n这个构造方法由另外一个构造方法调用，其中父类加载器由 getSystemClassLoader() 设置，该方法返回的是AppClassLoader。\n问题：两个自定义类加载器加载相同限定名的类，会不会冲突？ 不会冲突，在同一个Java虚拟机中，只有“相同类加载器+相同的类限定名”才会被认为是同一个类。\n# 在Arthas中使用下列方式查看具体的情况 sc –d 类的全限定名 Java9之后的类加载器 JDK8及之前的版本中，扩展类加载器和应用程序类加载器的源码位于rt.jar包中的sun.misc.Launcher.java。\nJDK9引入了module的概念，类加载器在设计上发生了变化：\n启动类加载器使用Java编写，位于jdk.internal.loader.ClassLoaders类中。 Java中的BootClassLoader继承自BuiltinClassLoader，实现从模块中找到要加载的字节码资源文件。\n启动类加载器依然无法通过Java代码获取到，返回的仍然是null，保持了统一。\n扩展类加载器被替换成了平台类加载器（Platform Class Loader）。 平台类加载器遵循模块化方式加载字节码文件，所以继承关系从URLClassLoader变成了BuiltinClassLoader，BuiltinClassLoader实现了从模块中加载字节码文件。平台类加载器的存在更多的是为了与老版本的设计方案兼容，自身没有特殊的逻辑。\n连接 验证：验证被加载的类是否满足Java虚拟机规范 验证是连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息遵守《Java虚拟机规范》中的约束，并且不会危害虚拟机自身的安全。\n这个阶段一般不需要程序员参与。验证阶段大致会完成4个阶段的检验动作:\n文件格式验证：验证字节流是否符合Class文件格式的规范；例如: 是否以0xCAFEBABE开头、主次版本号是否在当前虚拟机的处理范围之内、常量池中的常量是否有不被支持的类型 元数据验证：对字节码描述的信息进行语义分析(注意: 对比Javac编译阶段的语义分析)，以保证其描述的信息符合Java语言规范的要求；例如: 这个类是否有父类，除了Java.lang.Object之外 字节码验证：通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的 符号引用验证：确保解析动作能正确执行 验证阶段是非常重要的，但不是必须的，它对程序运行期没有影响，\n如果所引用的类经过反复验证，那么可以考虑采用-Xverifynone参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间\n准备：为静态变量分配内存 并 为其设置默认值 准备阶段是为静态变量（static）分配内存并设置默认值。这些内存都将在方法区中分配。\n对于该阶段有以下几点需要注意：\n这时候进行内存分配的仅包括静态变量(static)，而不包括实例变量，实例变量会在对象实例化时随着对象一块分配在Java堆中。 这里所设置的默认值通常情况下是数据类型默认的零值，而不是在Java代码中被显式地赋予的值。 数据类型 默认值 byte 0 short 0 int 0 long 0L boolean false double 0.0 char ‘\\u0000’ 引用数据类型 null 对基本数据类型来说，静态变量(static)和全局变量，如果不显式地对其赋值而直接使用，则系统会为其赋予默认的零值；而对于局部变量来说，在使用前必须显式地为其赋值，否则编译时不通过。 只被final修饰的常量则既可以在声明时显式地为其赋值，也可以在类初始化时显式地为其赋值，总之，在使用前必须为其显式地赋值，系统不会为其赋予默认零值。 同时被static和final修饰的基本数据类型的常量，准备阶段直接会将代码中的值进行赋值（即必须在声明的时候就为其显式地赋值，否则编译时不通过）。 解析：将常量池中的符号引用 替换为 指向内存的直接引用 解析阶段主要是将常量池中的符号引用替换为直接引用。\n解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引。\n符号引用就是在字节码文件中使用编号来访问常量池中的内容。\n直接引用不再使用编号，而是使用内存地址来访问具体的数据。\n初始化：为类的静态变量赋正确值，对类进行初始化 初始化：为类的静态变量赋予正确的初始值，JVM负责对类进行初始化（主要对类变量进行初始化）。\n初始化阶段会执行字节码文件中 clinit （若是有）部分的字节码指令。clinit就是class init，即类构造方法，此类构造方法不是我们说的构造方法，不是一回事。\nclinit指令在特定情况下不会出现：\n注：\n子类的初始化clinit调用之前，会先调用父类的clinit初始化方法。 虚拟机会保证一个类的clinit方法在多线程下被同步加锁，即一个类的clinit方法只会被加载一次。 无静态代码块且无静态变量赋值语句。 有静态变量的声明，但是没有赋值语句。 静态变量的定义使用final关键字，这类变量会在准备阶段直接进行初始化。 在Java中对类变量进行初始值设定有两种方式：\n声明类变量时指定初始值 使用静态代码块为类变量指定初始值 JVM初始化步骤：\n若这个类还没有被加载和连接，则程序先加载并连接该类。 若该类的父类还没有被初始化，则先初始化其父类。 若类中有初始化语句，则系统依次执行这些初始化语句。 关于第3点：原因是在链接阶段的准备中，已经将静态变量加载到内存中了，只是初始值是数据类型的默认值而已，而这里初始化就是重新赋正确值，而这顺序就按代码顺序赋值。\n如下图，虚拟机指令是按顺序执行初始化语句\n类初始化时机：只有当对类的主动使用时会导致类的初始化。类的主动使用包括以下六种：\n添加 -XX:+TraceClassLoading 虚拟机参数可以打印出加载并初始化的类。\n创建类的对象，也就是new的方式。 访问某个类或接口的静态变量，或者对该静态变量赋值。注：变量是final修饰且等号右边是常量不会触发初始化。 /** * 变量是 final 修饰且等号右边是常量不会触发初始化 */ public class Initialization { public static final int value = 8; static { System.out.println(\u0026#34;Initialization类被初始化了\u0026#34;); } } class Test { public static void main(String[] args) { System.out.println(Initialization.value); } } 调用类的静态方法。 反射。如：Class.forName(\u0026quot;com.zixieqing.JVM.Test\u0026quot;)) 。若使用的是下面这个API，则是否初始化取决于程序员。 public static Class\u0026lt;?\u0026gt; forName(String name, boolean initialize, ClassLoader loader) { } 初始化某个类的子类，则其父类也会被初始化。 Java虚拟机启动时被标明为启动类的类，直接使用Java.exe命令来运行某个主类。 使用 类访问方法区内的数据结构的接口， 对象是Heap（堆）区的数据。\n卸载 这个玩意儿在垃圾回收还会整。\nJava虚拟机将结束生命周期的几种情况：\n调用 Runtime 类 或 system 类的 exit()，或 Runtime 类的 halt()，并且 Java 安全管理器也允许这次 exit 或 halt 操作。 程序正常执行结束。 程序在执行过程中遇到了异常或错误而异常终止。 由于操作系统出现错误而导致Java虚拟机进程终止。 JVM内存结构 注：不要和Java内存模型混淆了。\n运行时数据区 Java虚拟机在运行Java程序过程中管理的内存区域，称之为运行时数据区。\nJava 虚拟机定义了若干种程序运行期间会使用到的运行时数据区，其中有一些会随着虚拟机启动而创建，随着虚拟机退出而销毁，另外一些则是与线程一 一对应的，这些与线程一 一对应的数据区域会随着线程开始和结束而创建和销毁。\n线程不共享：\n程序计数器 本地方法栈 Java虚拟机栈 线程共享：\n方法区 堆 程序计数器 程序计数器（Program Counter Register）也叫PC寄存器，用来存储指向下一条字节码指令的地址，即将要执行的指令代码由执行引擎读取下一条指令。\n程序计数器是唯一 一个在 JVM 规范中没有规定任何 内存溢出（OutOfMemoryError ）情况的区域。 内存溢出： 指的是程序在使用某一块内存区域时，存放的数据需要占用的内存大小超过了虚拟机能提供的内存上限。\n因为每个线程只存储一个固定长度的内存地址，所以程序计数器是不会发生内存溢出的。 因此：程序员无需对程序计数器做任何处理。 在 JVM 规范中，每个线程都有它自己的程序计数器，是线程私有的，生命周期与线程的生命周期一致。 程序计数器是一块很小的内存空间，几乎可以忽略不计，也是运行速度最快的存储区域。 分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 如：分支、跳转\nJVM 中的 PC 寄存器是对物理 PC 寄存器的一种抽象模拟。 接下来结合图理解一下程序计数器。\n在加载阶段，虚拟机将字节码文件中的指令读取到内存之后，会将原文件中的偏移量转换成内存地址。每一条字节码指令都会拥有一个内存地址。\n在代码执行过程中，程序计数器会记录下一行字节码指令的地址。执行完当前指令之后，虚拟机的执行引擎根据程序计数器执行下一行指令。\n**注：**如果当前线程正在执行的是 Java 方法，程序计数器记录的是 JVM 字节码指令地址，如果是执行 native 方法，则是未指定值（undefined）。\n问题：使用程序计数器存储字节码指令地址有什么用？为什么使用程序计数器记录当前线程的执行地址？ 因为CPU需要不停的切换各个线程，当切换回来以后，就得知道接着从哪开始继续执行，JVM的字节码解释器就需要通过改变程序计数器的值来明确下一条应该执行什么样的字节码指令。\n问题：程序计数器为什么会被设定为线程私有的？ 多线程在一个特定的时间段内只会执行其中某一个线程方法，CPU会不停的做任务切换，这样必然会导致经常中断或恢复。为了能够准确的记录各个线程正在执行的当前字节码指令地址，所以为每个线程都分配了一个程序计数器，每个线程都独立计算，不会互相影响。\n栈内存：Java虚拟机栈 与 本地方法栈 栈即先进后出（First In Last Out），是一种快速有效的分配存储方式，访问速度仅次于程序计数器.\n栈不存在垃圾回收问题。\nJava虚拟机栈（JVM Stack） Java虚拟机栈（Java Virtual Machine Stack），早期也叫 Java 栈。采用栈的数据结构来管理方法调用中的基本数据。\n每个线程在创建的时候都会创建一个虚拟机栈，其内部保存一个个的栈帧(Stack Frame），每一个Java方法的调用都使用一个栈帧来保存。\nJava虚拟机栈主管 Java 程序的运行，它保存方法的局部变量、部分结果，并参与方法的调用和返回。 Java虚拟机栈是线程私有的，生命周期和线程一致。 JVM 直接对虚拟机栈的操作只有两个：方法的入栈(方法的执行) 与 出栈(方法的结束)。 Java虚拟机栈如果栈帧过多，占用内存超过栈内存可以分配的最大大小就会出现内存溢出（内存溢出会出现StackOverflowError错误）。 package com.zixieqing.runtime_data_area.stack; /** * \u0026lt;p\u0026gt; * JVM内存结构：运行时数据区之Java虚拟机栈 * \u0026lt;/p\u0026gt; * * \u0026lt;p\u0026gt;@author : ZiXieqing\u0026lt;/p\u0026gt; */ public class JVM_Stack { /** * 计数器：得到当前系统的栈帧大小 */ private static int count = 0; public static void main(String[] args) { stackOverFlowTest(); } /** * \u0026lt;p\u0026gt; * 1、测试Java虚拟机栈是否会内存溢出 * \u0026lt;/p\u0026gt; */ public static void stackOverFlowTest() { System.out.println(++count); stackOverFlowTest(); } } // 结果 10710 Exception in thread \u0026#34;main\u0026#34; java.lang.StackOverflowError Java虚拟机栈默认大小：如果我们不指定栈的大小，JVM 将创建一个具有默认大小的栈。大小取决于操作系统和计算机的体系结构。 Linux x86（64位）：1MB Windows 基于操作系统默认值 BSD x86（64位）：1MB Solarls 64位：1MB 自己设置栈大小：使用虚拟机参数 -Xss栈大小 注： HotSpot Java虚拟机对栈大小的最大值和最小值有要求\nWindows（64位）下的JDK8最小值为180k，最大值为1024m 。 一般情况下，工作中栈的深度最多也只能到几百,不会出现栈的溢出。所以此参数可以手动指定为-Xss256k节省内存。\n参数含义：设置线程的最大栈空间 语法：-Xss栈大小 单位：字节（默认，必须是 1024 的倍数）、k或者K(KB)、m或者M(MB)、g或者G(GB)。示例如下： -Xss1048576 -Xss1024K -Xss1m -Xss1g 与 -Xss 类似，也可以使用 -XX:ThreadStackSize 来配置栈大小。 格式为： -XX:ThreadStackSize=1024 由前面内容知道：每个线程在创建的时候都会创建一个虚拟机栈，其内部保存一个个的栈帧(Stack Frame），这些栈帧对应着一个个方法的调用，那栈帧组成又是怎么样的？\n栈帧的组成 每个栈帧（Stack Frame）中存储着：\n局部变量表（Local Variables）：局部变量表的作用是在运行过程中存放所有的局部变量。 操作数栈（Operand Stack）：操作数栈是栈帧中虚拟机在执行指令过程中用来存放临时数据的一块区域。 帧数据（Frame Data）：帧数据主要包含动态链接、方法出口、异常表的引用。 动态链接（Dynamic Linking）：当前类的字节码指令引用了其他类的属性或者方法时，需要将符号引用（编号）转换成对应的运行时常量池中的内存地址。动态链接就保存了编号（符号引用）到 运行时常量池的内存地址 的映射关系。 方法返回地址 / 方法出口（Return Address）：方法在正确或者异常结束时，当前栈帧会被弹出，同时程序计数器应该指向上一个栈帧中的下一条指令的地址。所以在当前栈帧中，需要存储此方法出口的地址。 一些附加信息：栈帧中还允许携带与 Java 虚拟机实现相关的一些附加信息，例如，对程序调试提供支持的信息，但这些信息取决于具体的虚拟机实现，所以在这里不说明这玩意儿。 局部变量表（Local Variables） 局部变量表也被称为局部变量数组或者本地变量表。\n局部变量表的作用是在方法执行过程中存放所有的局部变量。编译成字节码文件时就可以确定局部变量表的内容。\n局部变量表中保存的是：实例方法的this对象，方法的参数，方法体中声明的局部变量\n栈帧中的局部变量表是一个数组，数组中每一个位置称之为槽(slot)，long和double类型占用两个槽，其他类型占用一个槽。 byte、short、char 在存储前被转换为int；\nboolean也被转换为int，0 表示 false，1 表示 true。\n栈帧中的局部变量表是咋样的？数组咯，每个索引位置就是一个槽（Slot）\n插入一个与此相关的内容：Java中的8大数据类型在虚拟机中的实现。\n问题：boolean、byte、char、short在栈上是不是存在空间浪费？ 是的，Java虚拟机采用的是空间换时间方案，在栈上不存储具体的类型，只根据slot槽进行数据的处理，浪费了一些内存空间，但是避免不同数据类型不同处理方式带来的时间开销。\n同时，像long型在64位系统中占用2个slot，使用了16字节空间，但实际上在Hotspot虚拟机中，它的高8个字节没有使用，这样就满足了long型使用8个字节的需要。\n如果当前帧是由构造方法或实例方法创建的，那么该对象引用 this 将会存放在 index 为 0 的 Slot 处，其余的参数按照参数表顺序继续排列。 因为实例方法需要先拿到实例对象，即代码首行有个隐藏的this，它去搞对象了。\n为了节省空间，局部变量表中的槽（Slot）是可以被复用的。一旦某个局部变量不再生效，当前槽就可以再次被使用。 操作数栈（Operand Stack） 操作数栈：是栈帧中虚拟机在执行指令过程中用来存放中间数据的一块区域。如果一条指令将一个值压入操作数栈，则后面的指令可以弹出并使用该值。\n操作数栈，在方法执行过程中，根据字节码指令，往操作数栈中写入数据或提取数据，即入栈（push）、出栈（pop）。\n如果被调用的方法带有返回值的话，其返回值将会被压入当前栈帧的操作数栈中，并更新 PC 寄存器中下一条需要执行的字节码指令。\n所谓的Java虚拟机的解释引擎是基于栈的执行引擎，其中的栈指的就是操作数栈。\n每一个操作数栈在编译期就已经确定好了其所需的最大深度，从而在执行时正确的分配内存大小。\n那这个所需的最大深度是怎么确定的？\n编译器模拟对应的字节码指令执行过程，在这个过程中最多可以存放几个数据，这个最多存放多少个数据就是操作数栈所需的最大深度。\n如下图，共出现了0和1这两个数据，所以操作数栈的最大深度就是2。\n另一个小知识点：栈顶缓存（Top-of-stack-Cashing）\nHotSpot 的执行引擎采用的并非是基于寄存器的架构，但这并不代表 HotSpot VM 的实现并没有间接利用到寄存器资源，寄存器是物理 CPU 中的组成部分之一，它同时也是 CPU 中非常重要的高速存储资源。一般来说，寄存器的读/写速度非常迅速，甚至可以比内存的读/写速度快上几十倍不止，不过寄存器资源却非常有限，不同平台下的CPU 寄存器数量是不同和不规律的。寄存器主要用于缓存本地机器指令、数值和下一条需要被执行的指令地址等数据\n基于栈式架构的虚拟机所使用的零地址指令更加紧凑，但完成一项操作的时候必然需要使用更多的入栈和出栈指令，这同时也就意味着将需要更多的指令分派（instruction dispatch）次数和内存读/写次数，由于操作数是存储在内存中的，因此频繁的执行内存读/写操作必然会影响执行速度。为了解决这个问题，HotSpot JVM 设计者们提出了栈顶缓存技术，将栈顶元素全部缓存在物理 CPU 的寄存器中，以此降低对内存的读/写次数，提升执行引擎的执行效率\n帧数据（Frame Data） 动态链接（Dynamic Linking）：当前类的字节码指令引用了其他类的属性或者方法时，需要将符号引用（编号）转换成对应的运行时常量池中的内存地址。动态链接就保存了编号（符号引用）到 运行时常量池的内存地址 的映射关系。 JVM 是如何执行方法调用的？\n方法调用不同于方法执行，方法调用阶段的唯一任务就是确定被调用方法的版本（即调用哪一个方法），暂时还不涉及方法内部的具体运行过程，Class 文件的编译过程中不包括传统编译器中的连接步骤，一切方法调用在 Class文件里面存储的都是符号引用，而不是方法在实际运行时内存布局中的入口地址（直接引用），也就是需要在类加载阶段，甚至到运行期才能确定目标方法的直接引用。\n在 JVM 中，将符号引用转换为调用方法的直接引用与方法的绑定机制有关\n静态链接：当一个字节码文件被装载进 JVM 内部时，如果被调用的目标方法在编译期可知，且运行期保持不变时，这种情况下将调用方法的符号引用转换为直接引用的过程称之为静态链接。 动态链接：如果被调用的方法在编译期无法被确定下来，也就是说，只能在程序运行期将调用方法的符号引用转换为直接引用，由于这种引用转换过程具备动态性，因此也就被称之为动态链接。 对应的方法的绑定机制为：早期绑定（Early Binding）和晚期绑定（Late Binding）。\n绑定是一个字段、方法或者类在符号引用被替换为直接引用的过程，这仅仅发生一次。\n早期绑定：指被调用的目标方法如果在编译期可知，且运行期保持不变时，即可将这个方法与所属的类型进行绑定，这样一来，由于明确了被调用的目标方法究竟是哪一个，因此也就可以使用静态链接的方式将符号引用转换为直接引用。 晚期绑定：如果被调用的方法在编译器无法被确定下来，只能够在程序运行期根据实际的类型绑定相关的方法，这种绑定方式就被称为晚期绑定。 虚方法与非虚方法\n非虚方法：指的是方法在编译器就确定了具体的调用版本，这个版本在运行时是不可变的，如静态方法、私有方法、final 方法、实例构造器、父类方法都是非虚方法。 其他方法称为虚方法。 方法返回地址 / 方法出口（Return Address）：方法在正确或者异常结束时，当前栈帧会被弹出，同时程序计数器应该指向上一个栈帧中的下一条指令的地址。所以在当前栈帧中，存放的这条指令地址就是方法出口地址。 本质上，方法的结束就是当前栈帧出栈的过程，此时，需要恢复上层方法的局部变量表、操作数栈、将返回值压入调用者栈帧的操作数栈、设置PC寄存器值等，让调用者方法继续执行下去\n细节说明一下：\n方法正常退出时，调用该方法的指令的下一条指令的地址即为返回地址。 一个方法的正常调用完成之后，究竟需要使用哪一个返回指令，还需要根据方法返回值的实际数据类型而定。\n返回类型 返回指令 void、类和接口的初始化方法 return int (boolean、byte、char、short) ireturn long lreturn float freturn double dreturn reference areturn 方法通过异常退出的，返回地址是要通过异常表来确定的，栈帧中一般不会保存这部分信息。 在方法执行的过程中遇到了异常，并且这个异常没有在方法内进行处理，也就是只要在本方法的异常表中没有搜索到匹配的异常处理器，就会导致方法退出，简称异常完成出口。\n方法执行过程中抛出异常时的异常处理，存储在一个异常处理表，方便在发生异常的时候找到处理异常的代码。\n上述内容说到了“异常表”，也顺便解释一下这个东西\n异常表：存放的是代码中异常的处理信息，包含了异常捕获的生效范围以及异常发生后跳转到的字节码指令位置。\n程序运行中触发异常时，Java 虚拟机会从上至下遍历异常表中的所有条目。当触发异常的字节码的索引值在某个异常表条目的监控范围内，Java 虚拟机会判断所抛出的异常和该条目想要捕获的异常是否匹配。\n如果匹配，跳转到“跳转PC”对应的字节码位置。 如果遍历完都不能匹配，说明异常无法在当前方法执行时被捕获，此方法栈帧直接弹出，在上一层的栈帧中进行异常捕获的查询。 多个catch分支情况下（multi-catch的写法也一样），异常表会从上往下遍历，先捕获RuntimeException，如果捕获不了，再捕获Exception。\nfinally的处理方式：\nfinally中的字节码指令会插入到try 和 catch代码块中，保证在try和catch执行之后一定会执行finally中的代码。 如果抛出的异常范围超过了Exception，比如Error或者Throwable，此时也要执行finally，所以异常表中增加了两个条目。覆盖了try和catch两段字节码指令的范围，any代表可以捕获所有种类的异常。 本地方法栈（Native Method Stack） Java虚拟机栈存储了Java方法调用时的栈帧，而本地方法栈存储的是native本地方法的栈帧。\n它的具体做法是 Native Method Stack 中登记 native 方法，在 Execution Engine 执行时加载本地方法库，当某个线程调用一个本地方法时，它就进入了一个全新的并且不再受虚拟机限制的世界，它和虚拟机拥有同样的权限。\n本地方法栈也是线程私有的。也会发生内存溢出。\n如果线程请求分配的栈容量超过本地方法栈允许的最大容量，Java 虚拟机将会抛出一个 StackOverflowError 异常 如果本地方法栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程时没有足够的内存去创建对应的本地方法栈，那么 Java虚拟机将会抛出一个OutofMemoryError异常 在Hotspot虚拟机中，Java虚拟机栈和本地方法栈实现上使用了同一个栈空间，即在 Hotspot JVM 中，直接将本地方法栈和虚拟机栈合二为一了。\n本地方法栈会在栈内存上生成一个栈帧，临时保存方法的参数同时方便出现异常时也把本地方法的栈信息打印出来。\npackage com.zixieqing.runtime_data_area.stack; import java.io.FileNotFoundException; import java.io.FileOutputStream; import java.io.IOException; /** * \u0026lt;p\u0026gt; * JVM -\u0026gt; 运行时数据区 -\u0026gt; 本地方法栈 * \u0026lt;/p\u0026gt; * * \u0026lt;p\u0026gt;@author : ZiXieqing\u0026lt;/p\u0026gt; */ public class NativeMethodStack { public static void main(String[] args) { try { // 这里并没有F盘 FileOutputStream fos = new FileOutputStream(\u0026#34;F:\\\\zixq.txt\u0026#34;); fos.write(2); } catch (FileNotFoundException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); } } } // 结果 java.io.FileNotFoundException: F:\\zixq.txt (系统找不到指定的路径。) at java.io.FileOutputStream.open0(Native Method)\t// 这里就把Native方法信息也打印出来了 at java.io.FileOutputStream.open(FileOutputStream.java:270) at java.io.FileOutputStream.\u0026lt;init\u0026gt;(FileOutputStream.java:213) at java.io.FileOutputStream.\u0026lt;init\u0026gt;(FileOutputStream.java:101) at com.zixieqing.runtime_data_area.stack.NativeMethodStack.main(NativeMethodStack.java:20) 本地方法可以通过本地方法接口来访问虚拟机内部的运行时数据区，它甚至可以直接使用本地处理器中的寄存器，直接从本地内存的堆中分配任意数量的内存。 并不是所有 JVM 都支持本地方法，因为 Java 虚拟机规范并没有明确要求本地方法栈的使用语言、具体实现方式、数据结构等，如果 JVM 产品不打算支持 native 方法，也可以无需实现本地方法栈。 堆区（Heap Area） 栈是运行时的单位，而堆是存储的单位。\n栈解决的是程序的运行问题，即程序如何执行，或者说如何处理数据。 堆解决的是数据存储的问题，即数据怎么放、放在哪。 一般Java程序中堆内存是空间最大的一块内存区域。创建出来的对象都存在于堆上。几乎所有的对象实例以及数据都在这里分配内存。\n被所有线程共享，会发生内存溢出。\n栈上的局部变量表中，可以存放堆上对象的引用。静态变量也可以存放堆对象的引用，通过静态变量就可以实现对象在线程之间共享。 Java 虚拟机规范规定，Java 堆可以是处于物理上不连续的内存空间中，只要逻辑上是连续的即可。 堆的大小可以是固定大小，也可以是可扩展的，主流虚拟机都是可扩展的（通过 -Xmx 和 -Xms 控制）。 如果堆中没有完成实例分配，并且堆无法再扩展时，就会抛出 OutOfMemoryError 异常。 堆内存溢出模拟：\nimport java.util.ArrayList; /** * \u0026lt;p\u0026gt; * 模拟堆内存溢出 * \u0026lt;/p\u0026gt; * * \u0026lt;p\u0026gt;@author : ZiXieqing\u0026lt;/p\u0026gt; */ public class OutOfMemoryTest { private static ArrayList\u0026lt;Object\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); public static void main(String[] args) { while (true) { list.add(new byte[1024 * 1024 * 10]); } } } // 结果 Exception in thread \u0026#34;main\u0026#34; java.lang.OutOfMemoryError: Java heap space at com.zixieqing.runtime_data_area.heap.OutOfMemoryTest.main(OutOfMemoryTest.java:20) 为了进行高效的垃圾回收（GC后续说明），虚拟机把堆内存逻辑上划分成三块区域（分代的唯一理由就是优化 GC 性能）：\n新生代 / 年轻代 （Young Generation）：新对象和没达到一定年龄的对象都在新生代。 年轻代是所有新对象创建的地方。当填充年轻代时，执行垃圾收集，这种垃圾收集称为 Young GC。\n年轻代被分为三个部分——伊甸园（Eden Memory，伊甸园-上帝创造夏娃）和两个幸存区（Survivor Memory，被称为 from / to 或 s0 / s1），默认比例是8:1:1，这个比例可以通过 -XX:SurvivorRatio 来配置。\n大多数新创建的对象都位于 Eden 内存空间中。 当 Eden 空间被对象填充时，执行Minor GC，并将所有幸存者对象移动到一个幸存者空间中。 Minor GC 检查幸存者对象，并将它们移动到另一个幸存者空间。所以每次，一个幸存者空间总是空的。 经过多次 GC 循环后存活下来的对象被移动到老年代。通常，这是通过设置年轻一代对象的年龄阈值来实现的，然后他们才有资格提升到老一代。 老年代 / 养老区 （Old Generation）：被长时间使用的对象，老年代的内存空间比年轻代更大（因大部分对象都是创建出来之后就使用了，之后就不再使用了，就可以回收了。如：自己封装的对象-获取订单到返回订单就基本上不用了）。 旧的一代内存包含那些经过许多轮小型 GC 后仍然存活的对象。通常，垃圾收集是在老年代内存满时执行的。老年代垃圾收集称为 主GC（Major GC），通常需要更长的时间。\n大对象直接进入老年代（大对象是指需要大量连续内存空间的对象），这样做的目的是避免在 Eden 区和两个Survivor 区之间发生大量的内存拷贝。\n默认情况下新生代和老年代的比例是 1:2，可以通过 –XX:NewRatio 来配置。\n若在 JDK 7 中开启了 -XX:+UseAdaptiveSizePolicy，JVM 会动态调整 JVM 堆中各个区域的大小以及进入老年代的年龄，此时 –XX:NewRatio 和 -XX:SurvivorRatio 将会失效，而 JDK 8 是默认开启-XX:+UseAdaptiveSizePolicy。\n在 JDK 8中，不要随意关闭-XX:+UseAdaptiveSizePolicy，除非对堆内存的划分有明确的规划。\n元空间（Meta Space） / 永久代（Permanent-Generation）：JDK1.8前是永久代，JDK1.8及之后是元空间。JDK1.8 之前是占用 JVM 内存，JDK1.8 之后直接使用物理 / 直接内存。 不管是 JDK8 之前的永久代，还是 JDK8 及之后的元空间，都是 Java 虚拟机规范中方法区的实现。因此：这点内容在这里不多说明，到后面方法区再进行说明。\n对象在堆中的生命周期 在 JVM 内存模型的堆中，堆被划分为新生代和老年代 新生代又被进一步划分为 Eden区 和 Survivor区，Survivor 区由 From Survivor 和 To Survivor 组成 当创建一个对象时，对象会被优先分配到新生代的 Eden 区 此时 JVM 会给对象定义一个对象年龄计数器（-XX:MaxTenuringThreshold） 当 Eden 空间不足时，JVM 将执行新生代的垃圾回收（Minor GC） JVM 会把存活的对象转移到 Survivor 中，并且对象年龄 +1 对象在 Survivor 中同样也会经历 Minor GC，每经历一次 Minor GC，对象年龄都会+1 如果分配的对象超过了-XX:PetenureSizeThreshold ，对象会直接被分配到老年代 对象的分配过程 涉及的内容对于初识JVM的人有点超纲，后续会慢慢了解。\n为对象分配内存是一件非常严谨和复杂的任务，JVM 的设计者们不仅需要考虑内存如何分配、在哪里分配等问题，并且由于内存分配算法和内存回收算法密切相关，所以还需要考虑 GC 执行完内存回收后是否会在内存空间中产生内存碎片。\nnew 的对象先放在伊甸园区，此区有大小限制。 当伊甸园的空间填满时，程序又需要创建对象，JVM 的垃圾回收器将对伊甸园区进行垃圾回收（Minor GC），将伊甸园区中不再被其他对象所引用的对象进行销毁，再加载新的对象放到伊甸园区。 然后将伊甸园中的剩余对象移动到幸存者 0 区。 如果再次触发垃圾回收，此时上次幸存下来的放到幸存者 0 区，如果没有被回收，就会放到幸存者 1 区。 如果再次经历垃圾回收，此时会重新放回幸存者 0 区，接着再去幸存者 1 区。 什么时候才会去养老区呢？ 默认是 15 次回收标记。 在养老区，相对悠闲，当养老区内存不足时，触发 Major GC，进行养老区的内存清理。 若养老区执行了 Major GC 之后发现依然无法进行对象的保存，就会产生 OOM 异常。 堆内存三个值：used、total、max used：指的是当前已使用的堆内存；\ntotal：指的是Java虚拟机已经分配的可用堆内存；\nmax：指的是Java虚拟机可以分配的最大堆内存。\nArthas中堆内存相关的功能 堆内存used total max三个值可以通过dashboard命令看到。 手动指定刷新频率（不指定默认5秒一次）：dashboard –i 刷新频率(毫秒) 要是只想看内存栏的数据，可以直接使用指令：memory package com.zixieqing.runtime_data_area.heap; import java.io.IOException; import java.util.ArrayList; /** * \u0026lt;p\u0026gt; * Arthas中堆内存的相关功能 * \u0026lt;/p\u0026gt; * * \u0026lt;p\u0026gt;@author : ZiXieqing\u0026lt;/p\u0026gt; */ public class Arthas_Heap { public static void main(String[] args) throws IOException, InterruptedException { ArrayList\u0026lt;Object\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); System.in.read(); while (true) { list.add(new byte[1024 * 1024 * 100]); } } } 随着堆中的对象增多，当total可以使用的内存即将不足时，Java虚拟机会继续分配内存给堆。 如果堆内存不足，Java虚拟机就会不断的分配内存，total值会变大。total最多只能与max相等。 问题：是不是当used = max = total的时候，堆内存就溢出了？\n不是，堆内存溢出的判断条件比较复杂（具体内容需要到后续的垃圾回收相关内容去了解）。\n设置堆内存大小 如果不设置任何的虚拟机参数，max默认是系统内存的1/4，total默认是系统内存的1/64。在实际应用中一般都需要设置total和max的值\nOracle官方文档：https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html 要修改堆内存大小，可以使用虚拟机参数 -Xms值 (初始的total) 和 –Xmx值（max最大值）。\nJava 堆用于存储 Java 对象实例，那么堆的大小在 JVM 启动的时候就确定了，我们可以通过 -Xmx 和 -Xms 来设定\n-Xms 用来表示堆的起始内存，等价于 -XX:InitialHeapSize -Xmx 用来表示堆的最大内存，等价于 -XX:MaxHeapSize 在工作中，这两个值一般配置的都是相同的值\n好处：这样在程序启动之后可使用的总内存就是最大内存，而无需向java虚拟机再次申请，减少了申请并分配内存时间上的开销，同时也不会出现内存过剩之后堆收缩的情况。 PS：如果堆的内存大小超过 -Xmx 设定的最大内存， 就会抛出 OutOfMemoryError 异常\n语法：-Xmx值 -Xms值 单位：字节（默认，必须是 1024 的倍数）、k或者K(KB)、m或者M(MB)、g或者G(GB) 限制：Xmx必须大于 2 MB，Xms必须大于1MB 示例： -Xms6291456 -Xms6144k -Xms6m -Xmx83886080 -Xmx81920k -Xmx80m 可以通过代码获取到我们的设置值：\npublic static void main(String[] args) { // 返回 JVM 堆大小 long initalMemory = Runtime.getRuntime().totalMemory() / 1024 /1024; // 返回 JVM 堆的最大内存 long maxMemory = Runtime.getRuntime().maxMemory() / 1024 /1024; System.out.println(\u0026#34;-Xms : \u0026#34;+initalMemory + \u0026#34;M\u0026#34;); System.out.println(\u0026#34;-Xmx : \u0026#34;+maxMemory + \u0026#34;M\u0026#34;); System.out.println(\u0026#34;系统内存大小：\u0026#34; + initalMemory * 64 / 1024 + \u0026#34;G\u0026#34;); System.out.println(\u0026#34;系统内存大小：\u0026#34; + maxMemory * 4 / 1024 + \u0026#34;G\u0026#34;); } 拓展点：为什么Arthas中显示的heap堆大小与设置的值不一样？\nPS：测试自行在IDEA中设置下面内容的Java虚拟机参数，然后启动Arthas，不断添加对象，在Arthas中输入memory参数进行对比查看。\n-Xms1g -Xmx1g 原因：arthas中的heap堆内存使用了JMX技术的内存获取方式，这种方式与垃圾回收器有关，计算的是可以分配对象的内存，而不是整个内存。\n即：虽然设置了多少内存，但有一点内存是不会用到的，也就是JMX技术会把这部分内存去掉，不申请这部分内存，因为这点内存也放不下一个新对象，因此申请了也是浪费。\n方法区（Method Area） 方法区只是 JVM 规范中定义的一个概念。并没有规定如何去实现它，不同的厂商有不同的实现。\n永久代（PermGen）是 Hotspot 虚拟机特有的概念， Java8 的时候被 元空间取代了，永久代和元空间都是方法区的落地实现方式。\n方法区是线程共享的，并且也有内存溢出\nPS：如果方法区域中的内存不能用于满足分配请求，则 Java 虚拟机抛出 OutOfMemoryError。 HotSpot虚拟机中：\n永久代是HopSpot虚拟机中才有的概念。 JDK1.6及之前，方法区的实现方式是永久代，是在堆区中（运行时常量池[里面的逻辑包含了字符串常量池]、静态变量就存储在这个永久代中） JDK1.7，方法区的实现方式还是永久代，也还在堆区中，但逐步“去永久代”，将字符串常量池、静态变量放到了堆区中（java.lang.Class对象） JDK1.8及之后，取消永久代，方法区的实现方式变为了堆+元空间，元空间位于操作系统维护的直接内存中，默认情况下只要不超过操作系统承受的上限就可以一直分配内存。 PS：此时，类型信息、字段、方法、常量保存在元空间中，字符串常量池、静态变量还存储在堆区中（java.lang.Class对象） Java与直接内存 直接内存（Direct Memory）并不在《Java虚拟机规范》中存在，所以并不属于Java运行时的内存区域。\n在 JDK 1.4 中引入了 NIO 机制，使用了直接内存，主要为了解决以下两个问题：\nJava堆中的对象如果不再使用要回收，回收时会影响对象的创建和使用。 以前，IO操作比如读文件，需要先把文件读入直接内存（缓冲区）再把数据复制到Java堆中。现在，直接放入直接内存即可，同时Java堆上维护直接内存的引用，减少了数据复制的开销。写文件也是类似的思路。 要创建直接内存上的数据，可以使用java.nio.ByteBuffer。\n语法：ByteBuffer directBuffer = ByteBuffer.allocateDirect(size);\n注意：也会抛OutOfMemoryError。\npackage com.zixieqing.runtime_data_area; import java.io.IOException; import java.nio.ByteBuffer; import java.util.ArrayList; import java.util.List; /** * \u0026lt;p\u0026gt; * Java使用直接内存Direct Memory * \u0026lt;/p\u0026gt; * * \u0026lt;p\u0026gt;@author : ZiXieqing\u0026lt;/p\u0026gt; */ public class DirectMemory { /** * SIZE = 100mb */ private static int SIZE = 1024 * 1025 * 100; private static List\u0026lt;ByteBuffer\u0026gt; LIST = new ArrayList\u0026lt;\u0026gt;(); private static int COUNT = 0; public static void main(String[] args) throws IOException, InterruptedException { System.in.read(); while (true) { ByteBuffer byteBuffer = ByteBuffer.allocateDirect(SIZE); LIST.add(byteBuffer); System.out.println(\u0026#34;COUNT = \u0026#34; + (++COUNT)); Thread.sleep(5000); } } } Arthas的memory命令可以查看直接内存大小，属性名direct。\n如果需要手动调整直接内存的大小，可以使用 -XX:MaxDirectMemorySize=值\n默认不设置该参数情况下，JVM 自动选择最大分配的大小。示例如下：\n-XX:MaxDirectMemorySize=1m -XX:MaxDirectMemorySize=1024k -XX:MaxDirectMemorySize=1048576 方法区的内部结构 说的是HotSpot虚拟机，且是JDK1.8及之后。\n主要包含三部分内容：\n类的元信息：保存所有类的基本信息。一般称之为**InstanceKlass对象。**在类的加载阶段完成。这一点就是前面一开始玩的字节码文件内容 运行时常量池：字节码文件中通过编号查表的方式找到常量，这种常量池称为静态常量池。当常量池加载到内存中之后，可以通过内存地址快速的定位到常量池中的内容，这种常量池称为运行时常量池。 常量池表（Constant Pool Table）是 Class 文件的一部分，用于存储编译期生成的各种字面量和符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。\n为什么需要常量池？\n一个 Java 源文件中的类、接口，编译后产生一个字节码文件。而 Java 中的字节码需要数据支持，通常这种数据会很大以至于不能直接存到字节码里，换另一种方式，可以存到常量池，这个字节码包含了指向常量池的引用。在动态链接的时候用到的就是运行时常量池 字符串常量池（StringTable）：JDK7后，在堆中，存储的是在代码中定义的常量字符串内容。比如“123” 这个123就会被放入字符串常量池。 JDK6中，String.intern() 方法会把第一次遇到的字符串实例复制到永久代的字符串常量池中，返回的也是永久代里面这个字符串实例的引用。\nJDK7及之后中，由于字符串常量池在堆上，所以 String.intern() 方法会把第一次遇到的字符串的引用放入字符串常量池。\n如下图：上为JDK6的结果，下为JDK7及之后中的结果\n早期设计时（JDK1.6及之前），字符串常量池是属于运行时常量池的一部分，他们存储的位置也是一致的（堆中的永久代空间），后续做出了调整，大意图如下：\n设置方法区大小 JDK1.7及之前，通过下列参数设置永久代空间大小。 -XX:PermSize=值 和 -xx:MaxPermSize=值 JDK1.8及之后，通过下列参数设置元空间大小。 -XX:MetaspaceSize=值 和 -XX:MaxMetaspaceSize=值 默认值依赖于平台。Windows 下，-XX:MetaspaceSize 是 21M，-XX:MaxMetaspacaSize 的值是 -1，即没有限制。 与永久代不同，如果不指定大小，默认情况下，虚拟机会耗尽所有的可用系统内存。如果元数据发生溢出，虚拟机一样会抛出异常 OutOfMemoryError:Metaspace。 -XX:MetaspaceSize ：到达这个值后触发Full GC。对于一个 64 位的服务器端 JVM 来说，其默认的 -XX:MetaspaceSize 的值为20.75MB，这就是初始的高水位线，一旦触及这个水位线，Full GC 将会被触发并卸载没用的类（即这些类对应的类加载器不再存活），然后这个高水位线将会重置，新的高水位线的值取决于 GC 后释放了多少元空间。如果释放的空间不足，那么在不超过 MaxMetaspaceSize时，适当提高该值。如果释放空间过多，则适当降低该值。 如果初始化的高水位线设置过低，上述高水位线调整情况会发生很多次，通过垃圾回收的日志可观察到 Full GC 多次调用。为了避免频繁 GC，建议将 -XX:MetaspaceSize 设置为一个相对较高的值。 对象在堆中的内存布局 对象在堆中的内存布局（对象在堆中如何存储的），指的是对象在堆中存放时的各个组成部分\n主要分为以下几个部分：\n标记字段（Mark Word）：保存对象自身的运行时数据，HashCode、GC Age、锁标记位、是否为偏向锁等。 标记字段相对比较复杂。在不同的对象状态（有无锁、是否处于垃圾回收的标记中）下存放的内容是不同的。同时在64位（又分为是否开启指针压缩）、32位虚拟机中的布局都不同。\n以64位开启指针压缩：JDK8默认开启指针压缩\n64位不开启指针压缩，只是将Cms使用这部分弃用:\n查看对象布局的方式：JOL工具。\nJOL是用于分析 JVM 中对象布局的一款专业工具。工具中使用 Unsafe、JVMTI 和 Serviceability Agent (SA)等虚拟机技术来打印实际的对象内存布局。\n依赖 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.openjdk.jol\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jol-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.9\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 打印对象内存布局 System.out.println(ClassLayout.parseInstance(对象).toPrintable()); 元数据的指针（Klass pointer）：指向方法区中保存的InstanceKlass对象。 指针压缩：可以使用-XX:-UseCompressedOops关闭。\n在64位的Java虚拟机中，Klass Pointer以及对象数据中的对象引用都需要占用8个字节，为了减少这部分的内存使用量，64 位 Java 虚拟机使用指针压缩技术，将堆中原本 8个字节的 指针压缩成 4个字节。\n指针压缩的思想：将寻址的单位放大。\n如上图所示，原来按编号1去寻址，能拿到1字节的数据；现在按1去寻址，就可以拿到8个字节的数据。所以结果是原来按1字节去寻址，现在可以按8字节寻址。\n因此优点是：这样将编号当成地址，就可以用更小的内存访问更多的数据。\n但是也会引发两个问题：\n需要进行内存对齐：指的是将对象的内存占用填充至\u0026quot;8字节的倍数\u0026quot;。存在空间浪费（对于Hotspot来说不存在，即便不开启指针压缩，也需要进行内存对齐）\n寻址大小仅仅能支持2的35 次方个字节（32GB，如果超过32GB指针压缩会自动关闭）：不用压缩指针，应该是2的64次方 = 16EB，用了压缩指针就变成了8（字节） = 2的3次方 * 2的32次方 = 2的35次方 。\n内存对齐填充：将对象的内存占用填充至\u0026quot;8字节的倍数\u0026quot;。主要目的是为了解决并发情况下CPU缓存失效的问题。 不采用内存对齐：会造成多个对象在同一缓存行中，如下图A对象与B对象\nCPU缓存修改A对象并将其写回内存，但另一个线程B读取的是B对象，由于A、B对象在同一缓存行，A对象的数据写回内存了，但B对象可没有，所以线程B就会读取到B对象的假数据。\n采用内存对齐：同一个缓存行中不会出现不同对象的属性。在并发情况下，如果让A对象一个缓存行失效，是不会影响到B对象的缓存行的。\n内存对齐涉及的小知识：字段重排列。在Hotspot中，要求每个属性的偏移量Offset（字段地址 – 起始地址）必须是字段长度的N倍。如果不满足要求，会尝试使用内存对齐，通过在属性之间插入一块对齐区域达到目的。\n如下图中（JOL打印），Student类中的id属性类型为long，那么偏移量就必须是8的倍数\n这里有个小注意点（字段重排列通俗解释）：为了保证偏移量是8的倍数，所以会进行字段顺序的重排列。\n如：上图id在代码中声明可能是在前面（即age的位置），但age的offset是12，不满足8的倍数，所以将字段id重排列，放到offset为16处（即和字段age换位了）。\n如下图，name字段是引用类型占用8个字节（关闭了指针压缩），因为Offset必须是8的倍数，所以在age和name之间插入了4个字节的空白区域。28 + 4 = 32，是8的倍数。\n提一嘴儿：子类继承自父类的属性，那么子类中会有和父类顺序一致的属性的偏移量，并且子类中属性的偏移量是先按父类属性偏移量的顺序排列好，再排列子类本身的属性偏移量。\nimport org.openjdk.jol.info.ClassLayout; public class A { long l; long m; String name; } class B extends A{ int a; int b; } class Test { public static void main(String[] args) { System.out.println(ClassLayout.parseInstance(new B()).toPrintable()); } } 栈中的数据要保存到堆上 或 从堆中加载到栈上时怎么处理？ 堆中的数据加载到栈上：由于栈上的空间大于或者等于堆上的空间，所以直接处理，但是需要注意下\u0026quot;符号位\u0026quot;。 无符号，低位复制，高位补0 有符号，低位复制，高位非负则补0，负则补1 栈中的数据要保存到堆上：由于堆上存储空间较小，需要将高位去掉（boolean比较特殊，只取低位的最后一位保存）。 小测试：通过字节码指令修改方式将iconst1修改为iconst2和iconst3会得到截然不同的结果。这个就涉及到上面所说的堆 -\u0026gt; 栈；栈 -\u0026gt; 堆，以及boolean的存储方式。\n字节码指令：IDEA中可以安装ASM Bytecode Outline插件生成类的ASM代码，也可以用其他方式。 package com.zixieqing; /** * \u0026lt;p\u0026gt; * 栈中数据保存到堆中、堆中数据保存到栈中。iconst2 -\u0026gt; 2 = 10\ticonst3 -\u0026gt; 3 = 11 * boolean：1为true、0为false\tboolean取低位最后一位 * \u0026lt;/p\u0026gt; * * \u0026lt;p\u0026gt;@author : ZiXieqing\u0026lt;/p\u0026gt; */ public class StackStore { static boolean a;\t// 堆上 public static void main(String[] args) { a = true;\t// 栈上 if (a) { System.out.println(\u0026#34;a为true\u0026#34;); } else { System.out.println(\u0026#34;a为false\u0026#34;); } if (a == true) { System.out.println(\u0026#34;a为true\u0026#34;); } else { System.out.println(\u0026#34;a为false\u0026#34;); } } } 方法调用原理 方法调用的本质是通过字节码指令的执行，能在栈上创建栈帧，并执行调用方法中的字节码执行。以invoke开头的字节码指令的作用就是找到字节码指令并执行。\n在JVM中，一共有五个字节码指令可以执行方法调用：\ninvokestatic：调用静态方法。 invokespecial：调用对象的private方法、构造方法，以及使用 super 关键字调用父类实例的方法、构造方法，以及所实现接口的默认方法。 invokevirtual：调用对象的非private方法。 invokeinterface：调用接口对象的方法。 invokedynamic：用于调用动态方法，主要应用于lambda表达式中，机制极为复杂了解即可 Invoke指令执行时，需要找到方法区中instanceKlass中保存的方法相关的字节码信息。但是方法区中有很多类，每一个类又包含很多个方法，怎么精确地定位到方法的位置呢？\n静态绑定：指的是方法第一次调用时，符号引用被替换成内存地址的直接引用。 编译期间，invoke指令会携带一个参数符号引用，引用到常量池中的方法定义。方法定义中包含了类名 + 方法名 + 返回值 + 参数。\n适用于处理静态方法、私有方法、或者使用final修饰的方法，因为这些方法不能被继承之后重写。即：invokestatic、invokespecial、final修饰的invokevirtual指令。\n动态绑定：非static、非private、非final的方法，有可能存在子类重写方法，那么就需要通过动态绑定来完成方法地址绑定的工作。 动态绑定是基于方法表来完成的，invokevirtual使用了虚方法表（vtable），invokeinterface使用了接口方法表(itable)，整体思路类似。\n虚方法表，本质上是一个数组，记录了方法的内存地址。每个类中都有一个虚方法表，子类方法表中包含父类方法表中的所有方法；子类如果重写了父类方法，则使用子类自己的方法的地址进行替换。\n使用invokevirtual和虚方法表来解释整个过程：产生invokevirtual调用时，先根据对象头中的类型指针找到方法区中InstanceKlass对象，获得虚方法表，再根据虚方法表找到对应的地方，获得方法的地址，最后调用方法。\n执行引擎 执行引擎：执行本地已经编译好的方法，如虚拟机提供的C++方法。\n包括：即时编译器（JIT，即Just-in-time）、解释器、垃圾回收器等。\n自动垃圾回收 在C/C++这类没有自动垃圾回收机制的语言中，一个对象如果不再使用，需要手动释放，否则就会出现内存泄漏。我们称这种释放对象的过程为垃圾回收，而需要程序员编写代码进行回收的方式为手动回收。\nPS：内存泄漏指的是不再使用的对象在系统中未被回收，内存泄漏的积累可能会导致内存溢出。 Java中为了简化对象的释放，引入了自动垃圾回收（Garbage Collection简称GC）机制。虚拟机通过垃圾回收器来对不再使用的对象完成自动的回收，垃圾回收器主要负责对堆上的内存进行回收。\n自动垃圾回收与手动垃圾回收的优缺点。\n自动垃圾回收：自动根据对象是否使用由虚拟机来回收对象。 优点：降低程序员实现难度、降低对象回收bug的可能性。 缺点：程序员无法控制内存回收的及时性。 手动垃圾回收：由程序员编程实现对象的删除。 优点：回收及时性高，由程序员把控回收的时机。 缺点：编写不当容易出现悬空指针、重复释放、内存泄漏等问题。 方法区的回收 线程不共享的部分（程序计数器、Java虚拟机栈、本地方法栈），都是伴随着线程的创建而创建，线程的销毁而销毁。而方法的栈帧在执行完方法之后就会自动弹出栈并释放掉对应的内存，因此不需要对这部分区域进行垃圾回收。\n由前面对方法区的了解可知：方法区中能回收的内容主要就是常量池中废弃的常量和不再使用的类型。\n开发中此类场景一般很少出现，主要在如 OSGi、JSP 的热部署等应用场景中。每个jsp文件对应一个唯一的类加载器，当一个jsp文件修改了，就直接卸载这个jsp类加载器。重新创建类加载器，重新加载jsp文件。\n在前面类的生命周期中，最后一步是卸载（unloading），而判定一个类可以被卸载。需要同时满足下面三个条件：\n可以使用虚拟机参数 -verbose:class 或 -XX:+TraceClassLoading 、-XX:+TraceClassUnloading 查看类加载和卸载信息。\n-XnoClassgc 参数可以关闭类的GC / 控制是否对类进行卸载。在垃圾收集时类对象不会被回收，会被认为总是存活的，这将导致存放类对象的内存被持续占用，如果不谨慎使用，将可能导致OOM。\n此类所有实例对象都已经被回收。在堆中不存在任何该类的实例对象以及子类对象。\n加载该类的类加载器已经被回收。\n该类对应的 java.lang.Class 对象没有在任何地方被引用。\npackage com.zixieqing.execution_engine.method_area_collection; import com.zixieqing.class_and_classloader.FindClassLoader; /** * \u0026lt;p\u0026gt; * 卸载（unloading）类“同时满足”的三个条件 * \u0026lt;/p\u0026gt; * * \u0026lt;p\u0026gt;@author : ZiXieqing\u0026lt;/p\u0026gt; */ public class UnloadingConditions { public static void main(String[] args) throws ClassNotFoundException, IllegalAccessException, InstantiationException, InterruptedException { ClassLoader classLoader = FindClassLoader.class.getClassLoader(); Class\u0026lt;?\u0026gt; clazz = classLoader.loadClass(\u0026#34;com.zixieqing.class_and_classloader.FindClassLoader\u0026#34;); Object obj = clazz.newInstance(); // 1、该类所有实例对象都被回收 反例证明：将obj这个对象放到其他地方去，让其被持有则不会不会被卸载了 obj = null; // 2、加载该类的类加载器已经被回收 反例证明：将此类加载器其他持有就不会被卸载 classLoader = null; // 3、该类对应的 java.lang.Class 对象没有在任何地方被引用 反例证明：该对象被其他持有 clazz = null; // 手动触发垃圾回收 // 不一定会立即回收垃圾，仅仅是向Java虚拟机发送一个垃圾回收的请求，具体是否需要执行垃圾回收Java虚拟机会自行判断 System.gc(); } } 补充：关于 finalize() 方法\nfinalize() 类似 C++ 的析构函数，用来做关闭外部资源等工作。但是 try-finally 等方式可以做的更好，并且该方法运行代价高昂，不确定性大，无法保证各个对象的调用顺序，因此最好不要使用。\n当一个对象可被回收时，如果需要执行该对象的 finalize() 方法，那么就有可能通过在该方法中让对象重新被引用，从而实现自救，自救只能进行一次，如果回收的对象之前调用了 finalize() 方法自救，后面回收时不会调用 finalize() 方法。\n堆回收 如何判断堆上的对象是否可被回收？ Java中的对象是否能被回收，是根据对象是否被引用来决定的。如果对象被引用了，说明该对象还在使用，不允许被回收。\n而判断对象是否有引用有两种判断方法：引用计数法和可达性分析法。\n引用计数法 引用计数法会为每个对象维护一个引用计数器，当对象被引用时加1，取消引用（或引用失效）时减1，引用计数为 0 的对象可被回收。\n引用计数法的优点是实现简单，C++中的智能指针就采用了引用计数法，但是它也存在缺点，主要有两点：\n每次引用和取消引用都需要维护计数器，对系统性能会有一定的影响。 存在循环引用问题，此时引用计数器永远不为 0，导致无法对它们进行回收。所谓循环引用就是当A引用B，B同时引用A时会出现对象无法回收的问题。 可达性分析法 可达性分析将对象分为两类：垃圾回收的根对象（GC Root）和普通对象，对象与对象之间存在引用关系。通过 GC Roots 作为起始点进行搜索，能够到达到的对象都是存活的，不可达的对象可被回收。\nJava 虚拟机使用的是可达性分析算法来判断对象是否可以被回收。\n注：可达性算法中描述的对象引用，一般指的是强引用（另外几种引用后续会说明）。即是GCRoot对象对普通对象有引用关系，只要这层关系存在，普通对象就不会被回收。\n哪些对象被称之为GC Root对象？\n线程Thread对象，引用线程栈帧中的方法参数、局部变量等。 系统类加载器加载的java.lang.Class对象，引用类中的静态变量。 监视器对象，用来保存同步锁synchronized关键字持有的对象。 本地方法调用时使用的全局对象。 在 Java 中 GC Roots 一般包含哪些内容？\n虚拟机栈中引用的对象。 本地方法栈中引用的对象。 方法区中类静态属性引用的对象。 方法区中的常量引用的对象。 引用类型 无论是通过引用计算算法判断对象的引用数量，还是通过可达性分析算法判断对象是否可达，判定对象是否可被回收都与引用有关。共有5种引用类型（由强到弱）：强引用、软引用、弱引用、虚引用、终结器引用\n强引用 强引用：指的是GCRoot对象对普通对象有引用关系，即由可达性分析法判断，只要这层关系存在，普通对象就不会被回收。\n创建强引用的方式：“可以使用” new 的方式来创建强引用。PS：别钻牛角尖，来个 new SoftReference\u0026lt;Object\u0026gt;(obj);\nObject obj = new Object(); 软引用 软引用相对于强引用是一种比较弱的引用关系。\n如果一个对象只有软引用关联到它，则当程序内存不足时，就会将此软引用中的数据进行回收。\n在JDK 1.2版之后提供了SoftReference类来实现软引用，软引用常用于缓存中。\nObject obj = new Object(); SoftReference\u0026lt;Object\u0026gt; sf = new SoftReference\u0026lt;Object\u0026gt;(obj); obj = null; // 使对象只被软引用关联 软引用的执行过程如下：\n将对象使用软引用包装起来，new SoftReference\u0026lt;对象类型\u0026gt;(对象)。 内存不足时，虚拟机尝试进行垃圾回收。 如果垃圾回收仍不能解决内存不足的问题，回收软引用中的对象。 如果依然内存不足，抛出OutOfMemory异常。 问题：软引用中的对象如果在内存不足时回收，SoftReference对象本身也需要被回收。如何知道哪些SoftReference对象需要回收？\nSoftReference提供了一套队列机制：\n软引用创建时，通过构造器传入引用队列。 在软引用中包含的对象被回收时，该软引用对象会被放入引用队列。 通过代码遍历引用队列，将SoftReference的强引用删除。 软引用应用场景：缓存示例\n弱引用 弱引用的整体机制和软引用基本一致，区别在于弱引用包含的对象在垃圾回收时，不管内存够不够都会直接被回收。即：被弱引用关联的对象一定会被回收，也就是说它只能存活到下一次垃圾回收发生之前。\nJDK 1.2版之后提供了WeakReference类来实现弱引用，弱引用主要在ThreadLocal中使用。\nObject obj = new Object(); WeakReference\u0026lt;Object\u0026gt; wf = new WeakReference\u0026lt;Object\u0026gt;(obj); obj = null; 虚引用和终结器引用 这两种引用在常规开发中是不会使用的。\n虚引用：也叫幽灵引用/幻影引用，不能通过虚引用对象获取到包含的对象。虚引用唯一的用途是当对象被垃圾回收器回收时可以接收到对应的通知。Java中使用PhantomReference实现了虚引用， 直接内存中为了及时知道直接内存对象不再使用，从而回收内存，使用了虚引用来实现。\nObject obj = new Object(); PhantomReference\u0026lt;Object\u0026gt; pf = new PhantomReference\u0026lt;Object\u0026gt;(obj); obj = null; 终结器引用：指的是在对象需要被回收时，终结器引用会关联对象并放置在Finalizer类的引用队列中，再稍后由一条FinalizerThread线程从队列中获取对象，然后执行对象的finalize方法，在对象第二次被回收时，该对象才真正的被回收。在这个过程中可以在finalize方法中再将自身对象使用强引用关联上，但是不建议这样做。 垃圾回收算法 垃圾回收算法核心思想：\n找到内存中存活的对象。 释放不再存活对象的内存，使得程序能再次利用这部分空间。 判断GC算法是否优秀的标准 Java垃圾回收过程会通过单独的GC线程来完成，但是不管使用哪一种GC算法，都会有部分阶段需要停止所有的用户线程。这个过程被称之为Stop The World简称STW，如果STW时间过长则会影响用户的使用。\n吞吐量 吞吐量指的是 CPU 用于执行用户代码的时间 与 CPU 总执行时间的比值，即：吞吐量 = 执行用户代码时间 /（执行用户代码时间 + GC时间）。吞吐量数值越高，垃圾回收的效率就越高。\n最大暂停时间 最大暂停时间指的是所有在垃圾回收过程中的STW时间最大值。如下图中，黄色部分的STW就是最大暂停时间，显而易见上图比下图拥有更少的最大暂停时间。最大暂停时间越短，用户使用系统时受到的影响就越短。\n如下图就是上优下劣：\n堆使用效率 不同垃圾回收算法，对堆内存的使用方式是不同的。比如标记清除算法，可以使用完整的堆内存。而复制算法会将堆内存一分为二，每次只能使用一半内存。从堆使用效率上来说，标记清除算法要优于复制算法。\n三种评价标准：堆使用效率、吞吐量，以及最大暂停时间不可兼得。\n一般来说，堆内存越大，最大暂停时间就越长。想要减少最大暂停时间，就会降低吞吐量。\n不同的垃圾回收算法，适用于不同的场景。\nGC算法：标记-清除算法 一句话概括就是：标记存活对象，删除未标记对象。\n标记-清除算法可以使用完整的堆内存。\n标记清除算法的核心思想分为两个阶段：\n标记阶段：将所有存活的对象进行标记。Java中使用可达性分析算法，从GC Root开始通过引用链遍历出所有存活对象。\n清除阶段：从内存中删除没有被标记（也就是非存活）对象。\n优点：实现简单，只需要在第一阶段给每个对象维护标志位，第二阶段删除对象即可。\n缺点：\n会产生内存碎片化问题。 由于内存是连续的，所以在对象被删除之后，内存中会出现很多细小的可用内存单元。如果我们需要的是一个比较大的空间，很有可能这些内存单元的大小过小无法进行分配。\n分配速度慢。 由于内存碎片的存在，需要维护一个空闲链表，极有可能发生每次需要遍历到链表的最后才能获得合适的内存空间。\nGC算法：标记-整理算法 一句话概括就是：让所有存活的对象都向堆内存的一端移动，然后直接清理掉“端边界以外”的内存。\n标记整理算法也叫标记压缩算法，是对标记清理算法中容易产生内存碎片问题的一种解决方案。\n标记-整理算法可以使用整个堆内存。\n核心思想分为两个阶段：\n标记阶段：将所有存活的对象进行标记。Java中使用可达性分析算法，从GC Root开始通过引用链遍历出所有存活对象。\n整理阶段：将存活对象移动到堆的一端。清理掉非存活对象的内存空间。\n优点：\n内存使用率高：整个堆内存都可以使用。 不会产生内存碎片化问题：在整理阶段可以将对象往内存的一侧进行移动，剩下的空间都是可以分配对象的有效空间。 缺点：\n整理阶段的效率不高：因为要去找存活和非存活对象，然后进行相应内存位置移动，这里又涉及对象引用问题，所以会造成整体性能不佳。 如：Lisp2整理算法就需要对整个堆中的对象搜索3次。当然也有优化整理阶段的算法，如Two-Finger、表格算法、ImmixFC等高效的整理算法来提升此阶段性能。\nGC算法：复制算法 复制算法每次只能使用一半堆内存。\n复制算法的核心思想：\n准备两块空间From空间和To空间，每次在对象分配阶段，只能使用其中一块空间（From空间）。 在垃圾回收GC阶段，将From中存活对象复制到To空间。 将两块空间的From和To名字互换。 优点：\n吞吐量高：复制算法只需要遍历一次存活对象复制到To空间即可。比标记-整理算法少了一次遍历过程，因而性能较好，但不如标记-清除算法，因标记-清除算法不需要进行对象的移动。 不会发生内存碎片化问题：复制算法在复制之后就会将对象按照顺序放入To内存，所以对象以外的区域是可用空间，因此不会产生内存碎片化问题。 缺点：\n内存使用率低：每次只能让一半的内存空间来供创建对象使用。 # GC算法：分代收集算法 主流的JVM（如：HotSpot）采用的就是此种算法。\n一般将堆分为新生代和老年代：\n新生代分为伊甸园（Eden）区、两个幸存（Survivor ）区——被称为 from / to 或 s0 / s1。默认比例是8:1:1。 新生代使用: 复制算法 老年代使用: 标记 - 清除 或者 标记 - 整理 算法 分代回收时，创建出来的对象，首先会被放入Eden伊甸园区。 随着对象在Eden区越来越多，如果Eden区满，新创建的对象已经无法放入，就会触发年轻代的GC，称为Minor GC 或 Young GC。 Minor GC会把eden中和From需要回收的对象回收，把没有回收的对象放入To区。 接下来，S0会变成To区，S1变成From区。当eden区满时再往里放入对象，依然会发生Minor GC。 此时会回收eden区和S1(from)中的对象，并把eden和from区中剩余的对象放入S0。 注意：每次Minor GC中都会为对象记录他的年龄（或者叫回收标记次数），默认值为0（默认值和垃圾回收器有关），每次GC完加1。JVM中此值最大为15。\n如果Minor GC后对象的年龄达到阈值（最大值为15），对象就会被晋升至老年代。 当老年代中空间不足，无法放入新的对象时，先尝试minor gc，如果还是不足，就会触发Full GC。 问题：为什么老年代空间不足，需要先尝试minor gc，即年轻代回收？\n因为第6步中年轻代中的对象不是一定是年龄达到15才会进入老年代。年轻代空间满了，此时有些对象年龄可能是小于15的，但为了腾出可用空间，这部分对象也可能会被丢进老年代。\n如果Full GC依然无法回收掉老年代的对象，那么当对象继续放入老年代时，就会抛出Out Of Memory异常。 关于伊甸园（Eden）区有一个小知识点：TLAB （Thread Local Allocation Buffer）\n从内存模型而不是垃圾回收的角度，对 Eden 区域继续进行划分，JVM 为每个线程分配了一个私有缓存区域，它包含在 Eden 空间内。 多线程同时分配内存时，使用 TLAB 可以避免一系列的非线程安全问题，同时还能提升内存分配的吞吐量，因此我们可以将这种内存分配方式称为快速分配策略。 OpenJDK 衍生出来的 JVM 大都提供了 TLAB 设计。 为什么要有 TLAB ?\n堆区是线程共享的，任何线程都可以访问到堆区中的共享数据。 由于对象实例的创建在 JVM 中非常频繁，因此在并发环境下从堆区中划分内存空间是线程不安全的。 为避免多个线程操作同一地址，需要使用加锁等机制，进而影响分配速度。 尽管不是所有的对象实例都能够在 TLAB 中成功分配内存，但 JVM 确实是将 TLAB 作为内存分配的首选。\n在程序中，可以通过 -XX:UseTLAB 设置是否开启 TLAB 空间。\n默认情况下，TLAB 空间的内存非常小，仅占有整个 Eden 空间的 1%，我们可以通过 -XX:TLABWasteTargetPercent 设置 TLAB 空间所占用 Eden 空间的百分比大小。\n一旦对象在 TLAB 空间分配内存失败时，JVM 就会尝试着通过使用加锁机制确保数据操作的原子性，从而直接在 Eden 空间中分配内存。\nArthas查看分代之后的内存情况\n在JDK8中，添加 -XX:+UseSerialGC 参数使用分代回收的垃圾回收器，运行程序。 使用 memory 命令查看内存，显示出三个区域的内存情况。 测试时需要的JVM参数参考：JDK 1.8(版本不同有些参数会无效) + 添加 -XX:+UseSerialGC 参数\n参数 参数含义 示例 -Xms 设置堆的最小 / 初始 大小（相当于前面说的total）。 必须是1024的倍数且大于1MB。 设置为6MB的写法： -Xms6291456 -Xms6144k -Xms6m -Xmx 设置最大堆的大小（相当于前面说的max）。 必须是1024倍数且大于2MB。 设置为80 MB的写法： -Xmx83886080 -Xmx81920k -Xmx80m -Xmn 新生代的大小。 默认为整个堆的1 / 3 设置256 MB的写法： -Xmn256m -Xmn262144k -Xmn268435456 -XX:SurvivorRatio 伊甸园区和幸存区的比例，默认为8。 如：新生代1g内存，伊甸园区800MB，S0和S1各100MB 比例调整为4的写法： -XX:SurvivorRatio=4 -XX:+PrintGCDetails 或 verbose:gc 打印GC日志 # 垃圾回收器 垃圾回收器（Garbage collector，即GC）是垃圾回收算法的具体实现。\n除G1之外，其他垃圾回收器必须成对组合进行使用（如下图）。\n年轻代回收都是复制算法（包括G1），老年代回收的算法不同。\n记忆方式：\nJDK8及之前 关注暂停时间：ParNew + CMS（CMS在使用中需测试，因CMS在回收老年代时可能会影响用户线程）。 关注吞吐量：Parallel Scavenge + Parallel Old（此组合为JDK8默认）。 较大堆且关注暂停时间（JDK8之前不建议用）：G1。PS：JDK8最新版算是成熟的G1，故其实可以直接使用。 JDK9之后：G1（默认）。生产环境中也建议使用。。 垃圾回收器：Serial 与 Serial Old 新生代：Serial Serial是一种单线程串行回收年轻代的垃圾回收器，采用的是复制算法。\n垃圾回收线程进行GC时，会让用户线程进入等待，GC执行完了才会进行用户线程（即STW）。\n适用场景：Java编写的客户端程序 或者 硬件配置有限（服务器不多）的场景。或者直接说 Client 模式下的场景。\nPS：Serial 收集器收集几十兆甚至一两百兆的新生代停顿时间可以控制在一百多毫秒以内，只要不是太频繁，这点停顿是可以接受的。 优点：单CPU处理器下吞吐量非常出色。\n缺点：多CPU下吞吐量不如其他垃圾回收器，堆如果偏大会让用户线程处于长时间的等待。\n老年代：Serial Old Serial Old是Serial垃圾回收器的老年代版本，单线程串行回收，采用的是标记-整理算法。\n开启的方式：使用虚拟机参数 -XX:+UseSerialGC 即：新生代、老年代都使用串行回收器。\n垃圾回收线程进行GC时，会让用户线程进入等待，GC执行完了才会进行用户线程。\n适用场景：与Serial垃圾回收器搭配使用 或者 在CMS特殊情况下使用（CMS时会说明）。\n优缺点和Serial一样。\n优点：单CPU处理器下吞吐量非常出色。\n缺点：多CPU下吞吐量不如其他垃圾回收器，堆如果偏大会让用户线程处于长时间的等待。\n垃圾回收器：ParNew 与 CMS 新生代：ParNew ParNew垃圾回收器本质上是对Serial在多CPU下的优化，但：JDK9之后不建议使用了。\n使用多线程进行垃圾回收，采用的是复制算法。\nPS：默认开启的线程数量与 CPU 数量相同，可以使用 -XX:ParallelGCThreads 参数来设置线程数。 开启方式：使用参数 -XX:+UseParNewGC 即：新生代使用ParNew（并行）回收器， 老年代使用串行回收器（即Serial Old）。\n垃圾回收线程进行GC时，会让用户线程进入等待，GC执行完了才会进行用户线程。\n适用场景：JDK8及之前的版本中，与老年代垃圾回收器CMS搭配使用。\n优点：多CPU处理器下停顿时间较短。\n缺点：吞吐量和停顿时间不如G1，所以在JDK9之后不建议使用。\n老年代：CMS(Concurrent Mark Sweep) CMS垃圾回收器关注的是系统的暂停时间。\n允许用户线程和垃圾回收线程在某些步骤中同时执行，减少了用户线程的等待时间。采用的是标记-清除算法。\n开启方式：使用参数 XX:+UseConcMarkSweepGC。即新生代使用并行（ParNew），老年代使用CMS。\n初识标记 与 重新标记阶段 会让用户线程进入等待，GC执行完了才会进行用户线程。\n适用场景：大型的互联网系统中用户请求数据量大、频率高的场景。如订单接口、商品接口等。\nCMS执行步骤：\n初始标记（Initial Mark）：用极短的时间标记出GC Roots能直接关联到的对象（可达性分析法）。 并发标记（Concurrent Mark）：标记所有的对象，用户线程不需要暂停。 这里采用了一个并发标记算法，学名叫三色标记法，G1垃圾回收器也采用的是这个算法，所以G1时再说明这个算法。\n并发阶段运行时的线程数可以通过参数 -XX:ConcGCThreads （默认值为0）设置，由系统计算得出。即：CMS存在的线程资源争抢问题的解决方式。\n计算公式为： (-XX:ParallelGCThreads定义的线程数 + 3) / 4 ParallelGCThreads\t是STW停顿之后的并行线程数 ParallelGCThreads是由处理器核数决定的： 1、当cpu核数小于8时，ParallelGCThreads = CPU核数 2、否则 ParallelGCThreads = 8 + (CPU核数 – 8 ) * 5 / 8 重新标记（Remark）：由于并发标记阶段有些对象会发生变化，故存在错标、漏标等情况，因此需要重新标记。 并发清理（Clean）：清理非存活对象，用户线程不需要暂停。 CMS存在的问题\n缺点：\nCMS使用了标记-清除算法，在垃圾收集结束之后会出现大量的内存碎片，CMS会在Full GC时进行碎片的整理。这样会导致用户线程暂停，可以使用参数 -XX:CMSFullGCsBeforeCompaction=N （默认0）调整N次Full GC之后再整理。 无法处理在并发清理过程中产生的“浮动垃圾”，不能做到完全的垃圾回收。 “浮动垃圾”的原因：并发清理时用户线程会产生一些很快就使用、后续不用的对象，而这些对象在这次的GC中无法回收，只能等到下次GC回收，这部分垃圾就是“浮动垃圾”。\n如果老年代内存不足无法分配对象，CMS就会退化成Serial Old单线程回收老年代（即：前面说的特殊情况会调用Serial Old）。 垃圾回收器：Parallel Scavenge 与 Parallel Old 新生代：Parallel Scavenge（PS） Parallel Scavenge是JDK8默认的年轻代垃圾回收器。\n多线程并行回收，关注的是系统的吞吐量。具备自动调整堆内存大小的特点，采用的是复制算法。\n自动调整堆内存——即不需要手动指定新生代的大小(-Xmn)、Eden 和 Survivor 区的比例（-XX:SurvivorRatio ）、晋升老年代对象年龄等细节参数了。虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量。\n可以使用参数 -XX:+UseAdaptiveSizePolicy 让垃圾回收器根据吞吐量和最大停顿毫秒数自动调整内存大小。\n开启方式：-XX:+UseParallelGC 或 -XX:+UseParallelOldGC 就可以使用Parallel Scavenge + Parallel Old这种组合。\nOracle官方建议在使用这个组合时，不要设置堆内存的最大值，垃圾回收器会根据最大暂停时间和吞吐量自动调整内存大小。 垃圾回收线程进行GC时，会让用户线程进入等待，GC执行完了才会进行用户线程。\n适用场景：后台任务，不需要与用户交互，并且容易产生大量的对象。如大数据的处理，大文件导出。\n优点：吞吐量高，而且手动可控。为了提高吞吐量，虚拟机会动态调整堆的参数。\n可以使用参数 -XX:GCTimeRatio=n 设置吞吐量为n。 用户线程执行时间 = n / (n + 1) 缺点：不能保证单次的停顿时间。\n可以使用参数 -XX:MaxGCPauseMillis=n 设置每次垃圾回收时的最大停顿毫秒数。 证明JDK8默认采用了Parallel Scavenge垃圾回收器\nCMD中输入下列参数即可 C:\\Users\\zixq\\Desktop\u0026gt; java -XX:+PrintCommandLineFlags -version\t# 打印出启动过程中使用的所有虚拟机参数 打印出的关键结果： -XX:InitialHeapSize=264767296 -XX:MaxHeapSize=4236276736 -XX:+PrintCommandLineFlags -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:-UseLargePagesIndividualAllocation -XX:+UseParallelGC\t# 此处：已经加了使用 Parallel Scavenge 垃圾回收器的虚拟机参数 也可在Arthas中查看：随便写段代码，使用 System.in.read(); 定住，不添加任何虚拟机参数启动。示例如下： import java.io.IOException; import java.util.ArrayList; import java.util.List; /** * \u0026lt;p\u0026gt; * 测试JDK8的垃圾回收器（GC）是什么 * \u0026lt;/p\u0026gt; * * \u0026lt;p\u0026gt;@author : ZiXieqing\u0026lt;/p\u0026gt; */ public class JDK8_GC_Test { public static void main(String[] args) throws IOException { List\u0026lt;Object\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); int count = 0; while (true) { System.in.read(); System.out.println(\u0026#34;++count = \u0026#34; + ++count); // 1M list.add(new byte[1024 * 1024]); } } } Arthas命令：\ndashboard -n 1 老年代：Parallel Old（PO） Parallel Old是为Parallel Scavenge收集器设计的老年代版本，JDK8默认的老年代垃圾回收器。\n利用多线程并发收集，采用标记-整理算法。\n开启方式：-XX:+UseParallelGC 或 -XX:+UseParallelOldGC 就可以使用Parallel Scavenge + Parallel Old这种组合。\n垃圾回收线程进行GC时，会让用户线程进入等待，GC执行完了才会进行用户线程。\n优点：并发收集，在多核CPU下效率较高。\n缺点：暂停时间会比较长。\n垃圾回收器：G1 G1（Garbage First）是在Java7 update 4之后引入的一个新的垃圾回收器，引入分区的思路，弱化了分代的概念。\nJDK9之后默认的垃圾回收器是G1垃圾回收器。\n堆被分为新生代和老年代，其它收集器进行收集的范围都是整个新生代或老年代，而 G1 可以直接对新生代和老年代一起回收（Mixed GC），采用标记-复制算法。\n开启方式：使用参数 -XX:+UseG1GC\n适用场景：JDK8最新版本、JDK9之后建议默认使用。\nParallel Scavenge关注吞吐量，允许用户设置最大暂停时间 ，但是会减少年轻代可用空间的大小。\nCMS关注暂停时间，但是吞吐量方面会下降。\n而G1设计目标就是将上述两种垃圾回收器的优点融合：\n支持巨大的堆空间回收，并有较高的吞吐量。 支持多CPU并行垃圾回收。 允许用户设置最大暂停时间。 优点：对比较大的堆，超过6G的堆回收时，延迟可控，会产生内存碎片，发标记的SATB算法效率高.\n缺点：JDK8之前还不够成熟。\nG1的内存划分 G1是将整个堆划分成多个大小相等的区域，称之为Region（默认将整堆划分为2048个分区），区域不要求是物理连续的（逻辑连续即可）。分为Eden、Survivor、Old区。\n问题：每个Region的大小是怎么计算来的？\n虚拟机自行计算的方式 每个Region的大小 = 堆空间大小 / 2048m 如：堆空间大小 = 4G，则每个Region的大小 = （1024 * 4）/ 2048 = 2m 程序员手动配置的方式 可通过参数 -XX:G1HeapRegionSize=32m 指定 其中32m指定每个region大小为32M，Region size必须是2的指数幂，取值范围从1M到32M 分区，即分Region，还会牵扯到一个小知识点：本地分配缓冲 Lab（Local allocation buffer）\n由于分区的思想，每个线程均可以\u0026quot;认领\u0026quot;某个分区用于线程本地的内存分配，而不需要顾及分区是否连续。因此，每个应用线程和GC线程都会独立地使用分区，进而减少同步时间，提升GC效率，这个分区称为本地分配缓冲区(Lab)。其中：\n应用线程可以独占一个本地缓冲区（TLAB，详情见前面的 GC算法：分代收集算法 ） 来创建对象，而大部分都会落入Eden区域（巨型对象或分配失败除外），因此TLAB的分区属于Eden空间。 而每次垃圾收集时，每个GC线程同样可以独占一个本地缓冲区(GCLAB)用来转移对象，每次回收会将对象复制到Suvivor空间或老年代空间；对于从Eden / Survivor空间晋升（Promotion）到Survivor / 老年代空间的对象，同样由GC独占的本地缓冲区进行操作，该部分称为晋升本地缓冲区(PLAB) G1垃圾回收的方式 G1垃圾回收有两种方式：\n年轻代回收：Young GC（Minor GC） Young GC：回收Eden区和Survivor区中不用的对象。会导致STW。采用复制算法。 G1中可以通过参数 -XX:MaxGCPauseMillis=n （默认200ms） 设置每次垃圾回收时的最大暂停时间毫秒数，G1垃圾回收器会“尽可能地”保证暂停时间（即软实时：尽可能在此时限内完成垃圾回收）。 混合回收（年轻代+老年代）：Mixed GC。 Mixed GC：回收所有年轻代和部分老年代的对象以及大对象区。采用标记-复制整理算法 年轻代回收Young GC执行流程 下列流程也有个专业名字：年轻代收集集合 CSet of Young Collection\n新创建的对象会存放在Eden区。当G1判断年轻代区不足（max默认60%），无法分配对象时需要回收时会执行Young GC。 max指的是：年轻代内存超过整个堆内存的60%。\n注意：部分对象如果大小达到甚至超过Region的一半，会直接放入老年代，这类老年代被称为Humongous【巨型】区。\n如堆内存是4G，那么每个Region是2M，而只要一个大对象超过了1M就被放入Humongous区，如果对象过大会横跨多个Region。\nG1内部做了一个优化，一旦发现没有引用指向巨型对象，则可直接在年轻代收集周期中被回收。\n从上图也可知：巨型对象会独占一个、或多个连续分区，其中\n第一个分区被标记为开始巨型(StartsHumongous)，相邻连续分区被标记为连续巨型(ContinuesHumongous)。 由于无法享受Lab带来的优化，并且确定一片连续的内存空间需要整堆扫描，因此确定巨型对象开始位置的成本非常高，如果可以，应用程序应避免生成巨型对象。 标记出Eden和Survivor区域中的存活对象。 根据配置的最大暂停时间选择“某些Region区域”，将这些区域中存活对象复制到一个新的Survivor区中（对象年龄【存活次数】+1），然后清空这些区域。 这里的小细节是：Eden分区存活的对象将被拷贝到Survivor分区；原有Survivor分区存活的对象，将根据任期阈值(tenuring threshold)分别晋升到PLAB、新的survivor分区和老年代分区中，而原有的年轻代分区将被整体回收掉。\n问题1：所谓的“某些Region区域“是怎么选择的？\nG1在进行Young GC的过程中会去记录每次垃圾回收时每个Eden区和Survivor区的平均耗时，以作为下次回收时的参考依据。\n然后根据配置的最大暂停时间【-XX:MaxGCPauseMillis=n （默认200ms）】就能计算出本次回收时最多能回收多少个Region区域。\n如：-XX:MaxGCPauseMillis=n（默认200ms），每个Region回收耗时40ms，那么这次回收最多只能回收200 / 40 = 5，但选5个可能会超出设置的最大暂停时间，所以只选择4个Region进行回收。\n问题2：此步要维护对象年龄（年龄+1）的原因是什么？\n答案：辅助判断老化(tenuring)对象晋升时是到Survivor分区还是到老年代分区。 年轻代收集首先先将晋升对象内存大小总和、对象年龄信息维护到年龄表中。 再根据年龄表、Survivor内存大小、Survivor填充容量 -XX:TargetSurvivorRatio (默认50%)、最大任期阈值-XX:MaxTenuringThreshold (默认15)，计算出一个恰当的任期阈值，凡是超过任期阈值的对象都会被晋升到老年代。 **后续Young GC时与之前相同，只不过Survivor区中存活对象会被搬运到另一个Survivor区。**当某个存活对象的年龄到达阈值（默认15），将被放入老年代。 关于上述年轻代回收有一个小知识点：收集集合（CSet）\n收集集合(CSet)：代表每次GC暂停时回收的一系列目标分区。 在任意一次收集暂停中，CSet所有分区都会被释放，内部存活的对象都会被转移到分配的空闲分区中。\n因此无论是年轻代收集，还是混合收集，工作的机制都是一致的。年轻代收集CSet只容纳年轻代分区，而混合收集会通过启发式算法，在老年代候选回收分区中，筛选出回收收益最高的分区添加到CSet中。\n候选老年代分区的CSet准入条件：可以通过活跃度阈值 -XX:G1MixedGCLiveThresholdPercent (默认85%)进行设置，从而拦截那些回收开销巨大的对象；同时，每次混合收集可以包含候选老年代分区，可根据CSet对堆的总大小占比 -XX:G1OldCSetRegionThresholdPercent (默认10%)设置数量上限。\n由上述可知，G1的收集都是根据CSet进行操作的，年轻代收集与混合收集没有明显的不同，最大的区别在于两种收集的触发条件。\n卡表Card Table 与 已记忆集合RSet 问题：Region内部又有什么？Card与RSet\n这个问题就是想问：G1的年轻代回收的原理（卡片Card + 卡表 Crad Table + 已记忆集合 RSet ）。 G1年轻代回收（Young GC）的执行流程请看 年轻代回收Young GC执行流程\n在前面G1年轻代回收（Young GC）时需要标记“存活对象”，请问：如果产生了跨代引用，我们怎么知道它算不算存活对象？如老年代对象引用了年轻代对象。\n方式一：从GC Root开始，扫描所有对象，如果年轻代对象在引用链上，就标记为存活。这种需要遍历引用链上的所有对象，效率太低，所以不可取。\n方式二：维护一个详细的表，记录哪个对象被哪个老年代引用了。在年轻代中被引用的对象，不进行回收。此方式看似可行，但如果对象太多这张表会占用很大的内存空间。存在错标的情况。可相对来说比方式一要靠谱一点。\n所以，对方式二进行优化：\n优化一：只记录Region被哪些对象引用了。这种引用详情表称为记忆集 RememberedSet（简称RS或RSet）：是一种记录了从非收集区域对象 引用 收集区域对象的这些关系的数据结构。扫描时将记忆集中的对象也加入到GC Root中，就可以根据引用链判断哪些对象需要回收了。 这样通过使用RSet，在做可达性分析时就可以避免全堆扫描。\n虽然引入了RSet，但是还有存在一个问题：如果区域中引用对象很多，还是占用很多内存。因此继续优化。\n优化二：将所有区域（Region）中的内存按一定大小划分成很多个块，每个块进行编号（即卡片【Card 或 Card Page】）。记忆集(RSet)中只记录对块（Card）的引用关系（现在才是RSet真正记录的东西）。如果一个块中有多个对象，只需要引用一次，减少了内存开销。 在串行和并行收集器中，GC通过整堆扫描，来确定对象是否处于可达路径中。\n然而G1为了避免STW式的整堆扫描，在每个分区记录了一个已记忆集合(RSet)，内部类似一个反向指针，记录引用分区内对象的卡片索引（见下述Card与Card Table）。当要回收该分区时，通过扫描分区的RSet，来确定引用本分区内的对象是否存活，进而确定本分区内的对象存活情况。\n这个RSet有个注意点：并非所有的引用都需要记录在RSet中，只有老年代的分区可能会有RSet记录，这些分区称为拥有RSet分区(an RSet’s owning region)\n如果一个分区确定需要扫描，那么无需RSet也可以无遗漏地得到引用关系，那么引用源自本分区的对象，当然不用落入RSet中；\nG1 GC每次都会对年轻代进行整体收集，因此引用源自年轻代的对象，也不需要在RSet中记录。\nG1对内存的使用以分区(Region)为单位，而对对象的分配则以卡片(Card)为单位。\n每个分区（Region）内部被分成了若干个大小为512 Byte的卡片(Card 或 Card Page)，标识堆内存最小可用粒度。\n所有分区的卡片将会记录在全局卡片表（Global Card Table，是一个字节数组）中，分配的对象会占用物理上连续的若干个卡片，当查找对分区内对象的引用时便可通过记录卡片来查找该引用对象。\n每次对内存的回收，本质都是对指定分区的卡片进行处理。\n每个分区（Region）都拥有一个自己的卡表（Card Table），如果产生了跨代引用（老年代引用年轻代），此时这个Region对应的卡表上就会将字节内容进行修改。\n上述的全局卡片表(Global Card Table)这个字节数组的一个元素就是这里的某个Region的卡表。 卡表会占用一定的内存空间，如：堆大小是1G时，卡表大小为 1024 MB / 512 = 2MB。 卡表的主要作用是生成记忆集（RSet）。 JDK8源码中0代表被引用了称为脏卡。这样就可以标记出当前Region被老年代中的哪些部分引用了。那么要生成记忆集就比较简单了，只需要遍历整个卡表，找到所有脏卡。\n0代码脏卡，其他数字代表意思如下：\n产生跨代引用（老年代引用年轻代），Region对应的卡表上就会将字节内容进行修改：\n年轻代回收标记时，会将记忆集中的对象也加入到GC Root对象中，进行扫描并标记其引用链上的对象。\n问题：RSet的内部又有什么？有个屁，人都问麻了\n答案：PRT（ Per Region Table ） RSet在内部使用Per Region Table(PRT)记录分区的引用情况。由于RSet的记录要占用分区的空间，如果一个分区非常\u0026quot;受欢迎\u0026quot;，那么RSet占用的空间会上升，从而降低分区的可用空间。G1应对这个问题采用了改变RSet的密度的方式，在PRT中将会以三种模式记录引用：\n稀少：直接记录引用对象的卡片索引。 细粒度：记录引用对象的分区索引。 粗粒度：只记录引用情况，每个分区对应一个比特位。 由上可知，粗粒度的PRT只是记录了引用数量，需要通过整堆扫描才能找出所有引用，因此扫描速度也是最慢的。\nRSet的维护：写屏障 与 并发优化线程 本节内容参考：@pdai：Java垃圾回收器 - G1详解 由于不能整堆扫描，又需要计算分区确切的活跃度，因此，G1需要一个增量式的完全标记并发算法，通过维护RSet，得到准确的分区引用信息。在G1中，RSet的维护主要来源两个方面：写屏障(Write Barrier) 和 并发优化线程(Concurrence Refinement Threads)。\n首先介绍一下栅栏(Barrier)的概念。栅栏是指在原生代码片段中，当某些语句被执行时，栅栏代码也会被执行。\nG1主要在赋值语句中，使用写前屏障(Pre-Write Barrrier)和写后屏障(Post-Write Barrrier)。事实上，写屏障的指令序列开销非常昂贵，应用吞吐量也会根据栅栏复杂度而降低。\n栅栏代码示意：\n写屏障（Write Barrier）：在执行引用关系建立的代码执行后插入一段指令，完成卡表的维护工作。损失的性能一般大约在5%~10%之间。\n每次引用类型数据写操作时，都会产生一个Write Barrier【写屏障/写栅栏】暂时中断操作； 然后检查将要写入的引用指向的对象是否和该引用类型数据在不同的Region（其他收集器：检查老年代对象是否引用了新生代对象）； 如果不同，通过cardTable把相关引用信息记录到引用指向对象的所在Region对应的Remembered Set中； 当进行垃圾收集时，在GC根节点的枚举范围加入Remembered Set；就可以保证不进行全局扫描，也不会有遗漏。 写前屏障（Pre-Write Barrrier）\n即将执行一段赋值语句时，等式左侧对象将修改引用到另一个对象，那么等式左侧对象原先引用的对象所在分区将因此丧失一个引用，那么JVM就需要在赋值语句生效之前，记录丧失引用的对象。JVM并不会立即维护RSet，而是通过批量处理，在将来RSet更新(见“起始快照算法（SATB）”)。\n写后屏障（Post-Write Barrrier）：G1使用写后屏障技术，在执行引用关系建立的代码执行后插入一段指令，完成卡表的维护工作。\n当执行一段赋值语句后，等式右侧对象获取了左侧对象的引用，那么等式右侧对象所在分区的RSet也应该得到更新。同样为了降低开销，写后栅栏发生后，RSet也不会立即更新，同样只是记录此次更新日志，在将来批量处理(见“并发优化线程（Concurrence Refinement Threads）“）。\n起始快照算法 Snapshot at the beginning (SATB)：\nTaiichi Tuasa贡献的增量式完全并发标记算法。 主要针对标记-清除垃圾收集器的并发标记阶段，非常适合G1的分区块的堆结构，同时解决了CMS的主要烦恼：重新标记暂停时间长带来的潜在风险。 SATB会创建一个对象图，相当于堆的逻辑快照，从而确保并发标记阶段所有的垃圾对象都能通过快照被鉴别出来。\n当赋值语句发生时，应用将会改变了它的对象图，那么JVM需要记录被覆盖的对象。因此写前栅栏会在引用变更前，将值记录在SATB日志或缓冲区中。每个线程都会独占一个SATB缓冲区，初始有256条记录空间。\n当空间用尽时，线程会分配新的SATB缓冲区继续使用，而原有的缓冲去则加入全局列表中。\n最终在并发标记阶段，并发标记线程（Concurrent Marking Threads）在标记的同时，还会定期检查和处理全局缓冲区列表的记录，然后根据标记位图分片的标记位，扫描引用字段来更新RSet。此过程又称为并发标记 / SATB写前栅栏。\n并发标记线程（Concurrent Marking Threads）\n并发标记位图过程：\n要标记存活的对象，每个分区都需要创建位图(Bitmap)信息来存储标记数据，来确定标记周期内被分配的对象。\nG1采用了两个位图Previous Bitmap、Next Bitmap 来存储标记数据。 Previous位图存储上次的标记数据，Next位图在标记周期内不断变化更新，同时Previous位图的标记数据也越来越过时，\n当标记周期结束后Next位图便替换Previous位图，成为上次标记的位图。同时，每个分区通过顶部开始标记(TAMS)来记录已标记过的内存范围。同样的，G1使用了两个顶部开始标记Previous TAMS(PTAMS)、Next TAMS(NTAMS)记录已标记的范围。\n在并发标记阶段，G1会根据参数-XX:ConcGCThreads(默认GC线程数的1/4，即-XX:ParallelGCThreads/4)分配并发标记线程(Concurrent Marking Threads)，进行标记活动。每个并发线程一次只扫描一个分区，并通过\u0026quot;手指\u0026quot;指针的方式优化获取分区。并发标记线程是爆发式的，在给定的时间段拼命干活，然后休息一段时间，再拼命干活。\n每个并发标记周期，在初始标记STW的最后，G1会分配一个空的Next位图和一个指向分区顶部(Top)的NTAMS标记。Previous位图记录的上次标记数据上次的标记位置，即PTAMS，在PTAMS与分区底部(Bottom)的范围内，所有的存活对象都已被标记。那么，在PTAMS与Top之间的对象都将是隐式存活(Implicitly Live)对象。在并发标记阶段，Next位图吸收了Previous位图的标记数据，同时每个分区都会有新的对象分配，则Top与NTAMS分离，前往更高的地址空间。在并发标记的一次标记中，并发标记线程将找出NTAMS与PTAMS之间的所有存活对象，将标记数据存储在Next位图中。同时，在NTAMS与Top之间的对象即成为已标记对象。如此不断地更新Next位图信息，并在清除阶段与Previous位图交换角色。\n并发优化线程（Concurrence Refinement Threads）：\nG1中使用基于Urs Hölzle的快速写栅栏，将栅栏开销缩减到2个额外的指令。栅栏将会更新一个card table type的结构来跟踪代间引用。\n当赋值语句发生后，写后栅栏会先通过G1的过滤技术判断是否是跨分区的引用更新，并将跨分区更新对象的卡片加入缓冲区序列，即更新日志缓冲区或脏卡片队列。与SATB类似，一旦日志缓冲区用尽，则分配一个新的日志缓冲区，并将原来的缓冲区加入全局列表中。\n并发优化线程(Concurrence Refinement Threads)，只专注扫描日志缓冲区记录的卡片来维护更新RSet，线程最大数目可通过-XX:G1ConcRefinementThreads(默认等于-XX:ParellelGCThreads)设置。并发优化线程永远是活跃的，一旦发现全局列表有记录存在，就开始并发处理。如果记录增长很快或者来不及处理，那么通过阈值-X:G1ConcRefinementGreenZone/-XX:G1ConcRefinementYellowZone/-XX:G1ConcRefinementRedZone，G1会用分层的方式调度，使更多的线程处理全局列表。如果并发优化线程也不能跟上缓冲区数量，则Mutator线程(Java应用线程)会挂起应用并被加进来帮助处理，直到全部处理完。因此，必须避免此类场景出现。\n更详细地G1年轻代回收的过程\n通过前面的铺垫之后，现更详细地在G1年轻代的回收过程如下：\nRoot扫描，将所有的静态变量、局部变量扫描出来。 处理脏卡队列中的没有处理完的信息，更新记忆集的数据，此阶段完成后，记忆集中包含了所有老年代对当前Region的引用关系。 标记存活对象。记忆集中的对象会加入到GC Root对象集合中，在GC Root引用链上的对象也会被标记为存活对象。 根据设定的最大停顿时间，选择本次收集的区域，称之为回收集合（Collection Set）。 复制对象：将标记出来的对象复制到新的区中，将年龄+1，如果年龄到达15则晋升到老年代。老的区域内存直接清空。 处理软、弱、虚、终结器引用，以及JNI中的弱引用。 混合收集：Mixed GC 回收所有年轻代和部分老年代的对象以及大对象区。采用的算法：标记-复制整理。\n触发时机：经过多次的回收之后(上述Young GC执行流程)，会出现很多老年代区（Old），此时总堆占有率达到阈值时（-XX:InitiatingHeapOccupancyPercent 默认45%）会触发混合回收Mixed GC。\n为了满足暂停目标，G1可能不能一口气将所有的候选分区收集掉，因此G1可能会产生连续多次的混合收集与应用线程交替执行，每次STW的混合收集与年轻代收集过程相类似。\n为了确定包含到年轻代收集集合CSet的老年代分区，JVM通过参数混合周期的最大总次数-XX:G1MixedGCCountTarget(默认8)、堆废物百分比-XX:G1HeapWastePercent(默认5%)。通过候选老年代分区总数与混合周期最大总次数，确定每次包含到CSet的最小分区数量；根据堆废物百分比，当收集达到参数时，不再启动新的混合收集。而每次添加到CSet的分区，则通过计算得到的GC效率进行安排。\nMixed GC的回收流程：\n初始标记（initial mark）：暂停所有用户线程（停段时间很短）。标记Gc Roots引用的对象为存活。 并发标记（concurrent mark）：会和用户线程一起执行。将第一步中标记的对象引用的对象，标记为存活。这里和Region维护的Remebered Set挂钩（请看：卡表Card Table 与 已记忆集合RSet）。 CMS和G1在并发标记时使用的是同一个算法：三色标记法\n使用黑灰白三种颜色标记对象。\n黑色（存活）：当前对象在GC Root引用链上，其自身与其引用对象都已标记完成； 灰色（待处理）：当前对象在GC Root引用链上，其自身被标记，其引用的对象未标记； 白色（可回收）：当前对象不在GC ROOT引用链上，是未标记。 执行流程如下：\nGC 开始前所有对象都是白色。 GC 一开始，所有根（GC Root）能够直达的对象被压到栈中，待搜索，此时颜色是灰色（即：放入灰色队列）。 然后灰色对象依次从栈中取出搜索子对象，子对象也会被涂为灰色，入栈。当其所有的子对象都涂为灰色之后，该对象被涂为黑色。 当 GC 结束之后，灰色对象将全部没了（即对象标记处理完成），剩下黑色的为存活对象，白色的为垃圾。 上面的三色标记法的黑色、白色就是使用了位图（BitMap）来实现的：\n如：8个字节使用1个bit来标识标记的内容，黑色为1，白色为0，灰色不会体现在位图中，会单独放入一个队列中。如果对象超过8个字节，仅仅使用第一个bit位处理。\n最终标记（remark或者Finalize Marking）：暂停所有用户线程。标记一些引用改变而漏标的对象。 和CMS的区别在这步：Mixed GC在这里不管新创建 和 不再关联的对象（等待下一轮回收该回收的）。\n小细节：为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程的 Remembered Set Logs 里，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中。\n问题：漏标问题是怎么产生的？\n三色标记法存在一个很严重的问题：由于用户线程可能同时在修改对象的引用关系，就会出现漏标的情况。\n如：用户线程执行了 B.c = null；将B到C的引用去除了。同时执行了A.c = c; 添加了A到C的引用。这就产生了严重问题。\n换言之就是：在最终标记（remark或者Finalize Marking）过程中，黑色指向了白色，如果不对黑色重新扫描，则会漏标。会把白色对象当作没有新引用指向从而回收掉。\n并发标记过程中，Mutator删除了所有从灰色到白色的引用，会产生漏标。此时白色对象应该被回收。\n产生漏标问题的条件有两个：\n黑色对象指向了白色对象。 灰色对象指向白色对象的引用消失。 所以要解决上述三色标记法带来的漏标问题，打破两个条件之一即可：\n跟踪黑指向白的增加 incremental update：增量更新，关注引用的增加。把黑色重新标记为灰色，下次重新扫描属性。CMS采用该方法。 记录灰指向白的消失 SATB（snapshot at the beginning 初始快照算法）：关注引用的删除。当灰–\u0026gt;白消失时，要把这个 引用 推到GC的栈中，保证白还能被GC扫描到。G1采用该方法。 SATB（snapshot at the beginning 起始快照算法）：\n标记开始时创建一个快照，记录当前所有对象，标记过程中新生成的对象直接标记为黑色。 采用写前屏障（Post-Write-Barrier）技术，在引用赋值前（如B.c = null之前），将之前引用的对象c放入SATB待处理队列中。SATB队列每个线程都有一个，最终标记阶段会汇总到一个总的SATB队列中，然后逐一处理。 SATB队列中的对象，默认按照存活处理，同时要处理他们引用的对象。\nSATB的缺点：是在本轮清理时可能会将不存活的对象标记成存活对象，产生了一些所谓的浮动垃圾，等到下一轮清理时才能回收.\n问题：为什么G1采用SATB而不用incremental update？\n因为采用incremental update把黑色重新标记为灰色后，之前扫描过的还要再扫描一遍，效率太低。G1有RSet与SATB相配合。Card Table里记录了RSet，RSet里记录了其他对象指向自己的引用，这样就不需要再扫描其他区域，只要扫描RSet就可以了。\n也就是说 灰色–\u0026gt;白色 引用消失时，如果没有 黑色–\u0026gt;白色，引用会被push到堆栈，下次扫描时拿到这个引用，由于有RSet的存在，不需要扫描整个堆去查找指向白色的引用，效率比较高SATB配合RSet浑然天成。\n并发清理（cleanup）：与用户线程一起执行，STW很长。将存活对象复制到别的Region。使用复制算法的目的是为了不产生内存碎片。 根据最终标记的结果，可以计算出每一个区域的垃圾对象占用内存大小，根据停顿时间，选择复制效率最高（垃圾对象最多）的几个区域。 复制时先复制GC Root直接引用的对象，然后再复制其他对象。 G1对老年代的清理：会选择存活度最低的区域来进行回收，这样可以保证回收效率最高，这也是G1（Garbage first）名称的由来：G1的1（first）指的就是存活度最低的区域。\n回收老的区域，如果外部有其他区域对象引用了转移对象，也需要重新设置引用关系 顺便再提一下和这里相关的：Full GC 整堆收集，是单线程+标记-整理算法，会导致用户线程的暂停。\n建议：尽量保证应该用的堆内存有一定多余的空间。\n触发时机：\n如果上面的清理过程中发现没有足够的空Region存放转移的对象（大对象、长期存活的对象进入老年代，导致老年代空间不足），会出现Full GC。 避免这种情况引起Full GC的方式：\n一是：尽量不要创建过大的对象以及数组。\n二是：通过参数 -Xmn 调大新生代的大小，让对象尽量在新生代被回收掉，不进入老年代。\nPS：但得注意，这个参数的修改需要经过大量测试（所有接口、所有场景的测试），因为在实际场景中，接口响应时间、创建对象的大小、程序内部的定时任务等等这些不确定因素都会影响该值，所以理论计算并不能准确地得到该值，若要变动该值则需要进行大量测试【G`垃圾回收期中就尽量不要设置该值，因G1会动态调整年轻代大小】。 三是：通过参数 -XX:MaxTenuringThreshold 调大对象进入老年代的年龄，让对象在新生代多存活一段时间。\nPS：此值即最大晋升阈值，默认值为15。对象年龄大于此值之后会进入老年代。在JVM中有一个“动态年龄判断机制”，将对象从小到大的对象占据的空间加起来，若大于survivor区域得到50%，则把等于或大于该年龄的对象丢入到老年代。因此：此值个人建议别轻易去修改。 此处相关的小知识：Concurrent Mode Failure 并发模式失败\n执行 CMS GC 的过程中同时有对象要放入老年代（CMS的垃圾清理线程和用户线程并行执行），而此时老年代空间不足(可能是 GC 过程中浮动垃圾过多导致暂时性的空间不足)，便会报 Concurrent Mode Failure 错误，并触发 Full GC。 此模式一旦产生，那么Java虚拟机就会使用Serial Old单线程进行Full GC回收老年代，从而出现长时间停顿（STW）。 调用 System.gc()。不建议的方式。因为调用此方法只是建议虚拟机执行 Full GC，但是虚拟机不一定会真正去执行。 使用复制算法的 Minor GC 需要老年代的内存空间作担保，如果担保失败会执行一次 Full GC。 内存空间分配担保：在发生 Minor GC 之前，虚拟机先检查老年代最大可用的连续空间是否大于新生代所有对象总空间。\n如果条件成立的话，那么 Minor GC 可以确认是安全的。\n如果不成立的话：\nJDK 6 Update 24之前规则：虚拟机会查看 -XX:HandlePromotionFailure=true/false设置值是否允许担保失败\n如果允许，那么就会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小\n如果大于，将尝试着进行一次 Minor GC；\n如果小于，或者 HandlePromotionFailure 设置不允许冒险，那么就要进行一次 Full GC。\nJDK 6 Update 24之后的规则：-XX:HandlePromotionFailure=true/false配置不会再影响到虚拟机的空间分配担保策略。所以此时是只要老年代的连续空间大于新生代对象空间总大小 或者 历次晋升的平均大小，就会进行 Minor GC，否则将进行 Full GC。\n关于Minor GC、Major GC、Full GC的说明 尽量别让Major GC / Full GC触发。\nJVM 在进行 GC 时，并非每次都对堆内存（新生代、老年代；方法区）区域一起回收的，大部分时候回收的都是指新生代。\n针对 HotSpot VM 的实现，它里面的 GC 按照回收区域又分为两大类：部分收集（Partial GC），整堆收集（Full GC）。\n部分收集（Partial GC）：不是完整收集整个 Java 堆的垃圾收集其中又分为： 新生代收集（Minor GC/Young GC）：只是新生代的垃圾收集。\n老年代收集（Major GC/Old GC）：只是老年代的垃圾收集。\n目前，只有 CMS GC 会有单独收集老年代的行为。 很多时候 Major GC 会和 Full GC 混合使用，需要具体分辨是老年代回收还是整堆回收。 混合收集（Mixed GC）：收集整个新生代以及部分老年代的垃圾收集。\n目前只有 G1 GC 会有这种行为。 整堆收集（Full GC）：收集整个 Java 堆和方法区的垃圾。 年轻代GC（Minor GC）触发机制\n当年轻代空间不足时，就会触发MinorGC，这里的年轻代满指的是Eden代满，Survivor满不会引发GC。（每次Minor GC会清理年轻代的内存） 因为Java对象大多都具备朝生夕灭的特性.，所以Minor GC非常频繁，一般回收速度也比较快。这一定义既清晰又易于理解。 Minor GC会引发STW，暂停其它用户的线程，等垃圾回收结束，用户线程才恢复运行。 老年代GC（Major GC / Full GC）触发机制\n指发生在老年代的GC，对象从老年代消失时，我们说 “Major GC” 或 “Full GC” 发生了。 出现了Major Gc，经常会伴随至少一次的Minor GC（非绝对，在Paralle1 Scavenge收集器的收集策略里就有直接进行Major GC的策略选择过程）。\n也就是在老年代空间不足时，会先尝试触发Minor Gc。如果之后空间还不足，则触发Full GC（Major GC）。\nMajor GC的速度一般会比Minor GC慢10倍以上，STW的时间更长。 如果Major GC后，内存还不足，就报OOM了。 Full GC触发机制：Full GC 是开发或调优中尽量要避免的。这样暂停时间会短一些。因为Full GC是单线程+标记-整理，单线程会STW会长。\n触发Full GC执行的情况有如下几种：\n调用System.gc()时，系统建议执行Full GC，但是不必然执行。 老年代空间不足。前面G1说的触发时机基本都可统称为这个原因。 补充一种情况：由Eden区、survivor space0（From Space）区向survivor space1（To Space）区复制时，对象大小 大于 To Space可用内存，则把该对象转存到老年代，且老年代的可用内存 小于 该对象大小。 方法区空间不足。 即时编译器（JIT） 本节内容可以直接去看 @美团技术团队：Java即时编译器原理解析及实践 的内容，里面的内容更丰富、更全面，看完都不需要看我这里的内容了，因我这里的内容也是在此基础上调整的。\n作者：昊天 珩智 薛超\n在Java中，JIT（Just-In-Time）即时编译器是一项用来提升应用程序代码执行效率的技术。字节码指令被 Java 虚拟机解释执行，如果有一些指令执行频率高，称之为热点代码，这些字节码指令则被JIT即时编译器编译成机器码同时进行一些优化，最后保存在内存中，将来执行时直接读取就可以运行在计算机硬件上了\n在HotSpot中，有三款即时编译器，C1、C2和Graal。\n可使用Java虚拟机参数：-Xin 关闭即时编译器。\nC1编译效率比C2快，但是优化效果不如C2。所以C1适合优化一些执行时间较短的代码，C2适合优化服务端程序中长期执行的代码\nJDK7之后，采用了分层编译的方式，在JVM中C1和C2会一同发挥作用，分层编译将整个优化级别分成了5个等级：\n-XX:TieredStopAtLevel=1 分层编译下只使用1层C1进行编译\n下列保存内容的原因：为了执行C2即时编译器的需要，从而让C2更好地优化。\n等级 使用的组件 描述 保存的内容 性能打分（1 - 5） 0 解释器 解释执行； 记录方法调用次数及循环次数 无 1 1 C1即时编译器 C1完整优化 优化后的机器码 4 2 C1即时编译器 C1完整优化； 记录方法调用次数及循环次数 优化后的机器码； 部分额外信息：方法调用次数及循环次数 3 3 C1即时编译器 C1完整优化； 记录所有额外信息 优化后的机器码； 所有额外信息：分支跳转次数、类型转换等 2 4 C2即时编译器 C2完整优化 优化后的机器码 5 C1即时编译器和C2即时编译器都有独立的线程去进行处理，内部会保存一个队列，队列中存放需要编译的任务。一般即时编译器是针对方法级别来进行优化的，当然也有对循环进行优化的设计。\n看C1和C2是如何进行协作的？一句话概括就是：先有C1执行并收集C2需要的数据，然后C2执行，C1忙碌时交给C2执行，C2忙碌时交给C1执行。\n先由C1执行过程中收集所有运行中的信息，方法执行次数、循环执行次数、分支执行次数等等，然后等待执行次数触发阈值（分层即时编译由JVM动态计算）之后，进入C2即时编译器进行深层次的优化 方法字节码执行数目过少，先收集信息，JVM判断C1和C2优化性能差不多，那之后转为不收集信息，由C1直接进行优化 C1线程都在忙碌的情况下（队列中编译任务很多），直接由C2进行优化。 C2线程忙碌时，先由2层C1编译收集一些基础信息，多运行一会儿，然后再交由3层C1处理，由于3层C1处理效率不高，所以尽量减少这一层停留时间（C2忙碌着，一直收集也没有意义），最后C2线程不忙碌了再交由C2进行处理。 JIT优化手段：方法内联 与 逃逸分析 可以借助JIT Watch工具来查看（会涉及汇编语言）：https://github.com/AdoptOpenJDK/jitwatch/tree/1.4.2 注：以目前测试的结果来看，版本号最好用上面这个，因为比这版本高的会出现一些问题，如乱码之类的。 方法内联 方法内联（Method Inline）：方法体中的字节码指令直接复制到调用方的字节码指令中，节省了创建栈帧的开销\n方法内联是字节码层面，这里便于理解使用源码：\n方法内联的限制与条件\n并不是所有的方法都可以内联，有一定的限制：\n方法编译之后的字节码指令总大小 \u0026lt; 35字节，可以直接内联。（通过 -XX:MaxInlineSize=值 控制）。 方法编译之后的字节码指令总大小 \u0026lt; 325字节，并且是一个热方法。（通过- XX:FreqInlineSize=值 控制）。 方法编译生成的机器码不能大于1000字节。（通过 -XX:InlineSmallCode=值 控制） 。 一个接口的实现必须小于3个，如果大于三个就不会发生内联。 编译器的大部分优化都是在方法内联的基础上。所以一般来说，内联的方法越多，生成代码的执行效率越高。但是对于即时编译器来说，内联的方法越多，编译时间也就越长，程序达到峰值性能的时刻也就比较晚。\n可以通过虚拟机参数 -XX:MaxInlineLevel 调整内联的层数，以及1层的直接递归调用（可以通过虚拟机参数 -XX:MaxRecursiveInlineLevel 调整）。一些常见的内联相关的参数如下表所示：\n逃逸分析 逃逸分析（Escape Analysis）：指的是如果JIT发现在方法内创建的对象不会被外部引用，那么就可以采用锁消除、标量替换等方式进行优化。\n通过逃逸分析，Java Hotspot 编译器能够分析出一个新的对象的引用的使用范围，从而决定是否要将这个对象分配到堆上。\n在 JDK 6u23 版本之后，HotSpot 中默认就已经开启了逃逸分析。 如果使用较早版本，可以通过-XX\u0026quot;+DoEscapeAnalysis显式开启。 逃逸分析的基本行为就是分析对象动态作用域：\n当一个对象在方法中被定义后，对象只在方法内部使用，则认为没有发生逃逸 当一个对象在方法中被定义后，它被外部方法所引用，则认为发生逃逸，例如作为调用参数传递到其他地方中，称为方法逃逸 如下代码：因为sb通过return返回了，那么sb就有可能会被其他方法所改变，这就发生了逃逸。\npublic static StringBuffer craeteStringBuffer(String s1, String s2) { StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); return sb; } 所以就可以优化：\npublic static String createStringBuffer(String s1, String s2) { StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); return sb.toString(); } 锁消除：指的是如果对象被判断不会逃逸出去，那么在对象就不存在并发访问问题，对象上的锁处理都不会执行，从而提高性能。\n比如如下代码写法：\nsynchronized (new Test()) { } 当然，从上述代码也可以看出，锁消除优化在真正的工作代码中并不常见，一般加锁的对象都是支持多线程去访问的，除非程序员自己太拉胯。\n标量替换：在Java虚拟机中，对象中的基本数据类型称为标量，引用的其他对象称为聚合量。标量替换指的是如果方法中的对象不会逃逸，那么其中的标量就可以直接在栈上分配。\n逃逸分析真正对性能优化比较大的方式是标量替换。 常见栈上分配的场景：成员变量赋值、方法返回值、实例引用传递。 通过 -XX:+EliminateAllocations 可以开启标量替换，-XX:+PrintEliminateAllocations 查看标量替换情况。 因此：根据JIT即时编器优化代码的特性，在编写代码时可以注意以下几个事项，可以让代码执行时拥有更好的性能：\n尽量编写比较小的方法，让方法内联可以生效。 高频使用的代码，特别是第三方依赖库甚至是JDK中的，如果内容过度复杂是无法内联的，可以自行实现一个特定的优化版本。 注意下接口的实现数量，尽量不要超过2个，否则会影响内联的处理。 高频调用的方法中创建对象临时使用，尽量不要让对象逃逸。 ZGC详解 本节内容转载于：@美团技术团队：新一代垃圾回收器ZGC的探索与实践 ，ZGC调优实践之前的内容我做了调整。\n作者：王东 王伟\nZGC概述 ZGC（The Z Garbage Collector）是JDK 11中推出的一款低延迟垃圾回收器，堆大小对STW的时间基本没有影响。它的设计目标包括：\n停顿时间不超过10ms； 停顿时间不会随着堆的大小，或者活跃对象的大小而增加（对程序吞吐量影响小于15%）； 支持8MB~4TB级别的堆（未来支持16TB） 从设计目标来看，我们知道ZGC适用于大内存低延迟服务的内存管理和回收。本文主要介绍ZGC在低延时场景中的应用和卓越表现，文章内容主要分为四部分：\nGC之痛：介绍实际业务中遇到的GC痛点，并分析CMS收集器和G1收集器停顿时间瓶颈； ZGC原理：分析ZGC停顿时间比G1或CMS更短的本质原因，以及背后的技术原理； ZGC调优实践：重点分享对ZGC调优的理解，并分析若干个实际调优案例； 升级ZGC效果：展示在生产环境应用ZGC取得的效果 GC之痛 很多低延迟高可用Java服务的系统可用性经常受GC停顿的困扰。\nGC停顿指垃圾回收期间STW（Stop The World），当STW时，所有应用线程停止活动，等待GC停顿结束\n在G1垃圾回收器中，STW时间的主要来源是在转移阶段：\n初始标记：STW，采用三色标记法标记从GC Root可直达的对象。 STW时间极短。 并发标记：并发执行，对存活对象进行标记。 最终标记：STW，处理SATB相关的对象标记。 STW时间极短。 清理：STW，如果区域中没有任何存活对象就直接清理。 STW时间极短 。 转移：将存活对象复制到别的区域。 STW时间较长 G1停顿时间的瓶颈主要是标记-复制中的转移阶段STW。为什么转移阶段不能和标记阶段一样并发执行呢？主要是G1未能解决转移过程中准确定位对象地址的问题。\nZGC的执行流程（待完善）:\nZGC转移时需要停顿的主要原因\n在转移时，能不能让用户线程和GC线程同时工作呢？考虑下面的问题：\n转移完之后，需要将A对对象的引用更改为新对象的引用。但是在更改前，执行A.c.count = 2，此时更改的是转移前对象中的属性。 更改引用之后, A引用了转移之后的对象，此时获取A.c.count发现属性值依然是1。这样就产生了问题。 所以G1为了解决问题，在转移过程中需要进行用户线程的停止。ZGC和Shenandoah GC解决了这个问题，让转移过程也能够并发执行。\nShenandoah GC就是通过G1源代码改造而来的，通过修改对象头的方式来完成并发转移，使用的核心技术：前向指针+读前屏障。Shenandoah GC有两个版本：\n1.0版本（不稳定）存在于JDK8和JDK11中，此版本是直接在对象的前8个字节增加了前向指针 读数据：读前屏障，判断前向指针指向的是自己还是转移后的对象，然后进行操作； 写数据：写前屏障，判断Mark Work中的GC状态，若GC状态为0说明处于GC过程中，直接写入、不为0则根据GC状态值确认当前处于垃圾回收的哪个阶段，让用户线程执行垃圾回收相关的任务。 后续的JDK版本中均使用2.0版本，优化前向指针的位置，仅转移阶段将其放入了Mark Word中。 Shenandoah GC执行流程：\nZGC原理 全并发的ZGC 与CMS中的ParNew和G1类似，ZGC也采用标记-复制算法，不过ZGC对该算法做了重大改进：ZGC在标记、转移和重定位阶段几乎都是并发的，这是ZGC实现停顿时间小于10ms目标的最关键原因\nZGC垃圾回收周期如下图所示：\nZGC只有三个STW阶段：初始标记，再标记，初始转移。其中：\n初始标记和初始转移分别都只需要扫描所有GC Roots，其处理时间和GC Roots的数量成正比，一般情况耗时非常短； 再标记阶段STW时间很短，最多1ms，超过1ms则再次进入并发标记阶段。即，ZGC几乎所有暂停都只依赖于GC Roots集合大小，停顿时间不会随着堆的大小或者活跃对象的大小而增加。与ZGC对比，G1的转移阶段完全STW的，且停顿时间随存活对象的大小增加而增加。 ZGC关键技术 ZGC通过着色指针和读屏障技术，解决了转移过程中准确访问对象的问题，实现了并发转移。大致原理描述如下：并发转移中“并发”意味着GC线程在转移对象的过程中，应用线程也在不停地访问对象。假设对象发生转移，但对象地址未及时更新，那么应用线程可能访问到旧地址，从而造成错误。而在ZGC中，应用线程访问对象将触发“读屏障”，如果发现对象被移动了，那么“读屏障”会把读出来的指针更新到对象的新地址上，这样应用线程始终访问的都是对象的新地址。那么，JVM是如何判断对象被移动过呢？就是利用对象引用的地址，即着色指针。下面介绍着色指针和读屏障技术细节。\n读屏障 读屏障（Load Barrier）是JVM向应用代码插入一小段代码的技术来实现转移后对象的获取。当应用线程从堆中读取对象引用时，就会执行这段代码。如果对象指向的不是转移后的对象，用户线程会将引用指向转移后的对象。\n需要注意的是：仅“从堆中读取对象引用”才会触发这段代码。 仅“从堆中读取对象引用”才会触发插入的代码：\nObject o = obj.FieldA // 从堆中读取引用，需要加入屏障 \u0026lt;Load barrier\u0026gt; Object p = o // 无需加入屏障，因为不是从堆中读取引用 o.dosomething() // 无需加入屏障，因为不是从堆中读取引用 int i = obj.FieldB //无需加入屏障，因为不是对象引用 ZGC中读屏障的代码作用：在对象标记和转移过程中，用于确定对象的引用地址是否满足条件，并作出相应动作。\n着色指针 着色指针（Colored Pointers）是一种将信息存储在指针中的技术。\nZGC仅支持64位系统，它把64位虚拟地址空间划分为多个子空间，如下图所示：\n其中，[0~4TB) 对应Java堆，[4TB ~ 8TB) 称为M0地址空间，[8TB ~ 12TB) 称为M1地址空间，[12TB ~ 16TB) 预留未使用，[16TB ~ 20TB) 称为Remapped空间。\n当应用程序创建对象时，首先在堆空间申请一个虚拟地址，但该虚拟地址并不会映射到真正的物理地址。ZGC同时会为该对象在M0、M1和Remapped地址空间分别申请一个虚拟地址，且这三个虚拟地址对应同一个物理地址，但这三个空间在同一时间有且只有一个空间有效（就算颜色位不同，虚拟地址相同，最终指向的还是同一个物理地址）。ZGC之所以设置三个虚拟地址空间，是因为它使用“空间换时间”思想，去降低GC停顿时间。“空间换时间”中的空间是虚拟空间，而不是真正的物理空间。后续章节将详细介绍这三个空间的切换过程。\n与上述地址空间划分相对应：\nZGC实际仅使用64位地址空间的第0~41位，用于表示对象的地址（Obejct Address）； 而第42~45位存储元数据，即这中间4位为颜色位，每一位只能存放0或1，并且同一时间只有其中一位是1。 终结位（Finalizable）：为1时表示只能通过终结器访问； 重映射位(Remapped)：转移完之后，对象的引用关系已经完成变更。 Marked0 和 Marked1：标记可达对象。 留个问题：为什么要使用两个Marked（即Marked0 和 Marked1），而不是一个？\n第47~63位固定为0，这18位未使用（Unused）。 ZGC将对象存活信息存储在42~45位中，这与传统的垃圾回收并将对象存活信息放在对象头中完全不同。\nZGC的内存划分 在ZGC中，与G1垃圾回收器一样将堆内存划分成很多个区域，这些内存区域被称之为Zpage。\nZpage分成三类大中小，管控粒度比G1更细，这样更容易去控制停顿时间：\n小区域：2M，只能保存256KB内的对象。 中区域：32M，保存256KB – 4M的对象。 大区域：只保存一个大于4M的对象。 ZGC执行流程 已完善版（未分代ZGC，即：JDK11 - JDK20）：\n初始标记阶段：标记Gc Roots直接引用的对象为存活。对象数量不多，所以停顿时间非常短。 每个阶段都需要为当前阶段定义一个颜色，当前阶段为标记阶段（Mark），所以使用Marked0（上图举例定义的颜色为红色），初始时指针的颜色位都是0。\n现在需要将GC Roots能直接关联到的对象里面的颜色位（上述Marked0红色）对应的值由0改为1，\n这样就对GC Roots直接关联的对象的指针进行了着色，并且也就将GC Roots直接关联的对象（上图1、2、4）标记为了“存活对象”。\n并发标记阶段：遍历所有对象，标记可以到达的每一个对象是否存活。用户线程使用读屏障，如果发现对象没有完成标记也会帮忙进行标记。 顺着初始标记阶段中标记的GC Roots直接关联的对象，找出这些对象引用的对象标记为“存活对象”（如下图 2 -\u0026gt; 5 -\u0026gt; 8），并使用当前阶段定义的颜色（标记阶段，如前面定义的Marked0红色）对指针进行着色。\n因为是并发，所以用户线程会活动，假如就是上图用户线程通过4对象访问5对象，这时用户线程就会使用“读屏障”，判断4 -\u0026gt; 5的指针是否为当前阶段的颜色（如上图定义的Marked0红色），如果不是，那么用户线程也会帮忙进行标记（即：将 4 -\u0026gt; 5的指针颜色标记为Marked0红色），从而提升整个并发标记阶段的效率。\n并发处理阶段：选择需要转移的Zpage，并创建转移表，用于记录转移前对象和转移后对象地址。 转移开始阶段：转移GC Root直接关联的对象，不转移的对象remapped值设置成1，避免重复进行判断。 对象1、2不需要进行转移，所以将GC Roots对象到1、2的指针着色，颜色为当前阶段定义的颜色（如上图举例定义的Remapped绿色）；并且将不转移对象的指针对应的颜色位（Remapped）设置为1。此时用户线程若去访问对象1、2的指针就会认为1、2对象已经完成了转移的处理，直接使用即可。\n对于对象4，因它属于转移对象，所以就会将对象4复制到转移后的Zpage中，并且在转移映射表中记录该对象转移前的地址和转移后的地址：\n注意：上图GC Roots -\u0026gt; 4\u0026rsquo;的指针颜色为Remapped绿色，它的Remapped会被设置为1，而4\u0026rsquo; -\u0026gt; 5还是红色是因为4\u0026rsquo;指向的对象5是转移前的对象。\n并发转移阶段：将剩余对象转移到新的ZPage中，转移之后将两个对象的地址记入转移映射表。 转移完之后，转移前的ZPage就可以清空了，转移表需要保留下来。\n从上图也可看出：问题就出来了，虽然对象转移了，但它们的指针还没完全处理完。此时，如果用户线程访问4`对象引用的5对象：\n就会发现4\u0026rsquo; -\u0026gt; 5还是旧的引用（即还停留在Marked0阶段），那么会通过读屏障，利用转移映射表找到对象5转移后的地址5\u0026rsquo;，从而将4对5的引用进行重置，修改为对5`的引用，同时将remap标记为1代表已经重新映射完成。\n并发转移阶段结束之后，这一轮的垃圾回收就结束了，但其实并没有完成所有指针的重映射工作，这个工作会放到下一阶段，与下一阶段的标记阶段一起完成（因为都需要遍历整个对象图）。\n第二轮垃圾回收：\n初始标记阶段：同样地，沿着GC Root标记对象。 此阶段又要定义当前阶段的颜色，并且得需要和第一次标记阶段区分开来，所以就需要使用到Marked1了，如下举例Marked1蓝色：\n将GC Roots直接关联的对象指针颜色改为当前阶段定义的颜色，并将该指针的颜色位修改为1.\n并发标记阶段：如果Marked为1代表上一轮的重映射还没有完成，先完成重映射从转移表中找到老对象转移后的新对象，再进行标记。如果Remap为1，只需要进行标记。 沿着GC Roots直观关联的对象，找其引用的对象，此时扫描的指针颜色就会出现多种：前面Remapped定义使用的颜色 和 Marked0定义使用的颜色\n发现是Remapped的颜色（Remap为1），则值进行标记即可（弄为当前阶段Marked1颜色，且其Marked1设为1）； 发现是Marked0的颜色（Marked0为1），代表上一轮的重映射还没有完成（还停留在Marked0阶段，未从Marked0 -\u0026gt; Remapped），那么就需要通过转移映射表找到老对象转移后的新对象，进行标记（指针弄为当前阶段Marked1的颜色，且其Marked1设为1）。 这里也就解答了为什么要使用两个Marked（即Marked0 和 Marked1）？\n因为一个用来表示当前这一轮的垃圾回收的标记阶段；而另一个用来表示上一轮垃圾回收的标记阶段，这两个不断交替使用。 并发处理阶段：将转移映射表删除，释放内存空间。 并发转移阶段 – 并发问题：如果用户线程在帮忙转移时，GC线程也发现这个对象需要复制，那么就会去尝试写入转移映射表，如果发现映射表中已经有相同的老对象，直接放弃。 分代ZGC的设计\n在JDK21之后，ZGC设计了年轻代和老年代，这样可以让大部分对象在年轻代回收，减少老年代的扫描次数，同样可以提升一定的性能。同时，年轻代和老年代的垃圾回收可以并行执行。\n分代之后的着色指针将原来的8字节保存地址的指针拆分成了三部分：\n46位用来表示对象地址，最多可以表示64TB的地址空间。 中间的12位为颜色位。 最低4位和最高2位未使用 整个分代之后的读写屏障、着色指针的移位使用都变的异常复杂，仅作了解即可\nZGC调优实践 ZGC不是“银弹”，需要根据服务的具体特点进行调优。网络上能搜索到实战经验较少，调优理论需自行摸索，我们在此阶段也耗费了不少时间，最终才达到理想的性能。本文的一个目的是列举一些使用ZGC时常见的问题，帮助大家使用ZGC提高服务可用性。\n调优基础知识 理解ZGC重要配置参数 以我们服务在生产环境中ZGC参数配置为例，说明各个参数的作用：\n重要参数配置样例：\n-Xms10G -Xmx10G -XX:ReservedCodeCacheSize=256m -XX:InitialCodeCacheSize=256m -XX:+UnlockExperimentalVMOptions -XX:+UseZGC -XX:ConcGCThreads=2 -XX:ParallelGCThreads=6 -XX:ZCollectionInterval=120 -XX:ZAllocationSpikeTolerance=5 -XX:+UnlockDiagnosticVMOptions -XX:-ZProactive -Xlog:safepoint,Classhisto*=trace,age*,gc*=info:file=/opt/logs/logs/gc-%t.log:time,tid,tags:filecount=5,filesize=50m -Xms -Xmx：堆的最大内存和最小内存，这里都设置为10G，程序的堆内存将保持10G不变。 -XX:ReservedCodeCacheSize -XX:InitialCodeCacheSize：设置CodeCache的大小， JIT编译的代码都放在CodeCache中，一般服务64m或128m就已经足够。我们的服务因为有一定特殊性，所以设置的较大，后面会详细介绍。 -XX:+UnlockExperimentalVMOptions -XX:+UseZGC：启用ZGC的配置。 -XX:ConcGCThreads：并发回收垃圾的线程默认是总核数的12.5%，8核CPU默认是1调大后GC变快，但会占用程序运行时的CPU资源，吞吐会受到影响。 -XX:ParallelGCThreads：STW阶段使用线程数，默认是总核数的60%。 -XX:ZCollectionInterval：ZGC发生的最小时间间隔，单位秒。 -XX:ZAllocationSpikeTolerance：ZGC触发自适应算法的修正系数，默认2，数值越大，越早的触发ZGC。 -XX:+UnlockDiagnosticVMOptions -XX:-ZProactive：是否启用主动回收，默认开启，这里的配置表示关闭。 -Xlog：设置GC日志中的内容、格式、位置以及每个日志的大小。 理解ZGC触发时机 相比于CMS和G1的GC触发机制，ZGC的GC触发机制有很大不同。ZGC的核心特点是并发，GC过程中一直有新的对象产生。如何保证在GC完成之前，新产生的对象不会将堆占满，是ZGC参数调优的第一大目标。因为在ZGC中，当垃圾来不及回收将堆占满时，会导致正在运行的线程停顿，持续时间可能长达秒级之久。\nZGC有多种GC触发机制，总结如下：\n阻塞内存分配请求触发：当垃圾来不及回收，垃圾将堆占满时，会导致部分线程阻塞。我们应当避免出现这种触发方式。日志中关键字是“Allocation Stall”。 基于分配速率的自适应算法：最主要的GC触发方式，其算法原理可简单描述为”ZGC根据近期的对象分配速率以及GC时间，计算出当内存占用达到什么阈值时触发下一次GC”。自适应算法的详细理论可参考彭成寒《新一代垃圾回收器ZGC设计与实现》一书中的内容。通过ZAllocationSpikeTolerance参数控制阈值大小，该参数默认2，数值越大，越早的触发GC。我们通过调整此参数解决了一些问题。日志中关键字是“Allocation Rate”。 基于固定时间间隔：通过ZCollectionInterval控制，适合应对突增流量场景。流量平稳变化时，自适应算法可能在堆使用率达到95%以上才触发GC。流量突增时，自适应算法触发的时机可能会过晚，导致部分线程阻塞。我们通过调整此参数解决流量突增场景的问题，比如定时活动、秒杀等场景。日志中关键字是“Timer”。 主动触发规则：类似于固定间隔规则，但时间间隔不固定，是ZGC自行算出来的时机，我们的服务因为已经加了基于固定时间间隔的触发机制，所以通过-ZProactive参数将该功能关闭，以免GC频繁，影响服务可用性。 日志中关键字是“Proactive”。 预热规则：服务刚启动时出现，一般不需要关注。日志中关键字是“Warmup”。 外部触发：代码中显式调用System.gc()触发。 日志中关键字是“System.gc()”。 元数据分配触发：元数据区不足时导致，一般不需要关注。 日志中关键字是“Metadata GC Threshold”。 理解ZGC日志 一次完整的GC过程，需要注意的点已在图中标出\n注意：该日志过滤了进入安全点的信息。正常情况，在一次GC过程中还穿插着进入安全点的操作。\nGC日志中每一行都注明了GC过程中的信息，关键信息如下：\nStart：开始GC，并标明的GC触发的原因。上图中触发原因是自适应算法。 Phase-Pause Mark Start：初始标记，会STW。 Phase-Pause Mark End：再次标记，会STW。 Phase-Pause Relocate Start：初始转移，会STW。 Heap信息：记录了GC过程中Mark、Relocate前后的堆大小变化状况。High和Low记录了其中的最大值和最小值，我们一般关注High中Used的值，如果达到100%，在GC过程中一定存在内存分配不足的情况，需要调整GC的触发时机，更早或者更快地进行GC。 GC信息统计：可以定时的打印垃圾收集信息，观察10秒内、10分钟内、10个小时内，从启动到现在的所有统计信息。利用这些统计信息，可以排查定位一些异常点。 日志中内容较多，关键点已用红线标出，含义较好理解，更详细的解释大家可以自行在网上查阅资料。\n理解ZGC停顿原因 我们在实战过程中共发现了6种使程序停顿的场景，分别如下：\nGC时，初始标记：日志中Pause Mark Start。 GC时，再标记：日志中Pause Mark End。 GC时，初始转移：日志中Pause Relocate Start。 内存分配阻塞：当内存不足时线程会阻塞等待GC完成，关键字是”Allocation Stall”。 安全点：所有线程进入到安全点后才能进行GC，ZGC定期进入安全点判断是否需要GC。先进入安全点的线程需要等待后进入安全点的线程直到所有线程挂起。 dump线程、内存：比如jstack、jmap命令。 调优案例 我们维护的服务名叫Zeus，它是美团的规则平台，常用于风控场景中的规则管理。规则运行是基于开源的表达式执行引擎Aviator 。Aviator内部将每一条表达式转化成Java的一个类，通过调用该类的接口实现表达式逻辑。\nZeus服务内的规则数量超过万条，且每台机器每天的请求量几百万。这些客观条件导致Aviator生成的类和方法会产生很多的ClassLoader和CodeCache，这些在使用ZGC时都成为过GC的性能瓶颈。接下来介绍两类调优案例。\n第一类：内存分配阻塞，系统停顿可达到秒级\n案例一：秒杀活动中流量突增，出现性能毛刺 日志信息：对比出现性能毛刺时间点的GC日志和业务日志，发现JVM停顿了较长时间，且停顿时GC日志中有大量的“Allocation Stall”日志。\n分析：这种案例多出现在“自适应算法”为主要GC触发机制的场景中。ZGC是一款并发的垃圾回收器，GC线程和应用线程同时活动，在GC过程中，还会产生新的对象。GC完成之前，新产生的对象将堆占满，那么应用线程可能因为申请内存失败而导致线程阻塞。当秒杀活动开始，大量请求打入系统，但自适应算法计算的GC触发间隔较长，导致GC触发不及时，引起了内存分配阻塞，导致停顿。\n解决方法：\n（1）开启”基于固定时间间隔“的GC触发机制：-XX:ZCollectionInterval。比如调整为5秒，甚至更短。\n（2）增大修正系数-XX:ZAllocationSpikeTolerance，更早触发GC。ZGC采用正态分布模型预测内存分配速率，模型修正系数ZAllocationSpikeTolerance默认值为2，值越大，越早的触发GC，Zeus中所有集群设置的是5。\n案例二：压测时，流量逐渐增大到一定程度后，出现性能毛刺 日志信息：平均1秒GC一次，两次GC之间几乎没有间隔。\n分析：GC触发及时，但内存标记和回收速度过慢，引起内存分配阻塞，导致停顿。\n解决方法：增大-XX:ConcGCThreads， 加快并发标记和回收速度。ConcGCThreads默认值是核数的1/8，8核机器，默认值是1。该参数影响系统吞吐，如果GC间隔时间大于GC周期，不建议调整该参数。\n第二类：GC Roots 数量大，单次GC停顿时间长\n案例三： 单次GC停顿时间30ms，与预期停顿10ms左右有较大差距 日志信息：观察ZGC日志信息统计，“Pause Roots ClassLoaderDataGraph”一项耗时较长。\n分析：dump内存文件，发现系统中有上万个ClassLoader实例。我们知道ClassLoader属于GC Roots一部分，且ZGC停顿时间与GC Roots成正比，GC Roots数量越大，停顿时间越久。再进一步分析，ClassLoader的类名表明，这些ClassLoader均由Aviator组件生成。分析Aviator源码，发现Aviator对每一个表达式新生成类时，会创建一个ClassLoader，这导致了ClassLoader数量巨大的问题。在更高Aviator版本中，该问题已经被修复，即仅创建一个ClassLoader为所有表达式生成类。\n解决方法：升级Aviator组件版本，避免生成多余的ClassLoader。\n案例四：服务启动后，运行时间越长，单次GC时间越长，重启后恢复 日志信息：观察ZGC日志信息统计，“Pause Roots CodeCache”的耗时会随着服务运行时间逐渐增长。\n分析：CodeCache空间用于存放Java热点代码的JIT编译结果，而CodeCache也属于GC Roots一部分。通过添加-XX:+PrintCodeCacheOnCompilation参数，打印CodeCache中的被优化的方法，发现大量的Aviator表达式代码。定位到根本原因，每个表达式都是一个类中一个方法。随着运行时间越长，执行次数增加，这些方法会被JIT优化编译进入到Code Cache中，导致CodeCache越来越大。\n解决方法：JIT有一些参数配置可以调整JIT编译的条件，但对于我们的问题都不太适用。我们最终通过业务优化解决，删除不需要执行的Aviator表达式，从而避免了大量Aviator方法进入CodeCache中。\n值得一提的是，我们并不是在所有这些问题都解决后才全量部署所有集群。即使开始有各种各样的毛刺，但计算后发现，有各种问题的ZGC也比之前的CMS对服务可用性影响小。所以从开始准备使用ZGC到全量部署，大概用了2周的时间。在之后的3个月时间里，我们边做业务需求，边跟进这些问题，最终逐个解决了上述问题，从而使ZGC在各个集群上达到了一个更好表现。\n升级ZGC效果 延迟降低 TP(Top Percentile)是一项衡量系统延迟的指标：TP999表示99.9%请求都能被响应的最小耗时；TP99表示99%请求都能被响应的最小耗时。\n在Zeus服务不同集群中，ZGC在低延迟（TP999 \u0026lt; 200ms）场景中收益较大：\nTP999：下降12142ms，下降幅度18%74%。 TP99：下降528ms，下降幅度10%47%。 超低延迟（TP999 \u0026lt; 20ms）和高延迟（TP999 \u0026gt; 200ms）服务收益不大，原因是这些服务的响应时间瓶颈不是GC，而是外部依赖的性能。\n吞吐下降 对吞吐量优先的场景，ZGC可能并不适合例如，Zeus某离线集群原先使用CMS，升级ZGC后，系统吞吐量明显降低究其原因有二：\n第一，ZGC是单代垃圾回收器，而CMS是分代垃圾回收器单代垃圾回收器每次处理的对象更多，更耗费CPU资源； 第二，ZGC使用读屏障，读屏障操作需耗费额外的计算资源。 总结 ZGC作为下一代垃圾回收器，性能非常优秀。ZGC垃圾回收过程几乎全部是并发，实际STW停顿时间极短，不到10ms。这得益于其采用的着色指针和读屏障技术。\nZeus在升级JDK 11+ZGC中，通过将风险和问题分类，然后各个击破，最终顺利实现了升级目标，GC停顿也几乎不再影响系统可用性。\n最后推荐大家升级ZGC，Zeus系统因为业务特点，遇到了较多问题，而风控其他团队在升级时都非常顺利。欢迎大家加入“ZGC使用交流”群。\n参考文献 ZGC官网 彭成寒.《新一代垃圾回收器ZGC设计与实现》. 机械工业出版社, 2019. 从实际案例聊聊Java应用的GC优化 Java Hotspot G1 GC的一些关键技术 作者简介\n王东，美团信息安全资深工程师 王伟，美团信息安全技术专家 更多优秀文章推荐\nhttps://www.jianshu.com/p/664e4da05b2c 后续 链接：https://www.cnblogs.com/xiegongzi/p/18004148 本文转自 https://www.cnblogs.com/xiegongzi/p/17994659 ，如有侵权，请联系删除。\n","permalink":"http://localhost:1313/hugo-blog/public/post/dev-log/jvmjava%E8%99%9A%E6%8B%9F%E6%9C%BA-%E6%95%B4%E7%90%86%E4%B8%80/","tags":[],"title":"JVM（Java虚拟机） 整理（一）"},{"categories":[],"content":" 公众号：字节数组 希望对你有所帮助 🤣🤣\n最近一直在了解关于 Kotlin协程 的知识，那最好的学习资料自然是官方提供的学习文档了，看了看后我就萌生了翻译官方文档的想法。前后花了要接近一个月时间，一共九篇文章，在这里也分享出来，希望对读者有所帮助。个人知识所限，有些翻译得不是太顺畅，也希望读者能提出意见\n协程官方文档：coroutines-guide 此章节涵盖了协程的基本概念\n一、你的第一个协程程序 运行以下代码：\nimport kotlinx.coroutines.* fun main() { GlobalScope.launch { // 在后台启动一个新协程，并继续执行之后的代码 delay(1000L) // 非阻塞式地延迟一秒 println(\u0026#34;World!\u0026#34;) // 延迟结束后打印 } println(\u0026#34;Hello,\u0026#34;) //主线程继续执行，不受协程 delay 所影响 Thread.sleep(2000L) // 主线程阻塞式睡眠2秒，以此来保证JVM存活 } 输出结果\nHello, World! 本质上，协程可以称为轻量级线程。协程在 CoroutineScope （协程作用域）的上下文中通过 launch、async 等协程构造器（coroutine builder）来启动。在上面的例子中，在 GlobalScope ，即全局作用域内启动了一个新的协程，这意味着该协程的生命周期只受整个应用程序的生命周期的限制，即只要整个应用程序还在运行中，只要协程的任务还未结束，该协程就可以一直运行\n可以将以上的协程改写为常用的 thread 形式，可以获得相同的结果\nfun main() { thread { Thread.sleep(1000L) println(\u0026#34;World!\u0026#34;) } println(\u0026#34;Hello,\u0026#34;) Thread.sleep(2000L) } 但是如果仅仅是将 GlobalScope.launch 替换为 thread 的话，编译器将提示错误：\nSuspend function \u0026#39;delay\u0026#39; should be called only from a coroutine or another suspend function 这是由于 delay() 是一个挂起函数（suspending function），挂起函数只能由协程或者其它挂起函数进行调度。挂起函数不会阻塞线程，而是会将协程挂起，在特定的时候才再继续运行\n开发者需要明白，协程是运行于线程上的，一个线程可以运行多个（可以是几千上万个）协程。线程的调度行为是由 OS 来操纵的，而协程的调度行为是可以由开发者来指定并由编译器来实现的。当协程 A 调用 delay(1000L) 函数来指定延迟1秒后再运行时，协程 A 所在的线程只是会转而去执行协程 B，等到1秒后再把协程 A 加入到可调度队列里。所以说，线程并不会因为协程的延时而阻塞，这样可以极大地提高线程的并发灵活度\n二、桥接阻塞与非阻塞的世界 在第一个协程程序里，混用了非阻塞代码 delay() 与阻塞代码 Thread.sleep() ，使得我们很容易就搞混当前程序是否是阻塞的。可以改用 runBlocking 来明确这种情形\nimport kotlinx.coroutines.* fun main() { GlobalScope.launch { // launch a new coroutine in background and continue delay(1000L) println(\u0026#34;World!\u0026#34;) } println(\u0026#34;Hello,\u0026#34;) // main thread continues here immediately runBlocking { // but this expression blocks the main thread delay(2000L) // ... while we delay for 2 seconds to keep JVM alive } } 运行结果和第一个程序是一样的，但是这段代码只使用了非阻塞延迟。主线程调用了 runBlocking 函数，直到 runBlocking 内部的所有协程执行完成后，之后的代码才会继续执行\n可以将以上代码用更喜欢的方式来重写，使用 runBlocking 来包装 main 函数的执行体：\nimport kotlinx.coroutines.* fun main() = runBlocking\u0026lt;Unit\u0026gt; { // start main coroutine GlobalScope.launch { // launch a new coroutine in background and continue delay(1000L) println(\u0026#34;World!\u0026#34;) } println(\u0026#34;Hello,\u0026#34;) // main coroutine continues here immediately delay(2000L) // delaying for 2 seconds to keep JVM alive } 这里 runBlocking\u0026lt;Unit\u0026gt; { ... } 作为用于启动顶层主协程的适配器。我们显式地指定它的返回类型 Unit，因为 kotlin 中 main 函数必须返回 Unit 类型，但一般我们都可以省略类型声明，因为编译器可以自动推导（这需要代码块的最后一行代码语句没有返回值或者返回值为 Unit）\n这也是为挂起函数编写单元测试的一种方法：\nclass MyTest { @Test fun testMySuspendingFunction() = runBlocking\u0026lt;Unit\u0026gt; { // here we can use suspending functions using any assertion style that we like } } 需要注意的是，runBlocking 代码块默认运行于其声明所在的线程，而 launch 代码块默认运行于线程池中，可以通过打印当前线程名来进行区分\n三、等待作业 延迟一段时间来等待另一个协程运行并不是一个好的选择，可以显式（非阻塞的方式）地等待协程执行完成\nimport kotlinx.coroutines.* fun main() = runBlocking { //sampleStart val job = GlobalScope.launch { // launch a new coroutine and keep a reference to its Job delay(1000L) println(\u0026#34;World!\u0026#34;) } println(\u0026#34;Hello,\u0026#34;) job.join() // wait until child coroutine completes //sampleEnd } 现在，代码的运行结果仍然是相同的，但是主协程与后台作业的持续时间没有任何关系，这样好多了\n四、结构化并发 以上对于协程的使用还有一些需要改进的地方。GlobalScope.launch 会创建一个顶级协程。尽管它很轻量级，但在运行时还是会消耗一些内存资源。如果开发者忘记保留对该协程的引用，它将可以一直运行直到整个应用程序停止。我们会遇到一些比较麻烦的情形，比如协程中的代码被挂起（比如错误地延迟了太多时间），或者启动了太多协程导致内存不足。此时我们需要手动保留对所有已启动协程的引用以便在需要的时候停止协程，但这很容易出错\nkotlin 提供了更好的解决方案。我们可以在代码中使用结构化并发。正如我们通常使用线程那样（线程总是全局的），我们可以在特定的范围内来启动协程\n在上面的示例中，我们通过 runBlocking 将 main() 函数转为协程。每个协程构造器（包括 runBlocking）都会将 CoroutineScope 的实例添加到其代码块的作用域中。我们可以在这个作用域中启动协程，而不必显式地 join，因为外部协程（示例代码中的 runBlocking）在其作用域中启动的所有协程完成之前不会结束。因此，我们可以简化示例代码：\nimport kotlinx.coroutines.* fun main() = runBlocking { // this: CoroutineScope launch { // launch a new coroutine in the scope of runBlocking delay(1000L) println(\u0026#34;World!\u0026#34;) } println(\u0026#34;Hello,\u0026#34;) } launch 函数是 CoroutineScope 的扩展函数，而 runBlocking 的函数体参数也是被声明为 CoroutineScope 的扩展函数，所以 launch 函数就隐式持有了和 runBlocking 相同的协程作用域。此时即使 delay 再久， println(\u0026quot;World!\u0026quot;) 也一定会被执行\n五、作用域构建器 除了使用官方的几个协程构建器所提供的协程作用域之外，还可以使用 coroutineScope 来声明自己的作用域。coroutineScope 用于创建一个协程作用域，直到所有启动的子协程都完成后才结束\nrunBlocking 和 coroutineScope 看起来很像，因为它们都需要等待其内部所有相同作用域的子协程结束后才会结束自己。两者的主要区别在于 runBlocking 方法会阻塞当前线程，而 coroutineScope 只是挂起并释放底层线程以供其它协程使用。由于这个差别，所以 runBlocking 是一个普通函数，而 coroutineScope 是一个挂起函数\n可以通过以下示例来演示：\nimport kotlinx.coroutines.* fun main() = runBlocking { // this: CoroutineScope launch { delay(200L) println(\u0026#34;Task from runBlocking\u0026#34;) } coroutineScope { // Creates a coroutine scope launch { delay(500L) println(\u0026#34;Task from nested launch\u0026#34;) } delay(100L) println(\u0026#34;Task from coroutine scope\u0026#34;) // This line will be printed before the nested launch } println(\u0026#34;Coroutine scope is over\u0026#34;) // This line is not printed until the nested launch completes } 运行结果：\nTask from coroutine scope Task from runBlocking Task from nested launch Coroutine scope is over 注意，在 “Task from coroutine scope” 消息打印之后，在等待 launch 执行完之前 ，将执行并打印“Task from runBlocking”，尽管此时 coroutineScope 尚未完成\n六、提取函数并重构 抽取 launch 内部的代码块为一个独立的函数，需要将之声明为挂起函数。挂起函数可以像常规函数一样在协程中使用，但它们的额外特性是：可以依次使用其它挂起函数（如 delay 函数）来使协程挂起\nimport kotlinx.coroutines.* fun main() = runBlocking { launch { doWorld() } println(\u0026#34;Hello,\u0026#34;) } // this is your first suspending function suspend fun doWorld() { delay(1000L) println(\u0026#34;World!\u0026#34;) } 但是如果提取出的函数包含一个在当前作用域中调用的协程构建器的话该怎么办？ 在这种情况下，所提取函数上只有 suspend 修饰符是不够的。为 CoroutineScope 写一个扩展函数 doWorld 是其中一种解决方案，但这可能并非总是适用的，因为它并没有使 API 更加清晰。 常用的解决方案是要么显式将 CoroutineScope 作为包含该函数的类的一个字段， 要么当外部类实现了 CoroutineScope 时隐式取得。 作为最后的手段，可以使用 CoroutineScope(coroutineContext)，不过这种方法结构上并不安全， 因为你不能再控制该方法执行的作用域。只有私有 API 才能使用这个构建器。\n七、协程是轻量级的 运行以下代码：\nimport kotlinx.coroutines.* fun main() = runBlocking { repeat(100_000) { // launch a lot of coroutines launch { delay(1000L) print(\u0026#34;.\u0026#34;) } } } 以上代码启动了10万个协程，每个协程延时一秒后都会打印输出。如果改用线程来完成的话，很大可能会发生内存不足异常，但用协程来完成的话就可以轻松胜任\n八、全局协程类似于守护线程 以下代码在 GlobalScope 中启动了一个会长时间运行的协程，它每秒打印两次 \u0026ldquo;I\u0026rsquo;m sleeping\u0026rdquo; ，然后在延迟一段时间后从 main 函数返回\nimport kotlinx.coroutines.* fun main() = runBlocking { //sampleStart GlobalScope.launch { repeat(1000) { i -\u0026gt; println(\u0026#34;I\u0026#39;m sleeping $i ...\u0026#34;) delay(500L) } } delay(1300L) // just quit after delay //sampleEnd } 你可以运行代码并看到它打印了三行后终止运行：\nI\u0026#39;m sleeping 0 ... I\u0026#39;m sleeping 1 ... I\u0026#39;m sleeping 2 ... 这是由于 launch 函数依附的协程作用域是 GlobalScope，而非 runBlocking 所隐含的作用域。在 GlobalScope 中启动的协程无法使进程保持活动状态，它们就像守护线程（当主线程消亡时，守护线程也将消亡）\n","permalink":"http://localhost:1313/hugo-blog/public/post/kotlin/kotlin-%E5%8D%8F%E7%A8%8B%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A31%E5%8D%8F%E7%A8%8B%E5%9F%BA%E7%A1%80/","tags":[],"title":"Kotlin 协程官方文档（1）协程基础"},{"categories":[],"content":" 公众号：字节数组 希望对你有所帮助 🤣🤣\n最近一直在了解关于 Kotlin协程 的知识，那最好的学习资料自然是官方提供的学习文档了，看了看后我就萌生了翻译官方文档的想法。前后花了要接近一个月时间，一共九篇文章，在这里也分享出来，希望对读者有所帮助。个人知识所限，有些翻译得不是太顺畅，也希望读者能提出意见\n协程官方文档：coroutines-guide 本节讨论协程的取消和超时\n一、取消协程执行 在一个长时间运行的应用程序中，我们可能需要对协程进行细粒度控制。例如，用户可能关闭了启动了协程的页面，现在不再需要其运行结果，此时就应该主动取消协程。launch 函数的返回值 Job 对象就可用于取消正在运行的协程\nimport kotlinx.coroutines.* fun main() = runBlocking { //sampleStart val job = launch { repeat(1000) { i -\u0026gt; println(\u0026#34;job: I\u0026#39;m sleeping $i ...\u0026#34;) delay(500L) } } delay(1300L) // delay a bit println(\u0026#34;main: I\u0026#39;m tired of waiting!\u0026#34;) job.cancel() // cancels the job job.join() // waits for job\u0026#39;s completion println(\u0026#34;main: Now I can quit.\u0026#34;) //sampleEnd } 运行结果\njob: I\u0026#39;m sleeping 0 ... job: I\u0026#39;m sleeping 1 ... job: I\u0026#39;m sleeping 2 ... main: I\u0026#39;m tired of waiting! main: Now I can quit. 只要 main 函数调用了 job.cancel，我们就看不到 job 协程的任何输出了，因为它已被取消。还有一个 Job 的扩展函数 cancelAndJoin ，它结合了 cancel 和 join 的调用。\ncancel() 函数用于取消协程，join() 函数用于阻塞等待协程执行结束。之所以连续调用这两个方法，是因为 cancel() 函数调用后会马上返回而不是等待协程结束后再返回，所以此时协程不一定是马上就停止了，为了确保协程执行结束后再执行后续代码，此时就需要调用 join() 方法来阻塞等待。可以通过调用 Job 的扩展函数 cancelAndJoin() 来完成相同操作\npublic suspend fun Job.cancelAndJoin() { cancel() return join() } 二、取消操作是协作完成的 协程的取消操作是协作(cooperative)完成的，协程必须协作才能取消。kotlinx.coroutines 中的所有挂起函数都是可取消的，它们在运行时会检查协程是否被取消了，并在取消时抛出 CancellationException 。但是，如果协程正在执行计算任务，并且未检查是否已处于取消状态的话，则无法取消协程，如以下示例所示：\nimport kotlinx.coroutines.* fun main() = runBlocking { //sampleStart val startTime = System.currentTimeMillis() val job = launch(Dispatchers.Default) { var nextPrintTime = startTime var i = 0 while (i \u0026lt; 5) { // computation loop, just wastes CPU // print a message twice a second if (System.currentTimeMillis() \u0026gt;= nextPrintTime) { println(\u0026#34;job: I\u0026#39;m sleeping ${i++} ...\u0026#34;) nextPrintTime += 500L } } } delay(1300L) // delay a bit println(\u0026#34;main: I\u0026#39;m tired of waiting!\u0026#34;) job.cancelAndJoin() // cancels the job and waits for its completion println(\u0026#34;main: Now I can quit.\u0026#34;) //sampleEnd } 运行代码可以看到即使在 cancel 之后协程 job 也会继续打印 \u0026ldquo;I\u0026rsquo;m sleeping\u0026rdquo; ，直到 Job 在迭代五次后（运行条件不再成立）自行结束\njob: I\u0026#39;m sleeping 0 ... job: I\u0026#39;m sleeping 1 ... job: I\u0026#39;m sleeping 2 ... main: I\u0026#39;m tired of waiting! job: I\u0026#39;m sleeping 3 ... job: I\u0026#39;m sleeping 4 ... main: Now I can quit. 三、使计算代码可取消 有两种方法可以使计算类型的代码可以被取消。第一种方法是定期调用一个挂起函数来检查取消操作，yieid() 函数是一个很好的选择。另一个方法是显示检查取消操作。让我们来试试后一种方法\n使用 while (isActive) 替换前面例子中的 while (i \u0026lt; 5)\nimport kotlinx.coroutines.* fun main() = runBlocking { //sampleStart val startTime = System.currentTimeMillis() val job = launch(Dispatchers.Default) { var nextPrintTime = startTime var i = 0 while (isActive) { // cancellable computation loop // print a message twice a second if (System.currentTimeMillis() \u0026gt;= nextPrintTime) { println(\u0026#34;job: I\u0026#39;m sleeping ${i++} ...\u0026#34;) nextPrintTime += 500L } } } delay(1300L) // delay a bit println(\u0026#34;main: I\u0026#39;m tired of waiting!\u0026#34;) job.cancelAndJoin() // cancels the job and waits for its completion println(\u0026#34;main: Now I can quit.\u0026#34;) //sampleEnd } 如你所见，现在这个循环被取消了。isActive 是一个可通过 CoroutineScope 对象在协程内部使用的扩展属性\njob: I\u0026#39;m sleeping 0 ... job: I\u0026#39;m sleeping 1 ... job: I\u0026#39;m sleeping 2 ... main: I\u0026#39;m tired of waiting! main: Now I can quit. 四、用 finally 关闭资源 可取消的挂起函数在取消时会抛出 CancellationException，可以用常用的方式来处理这种情况。例如，try {...} finally {...} 表达式和 kotlin 的 use 函数都可用于在取消协程时执行回收操作\nimport kotlinx.coroutines.* fun main() = runBlocking { //sampleStart val job = launch { try { repeat(1000) { i -\u0026gt; println(\u0026#34;job: I\u0026#39;m sleeping $i ...\u0026#34;) delay(500L) } } finally { println(\u0026#34;job: I\u0026#39;m running finally\u0026#34;) } } delay(1300L) // delay a bit println(\u0026#34;main: I\u0026#39;m tired of waiting!\u0026#34;) job.cancelAndJoin() // cancels the job and waits for its completion println(\u0026#34;main: Now I can quit.\u0026#34;) //sampleEnd } join() 和 cancelAndJoin() 两个函数都会等待所有回收操作完成后再继续执行之后的代码，因此上面的示例生成以下输出：\njob: I\u0026#39;m sleeping 0 ... job: I\u0026#39;m sleeping 1 ... job: I\u0026#39;m sleeping 2 ... main: I\u0026#39;m tired of waiting! job: I\u0026#39;m running finally main: Now I can quit. 五、运行不可取消的代码块 如果在上一个示例中的 finally 块中使用挂起函数，将会导致抛出 CancellationException，因为此时协程已经被取消了（例如，在 finally 中先调用 delay(1000L) 函数，将导致之后的输出语句不执行）。通常这并不是什么问题，因为所有性能良好的关闭操作（关闭文件、取消作业、关闭任何类型的通信通道等）通常都是非阻塞的，且不涉及任何挂起函数。但是，在极少数情况下，当需要在取消的协程中调用挂起函数时，可以使用 withContext 函数和 NonCancellable 上下文将相应的代码包装在 withContext(NonCancellable) {...} 代码块中，如下例所示：\nimport kotlinx.coroutines.* fun main() = runBlocking { //sampleStart val job = launch { try { repeat(1000) { i -\u0026gt; println(\u0026#34;job: I\u0026#39;m sleeping $i ...\u0026#34;) delay(500L) } } finally { withContext(NonCancellable) { println(\u0026#34;job: I\u0026#39;m running finally\u0026#34;) delay(1000L) println(\u0026#34;job: And I\u0026#39;ve just delayed for 1 sec because I\u0026#39;m non-cancellable\u0026#34;) } } } delay(1300L) // delay a bit println(\u0026#34;main: I\u0026#39;m tired of waiting!\u0026#34;) job.cancelAndJoin() // cancels the job and waits for its completion println(\u0026#34;main: Now I can quit.\u0026#34;) //sampleEnd } 此时，即使在 finally 代码块中调用了挂起函数，其也将正常生效，且之后的输出语句也会正常输出\njob: I\u0026#39;m sleeping 0 ... job: I\u0026#39;m sleeping 1 ... job: I\u0026#39;m sleeping 2 ... main: I\u0026#39;m tired of waiting! job: I\u0026#39;m running finally job: And I\u0026#39;ve just delayed for 1 sec because I\u0026#39;m non-cancellable main: Now I can quit. 六、超时 大多数情况下，我们会主动取消协程的原因是由于其执行时间已超出预估的最长时间。虽然我们可以手动跟踪对相应 Job 的引用，并在超时后取消 Job，但官方也提供了 withTimeout 函数来完成此类操作。看一下示例：\nimport kotlinx.coroutines.* fun main() = runBlocking { //sampleStart withTimeout(1300L) { repeat(1000) { i -\u0026gt; println(\u0026#34;I\u0026#39;m sleeping $i ...\u0026#34;) delay(500L) } } //sampleEnd } 运行结果：\nI\u0026#39;m sleeping 0 ... I\u0026#39;m sleeping 1 ... I\u0026#39;m sleeping 2 ... Exception in thread \u0026#34;main\u0026#34; kotlinx.coroutines.TimeoutCancellationException: Timed out waiting for 1300 ms withTimeout 引发的 TimeoutCancellationException 是 CancellationException 的子类。之前我们从未在控制台上看过 CancellationException 这类异常的堆栈信息。这是因为对于一个已取消的协程来说，CancellationException 被认为是触发协程结束的正常原因。但是，在这个例子中，我们在主函数中使用了 withTimeout 函数，该函数会主动抛出 TimeoutCancellationException\n你可以通过使用 try{...}catch（e:TimeoutCancellationException）{...} 代码块来对任何情况下的超时操作执行某些特定的附加操作，或者通过使用 withTimeoutOrNull 函数以便在超时时返回 null 而不是抛出异常\nimport kotlinx.coroutines.* fun main() = runBlocking { //sampleStart val result = withTimeoutOrNull(1300L) { repeat(1000) { i -\u0026gt; println(\u0026#34;I\u0026#39;m sleeping $i ...\u0026#34;) delay(500L) } \u0026#34;Done\u0026#34; // will get cancelled before it produces this result } println(\u0026#34;Result is $result\u0026#34;) //sampleEnd } 此时将不会打印出异常信息\nI\u0026#39;m sleeping 0 ... I\u0026#39;m sleeping 1 ... I\u0026#39;m sleeping 2 ... Result is null ","permalink":"http://localhost:1313/hugo-blog/public/post/kotlin/kotlin-%E5%8D%8F%E7%A8%8B%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A32%E5%8F%96%E6%B6%88%E5%92%8C%E8%B6%85%E6%97%B6/","tags":[],"title":"Kotlin 协程官方文档（2）取消和超时"},{"categories":[],"content":" 公众号：字节数组 希望对你有所帮助 🤣🤣\n最近一直在了解关于 Kotlin协程 的知识，那最好的学习资料自然是官方提供的学习文档了，看了看后我就萌生了翻译官方文档的想法。前后花了要接近一个月时间，一共九篇文章，在这里也分享出来，希望对读者有所帮助。个人知识所限，有些翻译得不是太顺畅，也希望读者能提出意见\n协程官方文档：coroutines-guide 本节来介绍构成挂起函数的各种方法\n一、默认顺序 假设我们有两个定义于其它位置的挂起函数，它们用于执行一些有用操作，比如某种远程服务调用或者是计算操作。我们假设这两个函数是有实际意义的，但实际上它们只是为了模拟情况而延迟了一秒钟\nsuspend fun doSomethingUsefulOne(): Int { delay(1000L) // pretend we are doing something useful here return 13 } suspend fun doSomethingUsefulTwo(): Int { delay(1000L) // pretend we are doing something useful here, too return 29 } 在实践中，如果我们需要依靠第一个函数的运行结果来决定是否需要调用或者如何调用第二个函数，此时我们就需要按顺序来运行这两个函数\n我们使用默认顺序来调用这两个函数，因为协程中的代码和常规代码一样，在默认情况下是顺序的执行的。下面来计算两个挂起函数运行所需的总时间\nimport kotlinx.coroutines.* import kotlin.system.* fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart val time = measureTimeMillis { val one = doSomethingUsefulOne() val two = doSomethingUsefulTwo() println(\u0026#34;The answer is ${one + two}\u0026#34;) } println(\u0026#34;Completed in $time ms\u0026#34;) //sampleEnd } suspend fun doSomethingUsefulOne(): Int { delay(1000L) // pretend we are doing something useful here return 13 } suspend fun doSomethingUsefulTwo(): Int { delay(1000L) // pretend we are doing something useful here, too return 29 } 将得到类似于下边这样的输出，可以看出函数是按顺序先后执行的\nThe answer is 42 Completed in 2007 ms 二、使用 async 并发 如果 doSomethingUsefulOne() 和 doSomethingUsefulTwo() 这两个函数之间没有依赖关系，并且我们希望通过同时执行这两个操作（并发）以便更快地得到答案，此时就需要用到 async 了\n从概念上讲，async 就类似于 launch。async 启动一个单独的协程，这是一个与所有其它协程同时工作的轻量级协程。不同之处在于，launch 返回 Job 对象并且不携带任何运行结果值。而 async 返回一个轻量级非阻塞的 Deferred 对象，可用于在之后取出返回值，可以通过调用 Deferred 的 await() 方法来获取最终结果。此外，Deferred 也实现了 Job 接口，所以也可以根据需要来取消它\nimport kotlinx.coroutines.* import kotlin.system.* fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart val time = measureTimeMillis { val one = async { doSomethingUsefulOne() } val two = async { doSomethingUsefulTwo() } println(\u0026#34;The answer is ${one.await() + two.await()}\u0026#34;) } println(\u0026#34;Completed in $time ms\u0026#34;) //sampleEnd } suspend fun doSomethingUsefulOne(): Int { delay(1000L) // pretend we are doing something useful here return 13 } suspend fun doSomethingUsefulTwo(): Int { delay(1000L) // pretend we are doing something useful here, too return 29 } 运行结果类似于以下所示\nThe answer is 42 Completed in 1014 ms 可以看到运行耗时几乎是减半了，因为这两个协程是同时运行，总的耗时时间可以说是取决于耗时最长的任务。需要注意，协程的并发总是显式的\n三、惰性启动 async 可选的，可以将 async 的 start 参数设置为 CoroutineStart.lazy 使其变为懒加载模式。在这种模式下，只有在主动调用 Deferred 的 await() 或者 start() 方法时才会启动协程。运行以下示例：\nimport kotlinx.coroutines.* import kotlin.system.* fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart val time = measureTimeMillis { val one = async(start = CoroutineStart.LAZY) { doSomethingUsefulOne() } val two = async(start = CoroutineStart.LAZY) { doSomethingUsefulTwo() } // some computation one.start() // start the first one two.start() // start the second one println(\u0026#34;The answer is ${one.await() + two.await()}\u0026#34;) } println(\u0026#34;Completed in $time ms\u0026#34;) //sampleEnd } suspend fun doSomethingUsefulOne(): Int { delay(1000L) // pretend we are doing something useful here return 13 } suspend fun doSomethingUsefulTwo(): Int { delay(1000L) // pretend we are doing something useful here, too return 29 } 将得到以下类似输出：\nThe answer is 42 Completed in 1016 ms 以上定义了两个协程，但没有像前面的例子那样直接执行，而是将控制权交给了开发者，由开发者通过调用 start() 函数来确切地开始执行。首先启动了协程 one，然后启动了协程 two，然后再等待协程运行结束\n注意，如果只是在 println 中调用了 await() 而不首先调用 start() ,这将形成顺序行为，因为 await() 会启动协程并等待其完成，这不是 lazy 模式的预期结果。async(start=CoroutineStart.LAZY) 的用例是标准标准库中的 lazy 函数的替代品，用于在值的计算涉及挂起函数的情况下\n四、异步风格的函数 我们可以定义异步风格的函数，使用带有显式 GlobalScope 引用的异步协程生成器来调用 doSomethingUsefulOne 和 doSomethingUsefulTwo 函数。用 “…Async” 后缀来命名这些函数，以此来强调它们用来启动异步计算，并且需要通过其返回的延迟值来获取结果\n// The result type of somethingUsefulOneAsync is Deferred\u0026lt;Int\u0026gt; fun somethingUsefulOneAsync() = GlobalScope.async { doSomethingUsefulOne() } // The result type of somethingUsefulTwoAsync is Deferred\u0026lt;Int\u0026gt; fun somethingUsefulTwoAsync() = GlobalScope.async { doSomethingUsefulTwo() } 注意，这些 xxxAsync 函数不是挂起函数，它们可以从任何地方调用。但是，调用这些函数意味着是要用异步形式来执行操作\n以下示例展示了它们在协程之外的使用：\nimport kotlinx.coroutines.* import kotlin.system.* //sampleStart // note that we don\u0026#39;t have `runBlocking` to the right of `main` in this example fun main() { val time = measureTimeMillis { // we can initiate async actions outside of a coroutine val one = somethingUsefulOneAsync() val two = somethingUsefulTwoAsync() // but waiting for a result must involve either suspending or blocking. // here we use `runBlocking { ... }` to block the main thread while waiting for the result runBlocking { println(\u0026#34;The answer is ${one.await() + two.await()}\u0026#34;) } } println(\u0026#34;Completed in $time ms\u0026#34;) } //sampleEnd fun somethingUsefulOneAsync() = GlobalScope.async { doSomethingUsefulOne() } fun somethingUsefulTwoAsync() = GlobalScope.async { doSomethingUsefulTwo() } suspend fun doSomethingUsefulOne(): Int { delay(1000L) // pretend we are doing something useful here return 13 } suspend fun doSomethingUsefulTwo(): Int { delay(1000L) // pretend we are doing something useful here, too return 29 } 这里展示的带有异步函数的编程样式仅供说明，因为它是其它编程语言中的流行样式。强烈建议不要将此样式与 kotlin 协程一起使用，因为如下所述\n想象一下，如果在 val one = somethingUsefulOneAsync() 和 one.await() 这两行代码之间存在逻辑错误，导致程序抛出异常，正在执行的操作也被中止，此时会发生什么情况？通常，全局的错误处理者可以捕获此异常，为开发人员记录并报告错误，但是程序可以继续执行其它操作。但是这里 somethingUsefulOneAsync() 函数仍然还在后台运行（因为其协程作用域是 GlobalScope），即使其启动者已经被中止了。这个问题不会在结构化并发中出现，如下一节所示\n五、使用 async 的结构化并发 让我们以 Concurrent using async 章节为例，提取一个同时执行 doSomethingUsefulOne() 和 doSomethingUsefulTwo() 并返回其结果之和的函数。因为 async 函数被定义为 CoroutineScope 上的一个扩展函数，所以我们需要将它放在 CoroutineScope 中，这就是 coroutineScope 函数提供的功能：\nsuspend fun concurrentSum(): Int = coroutineScope { val one = async { doSomethingUsefulOne() } val two = async { doSomethingUsefulTwo() } one.await() + two.await() } 这样，如果 concurrentSum() 函数发生错误并引发异常，则在其作用域中启动的所有协程都将被取消\nimport kotlinx.coroutines.* import kotlin.system.* fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart val time = measureTimeMillis { println(\u0026#34;The answer is ${concurrentSum()}\u0026#34;) } println(\u0026#34;Completed in $time ms\u0026#34;) //sampleEnd } suspend fun concurrentSum(): Int = coroutineScope { val one = async { doSomethingUsefulOne() } val two = async { doSomethingUsefulTwo() } one.await() + two.await() } suspend fun doSomethingUsefulOne(): Int { delay(1000L) // pretend we are doing something useful here return 13 } suspend fun doSomethingUsefulTwo(): Int { delay(1000L) // pretend we are doing something useful here, too return 29 } 从 main 函数的输出结果来看，两个操作仍然是同时执行的\nThe answer is 42 Completed in 1017 ms 取消操作始终通过协程的层次结构来进行传播\nfun main() = runBlocking\u0026lt;Unit\u0026gt; { try { failedConcurrentSum() } catch(e: ArithmeticException) { println(\u0026#34;Computation failed with ArithmeticException\u0026#34;) } } suspend fun failedConcurrentSum(): Int = coroutineScope { val one = async\u0026lt;Int\u0026gt; { try { delay(Long.MAX_VALUE) // Emulates very long computation 42 } finally { println(\u0026#34;First child was cancelled\u0026#34;) } } val two = async\u0026lt;Int\u0026gt; { println(\u0026#34;Second child throws an exception\u0026#34;) throw ArithmeticException() } one.await() + two.await() } 需要注意协程 one 和正在等待的父级是如何在协程 two 失败时取消的\nSecond child throws an exception First child was cancelled Computation failed with ArithmeticException ","permalink":"http://localhost:1313/hugo-blog/public/post/kotlin/kotlin-%E5%8D%8F%E7%A8%8B%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A33%E7%BB%84%E5%90%88%E6%8C%82%E8%B5%B7%E5%87%BD%E6%95%B0/","tags":[],"title":"Kotlin 协程官方文档（3）组合挂起函数"},{"categories":[],"content":" 公众号：字节数组 希望对你有所帮助 🤣🤣\n最近一直在了解关于 Kotlin协程 的知识，那最好的学习资料自然是官方提供的学习文档了，看了看后我就萌生了翻译官方文档的想法。前后花了要接近一个月时间，一共九篇文章，在这里也分享出来，希望对读者有所帮助。个人知识所限，有些翻译得不是太顺畅，也希望读者能提出意见\n协程官方文档：coroutines-guide 协程总是在由 Kotlin 标准库中定义的 CoroutineContext 表示的某个上下文中执行\n协程上下文包含多种子元素。主要的元素是协程作业（Job，我们之前见过），以及它的调度器（Dispatche，本节将介绍）\n一、调度器和线程 协程上下文（coroutine context）包含一个协程调度器（参阅 CoroutineDispatcher），协程调度器 用于确定执行协程的目标载体，即运行于哪个线程，包含一个还是多个线程。协程调度器可以将协程的执行操作限制在特定线程上，也可以将其分派到线程池中，或者让它无限制地运行\n所有协程构造器（如 launch 和 async）都接受一个可选参数，即 CoroutineContext ，该参数可用于显式指定要创建的协程和其它上下文元素所要使用的调度器\n请尝试以下示例：\nimport kotlinx.coroutines.* fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart launch { // context of the parent, main runBlocking coroutine println(\u0026#34;main runBlocking : I\u0026#39;m working in thread ${Thread.currentThread().name}\u0026#34;) } launch(Dispatchers.Unconfined) { // not confined -- will work with main thread println(\u0026#34;Unconfined : I\u0026#39;m working in thread ${Thread.currentThread().name}\u0026#34;) } launch(Dispatchers.Default) { // will get dispatched to DefaultDispatcher println(\u0026#34;Default : I\u0026#39;m working in thread ${Thread.currentThread().name}\u0026#34;) } launch(newSingleThreadContext(\u0026#34;MyOwnThread\u0026#34;)) { // will get its own new thread println(\u0026#34;newSingleThreadContext: I\u0026#39;m working in thread ${Thread.currentThread().name}\u0026#34;) } //sampleEnd } 运行结果如下所示，日志的输出顺序可能不同\nUnconfined : I\u0026#39;m working in thread main Default : I\u0026#39;m working in thread DefaultDispatcher-worker-1 newSingleThreadContext: I\u0026#39;m working in thread MyOwnThread main runBlocking : I\u0026#39;m working in thread main 当 launch {...} 在不带参数的情况下使用时，它从外部的协程作用域继承上下文和调度器。在本例中，它继承于在主线程中中运行的 runBlocking 协程的上下文\nDispatchers.Unconfined 是一个特殊的调度器，看起来似乎也在主线程中运行，但实际上它是一种不同的机制，稍后将进行解释\n在 GlobalScope 中启动协程时默认使用的调度器是 Dispatchers.default，并使用共享的后台线程池，因此 launch(Dispatchers.default){...} 与 GlobalScope.launch{...} 是使用相同的调度器\nnewSingleThreadContext 用于为协程专门创建一个新的线程来运行。专用线程是非常昂贵的资源。在实际的应用程序中，它必须在不再需要时使用 close 函数释放掉，或者存储在顶级变量中以此实现在整个应用程序中重用\n二、Unconfined vs confined dispatcher Dispatchers.Unconfined 调度器在调用者线程中启动一个协程，但它仅仅只是运行到第一个挂起点。在挂起之后，它将恢复线程中的协程，该协程完全由调用的挂起函数决定。Unconfined 调度器适用于既不消耗CPU时间和不更新任何受限于特定线程的共享数据（如UI）的协程\n另一方面，调度器是默认继承于外部的协程作用域的。尤其是 runBlocking 启动的协程的调度器只能是调用者所在的线程，因此继承 runBlocking 的结果是在此线程上的调度执行操作是可预测的 FIFO\nimport kotlinx.coroutines.* fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart launch(Dispatchers.Unconfined) { // not confined -- will work with main thread println(\u0026#34;Unconfined : I\u0026#39;m working in thread ${Thread.currentThread().name}\u0026#34;) delay(500) println(\u0026#34;Unconfined : After delay in thread ${Thread.currentThread().name}\u0026#34;) } launch { // context of the parent, main runBlocking coroutine println(\u0026#34;main runBlocking: I\u0026#39;m working in thread ${Thread.currentThread().name}\u0026#34;) delay(1000) println(\u0026#34;main runBlocking: After delay in thread ${Thread.currentThread().name}\u0026#34;) } //sampleEnd } 运行结果：\nUnconfined : I\u0026#39;m working in thread main main runBlocking: I\u0026#39;m working in thread main Unconfined : After delay in thread kotlinx.coroutines.DefaultExecutor main runBlocking: After delay in thread main 因此，从 runBlocking{...} 继承了上下文的协程继续在主线程中执行，而调度器是 unconfined 的协程，在 delay 函数之后的代码则默认运行于 delay 函数所使用的运行线程\nunconfined 调度器是一种高级机制，可以在某些极端情况下提供帮助而不需要调度协程以便稍后执行或产生不希望的副作用， 因为某些操作必须立即在协程中执行。 非受限调度器不应该在一般的代码中使用\n三、调试协程和线程 协程可以在一个线程上挂起，在另一个线程上继续运行。即使使用单线程的调度器，也可能很难明确知道协程当前在做什么、在哪里、处于什么状态。调试线程的常用方法是在在日志文件中为每条日志语句加上线程名，日志框架普遍支持此功能。当使用协程时，线程名本身没有提供太多的上下文信息，因此 kotlinx.coroutines 包含了调试工具以便使协程调试起来更加容易\n开启 JVM 的 -Dkotlinx.coroutines.debug 配置后运行以下代码：\nimport kotlinx.coroutines.* fun log(msg: String) = println(\u0026#34;[${Thread.currentThread().name}] $msg\u0026#34;) fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart val a = async { log(\u0026#34;I\u0026#39;m computing a piece of the answer\u0026#34;) 6 } val b = async { log(\u0026#34;I\u0026#39;m computing another piece of the answer\u0026#34;) 7 } log(\u0026#34;The answer is ${a.await() * b.await()}\u0026#34;) //sampleEnd } 共有三个协程。runBlocking 中的主协程（#1）和两个计算延迟值a（#2）和b（#3）的协程。它们都在 runBlocking 的上下文中执行，并且仅限于主线程。此代码的输出为：\n[main @coroutine#2] I\u0026#39;m computing a piece of the answer [main @coroutine#3] I\u0026#39;m computing another piece of the answer [main @coroutine#1] The answer is 42 log 函数在方括号中打印线程名，可以看到协程都运行于主线程，线程名后附有有当前正在执行的协程的标识符。当调试模式打开时，此标识符将连续分配给所有创建的协程\n当使用 -ea 选项运行 JVM 时，调试模式也将打开，可以在 DEBUG_PROPERTY_NAME 属性文档中阅读有关调试工具的更多信息\n四、在线程间切换 开启 JVM 的 -Dkotlinx.coroutines.debug 配置后运行以下代码：\nimport kotlinx.coroutines.* fun log(msg: String) = println(\u0026#34;[${Thread.currentThread().name}] $msg\u0026#34;) fun main() { //sampleStart newSingleThreadContext(\u0026#34;Ctx1\u0026#34;).use { ctx1 -\u0026gt; newSingleThreadContext(\u0026#34;Ctx2\u0026#34;).use { ctx2 -\u0026gt; runBlocking(ctx1) { log(\u0026#34;Started in ctx1\u0026#34;) withContext(ctx2) { log(\u0026#34;Working in ctx2\u0026#34;) } log(\u0026#34;Back to ctx1\u0026#34;) } } } //sampleEnd } 这里演示了几种新技巧。一个是对显示指定的上下文使用 runBlocking，另一个是使用 withContext 函数更改协程的上下文并同时仍然保持在另一个协程中，如你在下面的输出中所看到的：\n[Ctx1 @coroutine#1] Started in ctx1 [Ctx2 @coroutine#1] Working in ctx2 [Ctx1 @coroutine#1] Back to ctx1 注意，本例还使用了 kotlin 标准库中的 use 函数用来在不再需要时释放 newSingleThreadContext 所创建的线程\n五、上下文中的 Job 协程中的 Job 是其上下文中的一部分，可以通过 coroutineContext[Job] 表达式从上下文中获取到\nimport kotlinx.coroutines.* fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart println(\u0026#34;My job is ${coroutineContext[Job]}\u0026#34;) //sampleEnd } 在 debug 模式下，输出结果类似于：\nMy job is \u0026#34;coroutine#1\u0026#34;:BlockingCoroutine{Active}@6d311334 注意，CoroutineScope 的 isActive 属性只是 coroutineContext[Job]?.isActive == true 的一种简便写法\npublic val CoroutineScope.isActive: Boolean get() = coroutineContext[Job]?.isActive ?: true 六、子协程 当一个协程在另外一个协程的协程作用域中启动时，它将通过 CoroutineScope.coroutineContext 继承其上下文，新启动的协程的 Job 将成为父协程的 Job 的子 Job。当父协程被取消时，它的所有子协程也会递归地被取消\n但是，当使用 GlobalScope 启动协程时，协程的 Job 没有父级。因此，它不受其启动的作用域和独立运作范围的限制\nimport kotlinx.coroutines.* fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart // launch a coroutine to process some kind of incoming request val request = launch { // it spawns two other jobs, one with GlobalScope GlobalScope.launch { println(\u0026#34;job1: I run in GlobalScope and execute independently!\u0026#34;) delay(1000) println(\u0026#34;job1: I am not affected by cancellation of the request\u0026#34;) } // and the other inherits the parent context launch { delay(100) println(\u0026#34;job2: I am a child of the request coroutine\u0026#34;) delay(1000) println(\u0026#34;job2: I will not execute this line if my parent request is cancelled\u0026#34;) } } delay(500) request.cancel() // cancel processing of the request delay(1000) // delay a second to see what happens println(\u0026#34;main: Who has survived request cancellation?\u0026#34;) //sampleEnd } 运行结果是：\njob1: I run in GlobalScope and execute independently! job2: I am a child of the request coroutine job1: I am not affected by cancellation of the request main: Who has survived request cancellation? 七、父协程的职责 父协程总是会等待其所有子协程完成。父协程不必显式跟踪它启动的所有子协程，也不必使用 Job.join 在末尾等待子协程完成\nimport kotlinx.coroutines.* fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart // launch a coroutine to process some kind of incoming request val request = launch { repeat(3) { i -\u0026gt; // launch a few children jobs launch { delay((i + 1) * 200L) // variable delay 200ms, 400ms, 600ms println(\u0026#34;Coroutine $i is done\u0026#34;) } } println(\u0026#34;request: I\u0026#39;m done and I don\u0026#39;t explicitly join my children that are still active\u0026#34;) } request.join() // wait for completion of the request, including all its children println(\u0026#34;Now processing of the request is complete\u0026#34;) //sampleEnd } 运行结果：\nrequest: I\u0026#39;m done and I don\u0026#39;t explicitly join my children that are still active Coroutine 0 is done Coroutine 1 is done Coroutine 2 is done Now processing of the request is complete 八、为协程命名以便调试 当协程经常需要进行日志调试时，协程自动分配到的 ID 是很有用处的，你只需要关联来自同一协程的日志记录。但是，当一个协程绑定到一个特定请求的处理或者执行某个特定的后台任务时，最好显式地为它命名，以便进行调试。CoroutineName 上下文元素的作用与线程名相同，它包含在启用调试模式时执行此协程的线程名中\n以下代码展示了此概念：\nimport kotlinx.coroutines.* fun log(msg: String) = println(\u0026#34;[${Thread.currentThread().name}] $msg\u0026#34;) fun main() = runBlocking(CoroutineName(\u0026#34;main\u0026#34;)) { //sampleStart log(\u0026#34;Started main coroutine\u0026#34;) // run two background value computations val v1 = async(CoroutineName(\u0026#34;v1coroutine\u0026#34;)) { delay(500) log(\u0026#34;Computing v1\u0026#34;) 252 } val v2 = async(CoroutineName(\u0026#34;v2coroutine\u0026#34;)) { delay(1000) log(\u0026#34;Computing v2\u0026#34;) 6 } log(\u0026#34;The answer for v1 / v2 = ${v1.await() / v2.await()}\u0026#34;) //sampleEnd } 开启 -Dkotlinx.coroutines.debug JVM 配置后的输出结果类似于：\n[main @main#1] Started main coroutine [main @v1coroutine#2] Computing v1 [main @v2coroutine#3] Computing v2 [main @main#1] The answer for v1 / v2 = 42 九、组合上下文元素 有时我们需要为协程上下文定义多个元素。我们可以用 + 运算符。例如，我们可以同时使用显式指定的调度器和显式指定的名称来启动协程\nimport kotlinx.coroutines.* fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart launch(Dispatchers.Default + CoroutineName(\u0026#34;test\u0026#34;)) { println(\u0026#34;I\u0026#39;m working in thread ${Thread.currentThread().name}\u0026#34;) } //sampleEnd } 开启 -Dkotlinx.coroutines.debug JVM 配置后的输出结果是：\nI\u0026#39;m working in thread DefaultDispatcher-worker-1 @test#2 十、协程作用域 让我们把关于作用域、子元素和 Job 的知识点放在一起。假设我们的应用程序有一个具有生命周期的对象，但该对象不是协程。例如，我们正在编写一个Android应用程序，并在Android Activity中启动各种协程，以执行异步操作来获取和更新数据、指定动画等。当 Activity 销毁时，必须取消所有协程以避免内存泄漏。当然，我们可以手动操作上下文和 Job 来绑定 Activity 和协程的生命周期。但是，kotlinx.coroutines 提供了一个抽象封装：CoroutineScope。你应该已经对协程作用域很熟悉了，因为所有的协程构造器都被声明为它的扩展函数\n我们通过创建与 Activity 生命周期相关联的协程作用域的实例来管理协程的生命周期。CoroutineScope 的实例可以通过 CoroutineScope() 或 MainScope() 的工厂函数来构建。前者创建通用作用域，后者创建 UI 应用程序的作用域并使用 Dispatchers.Main 作为默认的调度器\nclass Activity { private val mainScope = MainScope() fun destroy() { mainScope.cancel() } // to be continued ... } 或者，我们可以在这个 Activity 类中实现 CoroutineScope 接口。最好的实现方式是对默认工厂函数使用委托。我们还可以将所需的调度器（在本例中使用Dispatchers.Default）与作用域结合起来：\nclass Activity : CoroutineScope by CoroutineScope(Dispatchers.Default) { // to be continued ... 现在，我们可以在这个 Activity 内启动协程，而不必显示地指定它们的上下文。为了演示，我们启动了十个分别延时不同时间的协程：\n// class Activity continues fun doSomething() { // launch ten coroutines for a demo, each working for a different time repeat(10) { i -\u0026gt; launch { delay((i + 1) * 200L) // variable delay 200ms, 400ms, ... etc println(\u0026#34;Coroutine $i is done\u0026#34;) } } } } // class Activity ends 在主函数中，我们创建 Activity 对象，调用测试 doSomething 函数，并在500毫秒后销毁该活动。这将取消从 doSomething 中启动的所有协程。我们可以看到这一点，因为在销毁 activity 对象后，即使我们再等待一会儿，也不会再打印消息\nimport kotlin.coroutines.* import kotlinx.coroutines.* class Activity : CoroutineScope by CoroutineScope(Dispatchers.Default) { fun destroy() { cancel() // Extension on CoroutineScope } // to be continued ... // class Activity continues fun doSomething() { // launch ten coroutines for a demo, each working for a different time repeat(10) { i -\u0026gt; launch { delay((i + 1) * 200L) // variable delay 200ms, 400ms, ... etc println(\u0026#34;Coroutine $i is done\u0026#34;) } } } } // class Activity ends fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart val activity = Activity() activity.doSomething() // run test function println(\u0026#34;Launched coroutines\u0026#34;) delay(500L) // delay for half a second println(\u0026#34;Destroying activity!\u0026#34;) activity.destroy() // cancels all coroutines delay(1000) // visually confirm that they don\u0026#39;t work //sampleEnd } 输出结果：\nLaunched coroutines Coroutine 0 is done Coroutine 1 is done Destroying activity! 如你所见，只有前两个协程会打印一条消息，其它的则会被 Activity.destroy() 中的 job.cancel() 所取消\n十一、线程局部数据 有时，将一些线程局部数据传递到协程或在协程之间传递是有实际用途的。但是，由于协程没有绑定到任何特定的线程，如果手动完成，这可能会导致模板代码\n对于 ThreadLocal，扩展函数 asContextElement 可用于解决这个问题。它创建一个附加的上下文元素，该元素保持 ThreadLocal 给定的值，并在每次协程切换其上下文时恢复该值\n很容易在实践中证明：\nimport kotlinx.coroutines.* val threadLocal = ThreadLocal\u0026lt;String?\u0026gt;() // declare thread-local variable fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart threadLocal.set(\u0026#34;main\u0026#34;) println(\u0026#34;Pre-main, current thread: ${Thread.currentThread()}, thread local value: \u0026#39;${threadLocal.get()}\u0026#39;\u0026#34;) val job = launch(Dispatchers.Default + threadLocal.asContextElement(value = \u0026#34;launch\u0026#34;)) { println(\u0026#34;Launch start, current thread: ${Thread.currentThread()}, thread local value: \u0026#39;${threadLocal.get()}\u0026#39;\u0026#34;) yield() println(\u0026#34;After yield, current thread: ${Thread.currentThread()}, thread local value: \u0026#39;${threadLocal.get()}\u0026#39;\u0026#34;) } job.join() println(\u0026#34;Post-main, current thread: ${Thread.currentThread()}, thread local value: \u0026#39;${threadLocal.get()}\u0026#39;\u0026#34;) //sampleEnd } 在本例中，我们使用 Dispatchers.Default 在后台线程池中启动一个新的协程，因为它可以在线程池中不同的线程之间来回切换工作，但它仍然具有我们使用 threadLocal.asContextElement（value=\u0026quot;launch\u0026quot;）指定的线程局部变量的值，无论协程在哪个线程上执行。因此，输出结果是（开启了调试模式）：\nPre-main, current thread: Thread[main @coroutine#1,5,main], thread local value: \u0026#39;main\u0026#39; Launch start, current thread: Thread[DefaultDispatcher-worker-1 @coroutine#2,5,main], thread local value: \u0026#39;launch\u0026#39; After yield, current thread: Thread[DefaultDispatcher-worker-2 @coroutine#2,5,main], thread local value: \u0026#39;launch\u0026#39; Post-main, current thread: Thread[main @coroutine#1,5,main], thread local value: \u0026#39;main\u0026#39; 我们很容易就忘记设置相应的上下文元素。如果运行协程的线程会有多个，则从协程访问的线程局部变量可能会有意外值。为了避免这种情况，建议使用 ensurePresent 方法，并在使用不当时可以快速失败\nThreadLocal 具备一等支持，可以与任何基础 kotlinx.coroutines 一起使用。不过，它有一个关键限制：当线程局部变量发生变化时，新值不会传导到协程调用方（因为上下文元素无法跟踪所有的线程本地对象引用）。并且更新的值在下次挂起时丢失。使用 withContext 更新协程中线程的局部值，有关详细信息，请参阅 asContextElement\n或者，值可以存储在一个可变的类计数器中(var i: Int)，而类计数器又存储在一个线程局部变量中，但是，在这种情况下，您完全有责任同步此计数器中变量的潜在并发修改\n有关高级用法，比如与 logging MDC, transactional contexts或其它在内部使用线程局部变量传递数据的库集成，请参阅实现了 ThreadContextElement 接口的文档\n","permalink":"http://localhost:1313/hugo-blog/public/post/kotlin/kotlin-%E5%8D%8F%E7%A8%8B%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A34%E5%8D%8F%E7%A8%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%92%8C%E8%B0%83%E5%BA%A6%E5%99%A8/","tags":[],"title":"Kotlin 协程官方文档（4）协程上下文和调度器"},{"categories":[],"content":" 公众号：字节数组 希望对你有所帮助 🤣🤣\n最近一直在了解关于 Kotlin协程 的知识，那最好的学习资料自然是官方提供的学习文档了，看了看后我就萌生了翻译官方文档的想法。前后花了要接近一个月时间，一共九篇文章，在这里也分享出来，希望对读者有所帮助。个人知识所限，有些翻译得不是太顺畅，也希望读者能提出意见\n协程官方文档：coroutines-guide 挂起函数可以异步返回单个值，但如何返回多个异步计算值呢？这就是 kotlin Flows（流） 的用处了\n一、表示多个值 可以使用集合在 kotlin 中表示多个值。例如，有一个函数 foo()，它返回包含三个数字的 List，然后使用 forEach 打印它们\nfun foo(): List\u0026lt;Int\u0026gt; = listOf(1, 2, 3) fun main() { foo().forEach { value -\u0026gt; println(value) } } 输出结果：\n1 2 3 1.1、序列 如果我们使用一些 CPU 消耗型 的阻塞代码（每次计算需要100毫秒）来计算数字，那么我们可以使用一个序列(Sequence)来表示数字：\nfun foo(): Sequence\u0026lt;Int\u0026gt; = sequence { // sequence builder for (i in 1..3) { Thread.sleep(100) // pretend we are computing it yield(i) // yield next value } } fun main() { foo().forEach { value -\u0026gt; println(value) } } 这段代码输出相同的数字列表，但每打印一个数字前都需要等待100毫秒\n1.2、挂起函数 上一节的代码的计算操作会阻塞运行代码的主线程。当这些值由异步代码计算时，我们可以用 suspend 修饰符标记函数 foo，以便它可以在不阻塞的情况下执行其工作，并将结果作为列表返回\nimport kotlinx.coroutines.* //sampleStart suspend fun foo(): List\u0026lt;Int\u0026gt; { delay(1000) // pretend we are doing something asynchronous here return listOf(1, 2, 3) } fun main() = runBlocking\u0026lt;Unit\u0026gt; { foo().forEach { value -\u0026gt; println(value) } } //sampleEnd 这段代码在等待一秒后输出数字\n1.3、Flows 使用 List\u0026lt; Int \u0026gt; 作为返回值类型，意味着我们只能同时返回所有值。为了表示异步计算的值流，我们可以使用 Flow\u0026lt; Int \u0026gt; 类型，就像同步计算值的 Sequence\u0026lt; Int \u0026gt; 类型一样\n//sampleStart fun foo(): Flow\u0026lt;Int\u0026gt; = flow { // flow builder for (i in 1..3) { delay(100) // pretend we are doing something useful here emit(i) // emit next value } } fun main() = runBlocking\u0026lt;Unit\u0026gt; { // Launch a concurrent coroutine to check if the main thread is blocked launch { for (k in 1..3) { println(\u0026#34;I\u0026#39;m not blocked $k\u0026#34;) delay(100) } } // Collect the flow foo().collect { value -\u0026gt; println(value) } } //sampleEnd 此代码在打印每个数字前等待100毫秒，但不会阻塞主线程。通过从主线程中运行的单独协程中每隔100毫秒打印了一次 “I\u0026rsquo;m not blocked”，可以验证这一点：\nI\u0026#39;m not blocked 1 1 I\u0026#39;m not blocked 2 2 I\u0026#39;m not blocked 3 3 请注意，代码与前面示例中的 Flow 有以下不同：\nFlow 类型的构造器函数名为 flow flow{\u0026hellip;} 中的代码块可以挂起 foo 函数不再标记 suspend 修饰符 值通过 emit 函数从流中发出 通过 collect 函数从 flow 中取值 我们可以用 Thread.sleep 来代替 flow{\u0026hellip;} 中的 delay，可以看到在这种情况下主线程被阻塞住了\n二、流是冷的 Flows 是冷流（cold streams），类似于序列（sequences），flow builder 中的代码在开始收集流值之前不会运行。在下面的示例中可以清楚地看到这一点：\nimport kotlinx.coroutines.* import kotlinx.coroutines.flow.* //sampleStart fun foo(): Flow\u0026lt;Int\u0026gt; = flow { println(\u0026#34;Flow started\u0026#34;) for (i in 1..3) { delay(100) emit(i) } } fun main() = runBlocking\u0026lt;Unit\u0026gt; { println(\u0026#34;Calling foo...\u0026#34;) val flow = foo() println(\u0026#34;Calling collect...\u0026#34;) flow.collect { value -\u0026gt; println(value) } println(\u0026#34;Calling collect again...\u0026#34;) flow.collect { value -\u0026gt; println(value) } } //sampleEnd 运行结果：\nCalling foo... Calling collect... Flow started 1 2 3 Calling collect again... Flow started 1 2 3 这是 foo() 函数（返回了 flow）未标记 suspend 修饰符的一个关键原因。foo() 本身返回很快，不会进行任何等待。flow 每次收集时都会启动，这就是我们再次调用 collect 时会看到“flow started”的原因\n三、取消流 Flow 采用和协程取同样的协作取消。但是，Flow 实现基础并没有引入额外的取消点，它对于取消操作是完全透明的。通常，流的收集操作可以在当流在一个可取消的挂起函数（如 delay）中挂起的时候取消，否则不能取消\n以下示例展示了在 withTimeoutOrNull 块中流如何在超时时被取消并停止执行\n//sampleStart fun foo(): Flow\u0026lt;Int\u0026gt; = flow { for (i in 1..3) { delay(100) println(\u0026#34;Emitting $i\u0026#34;) emit(i) } } fun main() = runBlocking\u0026lt;Unit\u0026gt; { withTimeoutOrNull(250) { // Timeout after 250ms foo().collect { value -\u0026gt; println(value) } } println(\u0026#34;Done\u0026#34;) } //sampleEnd 注意，foo() 函数中的 Flow 只传出两个数字，得到以下输出：\nEmitting 1 1 Emitting 2 2 Done 相对应的，可以注释掉 flow 中的 delay 函数，并增大 for 循环的循环范围，此时可以发现 flow 没有被取消，因为 flow 中没有引入额外的挂起点\n//sampleStart fun foo(): Flow\u0026lt;Int\u0026gt; = flow { for (i in 1..Int.MAX_VALUE) { // delay(100) println(\u0026#34;Emitting $i\u0026#34;) emit(i) } } fun main() = runBlocking\u0026lt;Unit\u0026gt; { withTimeoutOrNull(250) { // Timeout after 250ms foo().collect { value -\u0026gt; println(value) } } println(\u0026#34;Done\u0026#34;) } //sampleEnd 四、流构建器 前面例子中的 flow{\u0026hellip;} 是最基础的一个流构建器，还有其它的构建器可以更容易地声明流：\nflowOf() 定义了一个发出固定值集的流构建器 可以使用扩展函数 .asFlow() 将各种集合和序列转换为流 因此，从流中打印从 1 到 3 的数字的例子可以改写成：\nfun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart // Convert an integer range to a flow (1..3).asFlow().collect { value -\u0026gt; println(value) } //sampleEnd } 五、中间流运算符 可以使用运算符来转换流，就像使用集合和序列一样。中间运算符应用于上游流并返回下游流。这些运算符是冷操作符，和流一样。此类运算符本身不是挂起函数，它工作得很快，其返回一个新的转换后的流，但引用仅包含对新流的操作定义，并不马上进行转换\n基础运算符有着熟悉的名称，例如 map 和 filter。流运算符和序列的重要区别在于流运算符中的代码可以调用挂起函数\n例如，可以使用 map 运算符将传入请求流映射为结果值，即使执行请求是由挂起函数实现的长时间运行的操作：\n//sampleStart suspend fun performRequest(request: Int): String { delay(1000) // imitate long-running asynchronous work return \u0026#34;response $request\u0026#34; } fun main() = runBlocking\u0026lt;Unit\u0026gt; { (1..3).asFlow() // a flow of requests .map { request -\u0026gt; performRequest(request) } .collect { response -\u0026gt; println(response) } } //sampleEnd 运行结果共有三行，每一秒打印一行输出\nresponse 1 response 2 response 3 5.1、转换操作符 在流的转换运算符中，最常用的一个称为 transform。它可以用来模拟简单的数据转换（就像 map 和 filter），以及实现更复杂的转换。使用 transform 运算符，我们可以发出任意次数的任意值\n例如，通过使用 transform，我们可以在执行长时间运行的异步请求之前发出一个字符串，并在该字符串后面跟随一个响应：\nsuspend fun performRequest(request: Int): String { delay(1000) // imitate long-running asynchronous work return \u0026#34;response $request\u0026#34; } fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart (1..3).asFlow() // a flow of requests .transform { request -\u0026gt; emit(\u0026#34;Making request $request\u0026#34;) emit(performRequest(request)) } .collect { response -\u0026gt; println(response) } //sampleEnd } 输出值：\nMaking request 1 response 1 Making request 2 response 2 Making request 3 response 3 5.2、限长运算符 限长中间运算符在达到相应限制时取消流的执行。协程中的取消总是通过抛出异常来实现，这样所有的资源管理函数（例如 try { \u0026hellip; } finally { \u0026hellip; } ）就可以在取消时正常执行\n//sampleStart fun numbers(): Flow\u0026lt;Int\u0026gt; = flow { try { emit(1) emit(2) println(\u0026#34;This line will not execute\u0026#34;) emit(3) } finally { println(\u0026#34;Finally in numbers\u0026#34;) } } fun main() = runBlocking\u0026lt;Unit\u0026gt; { numbers() .take(2) // take only the first two .collect { value -\u0026gt; println(value) } } //sampleEnd 这段代码的输出清楚地显示了 numbers() 函数中的 flow{\u0026hellip;} 函数体在发出第二个数字后就停止了：\n1 2 Finally in numbers 六、流运算符 终端流运算符是用于启动流的挂起函数。collect 是最基本的终端流运算符，但还有其它终端运算符，可以使得操作更加简便：\n转换为各种集合，如 toList 和 toSet 函数 first 运算符用于获取第一个值，single 运算符用于确保流发出单个值 使用 reduce 和 fold 将流还原为某个值 例如：\nimport kotlinx.coroutines.* import kotlinx.coroutines.flow.* fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart val sum = (1..5).asFlow() .map { it * it } // squares of numbers from 1 to 5 .reduce { a, b -\u0026gt; a + b } // sum them (terminal operator) println(sum) //sampleEnd } 输出单个值：\n55 七、流是连续的 除非使用对多个流进行操作的特殊运算符，否则每个流的单独集合都是按顺序执行的。集合直接在调用终端运算符的协程中工作，默认情况下不会启动新的协程。每个发出的值都由所有中间运算符从上游到下游进行处理，然后在之后传递给终端运算符\n请参阅以下示例，该示例过滤偶数并将其映射到字符串：\nimport kotlinx.coroutines.* import kotlinx.coroutines.flow.* fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart (1..5).asFlow() .filter { println(\u0026#34;Filter $it\u0026#34;) it % 2 == 0 } .map { println(\u0026#34;Map $it\u0026#34;) \u0026#34;string $it\u0026#34; }.collect { println(\u0026#34;Collect $it\u0026#34;) } //sampleEnd } 输出：\nFilter 1 Filter 2 Map 2 Collect string 2 Filter 3 Filter 4 Map 4 Collect string 4 Filter 5 八、流上下文 流的收集总是在调用协程的上下文中执行。例如，如果存在 foo 流，则无论 foo 流的实现详细信息如何，以下代码都将在该开发者指定的上下文中执行：\nwithContext(context) { foo.collect { value -\u0026gt; println(value) // run in the specified context } } 流的这个特性称为上下文保留\n所以，默认情况下，flow{\u0026hellip;} 中的代码在相应流的收集器提供的上下文中运行。例如，观察 foo 的实现，它打印调用它的线程并发出三个数字：\nfun log(msg: String) = println(\u0026#34;[${Thread.currentThread().name}] $msg\u0026#34;) //sampleStart fun foo(): Flow\u0026lt;Int\u0026gt; = flow { log(\u0026#34;Started foo flow\u0026#34;) for (i in 1..3) { emit(i) } } fun main() = runBlocking\u0026lt;Unit\u0026gt; { foo().collect { value -\u0026gt; log(\u0026#34;Collected $value\u0026#34;) } } //sampleEnd 运行结果：\n[main @coroutine#1] Started foo flow [main @coroutine#1] Collected 1 [main @coroutine#1] Collected 2 [main @coroutine#1] Collected 3 由于 foo().collect 是在主线程调用的，所以 foo 流也是在主线程中调用。对于不关心执行上下文且不阻塞调用方的快速返回代码或者异步代码，这是完美的默认设置\n8.1、错误地使用 withContext 但是，可能需要在 Dispatchers 的上下文中执行长时间运行的占用 CPU 的代码，可能需要在 Dispatchers.Main 的上下文中执行默认代码和 UI 更新。通常，withContext 用于在使用 kotlin 协程时更改代码中的上下文，但 fow{...} 中的代码必须遵守上下文本保留属性，并且不允许从其它上下文中触发\n尝试运行以下代码：\nimport kotlinx.coroutines.* import kotlinx.coroutines.flow.* //sampleStart fun foo(): Flow\u0026lt;Int\u0026gt; = flow { // The WRONG way to change context for CPU-consuming code in flow builder kotlinx.coroutines.withContext(Dispatchers.Default) { for (i in 1..3) { Thread.sleep(100) // pretend we are computing it in CPU-consuming way emit(i) // emit next value } } } fun main() = runBlocking\u0026lt;Unit\u0026gt; { foo().collect { value -\u0026gt; println(value) } } //sampleEnd 代码会生成以下异常：\nException in thread \u0026#34;main\u0026#34; java.lang.IllegalStateException: Flow invariant is violated: Flow was collected in [CoroutineId(1), \u0026#34;coroutine#1\u0026#34;:BlockingCoroutine{Active}@5511c7f8, BlockingEventLoop@2eac3323], but emission happened in [CoroutineId(1), \u0026#34;coroutine#1\u0026#34;:DispatchedCoroutine{Active}@2dae0000, DefaultDispatcher]. Please refer to \u0026#39;flow\u0026#39; documentation or use \u0026#39;flowOn\u0026#39; instead at ... 8.2、flowOn 运算符 有个例外情况，flowOn 函数能用于改变流发送值时的上下文。改变流上下文的正确方式如下面的示例所示，该示例还打印了相应线程的名称，以显示所有线程的工作方式：\nimport kotlinx.coroutines.* import kotlinx.coroutines.flow.* fun log(msg: String) = println(\u0026#34;[${Thread.currentThread().name}] $msg\u0026#34;) //sampleStart fun foo(): Flow\u0026lt;Int\u0026gt; = flow { for (i in 1..3) { Thread.sleep(100) // pretend we are computing it in CPU-consuming way log(\u0026#34;Emitting $i\u0026#34;) emit(i) // emit next value } }.flowOn(Dispatchers.Default) // RIGHT way to change context for CPU-consuming code in flow builder fun main() = runBlocking\u0026lt;Unit\u0026gt; { foo().collect { value -\u0026gt; log(\u0026#34;Collected $value\u0026#34;) } } //sampleEnd 注意，flow{\u0026hellip;} 在后台线程中工作，而在主线程中进行取值\n这里要注意的另一件事是 flowOn 操作符改变了流的默认顺序性质。现在取值操作发生在协程 \u0026ldquo;coroutine#1\u0026rdquo; 中，而发射值的操作同时运行在另一个线程中的协程 \u0026ldquo;coroutine#2\u0026rdquo; 上。当必须在上游流的上下文中更改 CoroutineDispatcher 时，flowOn 运算符将为该上游流创建另一个协程\n九、缓冲 从收集流所需的总时间的角度来看，在不同的协程中运行流的不同部分可能会有所帮助，特别是当涉及到长时间运行的异步操作时。例如，假设 foo() 流的发射很慢，生成元素需要100毫秒；收集器也很慢，处理元素需要300毫秒。让我们看看用三个数字收集这样的流需要多长时间：\nimport kotlinx.coroutines.* import kotlinx.coroutines.flow.* import kotlin.system.* //sampleStart fun foo(): Flow\u0026lt;Int\u0026gt; = flow { for (i in 1..3) { delay(100) // pretend we are asynchronously waiting 100 ms emit(i) // emit next value } } fun main() = runBlocking\u0026lt;Unit\u0026gt; { val time = measureTimeMillis { foo().collect { value -\u0026gt; delay(300) // pretend we are processing it for 300 ms println(value) } } println(\u0026#34;Collected in $time ms\u0026#34;) } //sampleEnd 以上代码会产生如下类似的结果，整个收集过程大约需要1200毫秒（三个数字，每个400毫秒）\n1 2 3 Collected in 1220 ms 我们可以在流上使用 buffer 运算符，在运行取集代码的同时运行 foo() 的发值代码，而不是按顺序运行它们\nimport kotlinx.coroutines.* import kotlinx.coroutines.flow.* import kotlin.system.* fun foo(): Flow\u0026lt;Int\u0026gt; = flow { for (i in 1..3) { delay(100) // pretend we are asynchronously waiting 100 ms emit(i) // emit next value } } fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart val time = measureTimeMillis { foo() .buffer() // buffer emissions, don\u0026#39;t wait .collect { value -\u0026gt; delay(300) // pretend we are processing it for 300 ms println(value) } } println(\u0026#34;Collected in $time ms\u0026#34;) //sampleEnd } 这可以得到相同的输出结果但运行速度更快，因为我们已经有效地创建了一个处理管道，第一个数字只需要等待100毫秒，然后只需要花费300毫秒来处理每个数字。这样运行大约需要1000毫秒：\n1 2 3 Collected in 1071 ms 请注意，flowOn 运算符在必须更改 CoroutineDispatcher 时使用相同的缓冲机制，但这里我们显示地请求缓冲而不更改执行上下文\n9.1、合并 当流用于表示操作或操作状态更新的部分结果时，可能不需要处理每个值，而是只处理最近的值。在这种情况下，当取值器处理中间值太慢时，可以使用合并运算符跳过中间值。在前面的例子的基础上再来修改下：\nimport kotlinx.coroutines.* import kotlinx.coroutines.flow.* import kotlin.system.* fun foo(): Flow\u0026lt;Int\u0026gt; = flow { for (i in 1..3) { delay(100) // pretend we are asynchronously waiting 100 ms emit(i) // emit next value } } fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart val time = measureTimeMillis { foo() .conflate() // conflate emissions, don\u0026#39;t process each one .collect { value -\u0026gt; delay(300) // pretend we are processing it for 300 ms println(value) } } println(\u0026#34;Collected in $time ms\u0026#34;) //sampleEnd } 可以看到，虽然第一个数字仍在处理中，但第二个数字和第三个数字已经生成，因此第二个数字被合并（丢弃），只有最近的一个数字（第三个）被交付给取值器：\n1 3 Collected in 758 ms 9.2、处理最新值 在发射端和处理端都很慢的情况下，合并是加快处理速度的一种方法。它通过丢弃发射的值来实现。另一种方法是取消慢速收集器，并在每次发出新值时重新启动它。有一系列 xxxLatest 运算符与 xxx 运算符执行相同的基本逻辑，但是在新值产生的时候取消执行其块中的代码。在前面的示例中，我们尝试将 conflate 更改为 collectLatest：\nimport kotlinx.coroutines.* import kotlinx.coroutines.flow.* import kotlin.system.* fun foo(): Flow\u0026lt;Int\u0026gt; = flow { for (i in 1..3) { delay(100) // pretend we are asynchronously waiting 100 ms emit(i) // emit next value } } fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart val time = measureTimeMillis { foo() .collectLatest { value -\u0026gt; // cancel \u0026amp; restart on the latest value println(\u0026#34;Collecting $value\u0026#34;) delay(300) // pretend we are processing it for 300 ms println(\u0026#34;Done $value\u0026#34;) } } println(\u0026#34;Collected in $time ms\u0026#34;) //sampleEnd } 由于 collectLatest 的主体需要延迟300毫秒，而每100毫秒会发出一个新值，因此我们可以看到 collectLatest 代码块得到了每一个发射值，但最终只完成了最后一个值：\nCollecting 1 Collecting 2 Collecting 3 Done 3 Collected in 741 ms 十、组合多个流 有许多方法可以组合多个流\n10.1、zip 与 Kotlin 标准库中的 Sequence.zip 扩展函数一样，流有一个 zip 运算符，用于组合两个流的相应值：\nimport kotlinx.coroutines.* import kotlinx.coroutines.flow.* fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart val nums = (1..3).asFlow() // numbers 1..3 val strs = flowOf(\u0026#34;one\u0026#34;, \u0026#34;two\u0026#34;, \u0026#34;three\u0026#34;) // strings nums.zip(strs) { a, b -\u0026gt; \u0026#34;$a -\u0026gt; $b\u0026#34; } // compose a single string .collect { println(it) } // collect and print //sampleEnd } 运行结果：\n1 -\u0026gt; one 2 -\u0026gt; two 3 -\u0026gt; three 10.2、Combine 当 flow 表示变量或操作的最新值时（参阅有关 conflation 的相关章节），可能需要执行依赖于相应流的最新值的计算，并在任何上游流发出值时重新计算它。相应的运算符族称为 combine\n例如，如果上例中的数字每300毫秒更新一次，但字符串每400毫秒更新一次，则使用 zip 运算符压缩它们仍会产生相同的结果，尽管结果是每400毫秒打印一次\n在本例中，我们使用中间运算符 onEach 来延迟每个元素，并使发出样本流的代码更具声明性，更加简短\nimport kotlinx.coroutines.* import kotlinx.coroutines.flow.* fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart val nums = (1..3).asFlow().onEach { delay(300) } // numbers 1..3 every 300 ms val strs = flowOf(\u0026#34;one\u0026#34;, \u0026#34;two\u0026#34;, \u0026#34;three\u0026#34;).onEach { delay(400) } // strings every 400 ms val startTime = System.currentTimeMillis() // remember the start time nums.zip(strs) { a, b -\u0026gt; \u0026#34;$a -\u0026gt; $b\u0026#34; } // compose a single string with \u0026#34;zip\u0026#34; .collect { value -\u0026gt; // collect and print println(\u0026#34;$value at ${System.currentTimeMillis() - startTime} ms from start\u0026#34;) } //sampleEnd } 但是，如果在此处使用 combine 运算符而不是 zip 时：\nimport kotlinx.coroutines.* import kotlinx.coroutines.flow.* fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart val nums = (1..3).asFlow().onEach { delay(300) } // numbers 1..3 every 300 ms val strs = flowOf(\u0026#34;one\u0026#34;, \u0026#34;two\u0026#34;, \u0026#34;three\u0026#34;).onEach { delay(400) } // strings every 400 ms val startTime = System.currentTimeMillis() // remember the start time nums.combine(strs) { a, b -\u0026gt; \u0026#34;$a -\u0026gt; $b\u0026#34; } // compose a single string with \u0026#34;combine\u0026#34; .collect { value -\u0026gt; // collect and print println(\u0026#34;$value at ${System.currentTimeMillis() - startTime} ms from start\u0026#34;) } //sampleEnd } 我们得到了完全不同的输出：\n1 -\u0026gt; one at 452 ms from start 2 -\u0026gt; one at 651 ms from start 2 -\u0026gt; two at 854 ms from start 3 -\u0026gt; two at 952 ms from start 3 -\u0026gt; three at 1256 ms from start 十一、展平流 流表示异步接收的值序列，因此在每个值触发对另一个值序列的请求的情况下很容易获取新值。例如，我们可以使用以下函数，该函数返回相隔500毫秒的两个字符串流：\nfun requestFlow(i: Int): Flow\u0026lt;String\u0026gt; = flow { emit(\u0026#34;$i: First\u0026#34;) delay(500) // wait 500 ms emit(\u0026#34;$i: Second\u0026#34;) } 现在，如果我们有一个包含三个整数的流，并为每个整数调用 requestFlow，如下所示：\n(1..3).asFlow().map { requestFlow(it) } 然后我们最终得到一个流（flow\u0026lt; flow\u0026lt; String \u0026raquo;），需要将其展平为单独一个流以进行进一步处理。集合和序列对此提供了 flatten 和 flatMap 运算符。然而，由于流的异步特性，它们需要不同的展开模式，因此流上有一系列 flattening 运算符\n11.1、flatMapConcat flatMapConcat 和 flattencat 运算符实现了 Concatenating 模式，它们是与序列运算符最直接的类比。它们等待内部流完成，然后开始收集下一个流，如下例所示：\nfun requestFlow(i: Int): Flow\u0026lt;String\u0026gt; = flow { emit(\u0026#34;$i: First\u0026#34;) delay(500) // wait 500 ms emit(\u0026#34;$i: Second\u0026#34;) } fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart val startTime = System.currentTimeMillis() // remember the start time (1..3).asFlow().onEach { delay(100) } // a number every 100 ms .flatMapConcat { requestFlow(it) } .collect { value -\u0026gt; // collect and print println(\u0026#34;$value at ${System.currentTimeMillis() - startTime} ms from start\u0026#34;) } //sampleEnd } flatMapConcat 的顺序特性在输出结果中清晰可见：\n1: First at 121 ms from start 1: Second at 622 ms from start 2: First at 727 ms from start 2: Second at 1227 ms from start 3: First at 1328 ms from start 3: Second at 1829 ms from start 11.2、flatMapMerge 另一种 flattening 模式是同时收集所有传入流并将其值合并到单个流中，以便尽快发出值。它由 flatMapMerge 和 flattenMerge 运算符实现。它们都接受一个可选的并发参数，该参数用于限制同时收集的并发流的数量（默认情况下等于 DEFAULT_CONCURRENCY）\nimport kotlinx.coroutines.* import kotlinx.coroutines.flow.* fun requestFlow(i: Int): Flow\u0026lt;String\u0026gt; = flow { emit(\u0026#34;$i: First\u0026#34;) delay(500) // wait 500 ms emit(\u0026#34;$i: Second\u0026#34;) } fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart val startTime = System.currentTimeMillis() // remember the start time (1..3).asFlow().onEach { delay(100) } // a number every 100 ms .flatMapMerge { requestFlow(it) } .collect { value -\u0026gt; // collect and print println(\u0026#34;$value at ${System.currentTimeMillis() - startTime} ms from start\u0026#34;) } //sampleEnd } flatMapMerge 的并发性是显而易见的：\n1: First at 136 ms from start 2: First at 231 ms from start 3: First at 333 ms from start 1: Second at 639 ms from start 2: Second at 732 ms from start 3: Second at 833 ms from start 请注意，flatMapMerge 按顺序调用其代码块（{requestFlow(it)}），但同时收集结果流，这相当于先执行序列 map{requestFlow(it)}，然后对返回值调用 flattenMerge\n11.3、flatMapLatest 与“Processing the latest value（处理最新值）”章节介绍的 collectLatest 操作符类似，存在相应的 \u0026ldquo;Latest\u0026rdquo; flattening 模式。在该模式下，一旦发出新流，将取消先前已发出的流。这通过 flatMapLatest 运算符实现\nimport kotlinx.coroutines.* import kotlinx.coroutines.flow.* fun requestFlow(i: Int): Flow\u0026lt;String\u0026gt; = flow { emit(\u0026#34;$i: First\u0026#34;) delay(500) // wait 500 ms emit(\u0026#34;$i: Second\u0026#34;) } fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart val startTime = System.currentTimeMillis() // remember the start time (1..3).asFlow().onEach { delay(100) } // a number every 100 ms .flatMapLatest { requestFlow(it) } .collect { value -\u0026gt; // collect and print println(\u0026#34;$value at ${System.currentTimeMillis() - startTime} ms from start\u0026#34;) } //sampleEnd } 本例中的输出很好的演示了 flatMapLatest 的工作原理\n1: First at 142 ms from start 2: First at 322 ms from start 3: First at 425 ms from start 3: Second at 931 ms from start 请注意，当新值到来时，flatMapLatest 将取消其块中的所有代码（{requestFlow(it)}）。requestFlow 函数本身的调用是很快速的，并非挂起函数，如果其内部不包含额外的挂起点，那么它就不能被取消，所以此处就在其内部使用了 delay 函数，使其可以达到被取消的目的\n十二、流异常 当发射器或运算符内部的代码引发异常时，流收集器可以结束运行，但会出现异常。有几种方法可以处理这些异常\n12.1、收集器 try 与 catch 收集器可以使用 kotlin 的 try/catch 代码块来处理异常\nimport kotlinx.coroutines.* import kotlinx.coroutines.flow.* //sampleStart fun foo(): Flow\u0026lt;Int\u0026gt; = flow { for (i in 1..3) { println(\u0026#34;Emitting $i\u0026#34;) emit(i) // emit next value } } fun main() = runBlocking\u0026lt;Unit\u0026gt; { try { foo().collect { value -\u0026gt; println(value) check(value \u0026lt;= 1) { \u0026#34;Collected $value\u0026#34; } } } catch (e: Throwable) { println(\u0026#34;Caught $e\u0026#34;) } } //sampleEnd 此代码成功捕获 collect 运算符中的异常，如我们所见，在此之后不再发出任何值：\nEmitting 1 1 Emitting 2 2 Caught java.lang.IllegalStateException: Collected 2 12.2、一切都已捕获 前面的示例实际上捕获了发射器或任何中间或终端运算符中发生的任何异常。例如，让我们更改代码，以便将发出的值映射到字符串，但相应的代码会产生异常：\nimport kotlinx.coroutines.* import kotlinx.coroutines.flow.* //sampleStart fun foo(): Flow\u0026lt;String\u0026gt; = flow { for (i in 1..3) { println(\u0026#34;Emitting $i\u0026#34;) emit(i) // emit next value } } .map { value -\u0026gt; check(value \u0026lt;= 1) { \u0026#34;Crashed on $value\u0026#34; } \u0026#34;string $value\u0026#34; } fun main() = runBlocking\u0026lt;Unit\u0026gt; { try { foo().collect { value -\u0026gt; println(value) } } catch (e: Throwable) { println(\u0026#34;Caught $e\u0026#34;) } } //sampleEnd 仍捕获此异常并停止收集：\nEmitting 1 string 1 Emitting 2 Caught java.lang.IllegalStateException: Crashed on 2 十三、异常透明性 但是发射器的代码如何封装其异常处理行为呢？\nflows 对于异常必须是透明的，并且在 flow{\u0026hellip;} 构建器中发射值有可能抛出异常时，异常必须显式地从 try/catch 块内部抛出。这保证了抛出异常的收集器始终可以使用 try/catch 来捕获异常，如前一个示例所示\n发射器可以使用 catch 运算符来保持此异常的透明性，并允许封装其异常处理行为。catch 运算符可以分析异常并根据捕获到的异常以不同的方式对其作出反应：\n可以使用 throw 重新引发异常 使用 catch 的 emit 可以将异常转换为值的 emission 异常可以被其他代码忽略、记录或处理 例如，让我们在捕获异常时发出一段文本：\nimport kotlinx.coroutines.* import kotlinx.coroutines.flow.* fun foo(): Flow\u0026lt;String\u0026gt; = flow { for (i in 1..3) { println(\u0026#34;Emitting $i\u0026#34;) emit(i) // emit next value } } .map { value -\u0026gt; check(value \u0026lt;= 1) { \u0026#34;Crashed on $value\u0026#34; } \u0026#34;string $value\u0026#34; } fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart foo() .catch { e -\u0026gt; emit(\u0026#34;Caught $e\u0026#34;) } // emit on exception .collect { value -\u0026gt; println(value) } //sampleEnd } 示例代码的输出结果是与之前相同的，即使我们不再在代码周围使用 try/catch\n13.1、透明捕获 catch 中间运算符遵循异常透明性，只捕获上游异常（即 catch 上所有运算符的异常，而不是 catch 下所有运算符的异常）。如果 collect{\u0026hellip;}（放在 catch 下面）抛出异常，程序将退出：\nimport kotlinx.coroutines.* import kotlinx.coroutines.flow.* //sampleStart fun foo(): Flow\u0026lt;Int\u0026gt; = flow { for (i in 1..3) { println(\u0026#34;Emitting $i\u0026#34;) emit(i) } } fun main() = runBlocking\u0026lt;Unit\u0026gt; { foo() .catch { e -\u0026gt; println(\u0026#34;Caught $e\u0026#34;) } // does not catch downstream exceptions .collect { value -\u0026gt; check(value \u0026lt;= 1) { \u0026#34;Collected $value\u0026#34; } println(value) } } //sampleEnd 尽管存在 catch 运算符，但不会打印 “Caught \u0026hellip;” 日志\n13.2、声明式捕获 我们可以将 catch 运算符的声明性与处理所有异常的愿望结合起来，方法是将 collect 运算符原先所要做的操作移动到 onEach 中，并将其放在 catch 运算符之前。此流的取值操作必须由不带参数的 collect() 函数来调用触发：\nimport kotlinx.coroutines.* import kotlinx.coroutines.flow.* fun foo(): Flow\u0026lt;Int\u0026gt; = flow { for (i in 1..3) { println(\u0026#34;Emitting $i\u0026#34;) emit(i) } } fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart foo() .onEach { value -\u0026gt; check(value \u0026lt;= 1) { \u0026#34;Collected $value\u0026#34; } println(value) } .catch { e -\u0026gt; println(\u0026#34;Caught $e\u0026#34;) } .collect() //sampleEnd } 现在我们可以看到打印了一条 “Caught \u0026hellip;” 消息，至此我们捕获了所有异常，而无需显式使用 try/catch\n十四、流完成 当流收集完成时（正常或异常），它可能需要执行一个操作。正如你可能已经注意到的，它可以通过两种方式完成：命令式或声明式\n14.1、命令式 finally 块 除了 try/catch 外，收集器还可以使用 finally 在收集完成时执行操作\nimport kotlinx.coroutines.* import kotlinx.coroutines.flow.* //sampleStart fun foo(): Flow\u0026lt;Int\u0026gt; = (1..3).asFlow() fun main() = runBlocking\u0026lt;Unit\u0026gt; { try { foo().collect { value -\u0026gt; println(value) } } finally { println(\u0026#34;Done\u0026#34;) } } //sampleEnd 此代码打印 fon() 流生成的三个数字，之后跟随 \u0026ldquo;Done\u0026rdquo; 字符串\n1 2 3 Done 14.2、声明式处理 对于声明性方法，flow 有一个 onCompletion 中间运算符，该运算符在流完全收集后调用\n前面的示例可以使用 onCompletion 运算符重写，并生成相同的输出：\nimport kotlinx.coroutines.* import kotlinx.coroutines.flow.* fun foo(): Flow\u0026lt;Int\u0026gt; = (1..3).asFlow() fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart foo() .onCompletion { println(\u0026#34;Done\u0026#34;) } .collect { value -\u0026gt; println(value) } //sampleEnd } onCompletion 的主要优点是包含一个 lambda 参数，该 lambda 包含一个可空的 Throwable 参数，该 Throwable 参数可用于确定流收集是正常完成还是异常完成。在以下示例中，foo() 流在发出数字1后引发异常：\nimport kotlinx.coroutines.* import kotlinx.coroutines.flow.* //sampleStart fun foo(): Flow\u0026lt;Int\u0026gt; = flow { emit(1) throw RuntimeException() } fun main() = runBlocking\u0026lt;Unit\u0026gt; { foo() .onCompletion { cause -\u0026gt; if (cause != null) println(\u0026#34;Flow completed exceptionally\u0026#34;) } .catch { cause -\u0026gt; println(\u0026#34;Caught exception\u0026#34;) } .collect { value -\u0026gt; println(value) } } //sampleEnd 如你所料，将打印：\n1 Flow completed exceptionally Caught exception 与 catch 运算符不同，onCompletion 运算符不处理异常。正如我们从上面的示例代码中看到的，异常仍然会流向下游。它将被传递给其他完成 onCompletion 运算符，并可以使用 catch 运算符进行处理\n14.3、仅限上游异常 就像 catch 操作符一样，onCompletion 只看到来自上游的异常，而看不到下游的异常。例如，运行以下代码：\nimport kotlinx.coroutines.* import kotlinx.coroutines.flow.* //sampleStart fun foo(): Flow\u0026lt;Int\u0026gt; = (1..3).asFlow() fun main() = runBlocking\u0026lt;Unit\u0026gt; { foo() .onCompletion { cause -\u0026gt; println(\u0026#34;Flow completed with $cause\u0026#34;) } .collect { value -\u0026gt; check(value \u0026lt;= 1) { \u0026#34;Collected $value\u0026#34; } println(value) } } //sampleEnd 我们可以看到 completion cause 为空，但流收集失败并抛出异常:\n1 Flow completed with null Exception in thread \u0026#34;main\u0026#34; java.lang.IllegalStateException: Collected 2 十五、命令式还是声明式 现在我们知道如何收集流，并以命令式和声明式的方式处理它的完成和异常。这里很自然的就有了个问题，应该首选哪种方法呢？为什么？作为一个库，我们不提倡任何特定的方法，并且相信这两种方式都是有效的，应该根据你自己的偏好和代码风格来选择\n十六、启动流 很容易使用流来表示来自某个数据源的异步事件。在这种情况下，我们需要一个模拟的 addEventListener 函数，该函数将一段代码注册为对传入事件的响应，并继续进一步工作。onEach 运算符可以担任此角色。然而，onEach 是一个中间运算符。我们还需要一个终端运算符来收集数据。否则，只注册 onEach 是没有效果的\n如果在 onEach 之后使用 collect 终端运算符，则在 collect 之后的代码将等待流被收集完成后再运行：\nimport kotlinx.coroutines.* import kotlinx.coroutines.flow.* //sampleStart // Imitate a flow of events fun events(): Flow\u0026lt;Int\u0026gt; = (1..3).asFlow().onEach { delay(100) } fun main() = runBlocking\u0026lt;Unit\u0026gt; { events() .onEach { event -\u0026gt; println(\u0026#34;Event: $event\u0026#34;) } .collect() // \u0026lt;--- Collecting the flow waits println(\u0026#34;Done\u0026#34;) } //sampleEnd 如你所见，将打印\nEvent: 1 Event: 2 Event: 3 Done launchIn 终端运算符在这里是很实用的。通过将 collect 替换为 launchIn，我们可以在单独的协程中启动收集流数据的操作，以便立即继续执行下一步的代码：\nimport kotlinx.coroutines.* import kotlinx.coroutines.flow.* // Imitate a flow of events fun events(): Flow\u0026lt;Int\u0026gt; = (1..3).asFlow().onEach { delay(100) } //sampleStart fun main() = runBlocking\u0026lt;Unit\u0026gt; { events() .onEach { event -\u0026gt; println(\u0026#34;Event: $event\u0026#34;) } .launchIn(this) // \u0026lt;--- Launching the flow in a separate coroutine println(\u0026#34;Done\u0026#34;) } //sampleEnd 运行结果：\nDone Event: 1 Event: 2 Event: 3 launchIn 所需的参数用于指定启动用于收集流的协程的作用域。在上面的示例中，此作用域来自 runBlocking，因此当流运行时，runBlocking 作用域等待其子协程完成，并阻止主函数返回和终止此示例代码\n在实际应用程序中，作用域将来自生命周期是有限的实体。一旦此实体的生命周期终止，相应的作用域将被取消，从而取消相应流的收集。onEach { \u0026hellip; }.launchIn(scope) 的工作方式与 addEventListener 类似。但是，不需要相应的 removeEventListener 函数，因为 cancellation 和结构化并发可以达到这个目的\n请注意，launchIn 还返回一个 Job 对象，该 Job 仅可用于取消相应的流数据收集协程，而不取消整个作用域或加入它\n十七、Flow and Reactive Streams For those who are familiar with Reactive Streams or reactive frameworks such as RxJava and project Reactor, design of the Flow may look very familiar.\nIndeed, its design was inspired by Reactive Streams and its various implementations. But Flow main goal is to have as simple design as possible, be Kotlin and suspension friendly and respect structured concurrency. Achieving this goal would be impossible without reactive pioneers and their tremendous work. You can read the complete story in Reactive Streams and Kotlin Flows article.\nWhile being different, conceptually, Flow is a reactive stream and it is possible to convert it to the reactive (spec and TCK compliant) Publisher and vice versa. Such converters are provided by kotlinx.coroutines out-of-the-box and can be found in corresponding reactive modules (kotlinx-coroutines-reactive for Reactive Streams, kotlinx-coroutines-reactor for Project Reactor and kotlinx-coroutines-rx2 for RxJava2). Integration modules include conversions from and to Flow, integration with Reactor\u0026rsquo;s Context and suspension-friendly ways to work with various reactive entities.\n","permalink":"http://localhost:1313/hugo-blog/public/post/kotlin/kotlin-%E5%8D%8F%E7%A8%8B%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A35%E5%BC%82%E6%AD%A5%E6%B5%81/","tags":[],"title":"Kotlin 协程官方文档（5）异步流"},{"categories":[],"content":" 公众号：字节数组 希望对你有所帮助 🤣🤣\n最近一直在了解关于 Kotlin协程 的知识，那最好的学习资料自然是官方提供的学习文档了，看了看后我就萌生了翻译官方文档的想法。前后花了要接近一个月时间，一共九篇文章，在这里也分享出来，希望对读者有所帮助。个人知识所限，有些翻译得不是太顺畅，也希望读者能提出意见\n协程官方文档：coroutines-guide Deferred 值提供了在协程之间传递单个值的方便方法，而通道（Channels）提供了一种传输值流的方法\n一、通道基础 通道在概念上非常类似于 BlockingQueue，它们之间的一个关键区别是：通道有一个挂起的 send 函数和一个挂起的 receive 函数，而不是一个阻塞的 put 操作和一个阻塞的 take 操作\nimport kotlinx.coroutines.* import kotlinx.coroutines.channels.* fun main() = runBlocking { //sampleStart val channel = Channel\u0026lt;Int\u0026gt;() launch { // this might be heavy CPU-consuming computation or async logic, we\u0026#39;ll just send five squares for (x in 1..5) channel.send(x * x) } // here we print five received integers: repeat(5) { println(channel.receive()) } println(\u0026#34;Done!\u0026#34;) //sampleEnd } 输出结果是:\n1 4 9 16 25 Done! 二、关闭和迭代通道 与队列不同，通道可以关闭，以此来表明元素已发送完成。在接收方，使用常规的 for 循环从通道接收元素是比较方便的\n从概念上讲，close 类似于向通道发送一个特殊的 cloase 标记。一旦接收到这个 close 标记，迭代就会停止，因此可以保证接收到 close 之前发送的所有元素：\nimport kotlinx.coroutines.* import kotlinx.coroutines.channels.* fun main() = runBlocking { //sampleStart val channel = Channel\u0026lt;Int\u0026gt;() launch { for (x in 1..5) channel.send(x * x) channel.close() // we\u0026#39;re done sending } // here we print received values using `for` loop (until the channel is closed) for (y in channel) println(y) println(\u0026#34;Done!\u0026#34;) //sampleEnd } 三、构建通道生产者 协程生成元素序列(sequence )的模式非常常见。这是可以经常在并发编程中发现的生产者-消费者模式的一部分。你可以将这样一个生产者抽象为一个以 channel 为参数的函数，但这与必须从函数返回结果的常识相反\n有一个方便的名为 product 的协程构造器，它使得在 producer 端执行该操作变得很容易；还有一个扩展函数 consumerEach，它替换了consumer 端的 for 循环：\nimport kotlinx.coroutines.* import kotlinx.coroutines.channels.* fun CoroutineScope.produceSquares(): ReceiveChannel\u0026lt;Int\u0026gt; = produce { for (x in 1..5) send(x * x) } fun main() = runBlocking { //sampleStart val squares = produceSquares() squares.consumeEach { println(it) } println(\u0026#34;Done!\u0026#34;) //sampleEnd } 四、管道 管道是一种模式，是一个协程正在生成的可能是无穷多个元素的值流\nfun CoroutineScope.produceNumbers() = produce\u0026lt;Int\u0026gt; { var x = 1 while (true) send(x++) // infinite stream of integers starting from 1 } 存在一个或多个协程对值流进行取值，进行一些处理并产生一些其它结果。在下面的示例中，每个返回值也是入参值（数字）的平方值\nfun CoroutineScope.square(numbers: ReceiveChannel\u0026lt;Int\u0026gt;): ReceiveChannel\u0026lt;Int\u0026gt; = produce { for (x in numbers) send(x * x) } 启动并连接整个管道：\nimport kotlinx.coroutines.* import kotlinx.coroutines.channels.* fun main() = runBlocking { //sampleStart val numbers = produceNumbers() // produces integers from 1 and on val squares = square(numbers) // squares integers repeat(5) { println(squares.receive()) // print first five } println(\u0026#34;Done!\u0026#34;) // we are done coroutineContext.cancelChildren() // cancel children coroutines //sampleEnd } fun CoroutineScope.produceNumbers() = produce\u0026lt;Int\u0026gt; { var x = 1 while (true) send(x++) // infinite stream of integers starting from 1 } fun CoroutineScope.square(numbers: ReceiveChannel\u0026lt;Int\u0026gt;): ReceiveChannel\u0026lt;Int\u0026gt; = produce { for (x in numbers) send(x * x) } 创建协程的所有函数都被定义为 CoroutineScope 的扩展，因此我们可以依赖结构化并发来确保应用程序中没有延迟的全局协程\n五、使用管道的素数 让我们以一个使用协程管道生成素数的例子，将管道发挥到极致。我们从一个无限的数字序列开始\nfun CoroutineScope.numbersFrom(start: Int) = produce\u0026lt;Int\u0026gt; { var x = start while (true) send(x++) // infinite stream of integers from start } 以下管道过滤传入的数字流，删除所有可被给定素数整除的数字：\nfun CoroutineScope.filter(numbers: ReceiveChannel\u0026lt;Int\u0026gt;, prime: Int) = produce\u0026lt;Int\u0026gt; { for (x in numbers) if (x % prime != 0) send(x) } 现在，我们通过从2开始一个数字流，从当前通道获取一个质数，并为找到的每个质数启动新的管道：\nnumbersFrom(2) -\u0026gt; filter(2) -\u0026gt; filter(3) -\u0026gt; filter(5) -\u0026gt; filter(7) ... 下面的示例代码打印了前十个质数，在主线程的上下文中运行整个管道。因为所有的协程都是在主 runBlocking 协程的范围内启动的，所以我们不必保留所有已启动的协程的显式引用。我们使用扩展函数 cancelChildren 来取消打印前十个质数后的所有子协程\nimport kotlinx.coroutines.* import kotlinx.coroutines.channels.* fun main() = runBlocking { //sampleStart var cur = numbersFrom(2) repeat(10) { val prime = cur.receive() println(prime) cur = filter(cur, prime) } coroutineContext.cancelChildren() // cancel all children to let main finish //sampleEnd } fun CoroutineScope.numbersFrom(start: Int) = produce\u0026lt;Int\u0026gt; { var x = start while (true) send(x++) // infinite stream of integers from start } fun CoroutineScope.filter(numbers: ReceiveChannel\u0026lt;Int\u0026gt;, prime: Int) = produce\u0026lt;Int\u0026gt; { for (x in numbers) if (x % prime != 0) send(x) } 运行结果：\n2 3 5 7 11 13 17 19 23 29 注意，你可以使用标准库中的 iterator 协程构造器来构建相同的管道。将 product 替换为 iterator，send 替换为 yield，receive 替换为 next，ReceiveChannel 替换为 iterator，并去掉协程作用域。你也不需要再使用 runBlocking 。但是，使用如上所示的通道的管道的好处是，如果在 Dispatchers.Default 上下文中运行它，它实际上可以利用多个 CPU 来执行代码\n但无论如何，如上所述的替代方案也是一个非常不切实际的来寻找素数的方法。实际上，管道确实涉及一些其他挂起调用（如对远程服务的异步调用），并且这些管道不能使用 sequence/iterator 来构建，因为它们不允许任意挂起，而 product 是完全异步的\n六、扇出 多个协程可以从同一个通道接收数据，在它们之间分配任务。让我们从一个周期性地生成整数（每秒10个数）的 producer 协程开始：\nfun CoroutineScope.produceNumbers() = produce\u0026lt;Int\u0026gt; { var x = 1 // start from 1 while (true) { send(x++) // produce next delay(100) // wait 0.1s } } 然后我们可以有多个处理器(processor)协程。在本例中，他们只需打印他们的 id 和接收的数字：\nfun CoroutineScope.launchProcessor(id: Int, channel: ReceiveChannel\u0026lt;Int\u0026gt;) = launch { for (msg in channel) { println(\u0026#34;Processor #$id received $msg\u0026#34;) } } 现在让我们启动5个处理器，让它们工作几乎一秒钟。看看会发生什么：\nimport kotlinx.coroutines.* import kotlinx.coroutines.channels.* fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart val producer = produceNumbers() repeat(5) { launchProcessor(it, producer) } delay(950) producer.cancel() // cancel producer coroutine and thus kill them all //sampleEnd } fun CoroutineScope.produceNumbers() = produce\u0026lt;Int\u0026gt; { var x = 1 // start from 1 while (true) { send(x++) // produce next delay(100) // wait 0.1s } } fun CoroutineScope.launchProcessor(id: Int, channel: ReceiveChannel\u0026lt;Int\u0026gt;) = launch { for (msg in channel) { println(\u0026#34;Processor #$id received $msg\u0026#34;) } } 尽管接收每个特定整数的处理器 id 可能不同，但运行结果将类似于以下输出：\nProcessor #2 received 1 Processor #4 received 2 Processor #0 received 3 Processor #1 received 4 Processor #3 received 5 Processor #2 received 6 Processor #4 received 7 Processor #0 received 8 Processor #1 received 9 Processor #3 received 10 请注意，取消 producer 协程会关闭其通道，从而最终终止 processor 协程正在执行的通道上的迭代\n另外，请注意我们如何使用 for 循环在通道上显式迭代以在 launchProcessor 代码中执行 fan-out。与 consumeEach 不同，这个 for 循环模式在多个协程中使用是完全安全的。如果其中一个 processor 协程失败，则其他处理器仍将处理通道，而通过 consumeEach 写入的处理器总是在正常或异常完成时消费（取消）底层通道\n七、扇入 多个协程可以发送到同一个通道。例如，有一个字符串通道和一个挂起函数，函数以指定的延迟将指定的字符串重复发送到此通道：\nsuspend fun sendString(channel: SendChannel\u0026lt;String\u0026gt;, s: String, time: Long) { while (true) { delay(time) channel.send(s) } } 现在，让我们看看如果启动两个协程来发送字符串会发生什么情况（在本例中，我们将它们作为主协程的子协程，在主线程的上下文中启动）：\nimport kotlinx.coroutines.* import kotlinx.coroutines.channels.* fun main() = runBlocking { //sampleStart val channel = Channel\u0026lt;String\u0026gt;() launch { sendString(channel, \u0026#34;foo\u0026#34;, 200L) } launch { sendString(channel, \u0026#34;BAR!\u0026#34;, 500L) } repeat(6) { // receive first six println(channel.receive()) } coroutineContext.cancelChildren() // cancel all children to let main finish //sampleEnd } suspend fun sendString(channel: SendChannel\u0026lt;String\u0026gt;, s: String, time: Long) { while (true) { delay(time) channel.send(s) } } 运行结果：\nfoo foo BAR! foo foo BAR! 八、带缓冲的通道 到目前为止显示的通道都没有缓冲区。无缓冲通道在发送方和接收方同时调用发送和接收操作时传输元素。如果先调用 send，则在调用 receive 之前会将其挂起；如果先调用 receive ，则在调用 send 之前会将其挂起\nChannel() 工厂函数和 produce 构建器都采用可选的参数 capacity 来指定缓冲区大小。 缓冲用于允许发送者在挂起之前发送多个元素，类似于具有指定容量的 BlockingQueue，它在缓冲区已满时才阻塞\n查看以下代码的效果：\nimport kotlinx.coroutines.* import kotlinx.coroutines.channels.* fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart val channel = Channel\u0026lt;Int\u0026gt;(4) // create buffered channel val sender = launch { // launch sender coroutine repeat(10) { println(\u0026#34;Sending $it\u0026#34;) // print before sending each element channel.send(it) // will suspend when buffer is full } } // don\u0026#39;t receive anything... just wait.... delay(1000) sender.cancel() // cancel sender coroutine //sampleEnd } 使用了容量为4的缓冲通道，所以将打印五次：\nSending 0 Sending 1 Sending 2 Sending 3 Sending 4 前四个元素被添加到缓冲区内，sender 在尝试发送第五个元素时挂起\n九、通道是公平的 对通道的发送和接收操作，对于从多个协程调用它们的顺序是公平的。它们按先入先出的顺序提供，例如，先调用 receive 的协程先获取到元素。在下面的示例中，两个协程 “ping” 和 “pong” 从共享的 “table” 通道接收 “ball” 对象\nimport kotlinx.coroutines.* import kotlinx.coroutines.channels.* //sampleStart data class Ball(var hits: Int) fun main() = runBlocking { val table = Channel\u0026lt;Ball\u0026gt;() // a shared table launch { player(\u0026#34;ping\u0026#34;, table) } launch { player(\u0026#34;pong\u0026#34;, table) } table.send(Ball(0)) // serve the ball delay(1000) // delay 1 second coroutineContext.cancelChildren() // game over, cancel them } suspend fun player(name: String, table: Channel\u0026lt;Ball\u0026gt;) { for (ball in table) { // receive the ball in a loop ball.hits++ println(\u0026#34;$name $ball\u0026#34;) delay(300) // wait a bit table.send(ball) // send the ball back } } //sampleEnd “ping” 协程首先开始运行，所以它是第一个接收到 ball 的。即使 “ping” 协程在将 ball 重新送回给 table 后又立即开始进行 receive，但 ball 还是会被 “pong” 接收到，因为它已经先在等待接收了：\nping Ball(hits=1) pong Ball(hits=2) ping Ball(hits=3) pong Ball(hits=4) 请注意，有时由于所使用的执行者的性质，通道可能会产生看起来不公平的执行效果。有关详细信息，请参阅此 issue 十、计时器通道 计时器通道是一种特殊的会合(rendezvous)通道，自该通道的最后一次消耗以来，每次给定的延迟时间结束后都将返回 Unit 值。尽管它看起来是无用处的，但它是一个有用的构建块，可以创建复杂的基于时间的 produce 管道和进行窗口化操作以及其它时间相关的处理。计时器通道可用于 select 执行 “on tick” 操作\n要创建这样的通道，请使用工厂方法 ticker。如果不需要通道发送更多元素了，请对其使用 ReceiveChannel.cancel 取消发送\n现在让我们看看它在实践中是如何工作的：\nimport kotlinx.coroutines.* import kotlinx.coroutines.channels.* fun main() = runBlocking\u0026lt;Unit\u0026gt; { val tickerChannel = ticker(delayMillis = 100, initialDelayMillis = 0) // create ticker channel var nextElement = withTimeoutOrNull(1) { tickerChannel.receive() } println(\u0026#34;Initial element is available immediately: $nextElement\u0026#34;) // initial delay hasn\u0026#39;t passed yet nextElement = withTimeoutOrNull(50) { tickerChannel.receive() } // all subsequent elements has 100ms delay println(\u0026#34;Next element is not ready in 50 ms: $nextElement\u0026#34;) nextElement = withTimeoutOrNull(60) { tickerChannel.receive() } println(\u0026#34;Next element is ready in 100 ms: $nextElement\u0026#34;) // Emulate large consumption delays println(\u0026#34;Consumer pauses for 150ms\u0026#34;) delay(150) // Next element is available immediately nextElement = withTimeoutOrNull(1) { tickerChannel.receive() } println(\u0026#34;Next element is available immediately after large consumer delay: $nextElement\u0026#34;) // Note that the pause between `receive` calls is taken into account and next element arrives faster nextElement = withTimeoutOrNull(60) { tickerChannel.receive() } println(\u0026#34;Next element is ready in 50ms after consumer pause in 150ms: $nextElement\u0026#34;) tickerChannel.cancel() // indicate that no more elements are needed } 运行结果：\nInitial element is available immediately: kotlin.Unit Next element is not ready in 50 ms: null Next element is ready in 100 ms: kotlin.Unit Consumer pauses for 150ms Next element is available immediately after large consumer delay: kotlin.Unit Next element is ready in 50ms after consumer pause in 150ms: kotlin.Unit 请注意，ticker 能感知到消费端可能处于暂停状态，并且在默认的情况下，如果发生暂停，将会延迟下一个元素的生成，尝试保持生成元素的固定速率\n可选的，ticker 函数的 mode 参数可以指定为 TickerMode.FIXED_DELAY，以保证元素之间的固定延迟\n","permalink":"http://localhost:1313/hugo-blog/public/post/kotlin/kotlin-%E5%8D%8F%E7%A8%8B%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A36%E9%80%9A%E9%81%93/","tags":[],"title":"Kotlin 协程官方文档（6）通道"},{"categories":[],"content":" 公众号：字节数组 希望对你有所帮助 🤣🤣\n最近一直在了解关于 Kotlin协程 的知识，那最好的学习资料自然是官方提供的学习文档了，看了看后我就萌生了翻译官方文档的想法。前后花了要接近一个月时间，一共九篇文章，在这里也分享出来，希望对读者有所帮助。个人知识所限，有些翻译得不是太顺畅，也希望读者能提出意见\n协程官方文档：coroutines-guide 本节讨论协程关于异常的处理和取消异常。我们已经知道，取消协程会使得在挂起点抛出 CancellationException，而协程机制会忽略这个异常。但是，如果在取消期间抛出异常，或者协程的多个子协程抛出异常，此时会发生什么情况呢?\n一、异常的传播 协程构建器有两种类型：自动传播异常（launch 和 actor）和向用户公开异常（async 和 product）。前者将异常视为未捕获异常，类似于 Java 的 Thread.uncaughtExceptionHandler，而后者则需要由开发者自己来处理最终的异常，例如通过 await 或 receive（product 和 receive 在 Channels 章节介绍）\n可以通过在 GlobalScope 创建协程的简单示例来演示：\nimport kotlinx.coroutines.* fun main() = runBlocking { val job = GlobalScope.launch { println(\u0026#34;Throwing exception from launch\u0026#34;) throw IndexOutOfBoundsException() // Will be printed to the console by Thread.defaultUncaughtExceptionHandler } job.join() println(\u0026#34;Joined failed job\u0026#34;) val deferred = GlobalScope.async { println(\u0026#34;Throwing exception from async\u0026#34;) throw ArithmeticException() // Nothing is printed, relying on user to call await } try { deferred.await() println(\u0026#34;Unreached\u0026#34;) } catch (e: ArithmeticException) { println(\u0026#34;Caught ArithmeticException\u0026#34;) } } 运行结果：\nThrowing exception from launch Exception in thread \u0026#34;DefaultDispatcher-worker-2 @coroutine#2\u0026#34; java.lang.IndexOutOfBoundsException Joined failed job Throwing exception from async Caught ArithmeticException 二、CoroutineExceptionHandler 如果不想将所有的异常都打印到控制台上，CoroutineExceptionHandler 上下文元素可以作为协程全局通用的 catch 块，在这里进行自定义日志记录或异常处理。它类似于对线程使用 Thread.uncaughtExceptionHandler\n在 JVM 上，可以通过 ServiceLoader 注册 CoroutineExceptionHandler 来重新定义所有协程的全局异常处理器。全局异常处理程序类似于 Thread.defaultUncaughtExceptionHandler ，后者在没有注册其它特定处理程序时使用。在 Android 上，uncaughtExceptionPreHandler 作为全局协程异常处理程序存在\nCoroutineExceptionHandler 只在预计不会由用户处理的异常上调用，因此在 async 这类协程构造器中注册它没有任何效果\nimport kotlinx.coroutines.* fun main() = runBlocking { //sampleStart val handler = CoroutineExceptionHandler { _, exception -\u0026gt; println(\u0026#34;Caught $exception\u0026#34;) } val job = GlobalScope.launch(handler) { throw AssertionError() } val deferred = GlobalScope.async(handler) { throw ArithmeticException() // Nothing will be printed, relying on user to call deferred.await() } joinAll(job, deferred) //sampleEnd } 运行结果：\nCaught java.lang.AssertionError 三、取消和异常 取消和异常是紧密联系的。协程在内部使用 CancellationException 来进行取消，所有处理程序都会忽略这类异常，因此它们仅用作调试信息的额外来源，这些信息可以用 catch 块捕获。当使用 Job.cancel 取消协程时，协程将停止运行，但不会取消其父协程\nimport kotlinx.coroutines.* fun main() = runBlocking { //sampleStart val job = launch { val child = launch { try { delay(Long.MAX_VALUE) } finally { println(\u0026#34;Child is cancelled\u0026#34;) } } yield() println(\u0026#34;Cancelling child\u0026#34;) child.cancel() child.join() yield() println(\u0026#34;Parent is not cancelled\u0026#34;) } job.join() //sampleEnd } 运行结果：\nCancelling child Child is cancelled Parent is not cancelled 如果协程遇到 CancellationException 以外的异常，它将用该异常取消其父级。无法重写此行为，它用于为不依赖于 CoroutineExceptionHandler 实现的结构化并发，为之提供稳定的协程层次结构。当父级的所有子级终止时，父级将处理原始异常\n这也是为什么在这些示例中，总是将 CoroutineExceptionHandler 作为参数传递给在 GlobalScope 中创建的协程中的原因。将 CoroutineExceptionHandler 设置给主 runBlocking 范围内启动的协程是没有意义的，因为尽管设置了异常处理器，主协程在其子级异常抛出后仍将被取消\nimport kotlinx.coroutines.* fun main() = runBlocking { //sampleStart val handler = CoroutineExceptionHandler { _, exception -\u0026gt; println(\u0026#34;Caught $exception\u0026#34;) } val job = GlobalScope.launch(handler) { launch { // the first child try { delay(Long.MAX_VALUE) } finally { withContext(NonCancellable) { println(\u0026#34;Children are cancelled, but exception is not handled until all children terminate\u0026#34;) delay(100) println(\u0026#34;The first child finished its non cancellable block\u0026#34;) } } } launch { // the second child delay(10) println(\u0026#34;Second child throws an exception\u0026#34;) throw ArithmeticException() } } job.join() //sampleEnd } 运行结果：\nSecond child throws an exception Children are cancelled, but exception is not handled until all children terminate The first child finished its non cancellable block Caught java.lang.ArithmeticException CoroutineExceptionHandler 将等到所有子协程运行结束后再回调。second child 抛出异常后将联动导致 first child 结束运行，之后再将异常交予 CoroutineExceptionHandler 处理\n四、异常聚合 如果一个协程的多个子协程抛出异常会发生什么情况呢？一般的规则是“第一个异常会获胜”，因此第一个抛出的异常将传递给异常处理器进行处理，但这也有可能会导致异常丢失。例如，如果在某个协程在抛出异常后，第二个协程在其 finally 块中抛出异常，此时第二个协程的异常将不会传递给 CoroutineExceptionHandler\n其中一个解决方案是分别抛出每个异常。await 应该有相同的机制来避免行为不一致，这将导致协程的实现细节（无论它是否将部分工作委托给其子级）泄漏给其异常处理器\nimport kotlinx.coroutines.* import java.io.* fun main() = runBlocking { val handler = CoroutineExceptionHandler { _, exception -\u0026gt; println(\u0026#34;Caught $exception with suppressed ${exception.suppressed.contentToString()}\u0026#34;) } val job = GlobalScope.launch(handler) { launch { try { delay(Long.MAX_VALUE) } finally { throw ArithmeticException() } } launch { delay(100) throw IOException() } delay(Long.MAX_VALUE) } job.join() } 注意：以上代码只能在支持 suppressed exceptions 的 JDK7+ 版本上正常运行\n运行结果：\nCaught java.io.IOException with suppressed [java.lang.ArithmeticException] 导致协程停止的异常在默认情况下是会被透传，不会被包装的\nimport kotlinx.coroutines.* import java.io.* fun main() = runBlocking { //sampleStart val handler = CoroutineExceptionHandler { _, exception -\u0026gt; println(\u0026#34;Caught original $exception\u0026#34;) } val job = GlobalScope.launch(handler) { val inner = launch { launch { launch { throw IOException() } } } try { inner.join() } catch (e: CancellationException) { println(\u0026#34;Rethrowing CancellationException with original cause\u0026#34;) throw e } } job.join() //sampleEnd } 运行结果：\nRethrowing CancellationException with original cause Caught original java.io.IOException 即使捕获到了 inner 被取消的异常信息，但最终传递给 CoroutineExceptionHandler 的还是 inner 内部真实的异常信息\n五、Supervision 正如我们之前所研究的，取消是一种双向关系，会在整个协程层次结构中传播。但如果需要单向取消呢？\n此类需求的一个很好的例子在某个范围内定义了 Job 的 UI 组件。如果 UI 组件的任意一个子任务失败了，此时并不一定需要取消（实际上是终止）整个 UI 组件。但是如果 UI 组件的生命周期结束了（并且取消了它的 Job），那么就必须取消所有子 Job， 因为它们的结果不再是必需的\n另一个例子是一个服务器进程，它生成几个子 Job 并且需要监测它们的执行，跟踪它们的失败时机，并且仅重新启动那么失败的子 Job\n5.1、SupervisorJob 出于这些目的，可以使用 SupervisorJob。它类似于常规的 Job，唯一的例外是取消操作只向下传播。用一个例子很容易演示：\nimport kotlinx.coroutines.* fun main() = runBlocking { val supervisor = SupervisorJob() with(CoroutineScope(coroutineContext + supervisor)) { // launch the first child -- its exception is ignored for this example (don\u0026#39;t do this in practice!) val firstChild = launch(CoroutineExceptionHandler { _, _ -\u0026gt; }) { println(\u0026#34;First child is failing\u0026#34;) throw AssertionError(\u0026#34;First child is cancelled\u0026#34;) } // launch the second child val secondChild = launch { firstChild.join() // Cancellation of the first child is not propagated to the second child println(\u0026#34;First child is cancelled: ${firstChild.isCancelled}, but second one is still active\u0026#34;) try { delay(Long.MAX_VALUE) } finally { // But cancellation of the supervisor is propagated println(\u0026#34;Second child is cancelled because supervisor is cancelled\u0026#34;) } } // wait until the first child fails \u0026amp; completes firstChild.join() println(\u0026#34;Cancelling supervisor\u0026#34;) supervisor.cancel() secondChild.join() } } 运行结果：\nFirst child is failing First child is cancelled: true, but second one is still active Cancelling supervisor Second child is cancelled because supervisor is cancelled 5.2、supervisorScope 对于作用域并发，可以使用 supervisorScope 代替 coroutineScope 来实现相同的目的。它只在一个方向上传播取消操作，并且仅在自身失败时才取消所有子级。它也像 coroutineScope 一样在结束运行之前等待所有的子元素结束运行\nimport kotlin.coroutines.* import kotlinx.coroutines.* fun main() = runBlocking { try { supervisorScope { val child = launch { try { println(\u0026#34;Child is sleeping\u0026#34;) delay(Long.MAX_VALUE) } finally { println(\u0026#34;Child is cancelled\u0026#34;) } } // Give our child a chance to execute and print using yield yield() println(\u0026#34;Throwing exception from scope\u0026#34;) throw AssertionError() } } catch(e: AssertionError) { println(\u0026#34;Caught assertion error\u0026#34;) } } 输出结果：\nChild is sleeping Throwing exception from scope Child is cancelled Caught assertion error 以下例子展示了 supervisorScope 中取消操作的单向传播性，子协程的异常不会导致其它子协程取消\nfun main() = runBlocking { supervisorScope { val child1 = launch { try { for (time in 1..Long.MAX_VALUE) { println(\u0026#34;Child 1 is printing: $time\u0026#34;) delay(1000) } } finally { println(\u0026#34;Child 1 is cancelled\u0026#34;) } } val child2 = launch { println(\u0026#34;Child 2 is sleeping\u0026#34;) delay(3000) println(\u0026#34;Child 2 throws an exception\u0026#34;) throw AssertionError() } } } 运行结果：\nChild 1 is printing: 1 Child 2 is sleeping Child 1 is printing: 2 Child 1 is printing: 3 Child 1 is printing: 4 Child 2 throws an exception Exception in thread \u0026#34;main\u0026#34; java.lang.AssertionError Child 1 is printing: 5 Child 1 is printing: 6 ······ 5.3、监督协程中的异常 常规 job 和 supervisor job 的另一个重要区别在于异常处理。每个子级都应该通过异常处理机制自己处理其异常。这种差异来自于这样一个事实：supervisorScope 中子元素的失败不会传导给父级\nimport kotlin.coroutines.* import kotlinx.coroutines.* fun main() = runBlocking { val handler = CoroutineExceptionHandler { _, exception -\u0026gt; println(\u0026#34;Caught $exception\u0026#34;) } supervisorScope { val child = launch(handler) { println(\u0026#34;Child throws an exception\u0026#34;) throw AssertionError() } println(\u0026#34;Scope is completing\u0026#34;) } println(\u0026#34;Scope is completed\u0026#34;) } 运行结果：\nScope is completing Child throws an exception Caught java.lang.AssertionError Scope is completed ","permalink":"http://localhost:1313/hugo-blog/public/post/kotlin/kotlin-%E5%8D%8F%E7%A8%8B%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A37%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/","tags":[],"title":"Kotlin 协程官方文档（7）异常处理"},{"categories":[],"content":" 公众号：字节数组 希望对你有所帮助 🤣🤣\n最近一直在了解关于 Kotlin协程 的知识，那最好的学习资料自然是官方提供的学习文档了，看了看后我就萌生了翻译官方文档的想法。前后花了要接近一个月时间，一共九篇文章，在这里也分享出来，希望对读者有所帮助。个人知识所限，有些翻译得不是太顺畅，也希望读者能提出意见\n协程官方文档：coroutines-guide 可以使用多线程调度器（如 Dispatchers.Default）并发执行协程，它呈现了所有常见的并发问题。主要问题是对共享可变状态的同步访问。在协程作用域中解决这个问题的一些方法类似于多线程世界中的方法，但有一些其它方法是独有的\n一、一个问题 让我们启动一百个协程，都做同样的操作一千次。我们还将计算它们的完成时间，以便进一步比较：\nsuspend fun massiveRun(action: suspend () -\u0026gt; Unit) { val n = 100 // number of coroutines to launch val k = 1000 // times an action is repeated by each coroutine val time = measureTimeMillis { coroutineScope { // scope for coroutines repeat(n) { launch { repeat(k) { action() } } } } } println(\u0026#34;Completed ${n * k} actions in $time ms\u0026#34;) } 我们从一个非常简单的操作开始，该操作使用多线程调度器 Dispatchers.Default，并增加一个共享的可变变量\nimport kotlinx.coroutines.* import kotlin.system.* suspend fun massiveRun(action: suspend () -\u0026gt; Unit) { val n = 100 // number of coroutines to launch val k = 1000 // times an action is repeated by each coroutine val time = measureTimeMillis { coroutineScope { // scope for coroutines repeat(n) { launch { repeat(k) { action() } } } } } println(\u0026#34;Completed ${n * k} actions in $time ms\u0026#34;) } //sampleStart var counter = 0 fun main() = runBlocking { withContext(Dispatchers.Default) { massiveRun { counter++ } } println(\u0026#34;Counter = $counter\u0026#34;) } //sampleEnd 最后会打印出什么呢？不太可能打印出 “Counter=100000”，因为100个协程从多个线程并发地递增 counter 而不进行任何同步。\n二、Volatiles 是没有作用的 有一种常见的误解是：将变量标记为 volatile 可以解决并发问题。让我们试试：\nimport kotlinx.coroutines.* import kotlin.system.* suspend fun massiveRun(action: suspend () -\u0026gt; Unit) { val n = 100 // number of coroutines to launch val k = 1000 // times an action is repeated by each coroutine val time = measureTimeMillis { coroutineScope { // scope for coroutines repeat(n) { launch { repeat(k) { action() } } } } } println(\u0026#34;Completed ${n * k} actions in $time ms\u0026#34;) } //sampleStart @Volatile // in Kotlin `volatile` is an annotation var counter = 0 fun main() = runBlocking { withContext(Dispatchers.Default) { massiveRun { counter++ } } println(\u0026#34;Counter = $counter\u0026#34;) } //sampleEnd 这段代码运行得比较慢，但是我们在最后仍然没有得到“Counter=100000”，因为 volatile 变量保证了可线性化（这是“atomic”的一个技术术语）对相应变量的读写，但不提供更大行为的原子性（在我们的例子中指递增操作）\n三、线程安全的数据结构 对线程和协程都有效的一个解决方案是使用线程安全的（也称为同步、可线性化或原子）数据结构，该结构为需要在共享状态上执行的相应操作提供所有必要的同步保障。对于一个简单的计数器，我们可以使用 AtomicInteger 类，该类具有保证原子性的 incrementAndGet 方法\nimport kotlinx.coroutines.* import java.util.concurrent.atomic.* import kotlin.system.* suspend fun massiveRun(action: suspend () -\u0026gt; Unit) { val n = 100 // number of coroutines to launch val k = 1000 // times an action is repeated by each coroutine val time = measureTimeMillis { coroutineScope { // scope for coroutines repeat(n) { launch { repeat(k) { action() } } } } } println(\u0026#34;Completed ${n * k} actions in $time ms\u0026#34;) } //sampleStart var counter = AtomicInteger() fun main() = runBlocking { withContext(Dispatchers.Default) { massiveRun { counter.incrementAndGet() } } println(\u0026#34;Counter = $counter\u0026#34;) } //sampleEnd 这是解决这个特殊问题的最快方法。它适用于普通计数器、集合、队列和其他标准数据结构及其基本操作。但是，它不容易扩展到复杂的状态或没有实现好了的线程安全的复杂操作\n四、以细粒度限制线程 线程限制是解决共享可变状态问题的一种方法，其中对特定共享状态的所有访问都限制在一个线程内。它通常用于 UI 应用程序，其中所有的 UI 状态都限制在“单个事件分派”或“应用程序线程”中。通过使用单线程上下文，可以很容易地使用协程来实现上述的计数器\nimport kotlinx.coroutines.* import kotlin.system.* suspend fun massiveRun(action: suspend () -\u0026gt; Unit) { val n = 100 // number of coroutines to launch val k = 1000 // times an action is repeated by each coroutine val time = measureTimeMillis { coroutineScope { // scope for coroutines repeat(n) { launch { repeat(k) { action() } } } } } println(\u0026#34;Completed ${n * k} actions in $time ms\u0026#34;) } //sampleStart val counterContext = newSingleThreadContext(\u0026#34;CounterContext\u0026#34;) var counter = 0 fun main() = runBlocking { withContext(Dispatchers.Default) { massiveRun { // confine each increment to a single-threaded context withContext(counterContext) { counter++ } } } println(\u0026#34;Counter = $counter\u0026#34;) } //sampleEnd 这段代码运行得非常缓慢，因为它执行细粒度的线程限制。每个单独的增值操作都使用 withContext(counterContext) 从多线程 Dispatchers.Default 上下文切换到单线程上下文\n五、以粗粒度限制线程 在实践中，线程限制是在比较大的范围内执行的，例如，更新状态的逻辑的范围被限制在单个线程中。下面的示例就是这样做的，首先在单线程上下文中运行每个协程\nimport kotlinx.coroutines.* import kotlin.system.* suspend fun massiveRun(action: suspend () -\u0026gt; Unit) { val n = 100 // number of coroutines to launch val k = 1000 // times an action is repeated by each coroutine val time = measureTimeMillis { coroutineScope { // scope for coroutines repeat(n) { launch { repeat(k) { action() } } } } } println(\u0026#34;Completed ${n * k} actions in $time ms\u0026#34;) } //sampleStart val counterContext = newSingleThreadContext(\u0026#34;CounterContext\u0026#34;) var counter = 0 fun main() = runBlocking { // confine everything to a single-threaded context withContext(counterContext) { massiveRun { counter++ } } println(\u0026#34;Counter = $counter\u0026#34;) } //sampleEnd 现在这段代码的运行速度会快得多，并产生了正确的结果\n六、互斥 互斥问题的解决方案是保护共享状态的所有修改操作，其中的关键代码永远不会同时执行。在一个阻塞的世界中，通常会使用 synchronized 或 ReentrantLock。协程的替换方案称为互斥(Mutex)。它具有 lock 和 unlock 函数以划定一个关键位置。关键的区别在于 Mutex.lock() 是一个挂起函数。它不会阻塞线程\n还有一个扩展函数 withLock 可以方便地来实现 mutex.lock(); try {...} finally { mutex.unlock() } import kotlinx.coroutines.* import kotlinx.coroutines.sync.* import kotlin.system.* suspend fun massiveRun(action: suspend () -\u0026gt; Unit) { val n = 100 // number of coroutines to launch val k = 1000 // times an action is repeated by each coroutine val time = measureTimeMillis { coroutineScope { // scope for coroutines repeat(n) { launch { repeat(k) { action() } } } } } println(\u0026#34;Completed ${n * k} actions in $time ms\u0026#34;) } //sampleStart val mutex = Mutex() var counter = 0 fun main() = runBlocking { withContext(Dispatchers.Default) { massiveRun { // protect each increment with lock mutex.withLock { counter++ } } } println(\u0026#34;Counter = $counter\u0026#34;) } //sampleEnd 本例中的锁是细粒度的，因此它也付出了某些代价（消耗）。但是，在某些情况下这是一个很好的选择，比如你必须定期修改某些共享状态，但不具备修改共享状态所需的原生线程\n七、Actors actor 是一个实体，由一个协程、被限制并封装到这个协程中的状态以及一个与其它协程通信的通道组成。简单的 actor 可以写成函数，但具有复杂状态的 actor 更适合类\n有一个 actor 协程构造器，它可以方便地将 actor 的 mailbox channel 合并到其接收的消息的作用域中，并将 send channel 合并到生成的 job 对象中，以便可以将对 actor 的单个引用作为其句柄引有\n使用 actor 的第一步是定义一类 actor 将要处理的消息。kotlin 的密封类非常适合这个目的。在 CounterMsg 密封类中，我们用 IncCounter 消息来定义递增计数器，用 GetCounter 消息来获取其值，后者需要返回值。为此，这里使用 CompletableDeferred communication primitive，它表示将来已知（通信）的单个值\n// Message types for counterActor sealed class CounterMsg object IncCounter : CounterMsg() // one-way message to increment counter class GetCounter(val response: CompletableDeferred\u0026lt;Int\u0026gt;) : CounterMsg() // a request with reply 然后，我们定义一个函数，该函数使用 actor 协程构造器来启动 actor：\n// This function launches a new counter actor fun CoroutineScope.counterActor() = actor\u0026lt;CounterMsg\u0026gt; { var counter = 0 // actor state for (msg in channel) { // iterate over incoming messages when (msg) { is IncCounter -\u0026gt; counter++ is GetCounter -\u0026gt; msg.response.complete(counter) } } } 代码很简单：\nimport kotlinx.coroutines.* import kotlinx.coroutines.channels.* import kotlin.system.* suspend fun massiveRun(action: suspend () -\u0026gt; Unit) { val n = 100 // number of coroutines to launch val k = 1000 // times an action is repeated by each coroutine val time = measureTimeMillis { coroutineScope { // scope for coroutines repeat(n) { launch { repeat(k) { action() } } } } } println(\u0026#34;Completed ${n * k} actions in $time ms\u0026#34;) } // Message types for counterActor sealed class CounterMsg object IncCounter : CounterMsg() // one-way message to increment counter class GetCounter(val response: CompletableDeferred\u0026lt;Int\u0026gt;) : CounterMsg() // a request with reply // This function launches a new counter actor fun CoroutineScope.counterActor() = actor\u0026lt;CounterMsg\u0026gt; { var counter = 0 // actor state for (msg in channel) { // iterate over incoming messages when (msg) { is IncCounter -\u0026gt; counter++ is GetCounter -\u0026gt; msg.response.complete(counter) } } } //sampleStart fun main() = runBlocking\u0026lt;Unit\u0026gt; { val counter = counterActor() // create the actor withContext(Dispatchers.Default) { massiveRun { counter.send(IncCounter) } } // send a message to get a counter value from an actor val response = CompletableDeferred\u0026lt;Int\u0026gt;() counter.send(GetCounter(response)) println(\u0026#34;Counter = ${response.await()}\u0026#34;) counter.close() // shutdown the actor } //sampleEnd 在什么上下文中执行 actor 本身并不重要（为了正确）。actor 是一个协程，并且协程是按顺序执行的，因此将状态限制到特定的协程可以解决共享可变状态的问题。实际上，actors 可以修改自己的私有状态，但只能通过消息相互影响（避免需要任何锁）\nactor 比使用锁更为有效，因为在这种情况下，它总是有工作要做，根本不需要切换到不同的上下文\n注意，actor 协程构造器是一个双重的 product 协程构造器 。actor 与它接收消息的通道相关联，而 producer 与向其发送元素的通道相关联\n","permalink":"http://localhost:1313/hugo-blog/public/post/kotlin/kotlin-%E5%8D%8F%E7%A8%8B%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A38%E5%85%B1%E4%BA%AB%E5%8F%AF%E5%8F%98%E7%8A%B6%E6%80%81%E5%92%8C%E5%B9%B6%E5%8F%91%E6%80%A7/","tags":[],"title":"Kotlin 协程官方文档（8）共享可变状态和并发性"},{"categories":[],"content":" 公众号：字节数组 希望对你有所帮助 🤣🤣\n最近一直在了解关于 Kotlin协程 的知识，那最好的学习资料自然是官方提供的学习文档了，看了看后我就萌生了翻译官方文档的想法。前后花了要接近一个月时间，一共九篇文章，在这里也分享出来，希望对读者有所帮助。个人知识所限，有些翻译得不是太顺畅，也希望读者能提出意见\n协程官方文档：coroutines-guide select 表达式可以同时等待多个挂起函数，并选择第一个可用的函数来执行\n选择表达式是 kotlinx.coroutines 的一个实验性的特性，这些 API 预计将在 kotlinx.coroutines 库的即将到来的更新中衍化，并可能会有突破性的变化\n一、Selecting from channels 我们现在有两个字符串生产者：fizz 和 buzz 。其中 fizz 每 300 毫秒生成一个字符串“Fizz”：\nfun CoroutineScope.fizz() = produce\u0026lt;String\u0026gt; { while (true) { // sends \u0026#34;Fizz\u0026#34; every 300 ms delay(300) send(\u0026#34;Fizz\u0026#34;) } } 接着 buzz 每 500 毫秒生成一个字符串“Buzz!”：\nfun CoroutineScope.buzz() = produce\u0026lt;String\u0026gt; { while (true) { // sends \u0026#34;Buzz!\u0026#34; every 500 ms delay(500) send(\u0026#34;Buzz!\u0026#34;) } } 使用挂起函数 receive，我们可以从两个通道接收其中一个的数据。但是 select 表达式允许我们使用其 onReceive 子句同时从两者接收：\nsuspend fun selectFizzBuzz(fizz: ReceiveChannel\u0026lt;String\u0026gt;, buzz: ReceiveChannel\u0026lt;String\u0026gt;) { select\u0026lt;Unit\u0026gt; { // \u0026lt;Unit\u0026gt; means that this select expression does not produce any result fizz.onReceive { value -\u0026gt; // this is the first select clause println(\u0026#34;fizz -\u0026gt; \u0026#39;$value\u0026#39;\u0026#34;) } buzz.onReceive { value -\u0026gt; // this is the second select clause println(\u0026#34;buzz -\u0026gt; \u0026#39;$value\u0026#39;\u0026#34;) } } } 让我们运行代码 7 次：\nimport kotlinx.coroutines.* import kotlinx.coroutines.channels.* import kotlinx.coroutines.selects.* fun CoroutineScope.fizz() = produce\u0026lt;String\u0026gt; { while (true) { // sends \u0026#34;Fizz\u0026#34; every 300 ms delay(300) send(\u0026#34;Fizz\u0026#34;) } } fun CoroutineScope.buzz() = produce\u0026lt;String\u0026gt; { while (true) { // sends \u0026#34;Buzz!\u0026#34; every 500 ms delay(500) send(\u0026#34;Buzz!\u0026#34;) } } suspend fun selectFizzBuzz(fizz: ReceiveChannel\u0026lt;String\u0026gt;, buzz: ReceiveChannel\u0026lt;String\u0026gt;) { select\u0026lt;Unit\u0026gt; { // \u0026lt;Unit\u0026gt; means that this select expression does not produce any result fizz.onReceive { value -\u0026gt; // this is the first select clause println(\u0026#34;fizz -\u0026gt; \u0026#39;$value\u0026#39;\u0026#34;) } buzz.onReceive { value -\u0026gt; // this is the second select clause println(\u0026#34;buzz -\u0026gt; \u0026#39;$value\u0026#39;\u0026#34;) } } } fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart val fizz = fizz() val buzz = buzz() repeat(7) { selectFizzBuzz(fizz, buzz) } coroutineContext.cancelChildren() // cancel fizz \u0026amp; buzz coroutines //sampleEnd } 运行结果：\nfizz -\u0026gt; \u0026#39;Fizz\u0026#39; buzz -\u0026gt; \u0026#39;Buzz!\u0026#39; fizz -\u0026gt; \u0026#39;Fizz\u0026#39; fizz -\u0026gt; \u0026#39;Fizz\u0026#39; buzz -\u0026gt; \u0026#39;Buzz!\u0026#39; fizz -\u0026gt; \u0026#39;Fizz\u0026#39; buzz -\u0026gt; \u0026#39;Buzz!\u0026#39; 二、Selecting on close 当通道关闭时，select 中的 onReceive 子句会失败并导致相应的 select 引发异常。我们可以使用 onReceiveOrNull 子句在通道关闭时执行特定操作。下面的示例还显示了 select 是一个返回其查询方法结果的表达式：\nsuspend fun selectAorB(a: ReceiveChannel\u0026lt;String\u0026gt;, b: ReceiveChannel\u0026lt;String\u0026gt;): String = select\u0026lt;String\u0026gt; { a.onReceiveOrNull { value -\u0026gt; if (value == null) \u0026#34;Channel \u0026#39;a\u0026#39; is closed\u0026#34; else \u0026#34;a -\u0026gt; \u0026#39;$value\u0026#39;\u0026#34; } b.onReceiveOrNull { value -\u0026gt; if (value == null) \u0026#34;Channel \u0026#39;b\u0026#39; is closed\u0026#34; else \u0026#34;b -\u0026gt; \u0026#39;$value\u0026#39;\u0026#34; } } 注意，onReceiveOrNull 是一个扩展函数，仅可用于具有不可为空元素的通道，这样就不会意外混淆通道是已关闭还是返回了空值这两种情况\n让我们将其与生成四次“Hello”字符串的通道 a 和生成四次“World”字符串的通道 b 一起使用：\nimport kotlinx.coroutines.* import kotlinx.coroutines.channels.* import kotlinx.coroutines.selects.* suspend fun selectAorB(a: ReceiveChannel\u0026lt;String\u0026gt;, b: ReceiveChannel\u0026lt;String\u0026gt;): String = select\u0026lt;String\u0026gt; { a.onReceiveOrNull { value -\u0026gt; if (value == null) \u0026#34;Channel \u0026#39;a\u0026#39; is closed\u0026#34; else \u0026#34;a -\u0026gt; \u0026#39;$value\u0026#39;\u0026#34; } b.onReceiveOrNull { value -\u0026gt; if (value == null) \u0026#34;Channel \u0026#39;b\u0026#39; is closed\u0026#34; else \u0026#34;b -\u0026gt; \u0026#39;$value\u0026#39;\u0026#34; } } fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart val a = produce\u0026lt;String\u0026gt; { repeat(4) { send(\u0026#34;Hello $it\u0026#34;) } } val b = produce\u0026lt;String\u0026gt; { repeat(4) { send(\u0026#34;World $it\u0026#34;) } } repeat(8) { // print first eight results println(selectAorB(a, b)) } coroutineContext.cancelChildren() //sampleEnd } 这段代码的结果非常有趣，所以我们将在细节中分析它：\na -\u0026gt; \u0026#39;Hello 0\u0026#39; a -\u0026gt; \u0026#39;Hello 1\u0026#39; b -\u0026gt; \u0026#39;World 0\u0026#39; a -\u0026gt; \u0026#39;Hello 2\u0026#39; a -\u0026gt; \u0026#39;Hello 3\u0026#39; b -\u0026gt; \u0026#39;World 1\u0026#39; Channel \u0026#39;a\u0026#39; is closed Channel \u0026#39;a\u0026#39; is closed 从中可以观察到几点\n首先，select 偏向于第一个子句。当同时可以选择多个子句时，将选择其中的第一个子句。在这里，两个通道都在不断地产生字符串，因此作为 select 中的第一个子句的通道获胜。但是，因为我们使用的是无缓冲通道，所以 a 在其发送调用时会不时地被挂起，从而给了 b 发送的机会\n第二个观察结果是，当通道已经关闭时，onReceiveOrNull 将立即被选中\n三、Selecting to send select 表达式有 onSend 子句，可以与 selection 的偏向性质结合使用。让我们写一个整数生产者的例子，当主通道上的消费者跟不上时，它会将其值发送到 side 通道：\nfun CoroutineScope.produceNumbers(side: SendChannel\u0026lt;Int\u0026gt;) = produce\u0026lt;Int\u0026gt; { for (num in 1..10) { // produce 10 numbers from 1 to 10 delay(100) // every 100 ms select\u0026lt;Unit\u0026gt; { onSend(num) {} // Send to the primary channel side.onSend(num) {} // or to the side channel } } } 消费者将会非常缓慢，每个数值处理需要 250 毫秒：\nimport kotlinx.coroutines.* import kotlinx.coroutines.channels.* import kotlinx.coroutines.selects.* fun CoroutineScope.produceNumbers(side: SendChannel\u0026lt;Int\u0026gt;) = produce\u0026lt;Int\u0026gt; { for (num in 1..10) { // produce 10 numbers from 1 to 10 delay(100) // every 100 ms select\u0026lt;Unit\u0026gt; { onSend(num) {} // Send to the primary channel side.onSend(num) {} // or to the side channel } } } fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart val side = Channel\u0026lt;Int\u0026gt;() // allocate side channel launch { // this is a very fast consumer for the side channel side.consumeEach { println(\u0026#34;Side channel has $it\u0026#34;) } } produceNumbers(side).consumeEach { println(\u0026#34;Consuming $it\u0026#34;) delay(250) // let us digest the consumed number properly, do not hurry } println(\u0026#34;Done consuming\u0026#34;) coroutineContext.cancelChildren() //sampleEnd } 让我们看看会发生什么：\nConsuming 1 Side channel has 2 Side channel has 3 Consuming 4 Side channel has 5 Side channel has 6 Consuming 7 Side channel has 8 Side channel has 9 Consuming 10 Done consuming 四、Selecting deferred values 延迟值可以使用 onAwait 子句来查询。让我们启动一个异步函数，它在随机的延迟后会延迟返回字符串：\nfun CoroutineScope.asyncString(time: Int) = async { delay(time.toLong()) \u0026#34;Waited for $time ms\u0026#34; } 让我们随机启动十余个异步函数，每个都延迟随机的时间\nfun CoroutineScope.asyncStringsList(): List\u0026lt;Deferred\u0026lt;String\u0026gt;\u0026gt; { val random = Random(3) return List(12) { asyncString(random.nextInt(1000)) } } 现在，main 函数等待它们中的第一个完成，并统计仍处于活动状态的延迟值的数量。注意，我们在这里使用 select 表达式事实上是一种 Kotlin DSL，因此我们可以使用任意代码为它提供子句。在本例中，我们遍历一个延迟值列表，为每个延迟值提供 onAwait 子句。\nimport kotlinx.coroutines.* import kotlinx.coroutines.selects.* import java.util.* fun CoroutineScope.asyncString(time: Int) = async { delay(time.toLong()) \u0026#34;Waited for $time ms\u0026#34; } fun CoroutineScope.asyncStringsList(): List\u0026lt;Deferred\u0026lt;String\u0026gt;\u0026gt; { val random = Random(3) return List(12) { asyncString(random.nextInt(1000)) } } fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart val list = asyncStringsList() val result = select\u0026lt;String\u0026gt; { list.withIndex().forEach { (index, deferred) -\u0026gt; deferred.onAwait { answer -\u0026gt; \u0026#34;Deferred $index produced answer \u0026#39;$answer\u0026#39;\u0026#34; } } } println(result) val countActive = list.count { it.isActive } println(\u0026#34;$countActive coroutines are still active\u0026#34;) //sampleEnd } 输出结果：\nDeferred 4 produced answer \u0026#39;Waited for 128 ms\u0026#39; 11 coroutines are still active 五、Switch over a channel of deferred values 现在我们来编写一个通道生产者函数，它消费一个产生延迟字符串的通道，并等待每个接收的延迟值，但它只在下一个延迟值到达或者通道关闭之前处于运行状态。此示例将 onReceiveOrNull 和 onAwait 子句放在同一个 select 中：\nfun CoroutineScope.switchMapDeferreds(input: ReceiveChannel\u0026lt;Deferred\u0026lt;String\u0026gt;\u0026gt;) = produce\u0026lt;String\u0026gt; { var current = input.receive() // start with first received deferred value while (isActive) { // loop while not cancelled/closed val next = select\u0026lt;Deferred\u0026lt;String\u0026gt;?\u0026gt; { // return next deferred value from this select or null input.onReceiveOrNull { update -\u0026gt; update // replaces next value to wait } current.onAwait { value -\u0026gt; send(value) // send value that current deferred has produced input.receiveOrNull() // and use the next deferred from the input channel } } if (next == null) { println(\u0026#34;Channel was closed\u0026#34;) break // out of loop } else { current = next } } } 为了测试它，我们将用一个简单的异步函数，它在特定的延迟后返回特定的字符串：\nfun CoroutineScope.asyncString(str: String, time: Long) = async { delay(time) str } main 函数只是启动一个协程来打印 switchMapDeferreds 的结果并向它发送一些测试数据：\nimport kotlinx.coroutines.* import kotlinx.coroutines.channels.* import kotlinx.coroutines.selects.* fun CoroutineScope.switchMapDeferreds(input: ReceiveChannel\u0026lt;Deferred\u0026lt;String\u0026gt;\u0026gt;) = produce\u0026lt;String\u0026gt; { var current = input.receive() // start with first received deferred value while (isActive) { // loop while not cancelled/closed val next = select\u0026lt;Deferred\u0026lt;String\u0026gt;?\u0026gt; { // return next deferred value from this select or null input.onReceiveOrNull { update -\u0026gt; update // replaces next value to wait } current.onAwait { value -\u0026gt; send(value) // send value that current deferred has produced input.receiveOrNull() // and use the next deferred from the input channel } } if (next == null) { println(\u0026#34;Channel was closed\u0026#34;) break // out of loop } else { current = next } } } fun CoroutineScope.asyncString(str: String, time: Long) = async { delay(time) str } fun main() = runBlocking\u0026lt;Unit\u0026gt; { //sampleStart val chan = Channel\u0026lt;Deferred\u0026lt;String\u0026gt;\u0026gt;() // the channel for test launch { // launch printing coroutine for (s in switchMapDeferreds(chan)) println(s) // print each received string } chan.send(asyncString(\u0026#34;BEGIN\u0026#34;, 100)) delay(200) // enough time for \u0026#34;BEGIN\u0026#34; to be produced chan.send(asyncString(\u0026#34;Slow\u0026#34;, 500)) delay(100) // not enough time to produce slow chan.send(asyncString(\u0026#34;Replace\u0026#34;, 100)) delay(500) // give it time before the last one chan.send(asyncString(\u0026#34;END\u0026#34;, 500)) delay(1000) // give it time to process chan.close() // close the channel ... delay(500) // and wait some time to let it finish //sampleEnd } 代码的执行结果：\nBEGIN Replace END Channel was closed ","permalink":"http://localhost:1313/hugo-blog/public/post/kotlin/kotlin-%E5%8D%8F%E7%A8%8B%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A39%E9%80%89%E6%8B%A9%E8%A1%A8%E8%BE%BE%E5%BC%8F/","tags":[],"title":"Kotlin 协程官方文档（9）选择表达式"},{"categories":[],"content":"目录\n收起\n01 | 基础架构： 一条SQL查询语句是如何执行的 ?\n02 | 日志系统： 一条SQL更新语句是如何执行的？\n03 | 事务隔离： 为什么你改了我还看不见？\n04 | 深入浅出索引（上）\n05 | 深入浅出索引（下）\n06 | 全局锁和表锁 ： 给表加个字段怎么有这么多阻碍？\n07 | 行锁功过： 怎么减少行锁对性能的影响？\n08 | 事务到底是隔离的还是不隔离的？\n09 | 普通索引和唯一索引， 应该怎么选择？\n10 | MySQL为什么有时候会选错索引？\n11 | 怎么给字符串字段加索引？\n12 | 为什么我的MySQL会“抖”一下？\n13 | 为什么表数据删掉一半， 表文件大小不变？\n14 | count(*)这么慢， 我该怎么办？\n15 | 答疑文章（一） ： 日志和索引相关问题\n16 | “order by”是怎么工作的？\n17 | 如何正确地显示随机消息？\n18 | 为什么这些SQL语句逻辑相同， 性能却差异巨大？\n19 | 为什么我只查一行的语句， 也执行这么慢？\n20 | 幻读是什么， 幻读有什么问题？\n21 | 为什么我只改一行的语句， 锁这么多？\n22 | MySQL有哪些“饮鸩止渴”提高性能的方法？\n23 | MySQL是怎么保证数据不丢的？\n24 | MySQL是怎么保证主备一致的？\n25 | MySQL是怎么保证高可用的？\n26 | 备库为什么会延迟好几个小时？\n27 | 主库出问题了， 从库怎么办？\n28 | 读写分离有哪些坑？\n29 | 如何判断一个数据库是不是出问题了？\n30 | 答疑文章（二） ： 用动态的观点看加锁\n31 | 误删数据后除了跑路， 还能怎么办？\n32 | 为什么还有kill不掉的语句？\n33 | 我查这么多数据， 会不会把数据库内存打爆？\n34 | 到底可不可以使用join？\n35 | join语句怎么优化？\n36 | 为什么临时表可以重名？\n37 | 什么时候会使用内部临时表？\n38 | 都说InnoDB好， 那还要不要使用Memory引擎？\n39 | 自增主键为什么不是连续的？\n40 | insert语句的锁为什么这么多？\n41 | 怎么最快地复制一张表？\n42 | grant之后要跟着flush privileges吗？\n43 | 要不要使用分区表？\n44 | 答疑文章（三） ： 说一说这些好问题\n45 | 自增id用完怎么办？\n01 | 基础架构： 一条SQL查询语句是如何执行的 ? MySQL可以分为Server层和存储引擎层两部分。Server层包括连接器、 查询缓存、 分析器、 优化器、 执行器等。存储引擎层负责数据的存储和提取，现在最常用的存储引擎是InnoDB。\n连接器\n第一步，会先连接到这个数据库上， 这时候接待你的就是连接器。 连接器负责跟客户端建立连接、 获取权限、 维持和管理连接。\n查询缓存\nMySQL拿到一个查询请求后， 会先到查询缓存看看， 之前是不是执行过这条语句。 之前执行过的语句及其结果可能会以key-value对的形式， 被直接缓存在内存中。 key是查询的语句， value是查询的结果。 如果你的查询能够直接在这个缓存中找到key， 那么这个value就会被直接返回给客户端。查询缓存往往弊大于利 ，大多数时候建议不要使用。\n分析器\n如果没有命中查询缓存， 就要开始真正执行语句了。 分析器先会做“词法分析”。 你输入的是由多个字符串和空格组成的一条SQL语句， MySQL需要识别出里面的字符串分别是什么， 代表什么 。做完了这些识别以后， 就要做“语法分析”。 根据词法分析的结果， 语法分析器会根据语法规则，判断你输入的这个SQL语句是否满足MySQL语法。\n优化器\n在开始执行之前， 还要先经过优化器的处理。优化器是在表里面有多个索引的时候， 决定使用哪个索引； 或者在一个语句有多表关联（join）的时候， 决定各个表的连接顺序。\n执行器\n开始执行的时候， 要先判断一下你对这个表T有没有执行查询的权限 。如果有权限， 就打开表继续执行。 打开表的时候， 执行器就会根据表的引擎定义， 去使用这个引擎提供的接口。\n02 | 日志系统： 一条SQL更新语句是如何执行的？ 与查询流程不一样的是， 更新流程还涉及两个重要的日志模块： redo log（重做日志） 和 binlog（归档日志）。 当有一条记录需要更新的时候， InnoDB引擎就会先把记录写到redo log里面， 并更新内存， 这个时候更新就算完成了。 同时， InnoDB引擎会在适当的时候， 将这个操作记录更新到磁盘里面。\nRedo log\nInnoDB的redo log是固定大小的， 比如可以配置为一组4个文件， 每个文件的大小是1GB， 那么这块“粉板”总共就可以记录4GB的操作。 从头开始写， 写到末尾就又回到开头循环写， 如下面这个图所示。\nwrite pos是当前记录的位置， 一边写一边后移， 写到第3号文件末尾后就回到0号文件开头。checkpoint是当前要擦除的位置， 也是往后推移并且循环的， 擦除记录前要把记录更新到数据文件。write pos和checkpoint之间的是“粉板”上还空着的部分， 可以用来记录新的操作。 如果write pos追上checkpoint， 表示“粉板”满了， 这时候不能再执行新的更新， 得停下来先擦掉一些记录， 把checkpoint推进一下。\nBinlog\n这两种日志有以下三点不同。\n• 1. redo log是InnoDB引擎特有的； binlog是MySQL的Server层实现的， 所有引擎都可以使用。\n• 2. redo log是物理日志， 记录的是“在某个数据页上做了什么修改”； binlog是逻辑日志， 记录的是这个语句的原始逻辑， 比如“给ID=2这一行的c字段加1 ”。\n• 3. redo log是循环写的， 空间固定会用完； binlog是可以追加写入的。 “追加写”是指binlog文件写到一定大小后会切换到下一个， 并不会覆盖以前的日志。\nupdate T set c=c+1 where ID=2; update语句的执行流程图\n两阶段提交\n由于redo log和binlog是两个独立的逻辑， 如果不用两阶段提交， 要么就是先写完redo log再写binlog， 或者采用反过来的顺序。仍然用前面的update语句来做例子。 假设当前ID=2的行， 字段c的值是0， 再假设执行update语句过程中在写完第一个日志后， 第二个日志还没有写完期间发生了crash， 会出现什么情况呢？\n先写redo log后写binlog。 假设在redo log写完， binlog还没有写完的时候， MySQL进程异常重启。 由redo log写完之后， 系统即使崩溃， 仍然能够把数据恢复回来， 所以恢复后这一行c的值是1。但是由于binlog没写完就crash了， 这时候binlog里面就没有记录这个语句。 因此， 之后备份日志的时候， 存起来的binlog里面就没有这条语句。如果需要用这个binlog来恢复临时库的话，恢复出来的这一行c的值就是0， 与原库的值不同。\n先写binlog后写redo log。 如果在binlog写完之后crash， 由于redo log还没写， 崩溃恢复以后这个事务无效， 所以这一行c的值是0。 但是binlog里面已经记录了“把c从0改成1”这个日志。 所以， 在之后用binlog来恢复的时候就多了一个事务出来， 恢复出来的这一行c的值就是1， 与原库的值不同。\n简单说， redo log和binlog都可以用于表示事务的提交状态， 而两阶段提交就是让这两个状态保持逻辑上的一致\n03 | 事务隔离： 为什么你改了我还看不见？ 简单来说， 事务就是要保证一组数据库操作， 要么全部成功， 要么全部失败。 在MySQL中， 事务支持是在引擎层实现的。 你现在知道， MySQL是一个支持多引擎的系统， 但并不是所有的引擎都支持事务。 比如MySQL原生的MyISAM引擎就不支持事务， 这也是MyISAM被InnoDB取代的重要原因之一。\n隔离性与隔离级别\n当数据库上有多个事务同时执行的时候， 就可能出现脏读（dirtyread） 、 不可重复读（non repeatable read） 、 幻读（ phantom read） 的问题， 为了解决这些问题， 就有了“隔离级别”的概念。SQL标准的事务隔离级别包括： 读未提交（ read uncommitted） 、读提交（read committed） 、 可重复读（ repeatable read） 和串行化（ serializable ） 。\n￮ 读未提交是指， 一个事务还没提交时， 它做的变更就能被别的事务看到。\n￮ 读提交是指， 一个事务提交之后， 它做的变更才会被其他事务看到。\n￮ 可重复读是指， 一个事务执行过程中看到的数据， 总是跟这个事务在启动时看到的数据是一致的。 当然在可重复读隔离级别下， 未提交变更对其他事务也是不可见的。\n￮ 串行化， 顾名思义是对于同一行记录， “写”会加“写锁”， “读”会加“读锁”。 当出现读写锁冲突的时候， 后访问的事务必须等前一个事务执行完成， 才能继续执行。\n假设数据表T中只有一列， 其中一行的值为1， 下面是按照时间顺序执行两个事务的行为。\nSQL\nmysql\u0026gt;\ncreate table T(c int) engine=InnoDB;\ninsert into T(c) values(1); • 若隔离级别是“读未提交”， 则V1的值就是2。 这时候事务B虽然还没有提交， 但是结果已经被A看到了。 因此， V2、 V3也都是2。\n• 若隔离级别是“读提交”， 则V1是1， V2的值是2。 事务B的更新在提交后才能被A看到。 所以，V3的值也是2。\n• 若隔离级别是“可重复读”， 则V1、 V2是1， V3是2。 之所以V2还是1， 遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。\n• 若隔离级别是“串行化”， 则在事务B执行“将1改成2”的时候， 会被锁住。 直到事务A提交后，事务B才可以继续执行。 所以从A的角度看， V1、 V2值是1， V3的值是2。\n在实现上， 数据库里面会创建一个视图， 访问的时候以视图的逻辑结果为准。 在“可重复读”隔离级别下， 这个视图是在事务启动时创建的， 整个事务存在期间都用这个视图。 在“读提交”隔离级别下， 这个视图是在每个SQL语句开始执行的时候创建的。 这里需要注意的是， “读未提交”隔离级别下直接返回记录上的最新值， 没有视图概念； 而“串行化”隔离级别下直接用加锁的方式来避免并行访问。\n事务隔离的实现\n可重复读 ：在MySQL中， 实际上每条记录在更新的时候都会同时记录一条回滚操作。 记录上的最新值， 通过回滚操作， 都可以得到前一个状态的值。假设一个值从1被按顺序改成了2、 3、 4， 在回滚日志里面就会有类似下面的记录。\n事务的启动方式\n1. 显式启动事务语句， begin 或 start transaction。 配套的提交语句是commit， 回滚语句是rollback。\n2. set autocommit=0， 这个命令会将这个线程的自动提交关掉。 意味着如果你只执行一个select语句， 这个事务就启动了， 而且并不会自动提交。 这个事务持续存在直到你主动执行commit 或 rollback 语句， 或者断开连接。\n04 | 深入浅出索引（上） 索引的出现其实就是为了提高数据查询的效率， 就像书的目录一样。\n索引的常见模型\n哈希表、 有序数组和搜索树\nInnoDB的索引模型\nInnoDB中， 表都是根据主键顺序以索引的形式存放的， 这种存储方式的表称为索引组织表。又因为前面我们提到的， InnoDB使用了B+树索引模型， 所以数据都是存储在B+树中的。每一个索引在InnoDB里面对应一棵B+树。\n假设， 我们有一个主键列为ID的表， 表中有字段k， 并且在k上有索引。\n这个表的建表语句是：\n表中R1~R5的(ID,k)值分别为(100,1)、 (200,2)、 (300,3)、 (500,5)和(600,6)， 两棵树的示例示意图如下。\n从图中不难看出， 根据叶子节点的内容， 索引类型分为主键索引和非主键索引。主键索引的叶子节点存的是整行数据。 在InnoDB里， 主键索引也被称为聚簇索引（clustered index） 。非主键索引的叶子节点内容是主键的值。 在InnoDB里， 非主键索引也被称为二级索引（secondaryindex）。\n基于主键索引和普通索引的查询有什么区别？\n如果语句是select * from Twhere ID=500， 即主键查询方式， 则只需要搜索ID这棵B+树；如果语句是select * from Twhere k=5， 即普通索引查询方式， 则需要先搜索k索引树， 得到ID的值为500， 再到ID索引树搜索一次。 这个过程称为回表。\n索引维护\n显然， 主键长度越小， 普通索引的叶子节点就越小， 普通索引占用的空间也就越小。\n如何避免长事务对业务的影响 ？\n首先， 从应用开发端来看：\n1. 确认是否使用了set autocommit=0。 这个确认工作可以在测试环境中开展， 把MySQL的general_log开起来， 然后随便跑一个业务逻辑， 通过general_log的日志来确认。 一般框架如果会设置这个值， 也就会提供参数来控制行为， 你的目标就是把它改成1。\n2. 确认是否有不必要的只读事务。 有些框架会习惯不管什么语句先用begin/commit框起来。 我见过有些是业务并没有这个需要， 但是也把好几个select语句放到了事务中。 这种只读事务可以去掉。\n3. 业务连接数据库的时候， 根据业务本身的预估， 通过SETMAX_EXECUTION_TIME命令，来控制每个语句执行的最长时间， 避免单个语句意外执行太长时间。 （为什么会意外？ 在后续的文章中会提到这类案例）\n其次， 从数据库端来看\n1. 监控 information_schema.Innodb_trx表， 设置长事务阈值， 超过就报警/或者kill；\n2. Percona的pt-kill这个工具不错， 推荐使用；\n3. 在业务功能测试阶段要求输出所有的general_log， 分析日志行为提前发现问题；\n4. 如果使用的是MySQL 5.6或者更新版本， 把innodb_undo_tablespaces设置成2（或更大的值） 。 如果真的出现大事务导致回滚段过大， 这样设置后清理起来更方便。\n05 | 深入浅出索引（下） select * from Twhere k between 3 and 5，\n我们一起来看看这条SQL查询语句的执行流程：\n1. 在k索引树上找到k=3的记录， 取得 ID = 300；\n2. 再到ID索引树查到ID=300对应的R3；\n3. 在k索引树取下一个值k=5， 取得ID=500；\n4. 再回到ID索引树查到ID=500对应的R4；\n5. 在k索引树取下一个值k=6， 不满足条件， 循环结束。\n回到主键索引树搜索的过程， 我们称为回表。\n覆盖索引\n由于覆盖索引可以减少树的搜索次数， 显著提升查询性能， 所以使用覆盖索引是一个常用的性能优化手段。\n最左前缀原则\n如果为每一种查询都设计一个索引， 索引是不是太多了。B+树这种索引结构， 可以利用索引的“最左前缀”， 来定位记录。\n可以看到， 索引项是按照索引定义里面出现的字段顺序排序的。\n索引下推\nmysql\u0026gt; select * from tuser where name like \u0026lsquo;张%\u0026rsquo; and age=10 and ismale=1;\n在MySQL 5.6之前， 只能从ID3开始一个个回表。 到主键索引上找出数据行， 再对比字段值。\n而MySQL 5.6 引入的索引下推优化（indexcondition pushdown)， 可以在索引遍历过程中， 对索引中包含的字段先做判断， 直接过滤掉不满足条件的记录， 减少回表次数。\n区别是， InnoDB在(name,age)索引内部就判断了age是否等于10， 对于不等于10的记录， 直接判断并跳过。 在我们的这个例子中， 只需要对ID4、 ID5这两条记录回表取数据判断， 就只需要回表2次。\n06 | 全局锁和表锁 ： 给表加个字段怎么有这么多阻碍？ 根据加锁的范围， MySQL里面的锁大致可以分成全局锁、 表级锁和行锁三类。\n全局锁\n当你需要让整个库处于只读状态的时候， 可以使用这个命令， 之后其他线程的以下语句会被阻塞： 数据更新语句（数据的增删改） 、 数据定义语句（包括建表、 修改表结构等） 和更新类事务的提交语句。\n全局锁的典型使用场景是， 做全库逻辑备份。\n但是让整库都只读， 听上去就很危险：\n如果你在主库上备份， 那么在备份期间都不能执行更新， 业务基本上就得停摆；\n如果你在从库上备份， 那么备份期间从库不能执行主库同步过来的binlog， 会导致主从延迟 。\n这个备份结果里， 用户A的数据状态是“账户余额没扣， 但是用户课程表里面已经多了一门课”。 如果后面用这个备份来恢复数据的话， 用户A就发现， 自己赚了。\n表级锁\nMySQL里面表级别的锁有两种： 一种是表锁， 一种是元数据锁（meta data lock， MDL) 。表锁的语法是 lock tables …read/write。举个例子, 如果在某个线程A中执行lock tables t1 read, t2 write; 这个语句， 则其他线程写t1、 读写t2的语句都会被阻塞。 同时， 线程A在执行unlock tables之前， 也只能执行读t1、 读写t2的操作。 连写t1都不允许， 自然也不能访问其他表。\n另一类表级的锁是MDL（ metadata lock)。 MDL不需要显式使用， 在访问一个表的时候会被自动加上。 MDL的作用是， 保证读写的正确性。 你可以想象一下， 如果一个查询正在遍历一个表中的数据， 而执行期间另一个线程对这个表结构做变更， 删了一列， 那么查询线程拿到的结果跟表结构对不上， 肯定是不行的。\nMDL读锁之间不互斥， 因此你可以有多个线程同时对一张表增删改查。读写锁之间、 写锁之间是互斥的， 用来保证变更表结构操作的安全性。 因此， 如果有两个线程要同时给一个表加字段， 其中一个要等另一个执行完才能开始执行。\n07 | 行锁功过： 怎么减少行锁对性能的影响？ MySQL的行锁是在引擎层由各个引擎自己实现的。 但并不是所有的引擎都支持行锁。 InnoDB是支持行锁的 。\n从两阶段锁说起\n实际上事务B的update语句会被阻塞， 直到事务A执行commit之后， 事务B才能继续执行。 在InnoDB事务中， 行锁是在需要的时候才加上的， 但并不是不需要了就立刻释放， 而是要等到事务结束时才释放。 这个就是两阶段锁协议。\n死锁和死锁检测\n这时候， 事务A在等待事务B释放id=2的行锁， 而事务B在等待事务A释放id=1的行锁。 事务A和事务B在互相等待对方的资源释放， 就是进入了死锁状态。 当出现死锁以后， 有两种策略：\n• 一种策略是， 直接进入等待， 直到超时。 这个超时时间可以通过参数innodb_lock_wait_timeout来设置。\n• 另一种策略是， 发起死锁检测， 发现死锁后， 主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。 将参数innodb_deadlock_detect设置为on， 表示开启这个逻辑。\n08 | 事务到底是隔离的还是不隔离的？ 如果是可重复读隔离级别， 事务T启动的时候会创建一个视图read-view， 之后事务T执行期间， 即使有其他事务修改了数据， 事务T看到的仍然跟在启动时看到的一样。\nbegin/start transaction 命令并不是一个事务的起点， 在执行到它们之后的第一个操作InnoDB表的语句， 事务才真正启动。 如果你想要马上启动一个事务， 可以使用start transaction withconsistent snapshot 这个命令。\n在MySQL里， 有两个“视图”的概念：一个是view。 它是一个用查询语句定义的虚拟表， 在调用的时候执行查询语句并生成结果。创建视图的语法是create view …， 而它的查询方法与表一样。另一个是InnoDB在实现MVCC时用到的一致性读视图， 即consistent read view， 用于支持RC（Read Committed， 读提交） 和RR（ Repeatable Read， 可重复读） 隔离级别的实现。\n“快照”在MVCC里是怎么工作的？\nInnoDB里面每个事务有一个唯一的事务ID， 叫作transaction id。 它是在事务开始的时候向InnoDB的事务系统申请的， 是按申请顺序严格递增的。而每行数据也都是有多个版本的。 每次事务更新数据的时候， 都会生成一个新的数据版本， 并且把transaction id赋值给这个数据版本的事务ID， 记为row trx_id。 同时， 旧的数据版本要保留，并且在新的数据版本中， 能够有信息可以直接拿到它。也就是说， 数据表中的一行记录， 其实可能有多个版本(row)， 每个版本有自己的row trx_id。\n实际上， 图2中的三个虚线箭头， 就是undo log； 而V1、 V2、 V3并不是物理上真实存在的， 而是每次需要的时候根据当前版本和undo log计算出来的。 比如， 需要V2的时候， 就是通过V4依次执行U3、 U2算出来。\nInnoDB为每个事务构造了一个数组， 用来保存这个事务启动瞬间， 当前正在“活跃”的所有事务ID。 “活跃”指的就是， 启动了但还没提交。\n更新数据都是先读后写的， 而这个读， 只能读当前的值， 称为“当前读”（ current read） 。\nInnoDB的行数据有多个版本， 每个数据版本有自己的row trx_id， 每个事务或者语句有自己的一致性视图。 普通查询语句是一致性读， 一致性读会根据row trx_id和一致性视图确定数据版本的可见性。\n￮ 对于可重复读， 查询只承认在事务启动前就已经提交完成的数据；\n￮ 对于读提交， 查询只承认在语句启动前就已经提交完成的数据；\n￮ 而当前读， 总是读取已经提交完成的最新版本。\n09 | 普通索引和唯一索引， 应该怎么选择？ 从性能的角度考虑， 你选择唯一索引还是普通索引呢？ 选择的依据是什么呢？\n如果要在这张表中插入一个新记录(4,400)的话， InnoDB的处理流程是怎样的。\n第一种情况是， 这个记录要更新的目标页在内存中。 这时， InnoDB的处理流程如下：对于唯一索引来说， 找到3和5之间的位置， 判断到没有冲突， 插入这个值， 语句执行结束；对于普通索引来说， 找到3和5之间的位置， 插入这个值， 语句执行结束。\n第二种情况是， 这个记录要更新的目标页不在内存中。 这时， InnoDB的处理流程如下：对于唯一索引来说， 需要将数据页读入内存， 判断到没有冲突， 插入这个值， 语句执行结束；对于普通索引来说， 则是将更新记录在change buffer， 语句执行就结束了。\nPlain\nText\nmysql\u0026gt;\ninsert into t(id,k) values(id1,k1),(id2,k2); 这里， 我们假设当前k索引树的状态， 查找到位置后， k1所在的数据页在内存(InnoDB bufferpool)中， k2所在的数据页不在内存中。 如图所示是带change buffer的更新状态图。\n分析这条更新语句， 你会发现它涉及了四个部分： 内存、 redo log（ib_log_fileX） 、 数据表空间（t.ibd） 、 系统表空间（ibdata1） 。\n这条更新语句做了如下的操作（按照图中的数字顺序） ：\n1. Page 1在内存中， 直接更新内存；\n2. Page 2没有在内存中， 就在内存的change buffer区域， 记录下“我要往Page 2插入一行”这个信息\n3. 将上述两个动作记入redo log中（图中3和4） 。\n那在这之后的读请求， 要怎么处理呢？我们现在要执行 select * from t where k in (k1, k2)。\n如果读语句发生在更新语句后不久， 内存中的数据都还在， 那么此时的这两个读操作就与系统表空间（ibdata1） 和 redo log（ib_log_fileX） 无关了。\n1. 读Page 1的时候， 直接从内存返回。\n2. 要读Page 2的时候， 需要把Page 2从磁盘读入内存中， 然后应用change buffer里面的操作日志， 生成一个正确的版本并返回结果。\n10 | MySQL为什么有时候会选错索引？ 一种方法是， 像我们第一个例子一样， 采用force index强行选择一个索引。\n第二种方法就是， 我们可以考虑修改 语句， 引导MySQL使用我们期望的索引。 比如， 在这个例子里， 显然把“order byb limit 1” 改成 “order byb,a limit 1” ， 语义的逻辑是相同的。\n第三种方法是， 在有些场景下， 我们可以新建一个更合适的索引， 来提供给优化器做选择， 或删掉误用的索引。\n11 | 怎么给字符串字段加索引？ Plain\nText\nmysql\u0026gt;\nalter table SUser add index index1(email);\nmysql\u0026gt; alter table SUser add index index2(email(6)); 第一个语句创建的index1索引里面， 包含了每个记录的整个字符串； 而第二个语句创建的index2索引里面， 对于每个记录都是只取前6个字节。\nselect\nid,name,email from SUser where email='zhangssxyz@xxx.com'; 如果使用的是index1（即email整个字符串的索引结构） ， 执行顺序是这样的：\n1. 从index1索引树找到满足索引值是’zhangssxyz@xxx.com’的这条记录， 取得ID2的值；\n2. 到主键上查到主键值是ID2的行， 判断email的值是正确的， 将这行记录加入结果集；\n3. 取index1索引树上刚刚查到的位置的下一条记录， 发现已经不满足\nemail='zhangssxyz@xxx.com ’的条件了， 循环结束。\n如果使用的是index2（即email(6)索引结构） ， 执行顺序是这样的：\n1. 从index2索引树找到满足索引值是’zhangs’的记录， 找到的第一个是ID1；\n2. 到主键上查到主键值是ID1的行， 判断出email的值不是’zhangssxyz@xxx.com’， 这行记录丢弃；\n3. 取index2上刚刚查到的位置的下一条记录， 发现仍然是’zhangs’， 取出ID2， 再到ID索引上取整行然后判断， 这次值对了， 将这行记录加入结果集；\n4. 重复上一步， 直到在idxe2上取到的值不是’zhangs’时， 循环结束。\n前缀索引对覆盖索引的影响\n使用前缀索引就用不上覆盖索引对查询性能的优化了， 这也是你在选择是否使用前缀索引时需要考虑的一个因素。\n其他方式\n第一种方式是使用倒序存储。\n第二种方式是使用hash字段。\n首先， 它们的相同点是， 都不支持范围查询。 倒序存储的字段上创建的索引是按照倒序字符串的方式排序的， 已经没有办法利用索引方式查出身份证号码在[ID_X, ID_Y]的所有市民了。 同样地， hash字段的方式也只能支持等值查询。\n它们的区别， 主要体现在以下三个方面：\n1. 从占用的额外空间来看， 倒序存储方式在主键索引上， 不会消耗额外的存储空间， 而hash字段方法需要增加一个字段。 当然， 倒序存储方式使用4个字节的前缀长度应该是不够的， 如果再长一点， 这个消耗跟额外这个hash字段也差不多抵消了。\n2. 在CPU消耗方面， 倒序方式每次写和读的时候， 都需要额外调用一次reverse函数， 而hash字段的方式需要额外调用一次crc32()函数。 如果只从这两个函数的计算复杂度来看的话， reverse函数额外消耗的CPU资源会更小些。\n3. 从查询效率上看， 使用hash字段方式的查询性能相对更稳定一些。 因为crc32算出来的值虽然有冲突的概率， 但是概率非常小， 可以认为每次查询的平均扫描行数接近1。 而倒序存储方式毕竟还是用的前缀索引的方式， 也就是说还是会增加扫描行数。\n12 | 为什么我的MySQL会“抖”一下？ 当内存数据页跟磁盘数据页内容不一致的时候， 我们称这个内存页为“脏页”。 内存数据写入到磁盘后， 内存和磁盘上的数据页的内容就一致了， 称为“干净页”。\n什么时候flush？\n1：是InnoDB的redo log写满了。 这时候系统会停止所有更新操作， 把:checkpoint往前推进， redo log留出空间可以继续写。\ncheckpoint可不是随便往前修改一下位置就可以的。 比如图中， 把checkpoint位置从CP推进到CP’， 就需要将两个点之间的日志（浅绿色部分） ， 对应的所有脏页都flush到磁盘上。 之后， 图中从write pos到CP’之间就是可以再写入的redo log的区域。\n2：系统内存不足。 当需要新的内存页， 而内存不够用的时候， 就要淘汰一些数据页， 空出内存给别的数据页使用。 如果淘汰的是“脏页”， 就要先将脏页写到磁盘。\n3：MySQL认为系统“空闲”的时候。\n4：MySQL正常关闭的情况。 这时候， MySQL会把内存的脏页都flush到磁盘上， 这样下次MySQL启动的时候， 就可以直接从磁盘上读数据， 启动速度会很快。\n第一种是“redo log写满了， 要flush脏页”， 这种情况是InnoDB要尽量避免的。 因为出现这种情况的时候， 整个系统就不能再接受更新了， 所有的更新都必须堵住。\n第二种是“内存不够用了， 要先将脏页写到磁盘”， 这种情况其实是常态。InnoDB用缓冲池（ buffer pool） 管理内存， 缓冲池中的内存页有三种状态：第一种是， 还没有使用的；第二种是， 使用了并且是干净页；第三种是， 使用了并且是脏页。\nInnoDB的刷盘速度就是要参考这两个因素： 一个是脏页比例， 一个是redo log写盘速度。 InnoDB会根据这两个因素先单独算出两个数字。\nInnoDB每次写入的日志都有一个序号， 当前写入的序号跟checkpoint对应的序号之间的差值，我们假设为N。 InnoDB会根据这个N算出一个范围在0到100之间的数字， 这个计算公式可以记为F2(N)。 F2(N)算法比较复杂， 你只要知道N越大， 算出来的值越大就好了。然后， 根据上述算得的F1(M)和F2(N)两个值， 取其中较大的值记为R， 之后引擎就可以按照innodb_io_capacity定义的能力乘以R%来控制刷脏页的速度。\n现在你知道了， InnoDB会在后台刷脏页， 而刷脏页的过程是要将内存页写入磁盘。 所以， 无论是你的查询语句在需要内存的时候可能要求淘汰一个脏页， 还是由于刷脏页的逻辑会占用IO资源并可能影响到了你的更新语句\n而MySQL中的一个机制， 可能让你的查询会更慢： 在准备刷一个脏页的时候， 如果这个数据页旁边的数据页刚好是脏页， 就会把这个“邻居”也带着一起刷掉； 而且这个把“邻居”拖下水的逻辑还可以继续蔓延， 也就是对于每个邻居数据页， 如果跟它相邻的数据页也还是脏页的话， 也会被放到一起刷\n13 | 为什么表数据删掉一半， 表文件大小不变？ InnoDB引擎只会把R4这个记录标记为删除。 如果之后要再插入一个ID在300和600之间的记录时， 可能会复用这个位置。 但是， 磁盘文件的大小并不会缩小。\ndelete命令其实只是把记录的位置， 或者数据页标记为了“可复用”， 但磁盘文件的大小是不会变的。 也就是说， 通过delete命令是不能回收表空间的。 这些可以复用， 而没有被使用的空间， 看起来就像是“空洞”。\n不止是删除数据会造成空洞， 插入数据也会。\npage A满了， 再插入一个ID是550的数据时， 就不得不再申请一个新的页面page B来保存数据了。 页分裂完成后， page A的末尾就留下了空洞（注意： 实际上， 可能不止1个记录的位置是空洞） 。\n重建表\n你可以新建一个与表A结构相同的表B， 然后按照主键ID递增的顺序， 把数据一行一行地从表A里读出来再插入到表B中。由于表B是新建的表， 所以表A主键索引上的空洞， 在表B中就都不存在了。 显然地， 表B的主键索引更紧凑， 数据页的利用率也更高。 如果我们把表B作为临时表， 数据从表A导入表B的操作完成后， 用表B替换A，从效果上看， 就起到了收缩表A空间的作用。\n引入了Online DDL之后， 重建表的流程：\n1. 建立一个临时文件， 扫描表A主键的所有数据页；\n2. 用数据页中表A的记录生成B+树， 存储到临时文件中；\n3. 生成临时文件的过程中， 将所有对A的操作记录在一个日志文件（row log） 中，对应的是图中state2的状态；\n4. 临时文件生成后， 将日志文件中的操作应用到临时文件， 得到一个逻辑数据上与表A相同的数据文件， 对应的就是图中state3的状态；\n5. 用临时文件替换表A的数据文件\n14 | count(*)这么慢， 我该怎么办？ count(*)的实现方式\n在不同的MySQL引擎中， count(*)有不同的实现方式。MyISAM引擎把一个表的总行数存在了磁盘上， 因此执行count(*)的时候会直接返回这个数，效率很高；而InnoDB引擎就麻烦了， 它执行count(*)的时候， 需要把数据一行一行地从引擎里面读出来， 然后累积计数\n那为什么InnoDB不跟MyISAM一样， 也把数字存起来呢？ 这是因为即使是在同一个时刻的多个查询， 由于多版本并发控制（MVCC） 的原因， InnoDB表“应该返回多少行”也是不确定的。 这里， 我用一个算count(*)的例子来为你解释一下。\n这和InnoDB的事务设计有关系， 可重复读是它默认的隔离级别， 在代码上就是通过多版本并发控制， 也就是MVCC来实现的。 每一行记录都要判断自己是否对这个会话可见， 因此对于count(*)请求来说， InnoDB只好把数据一行一行地读出依次判断， 可见的行才能够用于计算“基于这个查询”的表的总行数。\nMyISAM表虽然count(*)很快， 但是不支持事务；\nshow table status命令虽然返回很快， 但是不准确；\nInnoDB表直接count(*)会遍历全表， 虽然结果准确， 但会导致性能问题。\n15 | 答疑文章（一） ： 日志和索引相关问题 日志相关问题\n1. 如果redo log里面的事务是完整的， 也就是已经有了commit标识， 则直接提交；\n2. 如果redo log里面的事务只有完整的prepare， 则判断对应的事务binlog是否存在并完整：\na. 如果是， 则提交事务；\nb. 否则， 回滚事务。\nredo log 和 binlog是怎么关联起来的?\n回答： 它们有一个共同的数据字段， 叫XID。 崩溃恢复的时候， 会按顺序扫描redo log：\n如果碰到既有prepare、 又有commit的redo log， 就直接提交；\n如果碰到只有parepare、 而没有commit的redo log， 就拿着XID去binlog找对应的事务。\nredo log一般设置多大？\nredo log太小的话， 会导致很快就被写满， 然后不得不强行刷redo log， 这样WAL机制的能力就发挥不出来了。所以， 如果是现在常见的几个TB的磁盘的话， 就不要太小气了， 直接将redo log设置为4个文件、 每个文件1GB吧。\n16 | “order by”是怎么工作的？ SQL\nselect\ncity,name,age from t where city='杭州' order by name limit 1000\n; 为避免全表扫描， 我们需要在city字段加上索引。在city字段上创建索引之后， 我们用explain命令来看看这个语句的执行情况。\n通常情况下， 这个语句执行流程如下所示 ：\n1. 初始化sort_buffer， 确定放入name、 city、 age这三个字段；\n2. 从索引city找到第一个满足city=\u0026lsquo;杭州’条件的主键id， 也就是图中的ID_X；\n3. 到主键id索引取出整行， 取name、 city、 age三个字段的值， 存入sort_buffer中；\n4. 从索引city取下一个记录的主键id；\n5. 重复步骤3、 4直到city的值不满足查询条件为止， 对应的主键id也就是图中的ID_Y；\n6. 对sort_buffer中的数据按照字段name做快速排序；\n7. 按照排序结果取前1000行返回给客户端。\n新的算法放入sort_buffer的字段， 只有要排序的列（ 即name字段） 和主键id。但这时， 排序的结果就因为少了city和age字段的值， 不能直接返回了， 整个执行流程就变成如\n下所示的样子：\n1. 初始化sort_buffer， 确定放入两个字段， 即name和id；\n2. 从索引city找到第一个满足city=\u0026lsquo;杭州’条件的主键id， 也就是图中的ID_X；\n3. 到主键id索引取出整行， 取name、 id这两个字段， 存入sort_buffer中；\n4. 从索引city取下一个记录的主键id；\n5. 重复步骤3、 4直到不满足city=\u0026lsquo;杭州’条件为止， 也就是图中的ID_Y；\n6. 对sort_buffer中的数据按照字段name进行排序；\n7. 遍历排序结果， 取前1000行， 并按照id的值回到原表中取出city、 name和age三个字段返回给客户端。\n17 | 如何正确地显示随机消息？ 对于内存表， 回表过程只是简单地根据数据行的位置， 直接访问内存得到数据， 根本不会导致多访问磁盘。\nMySQL的表是用什么方法来定位“一行数据”的。 如果你创建的表没有主键， 或者把一个表的主键删掉了， 那么InnoDB会自己生成一个长度为6字节的rowid来作为主键\n18 | 为什么这些SQL语句逻辑相同， 性能却差异巨大？ 案例一： 条件字段函数操作\n对索引字段做函数操作， 可能会破坏索引值的有序性， 因此优化器就决定放弃走树搜索功能。\n案例二： 隐式类型转换\n数据类型转换的规则是什么？\n为什么有数据类型转换， 就需要走全索引扫描？\n在MySQL中， 字符串和数字做比较的话， 是将字符串转换成数字\n案例三： 隐式字符编码转换\n其实是在说同一件事儿， 即： 对索引字段做函数操作， 可能会破坏索引值的有序性， 因此优化器就决定放弃走树搜索功能。\n19 | 为什么我只查一行的语句， 也执行这么慢？ 有些情况下， “查一行”， 也会执行得特别慢。\n第一类： 查询长时间不返回\n如图1所示， 在表t执行下面的SQL语句：\nSQL\nmysql\u0026gt;\nselect * from t where id=1; 查询结果长时间不返回。一般碰到这种情况的话， 大概率是表t被锁住了。 接下来分析原因的时候， 一般都是首先执行一下show processlist命令， 看看当前语句处于什么状态。然后我们再针对每种状态， 去分析它们产生的原因、 如何复现， 以及如何处理。\n等MDL锁\n出现这个状态表示的是， 现在有一个线程正在表t上请求或者持有MDL写锁， 把select语句堵住了。\n等flush\nSQL\nmysql\u0026gt;\nselect * from information_schema.processlist where id=1; 等行锁\n现在， 经过了表级锁的考验， 我们的select 语句终于来到引擎里了\nSQL\nmysql\u0026gt;\nselect * from t where id=1 lock in share mode; 第二类： 查询慢\nSQL\nmysql\u0026gt;\nselect * from t where id=1； 虽然扫描行数是1， 但执行时间却长达800毫秒。\nselect * from t where id=1 lock in share mode， 执行时扫描行数也是1行， 执行时间是0.2毫秒。\nsession A先用start transaction with consistent snapshot命令启动了一个事务， 之后session B才开始执行update 语句。session B执行完100万次update语句后， id=1这一行处于什么状态呢？\n带lock in share mode的SQL语句， 是当前读， 因此会直接读到1000001这个结果， 所以速度很快； 而select * from t where id=1这个语句， 是一致性读， 因此需要从1000001开始， 依次执行undo log， 执行了100万次以后， 才将1这个结果返回。\n20 | 幻读是什么， 幻读有什么问题？ 幻读是什么？\n如果只在id=5这一行加锁， 而其他行的不加锁的话， 会怎么样。\n可以看到， session A里执行了三次查询， 分别是Q1、 Q2和Q3。 它们的SQL语句相同， 都是select * from t where d=5 for update。 查所有d=5的行， 而且使用的是当前读， 并且加上写锁。\n1. Q1只返回id=5这一行；\n2. 在T2时刻， session B把id=0这一行的d值改成了5， 因此T3时刻Q2查出来的是id=0和id=5这\n两行；\n3. 在T4时刻， session C又插入一行（1,1,5） ， 因此T5时刻Q3查出来的是id=0、 id=1和id=5的这三行。\n其中， Q3读到id=1这一行的现象， 被称为“幻读”。 也就是说， 幻读指的是一个事务在前后两次查询同一个范围的时候， 后一次查询看到了前一次查询没有看到的行。\n说明\n1.在可重复读隔离级别下， 普通的查询是快照读， 是不会看到别的事务插入的数据的。 因此，幻读在“当前读”下才会出现。\n2. 上面session B的修改结果， 被session A之后的select语句用“当前读”看到， 不能称为幻读。幻读仅专指“新插入的行”。\n幻读有什么问题？\n1. 经过T1时刻， id=5这一行变成 (5,5,100)， 当然这个结果最终是在T6时刻正式提交的;\n2. 经过T2时刻， id=0这一行变成(0,5,5);\n3. 经过T4时刻， 表里面多了一行(1,5,5);\n4. 其他行跟这个执行序列无关， 保持不变。\n如何解决幻读？\n行锁只能锁住行， 但是新插入记录这个动作， 要更新的是记录之间的“间隙”。 因此， 为了解决幻读问题， InnoDB只好引入新的锁， 也就是间隙锁(Gap Lock)。\n执行 select * from t where d=5 for update的时候， 就不止是给数据库中已有的6个记录加上了行锁， 还同时加了7个间隙锁。 这样就确保了无法再插入新的记录。也就是说这时候， 在一行行扫描的过程中， 不仅将给行加上了行锁， 还给行两边的空隙， 也加上了间隙锁。\n跟间隙锁存在冲突关系的， 是“往这个间隙中插入一个记录”这个操作。 间隙锁之间都不存在冲突关系\n间隙锁和行锁合称next-keylock， 每个next-keylock是前开后闭区间。 也就是说， 我们的表t初始化以后， 如果用select * from t for update要把整个表所有记录锁起来， 就形成了7个next-key lock， 分别是 (-∞,0]、 (0,5]、 (5,10]、 (10,15]、 (15,20]、 (20, 25]、 (25, +supremum]。\n21 | 为什么我只改一行的语句， 锁这么多？ 1. 原则1： 加锁的基本单位是next-keylock。 希望你还记得， next-keylock是前开后闭区间。\n2. 原则2： 查找过程中访问到的对象才会加锁。\n3. 优化1： 索引上的等值查询， 给唯一索引加锁的时候， next-keylock退化为行锁。\n4. 优化2： 索引上的等值查询， 向右遍历时且最后一个值不满足等值条件的时候， next-key lock退化为间隙锁。\n5. 一个bug： 唯一索引上的范围查询会访问到不满足条件的第一个值为止。\n22 | MySQL有哪些“饮鸩止渴”提高性能的方法？ 第一种方法： 先处理掉那些占着连接但是不工作的线程。\n第二种方法： 减少连接过程的消耗。\n慢查询性能问题\n导致慢查询的第一种可能是， 索引没有设计好。\n导致慢查询的第二种可能是， 语句没写好。\nQPS突增问题\n1. 一种是由全新业务的bug导致的。 假设你的DB运维是比较规范的， 也就是说白名单是一个个加的。 这种情况下， 如果你能够确定业务方会下掉这个功能， 只是时间上没那么快， 那么就可以从数据库端直接把白名单去掉。\n2. 如果这个新功能使用的是单独的数据库用户， 可以用管理员账号把这个用户删掉， 然后断开现有连接。 这样， 这个新功能的连接不成功， 由它引发的QPS就会变成0。\n3. 如果这个新增的功能跟主体功能是部署在一起的， 那么我们只能通过处理语句来限制。 这时， 我们可以使用上面提到的查询重写功能， 把压力最大的SQL语句直接重写成\u0026quot;select 1\u0026quot;返回。\n23 | MySQL是怎么保证数据不丢的？ 只要redo log和binlog保证持久化到磁盘， 就能确保MySQL异常重启后， 数据可以恢复。\nbinlog的写入机制\n事务执行过程中， 先把日志写到binlog cache， 事务提交的时候， 再把binlog cache写到binlog文件中。 一个事务的binlog是不能被拆开的， 因此不论这个事务多大， 也要确保一次性写入。系统给binlog cache分配了一片内存， 每个线程一个， 参数 binlog_cache_size用于控制单个线程内binlog cache所占内存的大小。 如果超过了这个参数规定的大小， 就要暂存到磁盘。事务提交的时候， 执行器把binlog cache里的完整事务写入到binlog中， 并清空binlog cache。\n每个线程有自己binlog cache， 但是共用同一份binlog文件。\n图中的write， 指的就是指把日志写入到文件系统的page cache， 并没有把数据持久化到磁盘， 所以速度比较快。图中的fsync， 才是将数据持久化到磁盘的操作。 一般情况下， 我们认为fsync才占磁盘的IOPS。\nredo log的写入机制\n事务在执行过程中， 生成的redolog是要先写到redo log buffer的。 redo log buffer里面的内容， 是不是每次生成后都要直接持久化到磁盘呢？答案是， 不需要。如果事务执行期间MySQL发生异常重启， 那这部分日志就丢了。 由于事务并没有提交， 所以这时日志丢了也不会有损失。事务还没提交的时候， redo log buffer中的部分日志有没有可能被持久化到磁盘呢？答案是， 确实会有。\n这三种状态分别是：\n1. 存在redo log buffer中， 物理上是在MySQL进程内存中， 就是图中的红色部分；\n2. 写到磁盘(write)， 但是没有持久化（fsync)， 物理上是在文件系统的page cache里面， 也就\n是图中的黄色部分；\n3. 持久化到磁盘， 对应的是hard disk， 也就是图中的绿色部分。\n日志写到redo log buffer是很快的， wirte到page cache也差不多， 但是持久化到磁盘的速度就慢多了。\n三个并发事务(trx1, trx2, trx3)在prepare 阶段， 都写完redo log buffer， 持久化到磁盘的过程， 对应的LSN分别是50、 120 和160。\n1. trx1是第一个到达的， 会被选为这组的 leader；\n2. 等trx1要开始写盘的时候， 这个组里面已经有了三个事务， 这时候LSN也变成了160；\n3. trx1去写盘的时候， 带的就是LSN=160， 因此等trx1返回时， 所有LSN小于等于160的redo log， 都已经被持久化到磁盘；\n4. 这时候trx2和trx3就可以直接返回了。\n所以， 一次组提交里面， 组员越多， 节约磁盘IOPS的效果越好。 但如果只有单线程压测， 那就\n只能老老实实地一个事务对应一次持久化操作了。\nWAL机制主要得益于两个方面：\n1. redo log 和 binlog都是顺序写， 磁盘的顺序写比随机写速度要快；\n2. 组提交机制， 可以大幅度降低磁盘的IOPS消耗。\n如果你的MySQL现在出现了性能瓶颈， 而且瓶颈在IO上， 可以通过哪些方法来提升性能呢？\n1. 设置 binlog_group_commit_sync_delay和 binlog_group_commit_sync_no_delay_count参数， 减少binlog的写盘次数。 这个方法是基于“额外的故意等待”来实现的， 因此可能会增加语句的响应时间， 但没有丢失数据的风险。\n2. 将sync_binlog 设置为大于1的值（比较常见是100~1000） 。 这样做的风险是， 主机掉电时会丢binlog日志。\n3. 将innodb_flush_log_at_trx_commit设置为2。 这样做的风险是， 主机掉电的时候会丢数据。\n24 | MySQL是怎么保证主备一致的？ MySQL主备的基本原理\n节点A到B这条线的内部流程是什么样的。\n当binlog_format=statement时， binlog里面记录的就是SQL语句的原文。\n把binlog的格式改为binlog_format=‘row’\nrow格式的binlog里没有了SQL语句的原文， 而是替换成了两个event： Table_map和Delete_rows\n为什么会有mixed这种binlog格式的存在场景？\n因为有些statement格式的binlog可能会导致主备不一致， 所以要使用row格式。但row格式的缺点是， 很占空间。 比如你用一个delete语句删掉10万行数据， 用statement的话就是一个SQL语句被记录到binlog中， 占用几十个字节的空间。 但如果用row格式的binlog，就要把这10万条记录都写到binlog中。 这样做， 不仅会占用更大的空间， 同时写binlog也要耗费IO资源， 影响执行速度。所以， MySQL就取了个折中方案， 也就是有了mixed格式的binlog。 mixed格式的意思是， MySQL自己会判断这条SQL语句是否可能引起主备不一致， 如果有可能， 就用row格式，否则就用statement格式。\n循环复制问题\n双M结构和M-S结构， 其实区别只是多了一条线， 即： 节点A和B之间总是互为主备关系。 这样在切换的时候就不用再修改主备关系。\n业务逻辑在节点A上更新了一条语句， 然后再把生成的binlog 发给节点B， 节点B执行完这条更新语句后也会生成binlog。如果节点A同时是节点B的备库， 相当于又把节点B新生成的binlog拿过来执行了一次， 然后节点A和B间， 会不断地循环执行这个更新语句， 也就是循环复制了。 这个要怎么解决呢？\nMySQL在binlog中记录了这个命令第一次执行时所在实例的serverid。 因此， 我们可以用下面的逻辑， 来解决两个节点间的循环复制的问题：\n1. 规定两个库的server id必须不同， 如果相同， 则它们之间不能设定为主备关系；\n2. 一个备库接到binlog并在重放的过程中， 生成与原binlog的server id相同的新的binlog；\n3. 每个库在收到从自己的主库发过来的日志后， 先判断server id， 如果跟自己的相同， 表示这个日志是自己生成的， 就直接丢弃这个日志。\n按照这个逻辑， 如果我们设置了双M结构， 日志的执行流就会变成这样：\n1. 从节点A更新的事务， binlog里面记的都是A的server id；\n2. 传到节点B执行一次以后， 节点B生成的binlog 的server id也是A的server id；\n3. 再传回给节点A， A判断到这个server id与自己的相同， 就不会再处理这个日志。 所以， 死循环在这里就断掉了。\n25 | MySQL是怎么保证高可用的？ 正常情况下， 只要主库执行更新生成的所有binlog， 都可以传到备库并被正确地执行， 备库就能达到跟主库一致的状态， 这就是最终一致性。\n主备延迟\n主备切换可能是一个主动运维动作， 比如软件升级、 主库所在机器按计划下线等， 也可能是被动操作， 比如主库所在机器掉电。\n与数据同步有关的时间点主要包括以下三个：\n1. 主库A执行完成一个事务， 写入binlog， 我们把这个时刻记为T1;\n2. 之后传给备库B， 我们把备库B接收完这个binlog的时刻记为T2;\n3. 备库B执行完成这个事务， 我们把这个时刻记为T3。\n所谓主备延迟， 就是同一个事务， 在备库执行完成的时间和主库执行完成的时间之间的差值， 也就是T3-T1。\n主备延迟的来源\n首先， 有些部署条件下， 备库所在机器的性能要比主库所在的机器性能差。\n备库的压力大：备库上的查询耗费了大量的CPU资源， 影响了同步速度， 造成主备延迟\n￮ 这种情况， 我们一般可以这么处理：\n1. 一主多从。 除了备库外， 可以多接几个从库， 让这些从库来分担读的压力。\n2. 通过binlog输出到外部系统， 比如Hadoop这类系统， 让外部系统提供统计类查询的能力。\n大事务\n可靠性优先策略\n双M结构下， 从状态1到状态2切换的详细过程是这样的：\n1. 判断备库B现在的seconds_behind_master， 如果小于某个值（比如5秒） 继续下一步， 否则\n持续重试这一步；\n2. 把主库A改成只读状态， 即把readonly设置为true；\n3. 判断备库B的seconds_behind_master的值， 直到这个值变成0为止；\n4. 把备库B改成可读写状态， 也就是把readonly设置为false；\n5. 把业务请求切到备库B。\n这个切换流程， 一般是由专门的HA系统来完成的， 我们暂时称之为可靠性优先流程。\n可用性优先策略\n强行把步骤4、 5调整到最开始执行， 也就是说不等主备数据同步， 直接把连接切到备库B， 并且让备库B可以读写， 那么系统几乎就没有不可用时间了。我们把这个切换流程， 暂时称作可用性优先流程。 这个切换流程的代价， 就是可能出现数据不一致的情况。\n26 | 备库为什么会延迟好几个小时？ 如果备库执行日志的速度持续低于主库生成日志的速度， 那这个延迟就有可能成了小时级别。 而且对于一个压力持续比较高的主库来说， 备库很可能永远都追不上主库的节奏。\ncoordinator在分发的时候， 需要满足以下这两个基本要求：\n1. 不能造成更新覆盖。 这就要求更新同一行的两个事务， 必须被分发到同一个worker中。\n2. 同一个事务不能被拆开， 必须放到同一个worker中。\nMySQL 5.5版本的并行复制策略\n按表分发策略\n按表分发事务的基本思路是， 如果两个事务更新不同的表， 它们就可以并行。 因为数据是存储在表里的， 所以按表分发， 可以保证两个worker不会更新同一行。\n按行分发策略\n要解决热点表的并行复制问题， 就需要一个按行并行复制的方案。 按行复制的核心思路是： 如果两个事务没有更新相同的行， 它们在备库上可以并行执行。 显然， 这个模式要求binlog格式必须是row。\n相比于按表并行分发策略， 按行并行策略在决定线程分发的时候， 需要消耗更多的计算资源。\nMySQL 5.6版本的并行复制策略\n官方MySQL5.6版本， 支持了并行复制， 只是支持的粒度是按库并行。这个策略的并行效果， 取决于压力模型。 如果在主库上有多个DB， 并且各个DB的压力均衡， 使用这个策略的效果会很好。\nMySQL 5.7的并行复制策略\nMySQL 5.7并行复制策略的思想是：\n1. 同时处于prepare状态的事务， 在备库执行时是可以并行的；\n2. 处于prepare状态的事务， 与处于commit状态的事务之间， 在备库执行时也是可以并行的。\n为什么要有多线程复制呢？ 这是因为单线程复制的能力全面低于多线程复制， 对于更新压力较大的主库， 备库是可能一直追不上主库的。 从现象上看就是， 备库上seconds_behind_master的值越来越大。\n27 | 主库出问题了， 从库怎么办？ 图中， 虚线箭头表示的是主备关系， 也就是A和A’互为主备， 从库B、 C、 D指向的是主库A。一主多从的设置， 一般用于读写分离， 主库负责所有的写入和一部分读， 其他的读请求则由从库分担。\n相比于一主一备的切换流程， 一主多从结构在切换完成后， A’会成为新的主库， 从库B、 C、 D也要改接到A’。 正是由于多了从库B、 C、 D重新指向的这个过程， 所以主备切换的复杂性也相应增加了。\n28 | 读写分离有哪些坑？ 怎么处理过期读问题\n强制走主库方案\n我们可以将查询请求分为这么两类：\n1. 对于必须要拿到最新结果的请求， 强制将其发到主库上。 比如， 在一个交易平台上， 卖家发布商品以后， 马上要返回主页面， 看商品是否发布成功。 那么， 这个请求需要拿到最新的结果， 就必须走主库。\n2. 对于可以读到旧数据的请求， 才将其发到从库上。 在这个交易平台上， 买家来逛商铺页面，就算晚几秒看到最新发布的商品， 也是可以接受的。 那么， 这类请求就可以走从库。\nSleep 方案\n主库更新后， 读从库之前先sleep一下。\n判断主备无延迟方案\n第一种确保主备无延迟的方法是， 每次从库执行查询请求前， 先判断seconds_behind_master是否已经等于0。 如果还不等于0 ， 那就必须等到这个参数变为0才能执行查询请求 。第二种方法， 对比位点确保主备无延迟 。第三种方法， 对比GTID集合确保主备无延迟 。\n等主库位点方案\n1. trx1事务更新完成后， 马上执行show master status得到当前主库执行到的File和Position；\n2. 选定一个从库执行查询语句；\n3. 在从库上执行select master_pos_wait(File, Position, 1)；\n4. 如果返回值是\u0026gt;=0的正整数， 则在这个从库执行查询语句；\n5. 否则， 到主库执行查询语句。\n29 | 如何判断一个数据库是不是出问题了？ 主备切换有两种场景， 一种是主动切换， 一种是被动切换。 而其中被动切换， 往往是因为主库出问题了， 由HA系统发起的。\n查表判断\n为了能够检测InnoDB并发线程数过多导致的系统不可用情况， 我们需要找一个访问InnoDB的场景。 一般的做法是， 在系统库（mysql库） 里创建一个表， 比如命名为health_check， 里面只放一行数据， 然后定期执行： mysql\u0026gt; select * from mysql.health_check;\n内部统计\nMySQL 5.6版本以后提供的performance_schema库， 就在file_summary_by_event_name表里统计了每次IO请求的时间。\n30 | 答疑文章（二） ： 用动态的观点看加锁 原则1： 加锁的基本单位是next-keylock。 希望你还记得， next-keylock是前开后闭区间。\n原则2： 查找过程中访问到的对象才会加锁。\n优化1： 索引上的等值查询， 给唯一索引加锁的时候， next-keylock退化为行锁。\n优化2： 索引上的等值查询， 向右遍历时且最后一个值不满足等值条件的时候， next-keylock退化为间隙锁。\n一个bug： 唯一索引上的范围查询会访问到不满足条件的第一个值为止。\n31 | 误删数据后除了跑路， 还能怎么办？ 先对和MySQL相关的误删数据， 做下分类：\n1. 使用delete语句误删数据行；\n2. 使用drop table或者truncate table语句误删数据表；\n3. 使用drop database语句误删数据库；\n4. 使用rm命令误删整个MySQL实例。\n误删行\n具体恢复数据时， 对单个事务做如下处理：\n1. 对于insert语句， 对应的binlog event类型是Write_rows event， 把它改成Delete_rows event即可；\n2. 同理， 对于delete语句， 也是将Delete_rows event改为Write_rows event；\n3. 而如果是Update_rows的话， binlog里面记录了数据行修改前和修改后的值， 对调这两行的位置即可。\n误删库/表\n这种情况下， 要想恢复数据， 就需要使用全量备份， 加增量日志的方式了。 这个方案要求线上有定期的全量备份， 并且实时备份binlog。在这两个条件都具备的情况下， 假如有人中午12点误删了一个库， 恢复数据的流程如下：\n1. 取最近一次全量备份， 假设这个库是一天一备， 上次备份是当天0点；\n2. 用备份恢复出一个临时库；\n3. 从日志备份里面， 取出凌晨0点之后的日志；\n4. 把这些日志， 除了误删除数据的语句外， 全部应用到临时库。\nrm删除数据\n只要不是恶意地把整个集群删除， 而只是删掉了其中某一个节点的数据的话， HA系统就会开始工作， 选出一个新的主库， 从而保证整个集群的正常工作。这时， 你要做的就是在这个节点上把数据恢复回来， 再接入整个集群\n32 | 为什么还有kill不掉的语句？ 在MySQL中有两个kill命令： 一个是kill query+线程id， 表示终止这个线程中正在执行的语句； 一个是kill connection +线程id， 这里connection可缺省， 表示断开这个线程的连接， 当然如果这个线程有语句正在执行， 也是要先停止正在执行的语句的。不知道你在使用MySQL的时候， 有没有遇到过这样的现象： 使用了kill命令， 却没能断开这个连接。 再执行show processlist命令， 看到这条语句的Command列显示的是Killed。\nkill并不是马上停止的意思， 而是告诉执行线程说， 这条语句已经不需要继续执行了，可以开始“执行停止的逻辑了”。\nMySQL客户端发送请求后， 接收服务端返回结果的方式有两种：\n1. 一种是本地缓存， 也就是在本地开一片内存， 先把结果存起来。 如果你用API开发， 对应的就是mysql_store_result 方法。\n2. 另一种是不缓存， 读一个处理一个。 如果你用API开发， 对应的就是mysql_use_result方法。\n33 | 我查这么多数据， 会不会把数据库内存打爆？ 全表扫描对server层的影响\nInnoDB的数据是保存在主键索引上的， 所以全表扫描实际上是直接扫描表t的主键索引。 这条查询语句由于没有其他的判断条件， 所以查到的每一行都可以直接放到结果集里面， 然后返回给客户端\n实际上， 服务端并不需要保存一个完整的结果集。 取数据和发数据的流程是这样的：\n1. 获取一行， 写到net_buffer中。 这块内存的大小是由参数net_buffer_length定义的， 默认是16k。\n2. 重复获取行， 直到net_buffer写满， 调用网络接口发出去。\n3. 如果发送成功， 就清空net_buffer， 然后继续取下一行， 并写入net_buffer。\n4. 如果发送函数返回EAGAIN或WSAEWOULDBLOCK， 就表示本地网络栈（socket send buffer） 写满了， 进入等待。 直到网络栈重新可写， 再继续发送。\n全表扫描对InnoDB的影响\nInnoDB内存管理用的是最近最少使用 (Least RecentlyUsed, LRU)算法， 这个算法的核心就是淘汰最久未使用的数据。\nInnoDB不能直接使用这个LRU算法。 实际上， InnoDB对LRU算法做了改进。在InnoDB实现上， 按照5:3的比例把整个LRU链表分成了young区域和old区域。 图中LRU_old指向的就是old区域的第一个位置， 是整个链表的5/8处。 也就是说， 靠近链表头部的5/8是young区域， 靠近链表尾部的3/8是old区域。\n改进后的LRU算法执行流程变成了下面这样。\n1. 图7中状态1， 要访问数据页P3， 由于P3在young区域， 因此和优化前的LRU算法一样， 将其移到链表头部， 变成状态2。\n2. 之后要访问一个新的不存在于当前链表的数据页， 这时候依然是淘汰掉数据页Pm， 但是新插入的数据页Px， 是放在LRU_old处。\n3. 处于old区域的数据页， 每次被访问的时候都要做下面这个判断：若这个数据页在LRU链表中存在的时间超过了1秒， 就把它移动到链表头部；如果这个数据页在LRU链表中存在的时间短于1秒， 位置保持不变。 1秒这个时间， 是由参数innodb_old_blocks_time控制的。 其默认值是1000， 单位毫秒。\n我们看看改进后的LRU算法的操作逻辑：\n1. 扫描过程中， 需要新插入的数据页， 都被放到old区域;\n2. 一个数据页里面有多条记录， 这个数据页会被多次访问到， 但由于是顺序扫描， 这个数据页第一次被访问和最后一次被访问的时间间隔不会超过1秒， 因此还是会被保留在old区域；\n3. 再继续扫描后续的数据， 之前的这个数据页之后也不会再被访问到， 于是始终没有机会移到链表头部（也就是young区域） ， 很快就会被淘汰出去。\n34 | 到底可不可以使用join？ 在实际生产中， 关于join语句使用的问题， 一般会集中在以下两类：\n1. 我们DBA不让使用join， 使用join有什么问题呢？\n2. 如果有两个大小不同的表做join， 应该用哪个表做驱动表呢？\nIndex Nested-Loop Join\nSQL\nselect\n* from t1 straight_join t2 on (t1.a=t2.a); 如果直接使用join语句， MySQL优化器可能会选择表t1或t2作为驱动表， 这样会影响我们分析SQL语句的执行过程。 所以， 为了便于分析执行过程中的性能问题， 我改用straight_join让MySQL使用固定的连接方式执行查询， 这样优化器只会按照我们指定的方式去join。 在这个语句里， t1 是驱动表， t2是被驱动表。\n可以看到， 在这条语句里， 被驱动表t2的字段a上有索引， join过程用上了这个索引， 因此这个语句的执行流程是这样的：\n1. 从表t1中读入一行数据 R；\n2. 从数据行R中， 取出a字段到表t2里去查找；\n3. 取出表t2中满足条件的行， 跟R组成一行， 作为结果集的一部分；\n4. 重复执行步骤1到3， 直到表t1的末尾循环结束。\n1. 使用join语句， 性能比强行拆成多个单表执行SQL语句的性能要好；\n2. 如果使用join语句的话， 需要让小表做驱动表。\nSimple Nested-Loop Join\n由于表的字段b上没有索引， 因此再用图的执行流程时， 每次到t2去匹配的时候， 就要做一次全表扫描 。\nBlock Nested-Loop Join\n这时候， 被驱动表上没有可用的索引， 算法的流程是这样的：\n1. 把表t1的数据读入线程内存join_buffer中， 由于我们这个语句中写的是select *， 因此是把整个表t1放入了内存；\n2. 扫描表t2， 把表t2中的每一行取出来， 跟join_buffer中的数据做对比， 满足join条件的， 作为结果集的一部分返回。\njoin_buffer的大小是由参数join_buffer_size设定的， 默认值是256k。 如果放不下表t1的所有数据话， 策略很简单， 就是分段放。 我把join_buffer_size改成1200， 再执行：\nSQL\nselect\n* from t1 straight_join t2 on (t1.a=t2.b); 执行过程就变成了：\n1. 扫描表t1， 顺序读取数据行放入join_buffer中， 放完第88行join_buffer满了， 继续第2步；\n2. 扫描表t2， 把t2中的每一行取出来， 跟join_buffer中的数据做对比， 满足join条件的， 作为结果集的一部分返回；\n3. 清空join_buffer；\n4. 继续扫描表t1， 顺序读取最后的12行数据放入join_buffer中， 继续执行第2步。\n我们再来看下， 在这种情况下驱动表的选择问题。\n假设， 驱动表的数据行数是N， 需要分K段才能完成算法流程， 被驱动表的数据行数是M。注意， 这里的K不是常数， N越大K就会越大， 因此把K表示为λ*N， 显然λ的取值范围是(0,1)。所以， 在这个算法的执行过程中：\n1. 扫描行数是 N+λ*N*M；\n2. 内存判断 N*M次。\n显然， 内存判断次数是不受选择哪个表作为驱动表影响的。 而考虑到扫描行数， 在M和N大小确定的情况下， N小一些， 整个算式的结果会更小。所以结论是， 应该让小表当驱动表。当然， 你会发现， 在N+λ*N*M这个式子里， λ才是影响扫描行数的关键因素， 这个值越小越好。\n第一个问题： 能不能使用join语句？\n1. 如果可以使用IndexNested-Loop Join算法， 也就是说可以用上被驱动表上的索引， 其实是没问题的；\n2. 如果使用Block Nested-Loop Join算法， 扫描行数就会过多。 尤其是在大表上的join操作， 这样可能要扫描被驱动表很多次， 会占用大量的系统资源。 所以这种join尽量不要用。所以你在判断要不要使用join语句时， 就是看explain结果里面， Extra字段里面有没有出现“Block Nested Loop”字样。\n第二个问题是： 如果要使用join， 应该选择大表做驱动表还是选择小表做驱动表？\n1. 如果是IndexNested-Loop Join算法， 应该选择小表做驱动表；\n2. 如果是Block Nested-Loop Join算法：\n在join_buffer_size足够大的时候， 是一样的；在join_buffer_size不够大的时候（这种情况更常见） ， 应该选择小表做驱动表。所以， 这个问题的结论就是， 总是应该使用小表做驱动表。\n在决定哪个表做驱动表的时候， 应该是两个表按照各自的条件过滤， 过滤完成之后， 计算参与join的各个字段的总数据量， 数据量小的那个表， 就是“小表”， 应该作为驱动表。\n35 | join语句怎么优化？ Multi-Range Read优化\nMulti-Range Read优化 (MRR)。 这个优化的主要目的是尽量使用顺序读盘。\n主键索引是一棵B+树， 在这棵树上， 每次只能根据一个主键id查到一行数据。 因此， 回表肯定是一行行搜索主键索引的\n如果随着a的值递增顺序查询的话， id的值就变成随机的， 那么就会出现随机访问， 性能相对较差。 虽然“按行查”这个机制不能改， 但是调整查询的顺序， 还是能够加速的。因为大多数的数据都是按照主键递增顺序插入得到的， 所以我们可以认为， 如果按照主键的递增顺序查询的话， 对磁盘的读比较接近顺序读， 能够提升读性能。\n这就是MRR优化的设计思路。 此时， 语句的执行流程变成了这样：\n1. 根据索引a， 定位到满足条件的记录， 将id值放入read_rnd_buffer中;\n2. 将read_rnd_buffer中的id进行递增排序；\n3. 排序后的id数组， 依次到主键id索引中查记录， 并作为结果返回。\nBatched Key Access\nNLJ算法执行的逻辑是： 从驱动表t1， 一行行地取出a的值， 再到被驱动表t2去做join。 也就是说， 对于表t2来说， 每次都是匹配一个值。 这时， MRR的优势就用不上了。\nBNL算法的性能问题\n大表join操作虽然对IO有影响， 但是在语句执行结束后， 对IO的影响也就结束了。 但是，对Buffer Pool的影响就是持续性的， 需要依靠后续的查询请求慢慢恢复内存命中率。\n也就是说， BNL算法对系统的影响主要包括三个方面：\n1. 可能会多次扫描被驱动表， 占用磁盘IO资源；\n2. 判断join条件需要执行M*N次对比（M、 N分别是两张表的行数） ， 如果是大表就会占用非常多的CPU资源；\n3. 可能会导致Buffer Pool的热数据被淘汰， 影响内存命中率。\n36 | 为什么临时表可以重名？ 有的人可能会认为， 临时表就是内存表。 但是，这两个概念可是完全不同的。\n• 内存表， 指的是使用Memory引擎的表， 建表语法是create table engine=memory。 这种表的数据都保存在内存里， 系统重启的时候会被清空， 但是表结构还在。 除了这两个特性看上去比较“奇怪”外， 从其他的特征上看， 它就是一个正常的表。\n• 而临时表， 可以使用各种引擎类型 。 如果是使用InnoDB引擎或者MyISAM引擎的临时表， 写数据的时候是写到磁盘上的。 当然， 临时表也可以使用Memory引擎。\n临时表的特性\n临时表在使用上有以下几个特点：\n1. 建表语法是create temporarytable …。\n2. 一个临时表只能被创建它的session访问， 对其他线程不可见。\n3. 临时表可以与普通表同名。\n4. session A内有同名的临时表和普通表的时候， show create语句， 以及增删改查语句访问的是临时表。\n5. show tables命令不显示临时表。\n为什么临时表可以重名？\nSQL\ncreate\ntemporary table temp_t(id int primary key)engine=innodb; MySQL要给这个InnoDB表创建一个frm文件保存表结构定义， 还要有地方保存表数据。这个frm文件放在临时文件目录下， 文件名的后缀是.frm， 前缀是“#sql{进程id}_{线程id}_序列号”。 你可以使用select @@tmpdir命令， 来显示实例的临时文件目录。\n37 | 什么时候会使用内部临时表？ union 执行流程\nSQL\n(select\n1000 as f) union (select id from t1 order by id desc limit 2); 1. 创建一个内存临时表， 这个临时表只有一个整型字段f， 并且f是主键字段。\n2. 执行第一个子查询， 得到1000这个值， 并存入临时表中。\n3. 执行第二个子查询：\ni. 拿到第一行id=1000， 试图插入临时表中。 但由于1000这个值已经存在于临时表了， 违反了唯一性约束， 所以插入失败， 然后继续执行；\nii. 取到第二行id=999， 插入临时表成功。\n4. 从临时表中按行取出数据， 返回结果， 并删除临时表， 结果中包含两行数据分别是1000和999。\n可以看到， 这里的内存临时表起到了暂存数据的作用， 而且计算过程还用上了临时表主键id的唯一性约束， 实现了union的语义。\ngroup by 执行流程\nSQL\nselect\nid%10 as m, count(*) as c from t1 group by m; 在Extra字段里面， 我们可以看到三个信息：\nUsing index， 表示这个语句使用了覆盖索引， 选择了索引a， 不需要回表；\nUsing temporary， 表示使用了临时表；\nUsing filesort， 表示需要排序。\n这个语句的执行流程是这样的：\n1. 创建内存临时表， 表里有两个字段m和c， 主键是m；\n2. 扫描表t1的索引a， 依次取出叶子节点上的id值， 计算id%10的结果， 记为x；\n￮ 如果临时表中没有主键为x的行， 就插入一个记录(x,1);\n￮ 如果表中有主键为x的行， 就将x这一行的c值加1；\n3. 遍历完成后， 再根据字段m做排序， 得到结果集返回给客户端。\n指导原则\n1. 如果对group by语句的结果没有排序要求， 要在语句后面加 order bynull；\n2. 尽量让group by过程用上表的索引， 确认方法是explain结果里没有Using temporary和 Using filesort；\n3. 如果group by需要统计的数据量不大， 尽量只使用内存临时表； 也可以通过适当调大tmp_table_size参数， 来避免用到磁盘临时表；\n4. 如果数据量实在太大， 使用SQL_BIG_RESULT这个提示， 来告诉优化器直接使用排序算法得到group by的结果。\n38 | 都说InnoDB好， 那还要不要使用Memory引擎？ 内存表的数据组织结构\n假设有以下的两张表t1 和 t2， 其中表t1使用Memory引擎， 表t2使用InnoDB引擎。\n可以看到， 内存表t1的返回结果里面0在最后一行， 而InnoDB表t2的返回结果里0在第一行。表t2用的是InnoDB引擎， 它的主键索引id的组织方式， 你已经很熟悉了： InnoDB表的数据就放在主键索引树上， 主键索引是B+树。 所以表t2的数据组织方式如下图所示：\n与InnoDB引擎不同， Memory引擎的数据和索引是分开的。\n可见， InnoDB和Memory引擎的数据组织方式是不同的：\n￮ InnoDB引擎把数据放在主键索引上， 其他索引上保存的是主键id。 这种方式， 我们称之为索引组织表（IndexOrganizied Table） 。\n￮ 而Memory引擎采用的是把数据单独存放， 索引上保存数据位置的数据组织形式， 我们称之为堆组织表（Heap Organizied Table） 。\n从中我们可以看出， 这两个引擎的一些典型不同\n1. InnoDB表的数据总是有序存放的， 而内存表的数据就是按照写入顺序存放的；\n2. 当数据文件有空洞的时候， InnoDB表在插入新数据的时候， 为了保证数据有序性， 只能在固定的位置写入新值， 而内存表找到空位就可以插入新值；\n3. 数据位置发生变化的时候， InnoDB表只需要修改主键索引， 而内存表需要修改所有索引；\n4. InnoDB表用主键索引查询时需要走一次索引查找， 用普通索引查询的时候， 需要走两次索引查找。 而内存表没有这个区别， 所有索引的“地位”都是相同的。\n5. InnoDB支持变长数据类型， 不同记录的长度可能不同； 内存表不支持Blob 和 Text字段， 并且即使定义了varchar(N)， 实际也当作char(N)， 也就是固定长度字符串来存储， 因此内存表的每行数据长度相同。\nhash索引和B-Tree索引\n存表也是支B-Tree索引的。 在id列上创建一个B-Tree索引， SQL语句可以这么写：\nSQL\nalter\ntable t1 add index a_btree_index using btree (id); 内存表的锁\n内存表不支持行锁， 只支持表锁。 因此， 一张表只要有更新， 就会堵住其他所有在这个表上的读写操作。\n数据持久性问题\n数据放在内存中， 是内存表的优势， 但也是一个劣势。 因为， 数据库重启的时候， 所有的内存表都会被清空。内存表并不适合在生产环境上作为普通数据表使用 。\n1. 如果你的表更新量大， 那么并发度是一个很重要的参考指标， InnoDB支持行锁， 并发度比内存表好；\n2. 能放到内存表的数据量都不大。 如果你考虑的是读的性能， 一个读QPS很高并且数据量不大的表， 即使是使用InnoDB， 数据也是都会缓存在InnoDB Buffer Pool里的。 因此， 使用InnoDB表的读性能也不会差。\n建议你把普通内存表都用InnoDB表来代替\n内存临时表刚好可以无视内存表的两个不足， 主要是下面的三个原因：\n1. 临时表不会被其他线程访问， 没有并发性的问题；\n2. 临时表重启后也是需要删除的， 清空数据这个问题不存在；\n3. 备库的临时表也不会影响主库的用户线程。\n39 | 自增主键为什么不是连续的？ 自增值保存在哪儿？\n可以看到， 表定义里面出现了一个AUTO_INCREMENT=2， 表示下一次插入数据时， 如果需要自动生成自增值， 会生成id=2。其实， 这个输出结果容易引起这样的误解： 自增值是保存在表结构定义里的。 实际上， 表的结构定义存放在后缀名为.frm的文件中， 但是并不会保存自增值。\n不同的引擎对于自增值的保存策略不同。MyISAM引擎的自增值保存在数据文件中。InnoDB引擎的自增值， 其实是保存在了内存里， 并且到了MySQL 8.0版本后， 才有了“自增值持久化”的能力， 也就是才实现了“如果发生重启， 表的自增值可以恢复为MySQL重启前的值”\n40 | insert语句的锁为什么这么多？ insert …select 是很常见的在两个表之间拷贝数据的方法。 你需要注意， 在可重复读隔离级别下， 这个语句会给select的表里扫描到的记录和间隙加读锁。\n而如果insert和select的对象是同一个表， 则有可能会造成循环写入。 这种情况下， 我们需要引入用户临时表来做优化。\ninsert 语句如果出现唯一键冲突， 会在冲突的唯一值上加共享的next-keylock(S锁)。 因此， 碰到由于唯一键约束导致报错后， 要尽快提交或回滚事务， 避免加锁时间过长。\n41 | 怎么最快地复制一张表？ mysqldump方法\nSQL\nmysqldump\n-h$host -P$port -u$user --add-locks=0 --no-create-info --single-transaction\n--set-gtid-purged=OFF db1 这条命令中， 主要参数含义如下：\n1. –single-transaction的作用是， 在导出数据的时候不需要对表db1.t加表锁， 而是使用STARTTRANSACTION WITH CONSISTENTSNAPSHOT的方法；\n2. –add-locks设置为0， 表示在输出的文件结果里， 不增加\u0026quot; LOCKTABLES t WRITE;\u0026quot;；\n3. –no-create-info的意思是， 不需要导出表结构；\n4. –set-gtid-purged=off表示的是， 不输出跟GTID相关的信息；\n5. –result-file指定了输出文件的路径， 其中client表示生成的文件是在客户端机器上的。\n通过这条mysqldump命令生成的t.sql文件中就包含了如图1所示的INSERT语句。\n导出CSV文件\n另一种方法是直接将结果导出成.csv文件。 MySQL提供了下面的语法， 用来将查询结果导出到服务端本地目录：\nSQL\nselect\n* from db1.t where a\u0026gt;900 into outfile '/server_tmp/t.csv'; 物理拷贝\n42 | grant之后要跟着flush privileges吗？ grant之后真的需要执行flush privileges吗？ 如果没有执行这个flush命令的话， 赋权语句真的不能生效吗？grant语句会同时修改数据表和内存， 判断权限的时候使用的是内存数据。 因此， 规范地使用grant和revoke语句， 是不需要随后加上flush privileges语句的。flush privileges语句本身会用数据表的数据重建一份内存权限数据， 所以在权限数据可能存在不一致的情况下再使用。 而这种不一致往往是由于直接用DML语句操作系统权限表导致的， 所以我们尽量不要使用这类语句。\n43 | 要不要使用分区表？ SQL\nCREATE\nTABLE `t` (\n`ftime` datetime NOT NULL,\n`c` int(11) DEFAULT NULL,\nKEY (`ftime`)\n) ENGINE=InnoDB DEFAULT CHARSET=latin1\nPARTITION BY RANGE (YEAR(ftime))\n(PARTITION p_2017 VALUES LESS THAN (2017) ENGINE = InnoDB,\nPARTITION p_2018 VALUES LESS THAN (2018) ENGINE = InnoDB,\nPARTITION p_2019 VALUES LESS THAN (2019) ENGINE = InnoDB,\nPARTITION p_others VALUES LESS THAN MAXVALUE ENGINE = InnoDB);\ninsert into t values('2017-4-1',1),('2018-4-1',1); 在表t中初始化插入了两行记录， 按照定义的分区规则， 这两行记录分别落在p_2018和p_2019这两个分区上。可以看到， 这个表包含了一个.frm文件和4个.ibd文件， 每个分区对应一个.ibd文件。 也就是说：对于引擎层来说， 这是4个表；对于Server层来说， 这是1个表。\n分区策略\n• MyISAM分区表使用的分区策略， 我们称为通用分区策略（generic partitioning） ， 每次访问分区都由server层控制。 通用分区策略， 是MySQL一开始支持分区表的时候就存在的代码， 在文件管理、 表管理的实现上很粗糙， 因此有比较严重的性能问题。\n• 从MySQL 5.7.9开始， InnoDB引擎引入了本地分区策略（native partitioning） 。 这个策略是在InnoDB内部自己管理打开分区的行为。\n• MySQL从5.7.17开始， 将MyISAM分区表标记为即将弃用(deprecated)， 意思是“从这个版本开始不建议这么使用， 请使用替代方案。 在将来的版本中会废弃这个功能”。\n• 从MySQL 8.0版本开始， 就不允许创建MyISAM分区表了， 只允许创建已经实现了本地分区策略的引擎。 目前来看， 只有InnoDB和NDB这两个引擎支持了本地分区策略。\n分区表的server层行为\n如果从server层看的话， 一个分区表就只是一个表。\n可以看到， 虽然session B只需要操作p_2107这个分区， 但是由于session A持有整个表t的MDL锁， 就导致了session B的alter语句被堵住。\n1. MySQL在第一次打开分区表的时候， 需要访问所有的分区；\n2. 在server层， 认为这是同一张表， 因此所有分区共用同一个MDL锁；\n3. 在引擎层， 认为这是不同的表， 因此MDL锁之后的执行过程， 会根据分区表规则，只访问必要的分区。\n有两个问题需要注意：1. 分区并不是越细越好。 实际上， 单表或者单分区的数据一千万行， 只要没有特别大的索引，对于现在的硬件能力来说都已经是小表了。2. 分区也不要提前预留太多， 在使用之前预先创建即可。 比如， 如果是按月分区， 每年年底时再把下一年度的12个新分区创建上即可。 对于没有数据的历史分区， 要及时的drop掉。\n至于分区表的其他问题， 比如查询需要跨多个分区取数据， 查询性能就会比较慢， 基本上就不是分区表本身的问题， 而是数据量的问题或者说是使用方式的问题了。\n44 | 答疑文章（三） ： 说一说这些好问题 45 | 自增id用完怎么办？ MySQL里面的几种自增id， 一起分析一下它们的值达到上限以后，会出现什么情况。2 -1（4294967295） 不是一个特别大的数， 对于一个频繁插入删除数据的表来说， 是可能会被用完的。 因此在建表的时候你需要考察你的表是否有可能达到这个上限， 如果有可能， 就应该创建成8个字节的bigint unsigned。\nInnoDB系统自增row_id\n如果你创建的InnoDB表没有指定主键， 那么InnoDB会给你创建一个不可见的， 长度为6个字节的row_id。 InnoDB维护了一个全局的dict_sys.row_id值， 所有无主键的InnoDB表， 每插入一行数据， 都将当前的dict_sys.row_id值作为要插入数据的row_id， 然后把dict_sys.row_id的值加1。\n每种自增id有各自的应用场景， 在达到上限后的表现也不同：\n1. 表的自增id达到上限后， 再申请时它的值就不会改变， 进而导致继续插入数据时报主键冲突的错误。\n2. row_id达到上限后， 则会归0再重新递增， 如果出现相同的row_id， 后写的数据会覆盖之前的数据。\n3. Xid只需要不在同一个binlog文件中出现重复值即可。 虽然理论上会出现重复值， 但是概率极小， 可以忽略不计。\n4. InnoDB的max_trx_id 递增值每次MySQL重启都会被保存起来， 所以我们文章中提到的脏读的例子就是一个必现的bug， 好在留给我们的时间还很充裕。\n5. thread_id是我们使用中最常见的， 而且也是处理得最好的一个自增id逻辑了。\n本文转自 https://zhuanlan.zhihu.com/p/658288649 ，如有侵权，请联系删除。\n","permalink":"http://localhost:1313/hugo-blog/public/post/dev-log/mysql%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/","tags":[],"title":"MySQL实战45讲笔记"},{"categories":[],"content":"背景 最近又收到新需求，原本项目已经集成了开源kafka进行功能开发，但是又因为开源的kafka不稳定，也不安全，所以就要求要集成华为RC6.5.1安全版kafka，并且能够跟开源的kafka进行动态切换，想用哪个用哪个。。\n注意：kafka集成是通过bean管理，所以有注册bean的操作\n废话不多说，开搞，我把我经历的踩坑和埋坑经验分享给有需要的人\n解决了哪些问题 1.如何通过配置文件控制初始化注册哪个版本的kafka的bean 简单说怎么解让springboot在启动时动态根据配置文件的配置项确定初始化注册指定版本的kafka的bean呢？ 使用@Bean+@ConditionalOnPoroperty+@ConditionalOnMissingBean做到可通过配置文件进行动态初始化\n示例：\n@Configuration public KafkaInitAutoConfigure{ @Bean @ConditionalOnPoroperty(prefix=\u0026#34;kafka\u0026#34;, name=\u0026#34;type\u0026#34;, havingValue=\u0026#34;apache\u0026#34;) @ConditionalOnMissingBean({KafkaInitTemplate.class,ApacheKafkaTemplate.class}) public KafkaInitTemplate apacheKafkaTemplateInit(){ //初始化apache开源kafka的逻辑 } @Bean @ConditionalOnPoroperty(prefix=\u0026#34;kafka\u0026#34;, name=\u0026#34;type\u0026#34;, havingValue=\u0026#34;huawei\u0026#34;) @ConditionalOnMissingBean({KafkaInitTemplate.class,HuaweiKafkaTemplate.class}) public HuaweiKafkaTemplate huaweiKafkaTemplateInit(){ //初始化华为安全版kafka的逻辑 } } kafka: # 选择使用开源版的kafka type: apache # 选择使用华为安全版的kafka # type: huawei 2.认证文件读取问题 使用华为安全版RC6.5.1，需要使用krb5.conf、user.keytab、以及jass.conf文件\njass.conf文件可代码生成，也可自己创建填写，内容格式如下：\nKafkaClient { com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true keyTab=\u0026#34;src/main/resources/user.keytab\u0026#34; principal=\u0026#34;developuser\u0026#34; useTicketCache=false storeKey=true debug=true; refreshKrb5Config=true; }; 其中keyTab为user.keytab文件的绝对路径，principal是认证用户.\n就如jass.conf文件中keytab的路径要求是一个绝对路径，所以，你的项目如果打成jar包去运行的话，就得考虑把这个认证文件放在一个固定的路径。\n如果你是上k8s，也不用担心，挂载对应的路径去读取就好了。\n3.运行报错：could not login: the client is being … 如果运行时初始化kafka生产者出现这个错误，一定是你的认证文件不正确，或者jass.conf中的配置信息填写不正确\n仔仔细细确认程序读取的那两个认证文件是否正确 仔仔细细确认jass.conf中配置的user.keytab路径是否正确 仔仔细细确认jass.conf中配置的principal是否正确 4. 运行报错：Clock skew too great (37) - PROCESS_TGS 原因就是：客户端和服务器系统时间相隔超过5分钟\n确认下两个系统之间的时间之差吧，通过相应的命令修改好即可\n注意：k8s启动的服务是看配置的时区是什么，即timezone，并不是所谓的系统时间。\n5. 运行报错：Server not found in Kerberos database (7) - LOOKING_UP_SERVER 原因：是因为kafka-clients版本问题\n要使用华为提供的kafka-clients，它兼容开源的kafka-clients，不用担心使用它，就不能切换到开源版的kafka\n完整的【同时集成华为RC6.5.1安全版kafka和原生kafka，通过配置文件动态控制】的代码如下 kafka自动装配类：KafkaInitAutoConfigure.java\n作用：用于项目启动时，根据指定配置初始化指定类型的kafkaTemple的bean，以便在各个service层使用。同一返回KafkaInitTemplate便于统一使用KafkaInitTemplate去进行kafka的生产和消费，关键在于底层的生产和消费使用不同的版本kafka即可，不需要把所有的类型都引用一遍\n@Configuration @EnableConfigurationProperties({KafkaInitProperties.class,HuaweiKafkaProperties.class}) @AutoConfigureAfter(KafkaAutoConfiguration.class) public KafkaInitAutoConfigure{ private static final Logger logger = LoggerFactory.getLogger(KafkaInitAutoConfigure.class) @Bean @ConditionalOnPoroperty(prefix=\u0026#34;kafka\u0026#34;, name=\u0026#34;type\u0026#34;, havingValue=\u0026#34;apache\u0026#34;) @ConditionalOnMissingBean({KafkaInitTemplate.class,ApacheKafkaTemplate.class}) public KafkaInitTemplate apacheKafkaTemplateInit(KafkaTemplate kafkaTemplate, ComsumerFactory consumerFactory, KafkaInitProperties kafkaInitProperties) throws Exception{ //初始化apache开源kafka的逻辑 logger.info(\u0026#34;初始化apache的kafka\u0026#34;); KafkaInitTemplate kafkaInitTemplate = new KafkaInitTemplate(); kafkaInitTemplate.setKafkaInitProperties(kafkaInitProperties); kafkaInitTemplate.setKafkaTemplate(kafkaTemplate); kafkaInitTemplate.setComsumerFactory(consumerFactory); kafkaInitTemplate.afterPropertiesSet(); return kafkaInitTemplate; } @Bean @ConditionalOnPoroperty(prefix=\u0026#34;kafka\u0026#34;, name=\u0026#34;type\u0026#34;, havingValue=\u0026#34;huawei\u0026#34;) @ConditionalOnMissingBean({KafkaInitTemplate.class,HuaweiKafkaTemplate.class}) public KafkaInitTemplate huaweiKafkaTemplateInit(HuaweiKafkaProperties huaweiKafkaProperties,KafkaInitProperties kafkaInitProperties) throws Exception{ //初始化华为安全版kafka的逻辑 logger.info(\u0026#34;初始化apache的kafka\u0026#34;); KafkaInitTemplate kafkaInitTemplate = new KafkaInitTemplate(); kafkaInitTemplate.setKafkaInitProperties(kafkaInitProperties); HuaweiKafkaTemplate huaweiKafkaTemplate = new HuaweiKafkaTemplate(); kafkaInitTemplate.setHuaweiKafkaTemplate(huaweiKafkaTemplate); kafkaInitTemplate.afterPropertiesSet(); return kafkaInitTemplate; } } 统一处理的kafka处理类：KafkaInitTemplate.java\n作用：提供一个各个类型的kafka装饰类，提供各个类型kafka的get和set方法，以及配置文件的get和set。提供send（生产）和recieve（消费）两个方法，recieve（消费）提供一个监听器，你可以通过代码起一个线程异步实时监听获取kafka消息\npublic class KafkaInitTemplate implements InitalizingBean{ private KafkaInitProperties kafkaInitProperties; private KafkaTemplate\u0026lt;String,String\u0026gt; kafkaTemplate; private ConsumerFactory consumerFactory; private HuaweiKafkaTemplate huaweiKafkaTemplate； @Override public void afterPropertiesSet() throws Exception{ switch(kafkaInitProperties.getKafkaType){ case \u0026#34;huawei\u0026#34;: Assert.state(huaweiKafkaTemplate != null, \u0026#34;huaweiKafkaTemplate未初始化\u0026#34;); break; default: Assert.state(kafkaTemplate != null, \u0026#34;kafkaTemplate未初始化\u0026#34;); Assert.state(consumerFactory != null, \u0026#34;consumerFactory未初始化\u0026#34;);\t} } public KafkaTemplate\u0026lt;String,String\u0026gt; getKafkaTemplate(){ Assert.state(kafkaTemplate != null, \u0026#34;kafkaTemplate未初始化\u0026#34;); return kafkaTemplate; } public void setKafkaTemplate(KafkaTemplate\u0026lt;String,String\u0026gt; kafkaTemplate){ this.kafkaTemplate = kafkaTemplate; } public KafkaInitProperties getKafkaInitProperties(){ return kafkaInitProperties; } public void setKafkaInitProperties(KafkaInitProperties kafkaInitProperties){ this.kafkaInitProperties = kafkaInitProperties; } public ConsumerFactory getConsumerFactory(){ Assert.state(consumerFactory != null, \u0026#34;consumerFactory未初始化\u0026#34;); return consumerFactory; } public void setConsumerFactory(ConsumerFactory consumerFactory){ this.consumerFactory = consumerFactory; } public HuaweiKafkaTemplate getHuaweiKafkaTemplate(){ Assert.state(huaweiKafkaTemplate != null, \u0026#34;huaweiKafkaTemplate未初始化\u0026#34;); return huaweiKafkaTemplate; } public void setKafkaTemplate(HuaweiKafkaTemplate huaweiKafkaTemplate){ this.huaweiKafkaTemplate = huaweiKafkaTemplate; } } /** * 往指定topic生产发布消息 */ public void send(String topic,String key, Object value){ Assert.notNull(topic,\u0026#34;topic不能为空\u0026#34;); Assert.notNull(key,\u0026#34;key不能为空\u0026#34;); Assert.notNull(value,\u0026#34;value不能为空\u0026#34;); switch(this.kafkaInitProperties.getKafkaType){ case \u0026#34;huawei\u0026#34;: this.huaweiKafkaTemplate.send(topic,key,JSON.toJSONString(value)); break; default: this.kafkaTemplate.send(topic,key,JSON.toJSONString(value));\t} } public AbstractMessageListenerContainer\u0026lt;String,String\u0026gt; receive(String topic, String groupId,MessageListener messageListener){ Assert.notNull(topic,\u0026#34;topic不能为空\u0026#34;); Assert.notNull(groupId,\u0026#34;groupId不能为空\u0026#34;); Assert.notNull(messageListener,\u0026#34;messageListener不能为空\u0026#34;); ContainerProperties containerProperties = new ContainerProperties(new String[]{topic}); containerProperties.setGroupId(groupId); containerProperties.setMessageListener(messageListener); KafkaMessageListenerContainer\u0026lt;String,String\u0026gt; messageListenerContainer; switch(this.kafkaInitProperties.getKafkaType){ case \u0026#34;huawei\u0026#34;: messageListenerContainer = new KafkaMessageListenerContainer(this.huaweiKafkaTemplate.createConsumerFactory(), containerProperties); break; default: messageListenerContainer = new KafkaMessageListenerContainer(this.consumerFactory, containerProperties);\t} messageListenerContainer.setBeanName(topic + \u0026#34;_\u0026#34; + groupId); messageListenerContainer.start(); return messageListenerContainer; } 至于HuaweiKafkaTemplate.java，参照从华为集群下载的kafka客户端示例中，初始化即可，下面就不一一手打了，太累了，提供一些照片给大家看看\n这是构造方法里面初始化了一个生产者\n这是创建一个消费者工厂的方法\n这是用消费者发送kafka消息的方法\n这是安全认证的方法\n如果你通过自己生成jass.conf文件，就没要调用writeJassFile方法\n以上只是提供一个实现思路，和一些问题的解决方案，大家在实操过程中可以参考，切不可生搬硬套，有问题可以问我，我会及时回复大家 文章知识点与官方知识档案匹配，可进一步学习相关知识\n云原生入门技能树 首页 概览 17248 人正在系统学习中\n本文转自 https://blog.csdn.net/zhangtao0417/article/details/125466693 ，如有侵权，请联系删除。\n","permalink":"http://localhost:1313/hugo-blog/public/post/dev-log/springboot%E7%AC%AC%E5%8D%81%E4%B8%89%E7%AF%87%E5%90%8C%E6%97%B6%E9%9B%86%E6%88%90%E5%8D%8E%E4%B8%BArc6.5.1%E5%AE%89%E5%85%A8%E7%89%88kafka%E5%92%8C%E5%8E%9F%E7%94%9Fkafka%E9%80%9A%E8%BF%87%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%8A%A8%E6%80%81%E6%8E%A7%E5%88%B6/","tags":[],"title":"SpringBoot第十三篇：同时集成华为RC6.5.1安全版kafka和原生kafka，通过配置文件动态控制"},{"categories":[],"content":" 一句话总结：Docker只是容器的一种，它面向的是单体，K8S可以管理多种容器，它面向的是集群，Docker可以作为一种容器方案被K8S管理。下文继续具体介绍。\n1、容器的核心概念 介绍这几个核心概念：OCI、CR、Runc、Containerd、CRI。\n1.1、容器运行规范 容器运行规范OCI（Open Container Initiative）即开放的容器运行时规范，定义了镜像和容器运行时的规范。\n容器镜像规范：该规范的目标是创建可互操作的工具，用于构建、传输和准备运行的容器镜像。\n容器运行时规范：该规范用于定义容器的配置、执行环境和生命周期。\n1.2、容器运行时 容器运行时（Container Runtime）负责以下工作：拉取镜像、提取镜像到文件系统、为容器准备挂载点、从容器镜像中设置元数据以确保容器按预期运行、提醒内核为该容器分配某种隔离、提醒内核为该容器分配资源限制、调用系统指令启动容器等。\n容器运行时的有如下方案：Containerd、CRI-O 、Kata、Virtlet等等。\n1.3、RunC RunC （Run Container）是从 Docker 的 libcontainer 中迁移而来的，实现了容器启停、资源隔离等功能。Docker将RunC捐赠给 OCI 作为OCI 容器运行时标准的参考实现。\nRunC是一个基于OCI标准实现的一个轻量级容器运行工具，用来创建和运行容器。纯从系统角度，Runc才是底层的容器运行时 。\n1.4、Containerd Containerd是用来维持通过RunC创建的容器的运行状态。即RunC用来创建和运行容器，containerd作为常驻进程用来管理容器。containerd（container daemon）是一个daemon进程用来管理和运行容器，可以用来拉取/推送镜像和管理容器的存储和网络。其中可以调用runc来创建和运行容器。\n很早之前的 Docker Engine 中就有了 Containerd，只不过现在是将 Containerd 从 Docker Engine 里分离出来，作为一个独立的开源项目，目标是提供一个更加开放、稳定的容器运行基础设施。分离出来的Containerd 将具有更多的功能，涵盖整个容器运行时管理的所有需求，提供更强大的支持。\nContainerd 是一个工业级标准的容器运行时，它强调简单性、健壮性和可移植性，Containerd 可以负责干下面这些事情：\n管理容器的生命周期（从创建容器到销毁容器） 拉取/推送容器镜像 存储管理（管理镜像及容器数据的存储） 调用 runc 运行容器（与 runc 等容器运行时交互） 管理容器网络接口及网络 K8S自v1.24 起，已经删除了Dockershim ，使用Containerd作为容器运行时。选择 Containerd原因是，它的调用链更短，组件更少，更稳定，占用节点资源更少。\n1.5、Docker、Containerd、RunC的关系 三者关系，见下图：\n1.6、CRI 容器运行时是 Kubernetes（K8S） 最重要的组件之一，负责管理镜像和容器的生命周期。Kubelet 通过 Container Runtime Interface (CRI) 与容器运行时交互，以管理镜像和容器。\nCRI即容器运行时接口，主要用来定义K8S与容器运行时的API调用，kubelet通过CRI来调用容器运行时，只要实现了CRI接口的容器运行时就可以对接到K8S的kubelet组件。\n2、Docker和K8S的关系 Docker和K8S本质上都是创建容器的工具，Docker作用与单机，K8S作用与集群。\n在单机的容器解决方案，首选Docker。随着时代的发展，对系统的性能有了更高的要求，高可用、高并发都是基本要求。随着要求变高的的同时，单机显然性能就跟不上了，服务器集群管理就是发展趋势，所以 Kubernetes 为代表的云原生技术强势发展。\n2.1、容器创建调用链路 Docker、Kubernetes、OCI、CRI-O、containerd、runc，他们是如何一起协作的呢，见下图。\n上图所示为容器的调用链路。如图我们看到的，只要是实现了CRI的容器运行时就能够被K8S采用。Containerd是通过CRI Plugin 来适配CRI的，而CRI-O则是为CRI量生打造。\n我们还可以看到包括了Docker和K8S两条主线，其中Docker主要是在面向单体应用，K8S是用于集群。\n2.2、关系 从上面的容器调用链路可以看到，对于Containerd 和 CRI-O我们非常清楚他们是干嘛的，但是对于Docker和K8S间的联系我们还需要再来理一下。\n如图为K8S与Docker之间的联系（包含K8S1.23版本在内以及之前的版本），从K8S-1.24版本开始将移除docker-shim模块。下面继续看看他们之间的小故事。\n3、Dockershim的小故事 3.1、dockershim的由来 自 K8S - v1.24 起，Dockershim 已被删除，这对K8S项目来说是一个积极的举措。\n在 K8S 的早期，只支持一个容器运行时，那个容器运行时就是 Docker Engine。 那时并没有其他的选择。\n随着时间推移，我们开始添加更多的容器运行时，比如 rkt 和 hypernetes，很明显 K8S 用户希望选择最适合他们的运行时。因此，K8S 需要一种方法来允许K8S集群灵活地使用任何容器运行时。\n于是有了容器运行时接口 (CRI) 的发布，CRI 的引入对K8S项目和K8S用户来说都很棒，但它引入了一个问题：Docker Engine 作为容器运行时的使用早于 CRI，所以Docker Engine 不兼容 CRI。\n为了解决这个问题，在 kubelet 组件中引入了一个小型软件 shim (dockershim)，专门用于填补 Docker Engine 和 CRI 之间的空白， 允许集群继续使用 Docker Engine 作为容器运行时。\n3.2、dockershim的宿命 然而，这个小软件 shim 从来没有打算成为一个永久的解决方案。 多年来，它的存在给 kubelet 本身带来了许多不必要的复杂性。由于这个 shim，Docker 的一些集成实现不一致，导致维护人员的负担增加。\n总之，这样的方式不但带来了更高的复杂度，而且由于部件的增加也增加了不稳定的因素，同时还增加了维护负担，所以弃用dockershim是迟早的事。\n总结：dockershim 一直都是 K8S 社区为了能让 Docker 成为其支持的容器运行时，所维护的一个兼容程序。 现在**所谓的废弃，**也仅仅是 K8S 要放弃对现在代码仓库中的 dockershim 的维护支持。以便K8S可以像刚开始时计划的那样，仅负责维护其 CRI ，任何兼容 CRI 的容器运行时，都可以作为 K8S 的 runtime。\n3.3、流转图：\n总结：本文讲了容器的核心概念、Docker和K8S的关系、Dockershim的小故事，希望对你有帮助！\n本篇完结！感谢你的阅读，欢迎点赞 关注 收藏 私信！！！\n原文链接：https://mp.weixin.qq.com/s/jmoxfDJxYKK7sLQLylaS8w 本文转自 https://www.cnblogs.com/mangod/p/18007490 ，如有侵权，请联系删除。\n","permalink":"http://localhost:1313/hugo-blog/public/post/dev-log/%E4%B8%80%E5%8F%A5%E8%AF%9D%E6%80%BB%E7%BB%93docker%E4%B8%8Ek8s%E7%9A%84%E5%85%B3%E7%B3%BB/","tags":[],"title":"一句话总结Docker与K8S的关系"},{"categories":[],"content":" 公众号：字节数组 希望对你有所帮助 🤣🤣\nConstraintLayout 目前是 Android Studio 的默认布局，其优势就是可以使用扁平化的视图层次结构（无嵌套视图组）来创建复杂多变的大型布局，在绘制效率上相对其它布局有很大优势。ConstraintLayout 与 RelativeLayout 相似，其中所有的视图均根据同级视图与父布局之间的关系来进行定位，但其灵活性要高于 RelativeLayout，并且更易于与 Android Studio 的布局编辑器配合使用\nConstraintLayout 能够灵活地定位和调整子 View 的大小，子 View 依靠约束关系来确定位置，且每个子 View 必须至少有一个水平约束条件加一个垂直约束条件，每个约束条件均表示与其它视图、父布局或隐形引导线之间连接或对齐方式。在一个约束关系中，需要有一个 Source（源）以及一个 Target（目标），Source 的位置依赖于 Target，可以理解为通过约束关系 Source 与 Target 链接在了一起，Source 相对于 Target 的位置便是固定的了\n引入依赖：\ndependencies { implementation \u0026#34;androidx.constraintlayout:constraintlayout:2.0.4\u0026#34; } 一、相对定位 ConstraintLayout 最基本的属性包含以下几个，即 layout_constraintXXX_toYYYOf 格式的属性，用于将 ViewA 的 XXX 方向和 ViewB 的 YYY 方向进行约束。当中，ViewB 也可以是父容器 ConstraintLayout，用 parent 来表示。这些属性都是用于为控件添加垂直和水平方向的约束力，根据约束力的 “有无” 或者 “强弱”，控件会处于不同的位置\nlayout_constraintLeft_toLeftOf layout_constraintLeft_toRightOf layout_constraintRight_toLeftOf layout_constraintRight_toRightOf layout_constraintTop_toTopOf layout_constraintTop_toBottomOf layout_constraintBottom_toTopOf layout_constraintBottom_toBottomOf layout_constraintStart_toEndOf layout_constraintStart_toStartOf layout_constraintEnd_toStartOf layout_constraintEnd_toEndOf layout_constraintBaseline_toBaselineOf 例如，根据约束的不同，控件在不同的方向上进行对齐\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;androidx.constraintlayout.widget.ConstraintLayout xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; xmlns:app=\u0026#34;http://schemas.android.com/apk/res-auto\u0026#34; xmlns:tools=\u0026#34;http://schemas.android.com/tools\u0026#34; android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;match_parent\u0026#34; tools:context=\u0026#34;.ConstraintLayoutActivity\u0026#34;\u0026gt; \u0026lt;TextView android:id=\u0026#34;@+id/tv1\u0026#34; android:layout_width=\u0026#34;200dp\u0026#34; android:layout_height=\u0026#34;150dp\u0026#34; android:layout_margin=\u0026#34;20dp\u0026#34; android:background=\u0026#34;#f5ec7e\u0026#34; android:gravity=\u0026#34;center\u0026#34; android:text=\u0026#34;Hello World!\u0026#34; app:layout_constraintStart_toStartOf=\u0026#34;parent\u0026#34; app:layout_constraintEnd_toStartOf=\u0026#34;@+id/tv2\u0026#34; app:layout_constraintTop_toTopOf=\u0026#34;parent\u0026#34; /\u0026gt; \u0026lt;TextView android:id=\u0026#34;@+id/tv2\u0026#34; android:layout_width=\u0026#34;0dp\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:layout_marginEnd=\u0026#34;20dp\u0026#34; android:background=\u0026#34;#68b0f9\u0026#34; android:gravity=\u0026#34;center\u0026#34; android:text=\u0026#34;没有设置底部约束，所以只会顶部和黄色方块对齐\u0026#34; app:layout_constraintEnd_toEndOf=\u0026#34;parent\u0026#34; app:layout_constraintStart_toEndOf=\u0026#34;@+id/tv1\u0026#34; app:layout_constraintTop_toTopOf=\u0026#34;@+id/tv1\u0026#34; /\u0026gt; \u0026lt;TextView android:id=\u0026#34;@+id/tv3\u0026#34; android:layout_width=\u0026#34;0dp\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:layout_marginEnd=\u0026#34;20dp\u0026#34; android:background=\u0026#34;#984ff7\u0026#34; android:gravity=\u0026#34;center\u0026#34; android:text=\u0026#34;上下均设置了约束，所以会居于中间\u0026#34; app:layout_constraintBottom_toBottomOf=\u0026#34;@+id/tv1\u0026#34; app:layout_constraintEnd_toEndOf=\u0026#34;parent\u0026#34; app:layout_constraintStart_toEndOf=\u0026#34;@+id/tv1\u0026#34; app:layout_constraintTop_toBottomOf=\u0026#34;@+id/tv2\u0026#34; /\u0026gt; \u0026lt;TextView android:id=\u0026#34;@+id/tv4\u0026#34; android:layout_width=\u0026#34;100dp\u0026#34; android:layout_height=\u0026#34;100dp\u0026#34; android:background=\u0026#34;#9C27B0\u0026#34; android:gravity=\u0026#34;center\u0026#34; android:text=\u0026#34;屏幕各个方向居中\u0026#34; app:layout_constraintBottom_toBottomOf=\u0026#34;parent\u0026#34; app:layout_constraintEnd_toEndOf=\u0026#34;parent\u0026#34; app:layout_constraintStart_toStartOf=\u0026#34;parent\u0026#34; app:layout_constraintTop_toTopOf=\u0026#34;parent\u0026#34; /\u0026gt; \u0026lt;/androidx.constraintlayout.widget.ConstraintLayout\u0026gt; 二、约束力的强度 如果想要让控件的左右或者上下间距具有固定的比例，这种即在某个方向上其两边的约束力的强度有所不同，可以依靠 layout_constraintHorizontal_bias 和 layout_constraintVertical_bias 两个属性来设置控件在水平和垂直方向的偏移量\n例如，可以来控制 TextView 的左右或者上下间距的百分比\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;androidx.constraintlayout.widget.ConstraintLayout xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; xmlns:app=\u0026#34;http://schemas.android.com/apk/res-auto\u0026#34; xmlns:tools=\u0026#34;http://schemas.android.com/tools\u0026#34; android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;match_parent\u0026#34; tools:context=\u0026#34;.ConstraintLayoutActivity\u0026#34;\u0026gt; \u0026lt;TextView android:layout_width=\u0026#34;200dp\u0026#34; android:layout_height=\u0026#34;200dp\u0026#34; android:background=\u0026#34;#FF9800\u0026#34; android:gravity=\u0026#34;center\u0026#34; android:text=\u0026#34;公众号：字节数组\u0026#34; android:textColor=\u0026#34;@android:color/white\u0026#34; app:layout_constraintBottom_toBottomOf=\u0026#34;parent\u0026#34; app:layout_constraintEnd_toEndOf=\u0026#34;parent\u0026#34; app:layout_constraintHorizontal_bias=\u0026#34;0.9\u0026#34; app:layout_constraintStart_toStartOf=\u0026#34;parent\u0026#34; app:layout_constraintTop_toTopOf=\u0026#34;parent\u0026#34; app:layout_constraintVertical_bias=\u0026#34;0.1\u0026#34; /\u0026gt; \u0026lt;TextView android:layout_width=\u0026#34;200dp\u0026#34; android:layout_height=\u0026#34;200dp\u0026#34; android:background=\u0026#34;#2196F3\u0026#34; android:gravity=\u0026#34;center\u0026#34; android:text=\u0026#34;https://github.com/leavesCZY\u0026#34; android:textColor=\u0026#34;@android:color/white\u0026#34; app:layout_constraintBottom_toBottomOf=\u0026#34;parent\u0026#34; app:layout_constraintEnd_toEndOf=\u0026#34;parent\u0026#34; app:layout_constraintHorizontal_bias=\u0026#34;0.9\u0026#34; app:layout_constraintStart_toStartOf=\u0026#34;parent\u0026#34; app:layout_constraintTop_toTopOf=\u0026#34;parent\u0026#34; app:layout_constraintVertical_bias=\u0026#34;0.9\u0026#34; /\u0026gt; \u0026lt;TextView android:layout_width=\u0026#34;200dp\u0026#34; android:layout_height=\u0026#34;200dp\u0026#34; android:background=\u0026#34;#4CAF50\u0026#34; android:gravity=\u0026#34;center\u0026#34; android:text=\u0026#34;Hello World!\u0026#34; android:textColor=\u0026#34;@android:color/white\u0026#34; app:layout_constraintBottom_toBottomOf=\u0026#34;parent\u0026#34; app:layout_constraintEnd_toEndOf=\u0026#34;parent\u0026#34; app:layout_constraintHorizontal_bias=\u0026#34;0.1\u0026#34; app:layout_constraintStart_toStartOf=\u0026#34;parent\u0026#34; app:layout_constraintTop_toTopOf=\u0026#34;parent\u0026#34; /\u0026gt; \u0026lt;/androidx.constraintlayout.widget.ConstraintLayout\u0026gt; 三、宽高比 在使用其它布局类型时，如果想让控件在不同的屏幕上都保持固定的宽高比是比较麻烦的，但用 ConstraintLayout 就很简单。例如，如果我们想为 Activity 实现一个固定宽高比的顶部标题栏的话，可以将宽度设置为占满屏幕，高设置为 0dp，然后通过 app:layout_constraintDimensionRatio 属性设定宽高比为一个固定比例，此时 ConstraintLayout 就会自动根据屏幕的宽度来动态计算标题栏应该具有的高度\n此外，要使用layout_constraintDimensionRatio属性，需要其宽度或者高度当中有一个值是可知的，且剩下的一个是 0dp。所谓的可知，即该值是已经具备了明确的约束条件。控件的宽高尺寸比例则通过 “float值” 或者 “宽度 : 高度” 的形式来设置，通过在比例值的前面添加 w 或者 h 来指明比例值是根据宽度还是高度来进行计算\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;androidx.constraintlayout.widget.ConstraintLayout xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; xmlns:app=\u0026#34;http://schemas.android.com/apk/res-auto\u0026#34; xmlns:tools=\u0026#34;http://schemas.android.com/tools\u0026#34; android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;match_parent\u0026#34; tools:context=\u0026#34;.ConstraintLayoutActivity\u0026#34;\u0026gt; \u0026lt;TextView android:layout_width=\u0026#34;0dp\u0026#34; android:layout_height=\u0026#34;0dp\u0026#34; android:background=\u0026#34;#f5ec7e\u0026#34; android:gravity=\u0026#34;center\u0026#34; android:text=\u0026#34;公众号：字节数组\u0026#34; android:textColor=\u0026#34;@android:color/black\u0026#34; android:textSize=\u0026#34;20sp\u0026#34; android:textStyle=\u0026#34;bold\u0026#34; app:layout_constraintDimensionRatio=\u0026#34;h,15:2\u0026#34; app:layout_constraintEnd_toEndOf=\u0026#34;parent\u0026#34; app:layout_constraintStart_toStartOf=\u0026#34;parent\u0026#34; app:layout_constraintTop_toTopOf=\u0026#34;parent\u0026#34; /\u0026gt; \u0026lt;TextView android:layout_width=\u0026#34;100dp\u0026#34; android:layout_height=\u0026#34;0dp\u0026#34; android:background=\u0026#34;#5476fd\u0026#34; android:gravity=\u0026#34;center\u0026#34; android:text=\u0026#34;Hello World!\u0026#34; app:layout_constraintBottom_toBottomOf=\u0026#34;parent\u0026#34; app:layout_constraintDimensionRatio=\u0026#34;W,1:1\u0026#34; app:layout_constraintEnd_toEndOf=\u0026#34;parent\u0026#34; app:layout_constraintStart_toStartOf=\u0026#34;parent\u0026#34; app:layout_constraintTop_toTopOf=\u0026#34;parent\u0026#34; /\u0026gt; \u0026lt;/androidx.constraintlayout.widget.ConstraintLayout\u0026gt; 四、控件之间的宽高占比 ConstraintLayout 也可以像 LinearLayout 一样为子控件设置 layout_weight 属性，从而控件子控件之间的宽高占比，对应的属性是：layout_constraintHorizontal_weight 和 layout_constraintVertical_weight\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;androidx.constraintlayout.widget.ConstraintLayout xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; xmlns:app=\u0026#34;http://schemas.android.com/apk/res-auto\u0026#34; xmlns:tools=\u0026#34;http://schemas.android.com/tools\u0026#34; android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;match_parent\u0026#34; tools:context=\u0026#34;.ConstraintLayoutActivity\u0026#34;\u0026gt; \u0026lt;TextView android:id=\u0026#34;@+id/tv1\u0026#34; android:layout_width=\u0026#34;0dp\u0026#34; android:layout_height=\u0026#34;0dp\u0026#34; android:background=\u0026#34;#f5ec7e\u0026#34; android:gravity=\u0026#34;center\u0026#34; android:text=\u0026#34;Hello World!\u0026#34; app:layout_constraintBottom_toTopOf=\u0026#34;@id/tv4\u0026#34; app:layout_constraintEnd_toStartOf=\u0026#34;@+id/tv2\u0026#34; app:layout_constraintHorizontal_weight=\u0026#34;3\u0026#34; app:layout_constraintStart_toStartOf=\u0026#34;parent\u0026#34; app:layout_constraintTop_toTopOf=\u0026#34;parent\u0026#34; app:layout_constraintVertical_weight=\u0026#34;1\u0026#34; /\u0026gt; \u0026lt;TextView android:id=\u0026#34;@+id/tv2\u0026#34; android:layout_width=\u0026#34;0dp\u0026#34; android:layout_height=\u0026#34;50dp\u0026#34; android:background=\u0026#34;#55e4f4\u0026#34; android:gravity=\u0026#34;center\u0026#34; android:text=\u0026#34;Hello World!\u0026#34; app:layout_constraintEnd_toStartOf=\u0026#34;@+id/tv3\u0026#34; app:layout_constraintHorizontal_weight=\u0026#34;2\u0026#34; app:layout_constraintStart_toEndOf=\u0026#34;@+id/tv1\u0026#34; app:layout_constraintTop_toTopOf=\u0026#34;parent\u0026#34; /\u0026gt; \u0026lt;TextView android:id=\u0026#34;@+id/tv3\u0026#34; android:layout_width=\u0026#34;0dp\u0026#34; android:layout_height=\u0026#34;50dp\u0026#34; android:background=\u0026#34;#f186ad\u0026#34; android:gravity=\u0026#34;center\u0026#34; android:text=\u0026#34;Hello World!\u0026#34; app:layout_constraintEnd_toEndOf=\u0026#34;parent\u0026#34; app:layout_constraintHorizontal_weight=\u0026#34;1\u0026#34; app:layout_constraintStart_toEndOf=\u0026#34;@+id/tv2\u0026#34; app:layout_constraintTop_toTopOf=\u0026#34;parent\u0026#34; /\u0026gt; \u0026lt;TextView android:id=\u0026#34;@+id/tv4\u0026#34; android:layout_width=\u0026#34;0dp\u0026#34; android:layout_height=\u0026#34;0dp\u0026#34; android:background=\u0026#34;#03A9F4\u0026#34; android:gravity=\u0026#34;center\u0026#34; android:text=\u0026#34;Hello World!\u0026#34; app:layout_constraintBottom_toTopOf=\u0026#34;@id/tv5\u0026#34; app:layout_constraintEnd_toEndOf=\u0026#34;@id/tv1\u0026#34; app:layout_constraintStart_toStartOf=\u0026#34;@id/tv1\u0026#34; app:layout_constraintTop_toBottomOf=\u0026#34;@id/tv1\u0026#34; app:layout_constraintVertical_weight=\u0026#34;1\u0026#34; /\u0026gt; \u0026lt;TextView android:id=\u0026#34;@+id/tv5\u0026#34; android:layout_width=\u0026#34;0dp\u0026#34; android:layout_height=\u0026#34;0dp\u0026#34; android:background=\u0026#34;#F44336\u0026#34; android:gravity=\u0026#34;center\u0026#34; android:text=\u0026#34;Hello World!\u0026#34; app:layout_constraintBottom_toBottomOf=\u0026#34;parent\u0026#34; app:layout_constraintEnd_toEndOf=\u0026#34;@id/tv4\u0026#34; app:layout_constraintStart_toStartOf=\u0026#34;@id/tv4\u0026#34; app:layout_constraintTop_toBottomOf=\u0026#34;@id/tv4\u0026#34; app:layout_constraintVertical_weight=\u0026#34;1\u0026#34; /\u0026gt; \u0026lt;/androidx.constraintlayout.widget.ConstraintLayout\u0026gt; 五、Dimensions 当控件的宽或者高设置为 0dp 时，可以用以下两个属性来指定控件的宽度或高度占父控件空间的百分比，属性值在 0 到 1 之间\nlayout_constrainWidth_percent layout_constrainHeight_percent \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;androidx.constraintlayout.widget.ConstraintLayout xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; xmlns:app=\u0026#34;http://schemas.android.com/apk/res-auto\u0026#34; xmlns:tools=\u0026#34;http://schemas.android.com/tools\u0026#34; android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;match_parent\u0026#34; tools:context=\u0026#34;.ConstraintLayoutActivity\u0026#34;\u0026gt; \u0026lt;Button android:id=\u0026#34;@+id/btn_target\u0026#34; android:layout_width=\u0026#34;0dp\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:text=\u0026#34;Target Button\u0026#34; android:textAllCaps=\u0026#34;false\u0026#34; app:layout_constraintBottom_toBottomOf=\u0026#34;parent\u0026#34; app:layout_constraintEnd_toEndOf=\u0026#34;parent\u0026#34; app:layout_constraintStart_toStartOf=\u0026#34;parent\u0026#34; app:layout_constraintTop_toTopOf=\u0026#34;parent\u0026#34; app:layout_constraintWidth_percent=\u0026#34;0.8\u0026#34; /\u0026gt; \u0026lt;Button android:layout_width=\u0026#34;0dp\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:text=\u0026#34;Source Button\u0026#34; android:textAllCaps=\u0026#34;false\u0026#34; app:layout_constraintBottom_toBottomOf=\u0026#34;parent\u0026#34; app:layout_constraintEnd_toEndOf=\u0026#34;parent\u0026#34; app:layout_constraintStart_toStartOf=\u0026#34;parent\u0026#34; app:layout_constraintTop_toBottomOf=\u0026#34;@id/btn_target\u0026#34; app:layout_constraintWidth_percent=\u0026#34;0.5\u0026#34; /\u0026gt; \u0026lt;/androidx.constraintlayout.widget.ConstraintLayout\u0026gt; 六、Visibility 在使用其它布局时，如果将 View 的 visibility 属性设置为 gone，那么其它原本依赖该 View 来参照定位的属性都会失效，而在 ConstraintLayout 布局中会有所不同\n在以下布局中，红色方块位于屏幕右上角与黄色方块左下角形成的矩形的中间位置\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;androidx.constraintlayout.widget.ConstraintLayout xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; xmlns:app=\u0026#34;http://schemas.android.com/apk/res-auto\u0026#34; xmlns:tools=\u0026#34;http://schemas.android.com/tools\u0026#34; android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;match_parent\u0026#34; tools:context=\u0026#34;.ConstraintLayoutActivity\u0026#34;\u0026gt; \u0026lt;TextView android:id=\u0026#34;@+id/tv1\u0026#34; android:layout_width=\u0026#34;100dp\u0026#34; android:layout_height=\u0026#34;100dp\u0026#34; android:background=\u0026#34;#f5ec7e\u0026#34; android:gravity=\u0026#34;center\u0026#34; android:text=\u0026#34;Hello World!\u0026#34; app:layout_constraintBottom_toBottomOf=\u0026#34;parent\u0026#34; app:layout_constraintEnd_toEndOf=\u0026#34;parent\u0026#34; app:layout_constraintStart_toStartOf=\u0026#34;parent\u0026#34; app:layout_constraintTop_toTopOf=\u0026#34;parent\u0026#34; /\u0026gt; \u0026lt;TextView android:id=\u0026#34;@+id/tv2\u0026#34; android:layout_width=\u0026#34;100dp\u0026#34; android:layout_height=\u0026#34;100dp\u0026#34; android:background=\u0026#34;#fa6e61\u0026#34; android:gravity=\u0026#34;center\u0026#34; android:text=\u0026#34;Hello World!\u0026#34; app:layout_constraintBottom_toBottomOf=\u0026#34;@+id/tv1\u0026#34; app:layout_constraintEnd_toEndOf=\u0026#34;parent\u0026#34; app:layout_constraintStart_toStartOf=\u0026#34;@+id/tv1\u0026#34; app:layout_constraintTop_toTopOf=\u0026#34;parent\u0026#34; /\u0026gt; \u0026lt;/androidx.constraintlayout.widget.ConstraintLayout\u0026gt; 而如果将黄色方块的 visibility 属性设置为 gone，那么红色方块的位置会发生变化。可以理解为黄色方块缩小为一个不可见的小点，位于其原先位置的中间，而红色方块则改为依照该点来进行定位\n此外，红色方块也可以依靠以下几个属性来控制当黄色方块为 Gone 时红色方块的 margin 值，这类属性只有在黄色方块的 visibility 属性设置为 gone 时才会生效\nlayout_goneMarginStart layout_goneMarginEnd layout_goneMarginLeft layout_goneMarginTop layout_goneMarginRight layout_goneMarginBottom 七、圆形定位 圆形定位用于将两个 View 以角度和距离这两个维度来进行定位，以两个 View 的中心点作为定位点\napp:layout_constraintCircle - 目标 View 的 ID app:layout_constraintCircleAngle - 对齐的角度 app:layout_constraintCircleRadius - 与目标 View 之间的距离（顺时针方向，0~360度） \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;androidx.constraintlayout.widget.ConstraintLayout xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; xmlns:app=\u0026#34;http://schemas.android.com/apk/res-auto\u0026#34; xmlns:tools=\u0026#34;http://schemas.android.com/tools\u0026#34; android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;match_parent\u0026#34; tools:context=\u0026#34;.ConstraintLayoutActivity\u0026#34;\u0026gt; \u0026lt;ImageView android:id=\u0026#34;@+id/iv_a\u0026#34; android:layout_width=\u0026#34;wrap_content\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:src=\u0026#34;@drawable/icon_a\u0026#34; app:layout_constraintBottom_toBottomOf=\u0026#34;parent\u0026#34; app:layout_constraintEnd_toEndOf=\u0026#34;parent\u0026#34; app:layout_constraintStart_toStartOf=\u0026#34;parent\u0026#34; app:layout_constraintTop_toTopOf=\u0026#34;parent\u0026#34; /\u0026gt; \u0026lt;ImageView android:id=\u0026#34;@+id/iv_b\u0026#34; android:layout_width=\u0026#34;wrap_content\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:src=\u0026#34;@drawable/icon_b\u0026#34; app:layout_constraintCircle=\u0026#34;@id/iv_a\u0026#34; app:layout_constraintCircleAngle=\u0026#34;45\u0026#34; app:layout_constraintCircleRadius=\u0026#34;200dp\u0026#34; /\u0026gt; \u0026lt;ImageView android:id=\u0026#34;@+id/iv_c\u0026#34; android:layout_width=\u0026#34;wrap_content\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:src=\u0026#34;@drawable/icon_c\u0026#34; app:layout_constraintCircle=\u0026#34;@id/iv_a\u0026#34; app:layout_constraintCircleAngle=\u0026#34;180\u0026#34; app:layout_constraintCircleRadius=\u0026#34;200dp\u0026#34; /\u0026gt; \u0026lt;/androidx.constraintlayout.widget.ConstraintLayout\u0026gt; 八、Guideline 当需要一个任意位置的锚点时，可以使用指示线（Guideline）来帮助定位，Guideline 是 View 的子类，使用方式和普通的 View 相同，但 Guideline 有着如下的特殊属性：\n宽度和高度均为 0 可见性为 View.GONE 即指示线只是为了帮助其他 View 进行定位，实际上并不会出现在页面上\n例如，如下代码加入了两条 Guideline，可以选择使用百分比或实际距离来设置 Guideline 的位置，并通过 orientation 属性来设置 Guideline 的方向\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;androidx.constraintlayout.widget.ConstraintLayout xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; xmlns:app=\u0026#34;http://schemas.android.com/apk/res-auto\u0026#34; xmlns:tools=\u0026#34;http://schemas.android.com/tools\u0026#34; android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;match_parent\u0026#34; tools:context=\u0026#34;.ConstraintLayoutActivity\u0026#34;\u0026gt; \u0026lt;androidx.constraintlayout.widget.Guideline android:id=\u0026#34;@+id/guideline1\u0026#34; android:layout_width=\u0026#34;wrap_content\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:orientation=\u0026#34;vertical\u0026#34; app:layout_constraintGuide_percent=\u0026#34;0.5\u0026#34; /\u0026gt; \u0026lt;androidx.constraintlayout.widget.Guideline android:id=\u0026#34;@+id/guideline2\u0026#34; android:layout_width=\u0026#34;wrap_content\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:orientation=\u0026#34;horizontal\u0026#34; app:layout_constraintGuide_begin=\u0026#34;100dp\u0026#34; /\u0026gt; \u0026lt;TextView android:id=\u0026#34;@+id/tv1\u0026#34; android:layout_width=\u0026#34;150dp\u0026#34; android:layout_height=\u0026#34;150dp\u0026#34; android:background=\u0026#34;#f5ec7e\u0026#34; android:gravity=\u0026#34;center\u0026#34; android:text=\u0026#34;Hello World!\u0026#34; app:layout_constraintLeft_toRightOf=\u0026#34;@+id/guideline1\u0026#34; app:layout_constraintTop_toBottomOf=\u0026#34;@+id/guideline2\u0026#34; /\u0026gt; \u0026lt;/androidx.constraintlayout.widget.ConstraintLayout\u0026gt; 设置横向指示线距离顶部 100dp，黄色方块根据该指示线来设定顶部位置。竖向指示线设置其横向距离百分比为 0.5，所以黄色方块的左侧会位于屏幕的中间位置\n九、Barrier 很多时候我们都会遇到控件的宽高值随着其包含的数据的多少而改变的情况，而此时如果有多个控件之间是相互约束的话，就比较难来设定各个控件间的约束关系了，而 Barrier（屏障）就是用于解决这种情况。Barrier 和 GuideLine 一样是一个虚拟的 View，对界面是不可见的，只是用于辅助布局\nBarrier 可以使用的属性有：\nbarrierDirection：用于设置 Barrier 的位置，属性值有：bottom、top、start、end、left、right constraint_referenced_ids：用于设置 Barrier 所引用的控件的 ID，可同时设置多个 barrierAllowsGoneWidgets：默认为 true，当 Barrier 所引用的控件为 Gone 时，则 Barrier 的创建行为是在已 Gone 的控件已解析的位置上进行创建。如果设置为 false，则不会将 Gone 的控件考虑在内 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;androidx.constraintlayout.widget.ConstraintLayout xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; xmlns:app=\u0026#34;http://schemas.android.com/apk/res-auto\u0026#34; xmlns:tools=\u0026#34;http://schemas.android.com/tools\u0026#34; android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;match_parent\u0026#34; tools:context=\u0026#34;.ConstraintLayoutActivity\u0026#34;\u0026gt; \u0026lt;TextView android:id=\u0026#34;@+id/btn_target\u0026#34; android:layout_width=\u0026#34;wrap_content\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:background=\u0026#34;#03A9F4\u0026#34; android:padding=\u0026#34;10dp\u0026#34; android:text=\u0026#34;这是一段并不长的文本\u0026#34; android:textAllCaps=\u0026#34;false\u0026#34; app:layout_constraintBottom_toBottomOf=\u0026#34;parent\u0026#34; app:layout_constraintStart_toStartOf=\u0026#34;parent\u0026#34; app:layout_constraintTop_toTopOf=\u0026#34;parent\u0026#34; /\u0026gt; \u0026lt;TextView android:id=\u0026#34;@+id/btn_source\u0026#34; android:layout_width=\u0026#34;wrap_content\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:background=\u0026#34;#009688\u0026#34; android:padding=\u0026#34;10dp\u0026#34; android:text=\u0026#34;我也不知道说什么好\u0026#34; android:textAllCaps=\u0026#34;false\u0026#34; app:layout_constraintBottom_toBottomOf=\u0026#34;parent\u0026#34; app:layout_constraintStart_toStartOf=\u0026#34;parent\u0026#34; app:layout_constraintTop_toBottomOf=\u0026#34;@id/btn_target\u0026#34; /\u0026gt; \u0026lt;androidx.constraintlayout.widget.Barrier android:id=\u0026#34;@+id/barrier\u0026#34; android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;match_parent\u0026#34; app:barrierAllowsGoneWidgets=\u0026#34;false\u0026#34; app:barrierDirection=\u0026#34;end\u0026#34; app:constraint_referenced_ids=\u0026#34;btn_target,btn_source\u0026#34; /\u0026gt; \u0026lt;TextView android:layout_width=\u0026#34;wrap_content\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:background=\u0026#34;#E91E63\u0026#34; android:padding=\u0026#34;10dp\u0026#34; android:text=\u0026#34;那就随便写写吧\u0026#34; android:textAllCaps=\u0026#34;false\u0026#34; app:layout_constraintBottom_toBottomOf=\u0026#34;parent\u0026#34; app:layout_constraintStart_toEndOf=\u0026#34;@id/barrier\u0026#34; app:layout_constraintTop_toBottomOf=\u0026#34;@id/btn_target\u0026#34; /\u0026gt; \u0026lt;/androidx.constraintlayout.widget.ConstraintLayout\u0026gt; 布局文件中约束了红色方块必须是一直处于蓝色方块+绿色方块这个整体的右侧，此时还看不出来 Barrier 的作用，但当文本内容增多时，就可以看出来了。不管是蓝色方块还是绿色方块的宽度变大，红色方块都会自动向右侧移动\n十、Group Group 用于控制多个控件的可见性，先依靠 constraint_referenced_ids来绑定其它 View，之后就可以通过单独控制 Group 的可见性从而来间接改变绑定的 View 的可见性\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;androidx.constraintlayout.widget.ConstraintLayout xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; xmlns:app=\u0026#34;http://schemas.android.com/apk/res-auto\u0026#34; xmlns:tools=\u0026#34;http://schemas.android.com/tools\u0026#34; android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;match_parent\u0026#34; tools:context=\u0026#34;.ConstraintLayoutActivity\u0026#34;\u0026gt; \u0026lt;Button android:id=\u0026#34;@+id/btn_target\u0026#34; android:layout_width=\u0026#34;wrap_content\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:text=\u0026#34;Target Button\u0026#34; android:textAllCaps=\u0026#34;false\u0026#34; app:layout_constraintBottom_toBottomOf=\u0026#34;parent\u0026#34; app:layout_constraintEnd_toEndOf=\u0026#34;parent\u0026#34; app:layout_constraintStart_toStartOf=\u0026#34;parent\u0026#34; app:layout_constraintTop_toTopOf=\u0026#34;parent\u0026#34; /\u0026gt; \u0026lt;Button android:id=\u0026#34;@+id/btn_source\u0026#34; android:layout_width=\u0026#34;wrap_content\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:text=\u0026#34;Source Button\u0026#34; android:textAllCaps=\u0026#34;false\u0026#34; app:layout_constraintCircle=\u0026#34;@id/btn_target\u0026#34; app:layout_constraintCircleAngle=\u0026#34;45\u0026#34; app:layout_constraintCircleRadius=\u0026#34;120dp\u0026#34; /\u0026gt; \u0026lt;androidx.constraintlayout.widget.Group android:layout_width=\u0026#34;wrap_content\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:visibility=\u0026#34;visible\u0026#34; app:constraint_referenced_ids=\u0026#34;btn_target, btn_source\u0026#34; /\u0026gt; \u0026lt;/androidx.constraintlayout.widget.ConstraintLayout\u0026gt; 十一、Placeholder Placeholder （占位符）用于和一个视图关联起来，通过 setContentId() 方法将占位符转换为指定的视图，即视图将在占位符所在位置上显示，如果此时布局中已包含该视图，则视图将从原有位置消失\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;androidx.constraintlayout.widget.ConstraintLayout xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; xmlns:app=\u0026#34;http://schemas.android.com/apk/res-auto\u0026#34; xmlns:tools=\u0026#34;http://schemas.android.com/tools\u0026#34; android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;match_parent\u0026#34; tools:context=\u0026#34;.ConstraintLayoutActivity\u0026#34;\u0026gt; \u0026lt;Button android:id=\u0026#34;@+id/btn_setContentId\u0026#34; android:layout_width=\u0026#34;0dp\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:onClick=\u0026#34;setContentId\u0026#34; android:text=\u0026#34;setContentId\u0026#34; android:textAllCaps=\u0026#34;false\u0026#34; app:layout_constraintEnd_toEndOf=\u0026#34;parent\u0026#34; app:layout_constraintStart_toStartOf=\u0026#34;parent\u0026#34; app:layout_constraintTop_toTopOf=\u0026#34;parent\u0026#34; /\u0026gt; \u0026lt;ImageView android:id=\u0026#34;@+id/iv_target\u0026#34; android:layout_width=\u0026#34;wrap_content\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:src=\u0026#34;@drawable/icon_a\u0026#34; app:layout_constraintEnd_toEndOf=\u0026#34;parent\u0026#34; app:layout_constraintStart_toStartOf=\u0026#34;parent\u0026#34; app:layout_constraintTop_toBottomOf=\u0026#34;@id/btn_setContentId\u0026#34; /\u0026gt; \u0026lt;androidx.constraintlayout.widget.Placeholder android:id=\u0026#34;@+id/placeholder\u0026#34; android:layout_width=\u0026#34;wrap_content\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; app:layout_constraintBottom_toBottomOf=\u0026#34;parent\u0026#34; app:layout_constraintEnd_toEndOf=\u0026#34;parent\u0026#34; app:layout_constraintStart_toStartOf=\u0026#34;parent\u0026#34; app:layout_constraintTop_toTopOf=\u0026#34;parent\u0026#34; /\u0026gt; \u0026lt;/androidx.constraintlayout.widget.ConstraintLayout\u0026gt; val placeholder = findViewById\u0026lt;Placeholder\u0026gt;(R.id.placeholder) placeholder.setContentId(R.id.iv_target) 十二、Chains Chain 比较难描述，它是一种特殊的约束形式，多个控件通过明确的相互约束来互相约束对方的位置，从而形成一个链条，Chain 可以设定链条中的剩余空间的分发规则\n例如，以下布局中三个 TextView 都明确规定了其左侧和右侧的约束条件，三个 TextView 形成了一个整体，此时它们就可以称为一条链条\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;androidx.constraintlayout.widget.ConstraintLayout xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; xmlns:app=\u0026#34;http://schemas.android.com/apk/res-auto\u0026#34; xmlns:tools=\u0026#34;http://schemas.android.com/tools\u0026#34; android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;match_parent\u0026#34; tools:context=\u0026#34;.ConstraintLayoutActivity\u0026#34;\u0026gt; \u0026lt;TextView android:id=\u0026#34;@+id/tv1\u0026#34; android:layout_width=\u0026#34;wrap_content\u0026#34; android:layout_height=\u0026#34;50dp\u0026#34; android:background=\u0026#34;#f5ec7e\u0026#34; android:gravity=\u0026#34;center\u0026#34; android:text=\u0026#34;Hello World!\u0026#34; app:layout_constraintEnd_toStartOf=\u0026#34;@+id/tv2\u0026#34; app:layout_constraintStart_toStartOf=\u0026#34;parent\u0026#34; app:layout_constraintTop_toTopOf=\u0026#34;parent\u0026#34; /\u0026gt; \u0026lt;TextView android:id=\u0026#34;@+id/tv2\u0026#34; android:layout_width=\u0026#34;wrap_content\u0026#34; android:layout_height=\u0026#34;50dp\u0026#34; android:layout_marginTop=\u0026#34;0dp\u0026#34; android:background=\u0026#34;#ff538c\u0026#34; android:gravity=\u0026#34;center\u0026#34; android:text=\u0026#34;Hello World!\u0026#34; app:layout_constraintEnd_toStartOf=\u0026#34;@+id/tv3\u0026#34; app:layout_constraintStart_toEndOf=\u0026#34;@+id/tv1\u0026#34; app:layout_constraintTop_toTopOf=\u0026#34;parent\u0026#34; /\u0026gt; \u0026lt;TextView android:id=\u0026#34;@+id/tv3\u0026#34; android:layout_width=\u0026#34;wrap_content\u0026#34; android:layout_height=\u0026#34;50dp\u0026#34; android:background=\u0026#34;#41c0ff\u0026#34; android:gravity=\u0026#34;center\u0026#34; android:text=\u0026#34;Hello World!\u0026#34; app:layout_constraintEnd_toEndOf=\u0026#34;parent\u0026#34; app:layout_constraintStart_toEndOf=\u0026#34;@+id/tv2\u0026#34; app:layout_constraintTop_toTopOf=\u0026#34;parent\u0026#34; /\u0026gt; \u0026lt;/androidx.constraintlayout.widget.ConstraintLayout\u0026gt; 链条分为水平链条和竖直链条两种，分别用 layout_constraintHorizontal_chainStyle 和 layout_constraintVertical_chainStyle 两个属性来设置，属性值有以下三种：\nspread（默认值） spread_inside packed 直接看效果图才容易理解各种效果\n当值为 spread 以及控件宽度为 wrap_content 时\nandroid:layout_width=\u0026#34;wrap_content\u0026#34; app:layout_constraintHorizontal_chainStyle=\u0026#34;spread\u0026#34; 当参数值为 spread 以及控件宽度为 0dp 时\nandroid:layout_width=\u0026#34;0dp\u0026#34; app:layout_constraintHorizontal_chainStyle=\u0026#34;spread\u0026#34; 当参数值为 spread_inside 以及控件宽度为 wrap_content 时\nandroid:layout_width=\u0026#34;wrap_content\u0026#34; app:layout_constraintHorizontal_chainStyle=\u0026#34;spread_inside\u0026#34; 当参数值为 packed 以及控件宽度为 wrap_content 时\nandroid:layout_width=\u0026#34;wrap_content\u0026#34; app:layout_constraintHorizontal_chainStyle=\u0026#34;packed\u0026#34; 十三、Flow Flow 是一种新的虚拟布局，它专门用来构建链式排版效果，当出现空间不足的情况时能够自动换行，甚至是自动延展到屏幕的另一区域。当需要对多个元素进行链式布局，但不确定在运行时布局空间的实际大小是多少时 Flow 对你来说就非常有用。你可以使用 Flow 来实现让布局随着应用屏幕尺寸的变化 (比如设备发生旋转后出现的屏幕宽度变化) 而动态地进行自适应。此外，Flow 是一种虚拟布局，并不会作为视图添加到视图层级结构中，而是仅仅引用其它视图来辅助它们在布局系统中完成各自的布局功能\nFlow 中最重要的一个配置选项是 wrapMode，它可以决定在内容溢出 (或出现换行) 时的布局行为，一共有三种模式：\nnone – 所有引用的视图以一条链的方式进行布局，如果内容溢出则溢出内容不可见 chain – 当出现溢出时，溢出的内容会自动换行，以新的一条链的方式进行布局 align – 同 chain 类似，但是不以行而是以列的方式进行布局 例如，你可以在布局文件中引入五个 CardView，每个 CardView 的方向约束均交由 Flow 来控制，Flow 默认是以水平方向来展示，可以主动设置 android:orientation=\u0026quot;vertical\u0026quot;改为竖直方向\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;androidx.constraintlayout.widget.ConstraintLayout xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; xmlns:app=\u0026#34;http://schemas.android.com/apk/res-auto\u0026#34; xmlns:tools=\u0026#34;http://schemas.android.com/tools\u0026#34; android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;match_parent\u0026#34; tools:context=\u0026#34;.FlowActivity\u0026#34;\u0026gt; \u0026lt;include android:id=\u0026#34;@+id/cardView1\u0026#34; layout=\u0026#34;@layout/item_cardview\u0026#34; /\u0026gt; \u0026lt;include android:id=\u0026#34;@+id/cardView2\u0026#34; layout=\u0026#34;@layout/item_cardview\u0026#34; /\u0026gt; \u0026lt;include android:id=\u0026#34;@+id/cardView3\u0026#34; layout=\u0026#34;@layout/item_cardview\u0026#34; /\u0026gt; \u0026lt;include android:id=\u0026#34;@+id/cardView4\u0026#34; layout=\u0026#34;@layout/item_cardview\u0026#34; /\u0026gt; \u0026lt;include android:id=\u0026#34;@+id/cardView5\u0026#34; layout=\u0026#34;@layout/item_cardview\u0026#34; /\u0026gt; \u0026lt;androidx.constraintlayout.helper.widget.Flow android:id=\u0026#34;@+id/flow\u0026#34; android:layout_width=\u0026#34;0dp\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; app:constraint_referenced_ids=\u0026#34;cardView1,cardView2,cardView3,cardView4,cardView5\u0026#34; app:flow_horizontalGap=\u0026#34;30dp\u0026#34; app:flow_verticalGap=\u0026#34;30dp\u0026#34; app:flow_wrapMode=\u0026#34;none\u0026#34; app:layout_constraintEnd_toEndOf=\u0026#34;parent\u0026#34; app:layout_constraintStart_toStartOf=\u0026#34;parent\u0026#34; app:layout_constraintTop_toTopOf=\u0026#34;parent\u0026#34; /\u0026gt; \u0026lt;/androidx.constraintlayout.widget.ConstraintLayout\u0026gt; none 此模式下控件不会自动换行，且由于屏幕宽度无法完整展示，所以只会展示一部分内容\n该模式下可以同时使用的配置项有：\nflow_horizontalStyle = \u0026ldquo;spread|spread_inside|packed\u0026rdquo; //Chains 链的展示形式 flow_verticalStyle = \u0026ldquo;spread|spread_inside|packed\u0026rdquo; flow_horizontalBias = \u0026ldquo;float\u0026rdquo; //只在 style 为 packed 时才生效，用于控制控件在水平方向上的偏移量 flow_verticalBias = \u0026ldquo;float\u0026rdquo; flow_horizontalGap = \u0026ldquo;dimension\u0026rdquo; //设置每个控件的左右间距 flow_verticalGap = \u0026ldquo;dimension\u0026rdquo; flow_horizontalAlign = \u0026ldquo;start|end\u0026rdquo; flow_verticalAlign = \u0026ldquo;top|bottom|center|baseline chain 此模式下控件会自动换行，且不足一行的内容会居中显示\n此模式下可以同时使用的配置项有：\nflow_firstHorizontalStyle = \u0026ldquo;spread|spread_inside|packed\u0026rdquo; //第一行 Chains 链的展示形式 flow_firstVerticalStyle = \u0026ldquo;spread|spread_inside|packed\u0026rdquo; flow_firstHorizontalBias = \u0026ldquo;float\u0026rdquo; //只在 style 为 packed 时才生效，用于控制第一行在水平方向上的偏移量 flow_firstVerticalBias = \u0026ldquo;float\u0026rdquo; flow_lastHorizontalStyle = \u0026ldquo;spread|spread_inside|packed\u0026rdquo; //最后一行 Chains 链的展示形式 flow_lastHorizontalBias = \u0026ldquo;float\u0026rdquo; 看个例子：\n\u0026lt;androidx.constraintlayout.helper.widget.Flow android:id=\u0026#34;@+id/flow\u0026#34; android:layout_width=\u0026#34;0dp\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; app:constraint_referenced_ids=\u0026#34;cardView1,cardView2,cardView3,cardView4,cardView5\u0026#34; app:flow_firstHorizontalStyle=\u0026#34;spread_inside\u0026#34; app:flow_horizontalGap=\u0026#34;30dp\u0026#34; app:flow_lastHorizontalBias=\u0026#34;1\u0026#34; app:flow_lastHorizontalStyle=\u0026#34;packed\u0026#34; app:flow_verticalGap=\u0026#34;30dp\u0026#34; app:flow_wrapMode=\u0026#34;chain\u0026#34; app:layout_constraintEnd_toEndOf=\u0026#34;parent\u0026#34; app:layout_constraintStart_toStartOf=\u0026#34;parent\u0026#34; app:layout_constraintTop_toTopOf=\u0026#34;parent\u0026#34; /\u0026gt; 由于 flow_firstHorizontalStyle 值为 spread_inside，所以首行会往两侧靠边。由于 flow_lastHorizontalBias值为 1，所以最后一行也会直接往右靠拢\naligned 此模式和 chain 类似，区别在于不足一行的内容会靠边对齐显示\n十四、Layer Layer 作为一种新的辅助工具，可以在多个视图上创建一个虚拟的图层 (layer)，和 Flow 不同，它并不会对视图进行布局，而是对多个视图同时进行变换 (transformation) 操作。如果想对多个视图整体进行旋转 (rotate)、平移 (translate) 或缩放 (scale) 操作，那么 Layer 将会是最佳的选择\n在布局文件中先通过 Layer 引用需要进行变换的所有 View，可以不用对 Layer 进行位置约束\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;androidx.constraintlayout.widget.ConstraintLayout xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; xmlns:app=\u0026#34;http://schemas.android.com/apk/res-auto\u0026#34; xmlns:tools=\u0026#34;http://schemas.android.com/tools\u0026#34; android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;match_parent\u0026#34; tools:context=\u0026#34;.LayerActivity\u0026#34;\u0026gt; \u0026lt;TextView android:id=\u0026#34;@+id/tv1\u0026#34; android:layout_width=\u0026#34;100dp\u0026#34; android:layout_height=\u0026#34;100dp\u0026#34; android:background=\u0026#34;#f5ec7e\u0026#34; android:gravity=\u0026#34;center\u0026#34; android:text=\u0026#34;Hello World!\u0026#34; app:layout_constraintStart_toStartOf=\u0026#34;parent\u0026#34; app:layout_constraintTop_toTopOf=\u0026#34;parent\u0026#34; /\u0026gt; \u0026lt;TextView android:id=\u0026#34;@+id/tv2\u0026#34; android:layout_width=\u0026#34;100dp\u0026#34; android:layout_height=\u0026#34;100dp\u0026#34; android:background=\u0026#34;#FF9800\u0026#34; android:gravity=\u0026#34;center\u0026#34; android:text=\u0026#34;Hello World!\u0026#34; app:layout_constraintStart_toEndOf=\u0026#34;@id/tv1\u0026#34; app:layout_constraintTop_toBottomOf=\u0026#34;@id/tv1\u0026#34; /\u0026gt; \u0026lt;TextView android:id=\u0026#34;@+id/tv3\u0026#34; android:layout_width=\u0026#34;100dp\u0026#34; android:layout_height=\u0026#34;100dp\u0026#34; android:background=\u0026#34;#2196F3\u0026#34; android:gravity=\u0026#34;center\u0026#34; android:text=\u0026#34;Hello World!\u0026#34; app:layout_constraintStart_toEndOf=\u0026#34;@id/tv2\u0026#34; app:layout_constraintTop_toBottomOf=\u0026#34;@id/tv2\u0026#34; /\u0026gt; \u0026lt;androidx.constraintlayout.helper.widget.Layer android:id=\u0026#34;@+id/layer\u0026#34; android:layout_width=\u0026#34;0dp\u0026#34; android:layout_height=\u0026#34;0dp\u0026#34; app:constraint_referenced_ids=\u0026#34;tv1, tv2, tv3\u0026#34; tools:ignore=\u0026#34;MissingConstraints\u0026#34; /\u0026gt; \u0026lt;Button android:id=\u0026#34;@+id/btn_test\u0026#34; android:layout_width=\u0026#34;wrap_content\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:padding=\u0026#34;20dp\u0026#34; android:text=\u0026#34;开启动画\u0026#34; app:layout_constraintBottom_toBottomOf=\u0026#34;parent\u0026#34; app:layout_constraintEnd_toEndOf=\u0026#34;parent\u0026#34; app:layout_constraintStart_toStartOf=\u0026#34;parent\u0026#34; /\u0026gt; \u0026lt;/androidx.constraintlayout.widget.ConstraintLayout\u0026gt; 然后在代码中直接对 Layer 进行动画操作，这样其引用到的所有 View 都会进行整体动画\n/** * @Author: leavesCZY * @Desc: * @Github：https://github.com/leavesCZY */ class LayerActivity : AppCompatActivity() { override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) setContentView(R.layout.activity_layer) btn_test.setOnClickListener { val layer = findViewById\u0026lt;Layer\u0026gt;(R.id.layer) val animator = ValueAnimator.ofFloat(0f, 360f) animator.addUpdateListener { animation -\u0026gt; val angle = animation.animatedValue as Float layer.rotation = angle layer.scaleX = 1 + (180 - abs(angle - 180)) / 20f layer.scaleY = 1 + (180 - abs(angle - 180)) / 20f val translationX = 500 * sin(Math.toRadians((angle * 5).toDouble())).toFloat() val translationY = 500 * sin(Math.toRadians((angle * 7).toDouble())).toFloat() layer.translationX = translationX layer.translationY = translationY } animator.duration = 6000 animator.start() } } } 此外，Layer 比较有用的一个点就是可以用于设置背景色，以前如果我们想要对某块区域设置一个背景色的话往往需要多嵌套一层，而如果使用 Layer 的话则可以直接设置，不需要进行嵌套\n十五、ConstraintSet Layer 是对 ConstraintLayout 内的一部分控件做动画变换，ConstraintSet 则是用于对 ConstraintLayout 整体进行一次动画变换\nConstraintSet 可以理解为 ConstraintLayout 对其所有子控件的约束规则的集合。在不同的交互规则下，我们可能需要改变 ConstraintLayout 内的所有子控件的约束条件，即子控件的位置需要做一个大调整，ConstraintSet 就用于实现平滑地改变子控件的位置\n例如，我们需要在不同的场景下使用两种不同的布局形式，先定义好这两种布局文件，其中子 View 的 Id 必须保持一致，View 的约束条件则可以随意设置。然后在代码中通过 ConstraintSet 来加载这两个布局文件的约束规则，apply 给 ConstraintLayout 后即可平滑地切换两种布局效果\n/** * @Author: leavesCZY * @Desc: * @Github：https://github.com/leavesCZY */ class ConstraintSetActivity : AppCompatActivity() { companion object { private const val SHOW_BIG_IMAGE = \u0026#34;showBigImage\u0026#34; } private var showBigImage = false private val constraintSetNormal = ConstraintSet() private val constraintSetBig = ConstraintSet() override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) setContentView(R.layout.activity_constraint_set) //获取初始的约束集 constraintSetNormal.clone(cl_rootView) //加载目标约束集 constraintSetBig.load(this, R.layout.activity_constraint_set_big) if (savedInstanceState != null) { val previous = savedInstanceState.getBoolean(SHOW_BIG_IMAGE) if (previous != showBigImage) { showBigImage = previous applyConfig() } } } override fun onSaveInstanceState(outState: Bundle) { super.onSaveInstanceState(outState) outState.putBoolean(SHOW_BIG_IMAGE, showBigImage) } fun toggleMode(view: View) { TransitionManager.beginDelayedTransition(cl_rootView) showBigImage = !showBigImage applyConfig() } //将约束集应用到控件上 private fun applyConfig() { if (showBigImage) { constraintSetBig.applyTo(cl_rootView) } else { constraintSetNormal.applyTo(cl_rootView) } } } 十六、ConstraintHelper Flow 和 Layer 都是 ConstraintHelper 的子类，这两者都属于辅助布局的工具类，ConstraintLayout 也开放了 ConstraintHelper 交由开发者自己去进行自定义\n例如，我们可以来实现这么一种逐步展开的动画效果\n继承 ConstraintHelper，在 updatePostLayout方法中遍历其引用的所有控件，然后对每个控件应用 CircularReveal 动画。updatePostLayout方法会在执行 onLayout 之前被调用\n/** * @Author: leavesCZY * @Desc: * @Github：https://github.com/leavesCZY */ class CircularRevealHelper @JvmOverloads constructor( context: Context, attrs: AttributeSet? = null, defStyleAttr: Int = 0 ) : ConstraintHelper(context, attrs, defStyleAttr) { override fun updatePostLayout(container: ConstraintLayout) { super.updatePostLayout(container) val views = getViews(container) for (view in views) { val anim = ViewAnimationUtils.createCircularReveal( view, view.width / 2, view.height / 2, 0f, hypot((view.height / 2).toDouble(), (view.width / 2).toDouble()).toFloat() ) anim.duration = 3000 anim.start() } } } 在布局文件中引用需要执行动画的 View 即可\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;androidx.constraintlayout.widget.ConstraintLayout xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; xmlns:app=\u0026#34;http://schemas.android.com/apk/res-auto\u0026#34; xmlns:tools=\u0026#34;http://schemas.android.com/tools\u0026#34; android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;match_parent\u0026#34; tools:context=\u0026#34;.ConstraintHelperActivity\u0026#34;\u0026gt; \u0026lt;ImageView android:id=\u0026#34;@+id/imageView\u0026#34; android:layout_width=\u0026#34;300dp\u0026#34; android:layout_height=\u0026#34;300dp\u0026#34; app:layout_constraintBottom_toBottomOf=\u0026#34;parent\u0026#34; app:layout_constraintEnd_toEndOf=\u0026#34;parent\u0026#34; app:layout_constraintStart_toStartOf=\u0026#34;parent\u0026#34; app:layout_constraintTop_toTopOf=\u0026#34;parent\u0026#34; app:srcCompat=\u0026#34;@drawable/icon_avatar\u0026#34; /\u0026gt; \u0026lt;github.leavesc.constraint_layout.CircularRevealHelper android:layout_width=\u0026#34;wrap_content\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; app:constraint_referenced_ids=\u0026#34;imageView\u0026#34; tools:ignore=\u0026#34;MissingConstraints\u0026#34; /\u0026gt; \u0026lt;/androidx.constraintlayout.widget.ConstraintLayout\u0026gt; 十七、ImageFilterView ImageFilterView 是放在 ConstraintLayout 的 utils.widget包下的一个 View，从包名可以猜测 ImageFilterView 只是 Google 官方提供的一个额外的工具属性的类，和 ConstraintLayout 本身并没有啥关联\nImageFilterView 直接继承于 AppCompatImageView，在其基础上扩展了很多用于实现图形变换的功能\n属性 含义 altSrc 用于指定要从 src 变换成的目标图片，可以依靠 crossfade 来实现淡入淡出 crossfade 设置 src 和 altSrc 两张图片之间的混合程度。0=src 1=altSrc图像 saturation 饱和度。0=灰度，1=原始，2=过饱和 brightness 亮度。0=黑色，1=原始，2=两倍亮度 warmth 色温。1=自然，2=暖色，0.5=冷色 contrast 对比度。1=不变，0=灰色，2=高对比度 round 用于实现圆角，以 dimension 为值 roundPercent 用于实现圆角，取值在 0f-1f 之间，为 1f 时将形成一张圆形图片 看个例子。在 xml 中声明多个 ImageFilterView\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;androidx.constraintlayout.widget.ConstraintLayout xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; xmlns:app=\u0026#34;http://schemas.android.com/apk/res-auto\u0026#34; xmlns:tools=\u0026#34;http://schemas.android.com/tools\u0026#34; android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;match_parent\u0026#34; tools:context=\u0026#34;.ImageFilterViewActivity\u0026#34;\u0026gt; \u0026lt;androidx.constraintlayout.utils.widget.ImageFilterView android:id=\u0026#34;@+id/imageView1\u0026#34; android:layout_width=\u0026#34;100dp\u0026#34; android:layout_height=\u0026#34;100dp\u0026#34; app:layout_constraintEnd_toStartOf=\u0026#34;@id/imageView2\u0026#34; app:layout_constraintStart_toStartOf=\u0026#34;parent\u0026#34; app:layout_constraintTop_toTopOf=\u0026#34;parent\u0026#34; app:srcCompat=\u0026#34;@drawable/icon_avatar_normal\u0026#34; /\u0026gt; //省略其它 ImageFilterView \u0026lt;androidx.appcompat.widget.AppCompatSeekBar android:id=\u0026#34;@+id/seekBar\u0026#34; style=\u0026#34;@style/Widget.AppCompat.ProgressBar.Horizontal\u0026#34; android:layout_width=\u0026#34;0dp\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:layout_margin=\u0026#34;20dp\u0026#34; android:max=\u0026#34;100\u0026#34; android:progress=\u0026#34;0\u0026#34; app:layout_constraintBottom_toBottomOf=\u0026#34;parent\u0026#34; app:layout_constraintEnd_toEndOf=\u0026#34;parent\u0026#34; app:layout_constraintStart_toStartOf=\u0026#34;parent\u0026#34; /\u0026gt; \u0026lt;/androidx.constraintlayout.widget.ConstraintLayout\u0026gt; 在代码中来调整以上属性值\n/** * @Author: leavesCZY * @Desc: * @Github：https://github.com/leavesCZY */ class ImageFilterViewActivity : AppCompatActivity() { override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) setContentView(R.layout.activity_image_filter_view) seekBar.setOnSeekBarChangeListener(object : SeekBar.OnSeekBarChangeListener { override fun onProgressChanged(seekBar: SeekBar, progress: Int, fromUser: Boolean) { if (fromUser) { val realProgress = (progress / 100.0).toFloat() imageView1.saturation = realProgress * 20 imageView2.brightness = 1 - realProgress imageView3.warmth = realProgress * 20 imageView4.contrast = realProgress * 2 imageView5.round = realProgress * 40 imageView6.roundPercent = realProgress imageView7.crossfade = realProgress } } override fun onStartTrackingTouch(seekBar: SeekBar?) { } override fun onStopTrackingTouch(seekBar: SeekBar?) { } }) } } 十八、Demo 下载 示例代码我均已放到 Github，请查收：AndroidOpenSourceDemo 十九、参考资料 https://developer.android.google.cn/reference/androidx/constraintlayout/widget/ConstraintLayout https://juejin.cn/post/6905216987496972302 ","permalink":"http://localhost:1313/hugo-blog/public/post/kotlin/%E4%B8%80%E6%96%87%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8-constraintlayout/","tags":[],"title":"一文快速入门 ConstraintLayout"},{"categories":[],"content":" 公众号：字节数组 希望对你有所帮助 🤣🤣\nJson 是一种文本形式的数据交换格式，比 xml 更为轻量。Json 的解析和生成的方式很多，在 Android 平台上最常用的类库有 Gson 和 FastJson 两种，这里要介绍的是 Gson\nGson 的 GitHub 主页点击这里：Gson 一、基本用法 1、Gson 对象 在进行序列化与反序列操作前，需要先实例化一个 com .google.gson.Gson 对象，获取 Gson 对象的方法有两种\n//通过构造函数来获取 Gson gson = new Gson(); //通过 GsonBuilder 来获取，可以进行多项特殊配置 Gson gson = new GsonBuilder().create(); 2、生成 Json 利用 Gson 可以很方便地生成 Json 字符串，通过使用 addProperty 的四个重载方法\npublic static void main(String[] args) { JsonObject jsonObject = new JsonObject(); jsonObject.addProperty(\u0026#34;String\u0026#34;, \u0026#34;leavesC\u0026#34;); jsonObject.addProperty(\u0026#34;Number_Integer\u0026#34;, 23); jsonObject.addProperty(\u0026#34;Number_Double\u0026#34;, 22.9); jsonObject.addProperty(\u0026#34;Boolean\u0026#34;, true); jsonObject.addProperty(\u0026#34;Char\u0026#34;, \u0026#39;c\u0026#39;); System.out.println(); System.out.println(jsonObject); } addProperty 方法底层调用的是 add(String property, JsonElement value) 方法，即将基本数据类型转化为了 JsonElement 对象，JsonElement 是一个抽象类，而 JsonObject 继承了 JsonElement ，因此我们可以通过 JsonObject 自己来构建一个 JsonElement\npublic static void main(String[] args) { JsonObject jsonObject = new JsonObject(); jsonObject.addProperty(\u0026#34;String\u0026#34;, \u0026#34;leavesC\u0026#34;); jsonObject.addProperty(\u0026#34;Number\u0026#34;, 23); jsonObject.addProperty(\u0026#34;Number\u0026#34;, 22.9); jsonObject.addProperty(\u0026#34;Boolean\u0026#34;, true); jsonObject.addProperty(\u0026#34;Char\u0026#34;, \u0026#39;c\u0026#39;); JsonObject jsonElement = new JsonObject(); jsonElement.addProperty(\u0026#34;Boolean\u0026#34;, false); jsonElement.addProperty(\u0026#34;Double\u0026#34;, 25.9); jsonElement.addProperty(\u0026#34;Char\u0026#34;, \u0026#39;c\u0026#39;); jsonObject.add(\u0026#34;JsonElement\u0026#34;, jsonElement); System.out.println(); System.out.println(jsonObject); } 3、Json 与 Array、List 的转化 Json 数组与字符串数组\npublic static void main(String[] args) { //Json数组 转为 字符串数组 Gson gson = new Gson(); String jsonArray = \u0026#34;[\\\u0026#34;https://github.com/leavesCZY\\\u0026#34;,\\\u0026#34;https://www.jianshu.com/u/9df45b87cfdf\\\u0026#34;,\\\u0026#34;Java\\\u0026#34;,\\\u0026#34;Kotlin\\\u0026#34;,\\\u0026#34;Git\\\u0026#34;,\\\u0026#34;GitHub\\\u0026#34;]\u0026#34;; String[] strings = gson.fromJson(jsonArray, String[].class); System.out.println(\u0026#34;Json数组 转为 字符串数组: \u0026#34;); for (String string : strings) { System.out.println(string); } //字符串数组 转为 Json数组 jsonArray = gson.toJson(jsonArray, new TypeToken\u0026lt;String\u0026gt;() { }.getType()); System.out.println(\u0026#34;\\n字符串数组 转为 Json数组: \u0026#34;); System.out.println(jsonArray); } Json 数组 与 List\npublic static void main(String[] args) { //Json数组 转为 List Gson gson = new Gson(); String jsonArray = \u0026#34;[\\\u0026#34;https://github.com/leavesCZY\\\u0026#34;,\\\u0026#34;https://www.jianshu.com/u/9df45b87cfdf\\\u0026#34;,\\\u0026#34;Java\\\u0026#34;,\\\u0026#34;Kotlin\\\u0026#34;,\\\u0026#34;Git\\\u0026#34;,\\\u0026#34;GitHub\\\u0026#34;]\u0026#34;; List\u0026lt;String\u0026gt; stringList = gson.fromJson(jsonArray, new TypeToken\u0026lt;List\u0026lt;String\u0026gt;\u0026gt;() { }.getType()); System.out.println(\u0026#34;\\nJson数组 转为 List: \u0026#34;); for (String string : stringList) { System.out.println(string); } //List 转为 Json数组 jsonArray = gson.toJson(stringList, new TypeToken\u0026lt;List\u0026lt;String\u0026gt;\u0026gt;() { }.getType()); System.out.println(\u0026#34;\\nList 转为 Json数组: \u0026#34;); System.out.println(jsonArray); } 4、序列化与反序列化 Gson 也提供了 toJson() 和 fromJson() 两个方法用于转化 Model 与 Json，前者实现了序列化，后者实现了反序列化\n首先，声明一个 User 类\n/** * @Author: leavesCZY * @Date: 2018/3/17 18:32 * @Github：https://github.com/leavesCZY */ public class User { private String name; private int age; private boolean sex; public User(String name, int age, boolean sex) { this.name = name; this.age = age; this.sex = sex; } @Override public String toString() { return \u0026#34;User{\u0026#34; + \u0026#34;name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, age=\u0026#34; + age + \u0026#34;, sex=\u0026#34; + sex + \u0026#39;}\u0026#39;; } } 序列化的方法很简单，调用 gson 对象的 toJson 方法，传入要序列化的对象\npublic static void main(String[] args) { //序列化 User user = new User(\u0026#34;leavesC\u0026#34;, 24, true); Gson gson = new Gson(); System.out.println(); System.out.println(gson.toJson(user)); } 反序化的方式也类似\npublic static void main(String[] args) { //反序列化 String userJson = \u0026#34;{\\\u0026#34;name\\\u0026#34;:\\\u0026#34;leavesC\\\u0026#34;,\\\u0026#34;age\\\u0026#34;:24,\\\u0026#34;sex\\\u0026#34;:true}\u0026#34;; Gson gson = new Gson(); User user = gson.fromJson(userJson, User.class); System.out.println(); System.out.println(user); } 二、属性重命名 继续使用上一节声明的 User 类，根据 User 类声明的各个属性名，移动端的开发者希望接口返回的数据格式即是如下这样的\n{\u0026#34;name\u0026#34;:\u0026#34;leavesC\u0026#34;,\u0026#34;age\u0026#34;:24,\u0026#34;sex\u0026#34;:true} 如果没有和服务器端沟通好或者是 API 改版了，接口返回的数据格式可能是这样的\n{\u0026#34;Name\u0026#34;:\u0026#34;leavesC\u0026#34;,\u0026#34;age\u0026#34;:24,\u0026#34;sex\u0026#34;:true} {\u0026#34;userName\u0026#34;:\u0026#34;leavesC\u0026#34;,\u0026#34;age\u0026#34;:24,\u0026#34;sex\u0026#34;:true} 如果继续使用上一节介绍的方法，那无疑会解析出错\n例如\npublic static void main(String[] args) { //反序列化 String userJson = \u0026#34;{\\\u0026#34;userName\\\u0026#34;:\\\u0026#34;leavesC\\\u0026#34;,\\\u0026#34;age\\\u0026#34;:24,\\\u0026#34;sex\\\u0026#34;:true}\u0026#34;; Gson gson = new Gson(); User user = gson.fromJson(userJson, User.class); System.out.println(); System.out.println(user); } name 属性值解析不到，所以为 null\n此时为了兼顾多种格式的数据，就需要使用 SerializedName 注解\n根据 SerializedName 的声明来看，SerializedName 包含两个属性值，一个是字符串，一个是字符串数组，而字符串数组含有默认值\n@Documented @Retention(RetentionPolicy.RUNTIME) @Target({ElementType.FIELD, ElementType.METHOD}) public @interface SerializedName { String value(); String[] alternate() default {}; } SerializedName 的作用是为了在序列化或反序列化时，指导 Gson 如果将原有的属性名和其它特殊情况下的属性名联系起来\n例如，修改 User 类，为 name 声明 SerializedName 注解，注解值为 userName\n/** * @Author: leavesCZY * @Date: 2018/3/17 18:32 * @Github：https://github.com/leavesCZY */ public class User { @SerializedName(\u0026#34;userName\u0026#34;) private String name; private int age; private boolean sex; } 在序列时，Json 格式就会相应改变\npublic static void main(String[] args) { //序列化 User user = new User(\u0026#34;leavesC\u0026#34;, 24, true); Gson gson = new Gson(); System.out.println(); System.out.println(gson.toJson(user)); } 在反序列化时也一样，能够解析到正确的属性值\npublic static void main(String[] args) { //反序列化 String userJson = \u0026#34;{\\\u0026#34;userName\\\u0026#34;:\\\u0026#34;leavesC\\\u0026#34;,\\\u0026#34;age\\\u0026#34;:24,\\\u0026#34;sex\\\u0026#34;:true}\u0026#34;; Gson gson = new Gson(); User user = gson.fromJson(userJson, User.class); System.out.println(); System.out.println(user); } 还有个问题没解决，为了应对多种属性名不一致的情况，难道我们要声明多个 User 类吗？这显然是不现实的，所以还需要为 User 类设置多个备选属性名，这就需要用到 SerializedName 注解的另一个属性值 alternate 了。\n/** * @Author: leavesCZY * @Date: 2018/3/17 18:32 * @Github：https://github.com/leavesCZY */ public class User { @SerializedName(value = \u0026#34;userName\u0026#34;, alternate = {\u0026#34;user_name\u0026#34;, \u0026#34;Name\u0026#34;}) private String name; private int age; private boolean sex; } 以下几种情况都能够被正确的反序列化\npublic static void main(String[] args) { //反序列化 Gson gson = new Gson(); String userJson = \u0026#34;{\\\u0026#34;userName\\\u0026#34;:\\\u0026#34;leavesC\\\u0026#34;,\\\u0026#34;age\\\u0026#34;:24,\\\u0026#34;sex\\\u0026#34;:true}\u0026#34;; User user = gson.fromJson(userJson, User.class); System.out.println(); System.out.println(user); userJson = \u0026#34;{\\\u0026#34;user_name\\\u0026#34;:\\\u0026#34;leavesC\\\u0026#34;,\\\u0026#34;age\\\u0026#34;:24,\\\u0026#34;sex\\\u0026#34;:true}\u0026#34;; user = gson.fromJson(userJson, User.class); System.out.println(); System.out.println(user); userJson = \u0026#34;{\\\u0026#34;Name\\\u0026#34;:\\\u0026#34;leavesC\\\u0026#34;,\\\u0026#34;age\\\u0026#34;:24,\\\u0026#34;sex\\\u0026#34;:true}\u0026#34;; user = gson.fromJson(userJson, User.class); System.out.println(); System.out.println(user); } 三、字段过滤 有时候并不是所有的字段都需要进行系列化和反序列化，因此需要对某些字段进行排除，有四种方法可以来实现这种需求。\n1、基于@Expose注解 Expose 注解包含两个属性值，且均声明了默认值。Expose 的含义即为“暴露”，即用于对外暴露字段，serialize 用于指定是否进行序列化，deserialize 用于指定是否进行反序列化。如果字段不声明 Expose 注解，则意味着不进行序列化和反序列化操作，相当于两个属性值均为 false 。此外，Expose 注解需要和 GsonBuilder 构建的 Gson 对象一起使用才能生效\n@Documented @Retention(RetentionPolicy.RUNTIME) @Target({ElementType.FIELD}) public @interface Expose { boolean serialize() default true; boolean deserialize() default true; } Expose 注解的注解值声明情况有四种\n@Expose(serialize = true, deserialize = true) //序列化和反序列化都生效 @Expose(serialize = false, deserialize = true) //序列化时不生效，反序列化时生效 @Expose(serialize = true, deserialize = false) //序列化时生效，反序列化时不生效 @Expose(serialize = false, deserialize = false) //序列化和反序列化都不生效，和不写注解一样 现在来看个例子，修改 User 类\n/** * @Author: leavesCZY * @Date: 2018/3/17 18:32 * @Github：https://github.com/leavesCZY */ public class User { @Expose(serialize = true, deserialize = true) //序列化和反序列化都生效 private String a; @Expose(serialize = false, deserialize = true) //序列化时不生效，反序列化时生效 private String b; @Expose(serialize = true, deserialize = false) //序列化时生效，反序列化时不生效 private String c; @Expose(serialize = false, deserialize = false) //序列化和反序列化都不生效，和不写注解一样 private String d; private String e; public User(String a, String b, String c, String d, String e) { this.a = a; this.b = b; this.c = c; this.d = d; this.e = e; } @Override public String toString() { return \u0026#34;User{\u0026#34; + \u0026#34;a=\u0026#39;\u0026#34; + a + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, b=\u0026#39;\u0026#34; + b + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, c=\u0026#39;\u0026#34; + c + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, d=\u0026#39;\u0026#34; + d + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, e=\u0026#39;\u0026#34; + e + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#39;}\u0026#39;; } } 按照如上的注解值，只有声明了 Expose 注解且 serialize 值为 true 的字段才能被序列化，只有声明了 Expose 注解且 deserialize 值为 true 的字段才能被反序列化\npublic static void main(String[] args) { Gson gson = new GsonBuilder().excludeFieldsWithoutExposeAnnotation().create(); User user = new User(\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;C\u0026#34;, \u0026#34;D\u0026#34;, \u0026#34;E\u0026#34;); System.out.println(); System.out.println(gson.toJson(user)); String json = \u0026#34;{\\\u0026#34;a\\\u0026#34;:\\\u0026#34;A\\\u0026#34;,\\\u0026#34;b\\\u0026#34;:\\\u0026#34;B\\\u0026#34;,\\\u0026#34;c\\\u0026#34;:\\\u0026#34;C\\\u0026#34;,\\\u0026#34;d\\\u0026#34;:\\\u0026#34;D\\\u0026#34;,\\\u0026#34;e\\\u0026#34;:\\\u0026#34;E\\\u0026#34;}\u0026#34;; user = gson.fromJson(json, User.class); System.out.println(); System.out.println(user.toString()); } 2、基于版本 Gson 提供了 @Since 和 @Until 两个注解基于版本对字段进行过滤，@Since 和 @Until 都包含一个 Double 属性值，用于设置版本号。Since 的意思是“自……开始”，Until 的意思是“到……为止”，一样要和 GsonBuilder 配合使用\n@Documented @Retention(RetentionPolicy.RUNTIME) @Target({ElementType.FIELD, ElementType.TYPE}) public @interface Since { double value(); } @Documented @Retention(RetentionPolicy.RUNTIME) @Target({ElementType.FIELD, ElementType.TYPE}) public @interface Until { double value(); } 当版本( GsonBuilder 设置的版本) 大于或等于 Since 属性值或小于 Until 属性值时字段会进行序列化和反序列化操作，而没有声明注解的字段都会加入序列化和反序列操作\n现在来看个例子，修改 User 类\n/** * @Author: leavesCZY * @Date: 2018/3/17 18:32 * @Github：https://github.com/leavesCZY */ public class User { @Since(1.4) private String a; @Since(1.6) private String b; @Since(1.8) private String c; @Until(1.6) private String d; @Until(2.0) private String e; public User(String a, String b, String c, String d, String e) { this.a = a; this.b = b; this.c = c; this.d = d; this.e = e; } @Override public String toString() { return \u0026#34;User{\u0026#34; + \u0026#34;a=\u0026#39;\u0026#34; + a + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, b=\u0026#39;\u0026#34; + b + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, c=\u0026#39;\u0026#34; + c + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, d=\u0026#39;\u0026#34; + d + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, e=\u0026#39;\u0026#34; + e + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#39;}\u0026#39;; } } public static void main(String[] args) { Gson gson = new GsonBuilder().setVersion(1.6).create(); User user = new User(\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;C\u0026#34;, \u0026#34;D\u0026#34;, \u0026#34;E\u0026#34;); System.out.println(); System.out.println(gson.toJson(user)); String json = \u0026#34;{\\\u0026#34;a\\\u0026#34;:\\\u0026#34;A\\\u0026#34;,\\\u0026#34;b\\\u0026#34;:\\\u0026#34;B\\\u0026#34;,\\\u0026#34;c\\\u0026#34;:\\\u0026#34;C\\\u0026#34;,\\\u0026#34;d\\\u0026#34;:\\\u0026#34;D\\\u0026#34;,\\\u0026#34;e\\\u0026#34;:\\\u0026#34;E\\\u0026#34;}\u0026#34;; user = gson.fromJson(json, User.class); System.out.println(); System.out.println(user.toString()); } 3、基于访问修饰符 访问修饰符由 java.lang.reflect.Modifier 提供 int 类型的定义，而 GsonBuilder 对象的 excludeFieldsWithModifiers方法接收一个 int 类型可变参数，指定不进行序列化和反序列化操作的访问修饰符字段\n看个例子\n/** * @Author: leavesCZY * @Date: 2018/3/17 18:32 * @Github：https://github.com/leavesCZY */ public class ModifierSample { public String publicField = \u0026#34;public\u0026#34;; protected String protectedField = \u0026#34;protected\u0026#34;; private String privateField = \u0026#34;private\u0026#34;; String defaultField = \u0026#34;default\u0026#34;; final String finalField = \u0026#34;final\u0026#34;; static String staticField = \u0026#34;static\u0026#34;; } public static void main(String[] args) { Gson gson = new GsonBuilder().excludeFieldsWithModifiers(Modifier.PRIVATE, Modifier.STATIC).create(); ModifierSample modifierSample = new ModifierSample(); System.out.println(gson.toJson(modifierSample)); } 4、基于策略 GsonBuilder 类包含 setExclusionStrategies(ExclusionStrategy... strategies)方法用于传入不定长参数的策略方法，用于直接排除指定字段名或者指定字段类型\n看个例子\n/** * @Author: leavesCZY * @Date: 2018/3/17 18:32 * @Github：https://github.com/leavesCZY */ public class Strategies { private String stringField; private int intField; private double doubleField; public Strategies(String stringField, int intField, double doubleField) { this.stringField = stringField; this.intField = intField; this.doubleField = doubleField; } @Override public String toString() { return \u0026#34;Strategies{\u0026#34; + \u0026#34;stringField=\u0026#39;\u0026#34; + stringField + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, intField=\u0026#34; + intField + \u0026#34;, doubleField=\u0026#34; + doubleField + \u0026#39;}\u0026#39;; } } public static void main(String[] args) { Gson gson = new GsonBuilder().setExclusionStrategies(new ExclusionStrategy() { @Override public boolean shouldSkipField(FieldAttributes fieldAttributes) { //排除指定字段名 return fieldAttributes.getName().equals(\u0026#34;intField\u0026#34;); } @Override public boolean shouldSkipClass(Class\u0026lt;?\u0026gt; aClass) { //排除指定字段类型 return aClass.getName().equals(double.class.getName()); } }).create(); Strategies strategies = new Strategies(\u0026#34;stringField\u0026#34;, 111, 11.22); System.out.println(); System.out.println(gson.toJson(strategies)); String json = \u0026#34;{\\\u0026#34;stringField\\\u0026#34;:\\\u0026#34;stringField\\\u0026#34;,\\\u0026#34;intField\\\u0026#34;:111,\\\u0026#34;doubleField\\\u0026#34;:11.22}\u0026#34;; strategies = gson.fromJson(json, Strategies.class); System.out.println(); System.out.println(strategies); } 字段名为 \u0026ldquo;intField\u0026rdquo; 和字段类型为 double 的字段都会被排除掉\nsetExclusionStrategies 方法在序列化和反序列化时都会生效，如果只是想指定其中一种情况下的排除策略或分别指定排除策略，可以改为使用以下两个方法\naddSerializationExclusionStrategy(ExclusionStrategy strategy); addDeserializationExclusionStrategy(ExclusionStrategy strategy); 四、个性化配置 1、输出 null 对于 Gson 而言，在序列化时如果某个属性值为 null 的话，那么在序列化时该字段不会参与进来，如果想要显示输出该字段的话，可以通过 GsonBuilder 进行配置\n/** * @Author: leavesCZY * @Date: 2018/3/17 18:32 * @Github：https://github.com/leavesCZY */ public class Strategies { private String stringField; private int intField; private double doubleField; } public static void main(String[] args) { Gson gson = new GsonBuilder() .serializeNulls() //输出null .create(); Strategies strategies = new Strategies(null, 24, 22.333); System.out.println(); System.out.println(gson.toJson(strategies)); } 2、格式化输出Json 默认的序列化后的 Josn 字符串并不太直观，可以选择格式化输出\npublic static void main(String[] args) { Gson gson = new GsonBuilder() .serializeNulls() //输出null .setPrettyPrinting()//格式化输出 .create(); Strategies strategies = new Strategies(null, 24, 22.333); System.out.println(); System.out.println(gson.toJson(strategies)); } 3、格式化时间 Gson 也可以对时间值进行格式化\n/** * @Author: leavesCZY * @Date: 2018/3/17 18:32 * @Github：https://github.com/leavesCZY */ public class Strategies { private Date date; private Date date2; public Strategies(Date date, Date date2) { this.date = date; this.date2 = date2; } @Override public String toString() { SimpleDateFormat simpleDateFormat = new SimpleDateFormat(\u0026#34;yyyy-MM-dd HH:mm:ss:SSS\u0026#34;, Locale.CHINA); return \u0026#34;Strategies{\u0026#34; + \u0026#34;date=\u0026#34; + simpleDateFormat.format(date) + \u0026#34;, date2=\u0026#34; + simpleDateFormat.format(date2) + \u0026#39;}\u0026#39;; } } public static void main(String[] args) { Gson gson = new GsonBuilder() .setPrettyPrinting()//格式化输出 .setDateFormat(\u0026#34;yyyy-MM-dd HH:mm:ss:SSS\u0026#34;)//格式化时间 .create(); Date date = new Date(); Strategies strategies = new Strategies(date, new Date(date.getTime() + 1000000)); System.out.println(); System.out.println(gson.toJson(strategies)); String json = \u0026#34;{\\n\u0026#34; + \u0026#34; \\\u0026#34;date\\\u0026#34;: \\\u0026#34;2018-03-17 19:38:50:033\\\u0026#34;,\\n\u0026#34; + \u0026#34; \\\u0026#34;date2\\\u0026#34;: \\\u0026#34;2018-03-17 19:55:30:033\\\u0026#34;\\n\u0026#34; + \u0026#34;}\u0026#34;; System.out.println(); System.out.println(gson.fromJson(json, Strategies.class)); } 五、TypeAdapter TypeAdapter 是一个泛型抽象类，用于接管某种类型的序列化和反序列化过程，包含两个抽象方法，分别用于自定义序列化和反序列化过程\npublic abstract void write(JsonWriter var1, T var2) throws IOException; public abstract T read(JsonReader var1) throws IOException; 下面看个简单的例子\n/** * @Author: leavesCZY * @Date: 2018/3/17 18:32 * @Github：https://github.com/leavesCZY */ public class User { private String name; private int age; private boolean sex; public User() { } public User(String name, int age, boolean sex) { this.name = name; this.age = age; this.sex = sex; } @Override public String toString() { return \u0026#34;User{\u0026#34; + \u0026#34;name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, age=\u0026#34; + age + \u0026#34;, sex=\u0026#34; + sex + \u0026#39;}\u0026#39;; } } 定义 TypeAdapter 的子类 UserTypeAdapter 来接管 User 类的序列化和反序列化过程\n这里设定当 User 类序列化时 Json 中的Key值都是大写字母开头，反序列化时支持“name”和“Name”两种不同的 Json 风格\npublic class UserTypeAdapter extends TypeAdapter\u0026lt;User\u0026gt; { @Override public void write(JsonWriter jsonWriter, User user) throws IOException { //流式序列化成对象开始 jsonWriter.beginObject(); //将Json的Key值都指定为大写字母开头 jsonWriter.name(\u0026#34;Name\u0026#34;).value(user.getName()); jsonWriter.name(\u0026#34;Age\u0026#34;).value(user.getAge()); jsonWriter.name(\u0026#34;Sex\u0026#34;).value(user.isSex()); //流式序列化结束 jsonWriter.endObject(); } @Override public User read(JsonReader jsonReader) throws IOException { User user = new User(); //流式反序列化开始 jsonReader.beginObject(); while (jsonReader.hasNext()) { switch (jsonReader.nextName()) { //首字母大小写均合法 case \u0026#34;name\u0026#34;: case \u0026#34;Name\u0026#34;: user.setName(jsonReader.nextString()); break; case \u0026#34;age\u0026#34;: user.setAge(jsonReader.nextInt()); break; case \u0026#34;sex\u0026#34;: user.setSex(jsonReader.nextBoolean()); break; } } //流式反序列化结束 jsonReader.endObject(); return user; } } public static void main(String[] args) { Gson gson = new GsonBuilder().registerTypeAdapter(User.class, new UserTypeAdapter()).create(); User user = new User(\u0026#34;leavesC\u0026#34;, 24, true); System.out.println(); System.out.println(gson.toJson(user)); String json = \u0026#34;{\\\u0026#34;Name\\\u0026#34;:\\\u0026#34;leavesC\\\u0026#34;,\\\u0026#34;age\\\u0026#34;:24,\\\u0026#34;sex\\\u0026#34;:true}\u0026#34;; user = gson.fromJson(json, User.class); System.out.println(); System.out.println(user); } 可以看到 User 类按照预定义的策略来完成序列化和反序列化了\n六、JsonSerializer 和 JsonDeserializer TypeAdapter 将序列化和反序列操作都接管了过来，其实 Gson 还提供了只接管序列化过程的接口，即 JsonSerializer\n看个例子\npublic static void main(String[] args) { Gson gson = new GsonBuilder().registerTypeAdapter(User.class, new JsonSerializer\u0026lt;User\u0026gt;() { @Override public JsonElement serialize(User user, Type type, JsonSerializationContext jsonSerializationContext) { JsonObject jsonObject = new JsonObject(); jsonObject.addProperty(\u0026#34;NameHi\u0026#34;, user.getName()); jsonObject.addProperty(\u0026#34;Sex\u0026#34;, user.isSex()); jsonObject.addProperty(\u0026#34;Age\u0026#34;, user.getAge()); return jsonObject; } }).create(); User user = new User(\u0026#34;leavesC\u0026#34;, 24, true); System.out.println(); System.out.println(gson.toJson(user)); } 相对应的，JsonDeserializer 接口提供了反序列化的接口\npublic static void main(String[] args) { Gson gson = new GsonBuilder().registerTypeAdapter(User.class, new JsonDeserializer\u0026lt;User\u0026gt;() { @Override public User deserialize(JsonElement jsonElement, Type type, JsonDeserializationContext jsonDeserializationContext) throws JsonParseException { JsonObject jsonObject = jsonElement.getAsJsonObject(); String name = null; //同时支持 userName 和 name 两种情况 if (jsonObject.has(\u0026#34;userName\u0026#34;)) { name = jsonObject.get(\u0026#34;userName\u0026#34;).getAsString(); } else if (jsonObject.has(\u0026#34;name\u0026#34;)) { name = jsonObject.get(\u0026#34;name\u0026#34;).getAsString(); } int age = jsonObject.get(\u0026#34;age\u0026#34;).getAsInt(); boolean sex = jsonObject.get(\u0026#34;sex\u0026#34;).getAsBoolean(); return new User(name, age, sex); } }).create(); String json = \u0026#34;{\\\u0026#34;userName\\\u0026#34;:\\\u0026#34;leavesC\\\u0026#34;,\\\u0026#34;sex\\\u0026#34;:true,\\\u0026#34;age\\\u0026#34;:24}\u0026#34;; User user = gson.fromJson(json, User.class); System.out.println(); System.out.println(user); json = \u0026#34;{\\\u0026#34;name\\\u0026#34;:\\\u0026#34;leavesC\\\u0026#34;,\\\u0026#34;sex\\\u0026#34;:true,\\\u0026#34;age\\\u0026#34;:24}\u0026#34;; user = gson.fromJson(json, User.class); System.out.println(); System.out.println(user); } 这里有个比较麻烦的地方，那就是在使用 TypeAdapter 、JsonSerializer 和 JsonDeserializer 时，总需要调用 registerTypeAdapter 方法进行注册，那有没有更简单的注册方法呢？ 有的，Gosn 还提供了另一个注解 @JsonAdapter 用于进行简单的声明\n类似于这样，声明了 User 类的序列化或反序列化操作由 UserTypeAdapter 完成，注解的优先级高于 registerTypeAdapter 方法\n@JsonAdapter(UserTypeAdapter.class) public class User { } 七、TypeAdapterFactory TypeAdapterFactory 是用于创建 TypeAdapter 的工厂类，通过参数 TypeToken 来查找确定对应的 TypeAdapter，如果没有就返回 null 并由 Gson 默认的处理方法来进行序列化和反序列化操作，否则就由用户预定义的 TypeAdapter 来进行处理\nGson gson = new GsonBuilder().registerTypeAdapterFactory(new TypeAdapterFactory() { @Override public \u0026lt;T\u0026gt; TypeAdapter\u0026lt;T\u0026gt; create(Gson gson, TypeToken\u0026lt;T\u0026gt; typeToken) { //如果 Gson 需要与 User 类相关的 TypeAdapter ，则返回我们自己定义的 TypeAdapter 对象 if (typeToken.getType().getTypeName().equals(User.class.getTypeName())) { return (TypeAdapter\u0026lt;T\u0026gt;) new UserTypeAdapter(); } //找不到则返回null return null; } }).create(); 八、结语 这一篇文章好像写得太长了一点？Gson 的知识点介绍到这里也差不多了，以后如果还发现新内容的话我会继续补充，现在就先这样啦\n我的 GitHub： leavesC -\u0026gt; https://github.com/leavesCZY ","permalink":"http://localhost:1313/hugo-blog/public/post/kotlin/%E4%B8%80%E6%96%87%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8-gson/","tags":[],"title":"一文快速入门 Gson"},{"categories":[],"content":" 公众号：字节数组 希望对你有所帮助 🤣🤣\n在今年的三月份，我因为需要为项目搭建一个新的网络请求框架开始接触 Kotlin 协程。那时我司项目中同时存在着两种网络请求方式，采用的技术栈各不相同，Java、Kotlin、RxJava、LiveData 各种混搭，技术栈的不统一长远来看肯定是会造成很多不便的，所以就打算封装一个新的网络请求框架来作为项目的统一规范（前面的人估计也是这么想的，所以就造成了同个项目中的网络请求方式越来越多 😂😂），那么就需要考虑采用什么技术栈来实现了\n采用 Kotlin 语言来实现必不可少，都这年头了还用 Java 也说不过去。Retrofit 也必不可少，而目前 Retrofit 也已经支持 Kotlin 协程了，Google 官方推出的 Jetpack 协程扩展库也越来越多，就最终决定弃用 RxJava 拥抱 Kotlin 协程，将协程作为技术栈之一\n当时我是通过翻译协程官方文档来作为入门手段，到现在也大半年了，回头来看感觉官方文档还是挺晦涩难懂的，就想着再来写一两篇入门或进阶的文章来加深下理解，希望对你有所帮助\n附上我当时翻译的协程官方文档：\nKotlin 协程官方文档（1）-协程基础（Coroutine Basics） Kotlin 协程官方文档（2）-取消和超时（Cancellation and Timeouts） Kotlin 协程官方文档（3）-组合挂起函数（Coroutine Context and Dispatchers） Kotlin 协程官方文档（4）-协程上下文和调度器（Coroutine Context and Dispatchers） Kotlin 协程官方文档（5）-异步流（Asynchronous Flow） Kotlin 协程官方文档（6）-通道（Channels） Kotlin 协程官方文档（7）-异常处理（Exception Handling） Kotlin 协程官方文档（8）-共享可变状态和并发性（Shared mutable state and concurrency） Kotlin 协程官方文档（9）-选择表达式(实验阶段)（Select Expression (experimental) 一、Kotlin 协程 Kotlin 协程提供了一种全新处理并发的方式，你可以在 Android 平台上使用它来简化异步执行的代码。协程从 Kotlin 1.3 版本开始引入，但这一概念在编程世界诞生的黎明之际就有了，最早使用协程的编程语言可以追溯到 1967 年的 Simula 语言。在过去几年间，协程这个概念发展势头迅猛，现已经被诸多主流编程语言采用，比如 Javascript、C#、Python、Ruby 以及 Go 等。Kotlin 协程是基于来自其他语言的既定概念\nGoogle 官方推荐将 Kotlin 协程作为在 Android 上进行异步编程的解决方案，值得关注的功能点包括：\n轻量：可以在单个线程上运行多个协程，因为协程支持挂起，不会使正在运行协程的线程阻塞。挂起比阻塞节省内存，且支持多个并行操作 内存泄露更少：使用结构化并发机制在一个作用域内执行多个操作 内置取消支持：取消功能会自动通过正在运行的协程层次结构传播 Jetpack 集成：许多 Jetpack 库都包含提供全面协程支持的扩展。某些库还提供自己的协程作用域，可供你用于结构化并发 如果是用于 Android 平台的话，可以只引用以下的 coroutines-android，当中已经包含了 coroutines-core\nimplementation \u0026#39;org.jetbrains.kotlinx:kotlinx-coroutines-core:1.5.2\u0026#39; implementation \u0026#39;org.jetbrains.kotlinx:kotlinx-coroutines-android:1.5.2\u0026#39; 二、第一个协程 协程可以称为 轻量级线程。Kotlin 协程在 CoroutineScope 的上下文中通过 launch、async 等 协程构造器（CoroutineBuilder）来声明并启动\nfun main() { GlobalScope.launch(context = Dispatchers.IO) { //延时一秒 delay(1000) log(\u0026#34;launch\u0026#34;) } //主动休眠两秒，防止 JVM 过快退出 Thread.sleep(2000) log(\u0026#34;end\u0026#34;) } private fun log(msg: Any?) = println(\u0026#34;[${Thread.currentThread().name}] $msg\u0026#34;) [DefaultDispatcher-worker-1] launch [main] end 在上面的例子中，通过 GlobalScope（全局作用域）启动了一个协程，在延迟一秒后输出一行日志。从输出结果可以看出来，启动的协程是运行在协程内部的线程池中。虽然从表现结果上来看，启动一个协程类似于我们直接使用 Thread 来执行耗时任务，但实际上协程和线程有着本质上的区别。通过使用协程，可以极大的提高线程的并发效率，避免以往的嵌套回调地狱，极大提高了代码的可读性\n以上代码就涉及到了协程的四个基础概念：\nsuspend function。即挂起函数，delay() 就是协程库提供的一个用于实现非阻塞式延时的挂起函数 CoroutineScope。即协程作用域，GlobalScope 是 CoroutineScope 的一个实现类，用于指定协程的作用范围，可用于管理多个协程的生命周期，所有协程都需要通过 CoroutineScope 来启动 CoroutineContext。即协程上下文，包含多种类型的配置参数。Dispatchers.IO 就是 CoroutineContext 这个抽象概念的一种实现，用于指定协程的运行载体，即用于指定协程要运行在哪类线程上 CoroutineBuilder。即协程构建器，协程在 CoroutineScope 的上下文中通过 launch、async 等协程构建器来进行声明并启动。launch、async 均被声明为 CoroutineScope 的扩展方法 三、suspend 如果上述例子试图直接在 GlobalScope 外调用 delay() 函数的话，IDE 就会提示一个错误：Suspend function \u0026lsquo;delay\u0026rsquo; should be called only from a coroutine or another suspend function。意思是：delay() 函数是一个挂起函数，只能由协程或者由其它挂起函数来调用\ndelay() 函数就使用了 suspend 进行修饰，用 suspend 修饰的函数就是挂起函数\npublic suspend fun delay(timeMillis: Long) 读者在网上看关于协程的文章的时候，应该经常会看到这么一句话：挂起函数不会阻塞其所在线程，而是会将协程挂起，在特定的时候才再恢复执行\n对于这句话我的理解是：delay() 函数类似于 Java 中的 Thread.sleep()，而之所以说 delay() 函数是非阻塞的，是因为它和单纯的线程休眠有着本质的区别。例如，当在 ThreadA 上运行的 CoroutineA 调用了delay(1000L)函数指定延迟一秒后再运行，ThreadA 会转而去执行 CoroutineB，等到一秒后再来继续执行 CoroutineA。所以，ThreadA 并不会因为 CoroutineA 的延时而阻塞，而是能继续去执行其它任务，所以挂起函数并不会阻塞其所在线程，这样就极大地提高了线程的并发灵活度，最大化了线程的利用效率。而如果是使用Thread.sleep()的话，线程就只能干等着而不能去执行其它任务，降低了线程的利用效率\n协程是运行于线程上的，一个线程可以运行多个（几千上万个）协程。线程的调度行为是由操作系统来管理的，而协程的调度行为是可以由开发者来指定并由编译器来实现的，协程能够细粒度地控制多个任务的执行时机和执行线程，当线程所执行的当前协程被 suspend 后，该线程也可以腾出资源去处理其他任务\n四、suspend 挂起与恢复 协程在常规函数的基础上添加了两项操作用于处理长时间运行的任务，在invoke（或 call）和return之外，协程添加了suspend和 resume：\nsuspend 用于暂停执行当前协程，并保存所有局部变量 resume 用于让已暂停的协程从暂停处继续执行 suspend 函数只能由其它 suspend 函数调用，或者是由协程来调用\n以下示例展示了一项任务（假设 get 方法是一个网络请求任务）的简单协程实现：\nsuspend fun fetchDocs() { // Dispatchers.Main val result = get(\u0026#34;https://developer.android.com\u0026#34;) // Dispatchers.IO for `get` show(result) // Dispatchers.Main } suspend fun get(url: String) = withContext(Dispatchers.IO) { /* ... */ } 在上面的示例中，get() 仍在主线程上被调用，但它会在启动网络请求之前暂停协程。get() 主体内通过调用 withContext(Dispatchers.IO) 创建了一个在 IO 线程池中运行的代码块，在该块内的任何代码都始终通过 IO 调度器执行。当网络请求完成后，get() 会恢复已暂停的协程，使得主线程协程可以直接拿到网络请求结果而不用使用回调来通知主线程。Retrofit 就是以这种方式来实现对协程的支持\nKotlin 使用 堆栈帧 来管理要运行哪个函数以及所有局部变量。暂停协程时，系统会复制并保存当前的堆栈帧以供稍后使用。恢复时，会将堆栈帧从其保存的位置复制回来，然后函数再次开始运行。虽然代码可能看起来像普通的顺序阻塞请求，协程也能确保网络请求不会阻塞主线程\n在主线程进行的 暂停协程 和 恢复协程 的两个操作，既实现了将耗时任务交由后台线程完成，保障了主线程安全，又以同步代码的方式完成了实际上的多线程异步调用。可以说，在 Android 平台上协程主要就用来解决两个问题：\n处理耗时任务 (Long running tasks)，这种任务常常会阻塞主线程 保证主线程安全 (Main-safety)，即确保安全地从主线程调用任何 suspend 函数 五、CoroutineScope CoroutineScope 即 协程作用域，用于对协程进行追踪。如果我们启动了多个协程但是没有一个可以对其进行统一管理的途径的话，就会导致我们的代码臃肿杂乱，甚至发生内存泄露或者任务泄露。为了确保所有的协程都会被追踪，Kotlin 不允许在没有 CoroutineScope 的情况下启动协程。CoroutineScope 可被看作是一个具有超能力的 ExecutorService 的轻量级版本。它能启动协程，同时这个协程还具备上文所说的 suspend 和 resume 的优势\n所有的协程都需要通过 CoroutineScope 来启动，它会跟踪通过 launch 或 async 创建的所有协程，你可以随时调用 scope.cancel() 取消正在运行的协程。CoroutineScope 本身并不运行协程，它只是确保你不会失去对协程的追踪，即使协程被挂起也是如此。在 Android 中，某些 ktx 库为某些生命周期类提供了自己的 CoroutineScope，例如，ViewModel 有 viewModelScope，Lifecycle 有 lifecycleScope\nCoroutineScope 大体上可以分为三种：\nGlobalScope。即全局协程作用域，在这个范围内启动的协程可以一直运行直到应用停止运行。GlobalScope 本身不会阻塞当前线程，且启动的协程相当于守护线程，不会阻止 JVM 结束运行 runBlocking。一个顶层函数，和 GlobalScope 不一样，它会阻塞当前线程直到其内部所有相同作用域的协程执行结束 自定义 CoroutineScope。可用于实现主动控制协程的生命周期范围，对于 Android 开发来说最大意义之一就是可以在 Activity、Fragment、ViewModel 等具有生命周期的对象中按需取消所有协程任务，从而确保生命周期安全，避免内存泄露 1、GlobalScope GlobalScope 属于 全局作用域，这意味着通过 GlobalScope 启动的协程的生命周期只受整个应用程序的生命周期的限制，只要整个应用程序还在运行且协程的任务还未结束，协程就可以一直运行\nGlobalScope 不会阻塞其所在线程，所以以下代码中主线程的日志会早于 GlobalScope 内部输出日志。此外，GlobalScope 启动的协程相当于守护线程，不会阻止 JVM 结束运行，所以如果将主线程的休眠时间改为三百毫秒的话，就不会看到 launch A 输出日志\nfun main() { log(\u0026#34;start\u0026#34;) GlobalScope.launch { launch { delay(400) log(\u0026#34;launch A\u0026#34;) } launch { delay(300) log(\u0026#34;launch B\u0026#34;) } log(\u0026#34;GlobalScope\u0026#34;) } log(\u0026#34;end\u0026#34;) Thread.sleep(500) } [main] start [main] end [DefaultDispatcher-worker-1] GlobalScope [DefaultDispatcher-worker-3] launch B [DefaultDispatcher-worker-3] launch A GlobalScope.launch 会创建一个顶级协程，尽管它很轻量级，但在运行时还是会消耗一些内存资源，且可以一直运行直到整个应用程序停止（只要任务还未结束），这可能会导致内存泄露，所以在日常开发中应该谨慎使用 GlobalScope\n2、runBlocking 也可以使用 runBlocking 这个顶层函数来启动协程，runBlocking 函数的第二个参数即协程的执行体，该参数被声明为 CoroutineScope 的扩展函数，因此执行体就包含了一个隐式的 CoroutineScope，所以在 runBlocking 内部可以来直接启动协程\npublic fun \u0026lt;T\u0026gt; runBlocking(context: CoroutineContext = EmptyCoroutineContext, block: suspend CoroutineScope.() -\u0026gt; T): T runBlocking 的一个方便之处就是：只有当内部相同作用域的所有协程都运行结束后，声明在 runBlocking 之后的代码才能执行，即 runBlocking 会阻塞其所在线程\n看以下代码。runBlocking 内部启动的两个协程会各自做耗时操作，从输出结果可以看出来两个协程还是在交叉并发执行，且 runBlocking 会等到两个协程都执行结束后才会退出，外部的日志输出结果有明确的先后顺序。即 runBlocking 内部启动的协程是非阻塞式的，但 runBlocking 阻塞了其所在线程。此外，runBlocking 只会等待相同作用域的协程完成才会退出，而不会等待 GlobalScope 等其它作用域启动的协程\nfun main() { log(\u0026#34;start\u0026#34;) runBlocking { launch { repeat(3) { delay(100) log(\u0026#34;launchA - $it\u0026#34;) } } launch { repeat(3) { delay(100) log(\u0026#34;launchB - $it\u0026#34;) } } GlobalScope.launch { repeat(3) { delay(120) log(\u0026#34;GlobalScope - $it\u0026#34;) } } } log(\u0026#34;end\u0026#34;) } [main] start [main] launchA - 0 [main] launchB - 0 [DefaultDispatcher-worker-1] GlobalScope - 0 [main] launchA - 1 [main] launchB - 1 [DefaultDispatcher-worker-1] GlobalScope - 1 [main] launchA - 2 [main] launchB - 2 [main] end 所以说，runBlocking 本身带有阻塞线程的意味，但其内部运行的协程又是非阻塞的，读者需要明白这两者的区别\n基于是否会阻塞线程的区别，以下代码中 runBlocking 会早于 GlobalScope 输出日志\nfun main() { GlobalScope.launch(Dispatchers.IO) { delay(600) log(\u0026#34;GlobalScope\u0026#34;) } runBlocking { delay(500) log(\u0026#34;runBlocking\u0026#34;) } //主动休眠两百毫秒，使得和 runBlocking 加起来的延迟时间多于六百毫秒 Thread.sleep(200) log(\u0026#34;after sleep\u0026#34;) } [main] runBlocking [DefaultDispatcher-worker-1] GlobalScope [main] after sleep 3、coroutineScope coroutineScope 函数用于创建一个独立的协程作用域，直到所有启动的协程都完成后才结束自身。runBlocking 和 coroutineScope 看起来很像，因为它们都需要等待其内部所有相同作用域的协程结束后才会结束自己。两者的主要区别在于 runBlocking 方法会阻塞当前线程，而 coroutineScope不会，而是会挂起并释放底层线程以供其它协程使用。基于这个差别，runBlocking 是一个普通函数，而 coroutineScope 是一个挂起函数\nfun main() = runBlocking { launch { delay(100) log(\u0026#34;Task from runBlocking\u0026#34;) } coroutineScope { launch { delay(500) log(\u0026#34;Task from nested launch\u0026#34;) } delay(50) log(\u0026#34;Task from coroutine scope\u0026#34;) } log(\u0026#34;Coroutine scope is over\u0026#34;) } [main] Task from coroutine scope [main] Task from runBlocking [main] Task from nested launch [main] Coroutine scope is over 4、supervisorScope supervisorScope 函数用于创建一个使用了 SupervisorJob 的 coroutineScope，该作用域的特点就是抛出的异常不会连锁取消同级协程和父协程\nfun main() = runBlocking { launch { delay(100) log(\u0026#34;Task from runBlocking\u0026#34;) } supervisorScope { launch { delay(500) log(\u0026#34;Task throw Exception\u0026#34;) throw Exception(\u0026#34;failed\u0026#34;) } launch { delay(600) log(\u0026#34;Task from nested launch\u0026#34;) } } log(\u0026#34;Coroutine scope is over\u0026#34;) } [main] Task from runBlocking [main] Task throw Exception [main] Task from nested launch [main] Coroutine scope is over 5、自定义 CoroutineScope 假设我们在 Activity 中先后启动了多个协程用于执行异步耗时操作，那么当 Activity 退出时，必须取消所有协程以避免内存泄漏。我们可以通过保留每一个 Job 引用然后在 onDestroy方法里来手动取消，但这种方式相当来说会比较繁琐和低效。kotlinx.coroutines 提供了 CoroutineScope 来管理多个协程的生命周期\n我们可以通过创建与 Activity 生命周期相关联的协程作用域来管理协程的生命周期。CoroutineScope 的实例可以通过 CoroutineScope() 或 MainScope() 的工厂函数来构建。前者创建通用作用域，后者创建 UI 应用程序的作用域并使用 Dispatchers.Main 作为默认的调度器\nclass Activity { private val mainScope = MainScope() fun onCreate() { mainScope.launch { repeat(5) { delay(1000L * it) } } } fun onDestroy() { mainScope.cancel() } } 或者，我们可以通过委托模式来让 Activity 实现 CoroutineScope 接口，从而可以在 Activity 内直接启动协程而不必显示地指定它们的上下文，并且在 onDestroy()中自动取消所有协程\nclass Activity : CoroutineScope by CoroutineScope(Dispatchers.Default) { fun onCreate() { launch { repeat(5) { delay(200L * it) log(it) } } log(\u0026#34;Activity Created\u0026#34;) } fun onDestroy() { cancel() log(\u0026#34;Activity Destroyed\u0026#34;) } } fun main() = runBlocking { val activity = Activity() activity.onCreate() delay(1000) activity.onDestroy() delay(1000) } 从输出结果可以看出，当回调了onDestroy()方法后协程就不会再输出日志了\n[main] Activity Created [DefaultDispatcher-worker-1] 0 [DefaultDispatcher-worker-1] 1 [DefaultDispatcher-worker-1] 2 [main] Activity Destroyed 已取消的作用域无法再创建协程。因此，仅当控制其生命周期的类被销毁时，才应调用 scope.cancel()。例如，使用 viewModelScope 时， ViewModel 会在自身的 onCleared() 方法中自动取消作用域\n六、CoroutineBuilder 1、launch 看下 launch 函数的方法签名。launch 是一个作用于 CoroutineScope 的扩展函数，用于在不阻塞当前线程的情况下启动一个协程，并返回对该协程任务的引用，即 Job 对象\npublic fun CoroutineScope.launch( context: CoroutineContext = EmptyCoroutineContext, start: CoroutineStart = CoroutineStart.DEFAULT, block: suspend CoroutineScope.() -\u0026gt; Unit ): Job launch 函数共包含三个参数：\ncontext。用于指定协程的上下文 start。用于指定协程的启动方式，默认值为 CoroutineStart.DEFAULT，即协程会在声明的同时就立即进入等待调度的状态，即可以立即执行的状态。可以通过将其设置为CoroutineStart.LAZY来实现延迟启动，即懒加载 block。用于传递协程的执行体，即希望交由协程执行的任务 可以看到 launchA 和 launchB 是并行交叉执行的\nfun main() = runBlocking { val launchA = launch { repeat(3) { delay(100) log(\u0026#34;launchA - $it\u0026#34;) } } val launchB = launch { repeat(3) { delay(100) log(\u0026#34;launchB - $it\u0026#34;) } } } [main] launchA - 0 [main] launchB - 0 [main] launchA - 1 [main] launchB - 1 [main] launchA - 2 [main] launchB - 2 2、Job Job 是协程的句柄。使用 launch 或 async 创建的每个协程都会返回一个 Job 实例，该实例唯一标识协程并管理其生命周期。Job 是一个接口类型，这里列举 Job 几个比较有用的属性和函数\n//当 Job 处于活动状态时为 true //如果 Job 未被取消或没有失败，则均处于 active 状态 public val isActive: Boolean //当 Job 正常结束或者由于异常结束，均返回 true public val isCompleted: Boolean //当 Job 被主动取消或者由于异常结束，均返回 true public val isCancelled: Boolean //启动 Job //如果此调用的确启动了 Job，则返回 true //如果 Job 调用前就已处于 started 或者是 completed 状态，则返回 false public fun start(): Boolean //用于取消 Job，可同时通过传入 Exception 来标明取消原因 public fun cancel(cause: CancellationException? = null) //阻塞等待直到此 Job 结束运行 public suspend fun join() //当 Job 结束运行时（不管由于什么原因）回调此方法，可用于接收可能存在的运行异常 public fun invokeOnCompletion(handler: CompletionHandler): DisposableHandle Job 具有以下几种状态值，每种状态对应的属性值各不相同\nState isActive isCompleted isCancelled New (optional initial state) false false false Active (default initial state) true false false Completing (transient state) true false false Cancelling (transient state) false false true Cancelled (final state) false true true Completed (final state) false true false fun main() { //将协程设置为延迟启动 val job = GlobalScope.launch(start = CoroutineStart.LAZY) { for (i in 0..100) { //每循环一次均延迟一百毫秒 delay(100) } } job.invokeOnCompletion { log(\u0026#34;invokeOnCompletion：$it\u0026#34;) } log(\u0026#34;1. job.isActive：${job.isActive}\u0026#34;) log(\u0026#34;1. job.isCancelled：${job.isCancelled}\u0026#34;) log(\u0026#34;1. job.isCompleted：${job.isCompleted}\u0026#34;) job.start() log(\u0026#34;2. job.isActive：${job.isActive}\u0026#34;) log(\u0026#34;2. job.isCancelled：${job.isCancelled}\u0026#34;) log(\u0026#34;2. job.isCompleted：${job.isCompleted}\u0026#34;) //休眠四百毫秒后再主动取消协程 Thread.sleep(400) job.cancel(CancellationException(\u0026#34;test\u0026#34;)) //休眠四百毫秒防止JVM过快停止导致 invokeOnCompletion 来不及回调 Thread.sleep(400) log(\u0026#34;3. job.isActive：${job.isActive}\u0026#34;) log(\u0026#34;3. job.isCancelled：${job.isCancelled}\u0026#34;) log(\u0026#34;3. job.isCompleted：${job.isCompleted}\u0026#34;) } [main] 1. job.isActive：false [main] 1. job.isCancelled：false [main] 1. job.isCompleted：false [main] 2. job.isActive：true [main] 2. job.isCancelled：false [main] 2. job.isCompleted：false [DefaultDispatcher-worker-2] invokeOnCompletion：java.util.concurrent.CancellationException: test [main] 3. job.isActive：false [main] 3. job.isCancelled：true [main] 3. job.isCompleted：true 3、async 看下 async 函数的方法签名。async 也是一个作用于 CoroutineScope 的扩展函数，和 launch 的区别主要就在于：async 可以返回协程的执行结果，而 launch 不行\npublic fun \u0026lt;T\u0026gt; CoroutineScope.async( context: CoroutineContext = EmptyCoroutineContext, start: CoroutineStart = CoroutineStart.DEFAULT, block: suspend CoroutineScope.() -\u0026gt; T ): Deferred\u0026lt;T\u0026gt; 通过await()方法可以拿到 async 协程的执行结果，可以看到两个协程的总耗时是远少于七秒的，总耗时基本等于耗时最长的协程\nfun main() { val time = measureTimeMillis { runBlocking { val asyncA = async { delay(3000) 1 } val asyncB = async { delay(4000) 2 } log(asyncA.await() + asyncB.await()) } } log(time) } [main] 3 [main] 4070 由于 launch 和 async 仅能够在 CouroutineScope 中使用，所以任何创建的协程都会被该 scope 追踪。Kotlin 禁止创建不能够被追踪的协程，从而避免协程泄漏\n4、async 错误用法 修改上述代码，可以发现两个协程的总耗时就会变为七秒左右\nfun main() { val time = measureTimeMillis { runBlocking { val asyncA = async(start = CoroutineStart.LAZY) { delay(3000) 1 } val asyncB = async(start = CoroutineStart.LAZY) { delay(4000) 2 } log(asyncA.await() + asyncB.await()) } } log(time) } [main] 3 [main] 7077 会造成这不同区别是因为 CoroutineStart.LAZY 不会主动启动协程，而是直到调用async.await()或者async.satrt()后才会启动（即懒加载模式），所以asyncA.await() + asyncB.await()会导致两个协程其实是在顺序执行。而默认值 CoroutineStart.DEFAULT 参数会使得协程在声明的同时就被启动了（实际上还需要等待被调度执行，但可以看做是立即就执行了），所以此时调用第一个 async.await()时两个协程其实都是处于运行状态，所以总耗时就是四秒左右\n此时可以通过先调用start()再调用await()来实现第一个例子的效果\nasyncA.start() asyncB.start() log(asyncA.await() + asyncB.await()) 5、async 并行分解 由 suspend 函数启动的所有协程都必须在该函数返回结果时停止，因此你可能需要保证这些协程在返回结果之前完成。借助 Kotlin 中的结构化并发机制，你可以定义用于启动一个或多个协程的 coroutineScope。然后，你可以使用 await()（针对单个协程）或 awaitAll()（针对多个协程）保证这些协程在从函数返回结果之前完成\n假设我们定义一个用于异步获取两个文档的 coroutineScope，通过对每个延迟引用调用 await()，我们可以保证这两项 async 操作在返回值之前完成：\nsuspend fun fetchTwoDocs() = coroutineScope { val deferredOne = async { fetchDoc(1) } val deferredTwo = async { fetchDoc(2) } deferredOne.await() deferredTwo.await() } 还可以对集合使用 awaitAll()来达到相同效果。虽然 fetchTwoDocs() 使用 async 启动新协程，但该函数使用 awaitAll() 等待启动的协程完成后才会返回结果。不过，即使我们没有调用 awaitAll()，coroutineScope 构建器也会等到所有内部协程都完成后才会恢复名为 fetchTwoDocs 的协程。此外，coroutineScope 会捕获协程抛出的所有异常，并将其传送给调用方\nsuspend fun fetchTwoDocs() = coroutineScope { val deferreds = listOf( async { fetchDoc(1) }, async { fetchDoc(2) } ) deferreds.awaitAll() } 6、Deferred async 函数的返回值是一个 Deferred 对象。Deferred 是一个接口类型，继承于 Job 接口，所以 Job 包含的属性和方法 Deferred 都有，其主要是在 Job 的基础上扩展了 await()方法\n七、CoroutineContext CoroutineContext 使用以下元素集定义协程的行为：\nJob：控制协程的生命周期 CoroutineDispatcher：将任务指派给适当的线程 CoroutineName：协程的名称，可用于调试 CoroutineExceptionHandler：处理未捕获的异常 1、Job 协程中的 Job 是其上下文 CoroutineContext 中的一部分，可以通过 coroutineContext[Job] 表达式从上下文中获取到，我们可以通过控制 Job 来控制 CoroutineScope 的生命周期\nval job = Job() val scope = CoroutineScope(job + Dispatchers.IO) fun main(): Unit = runBlocking { log(\u0026#34;job is $job\u0026#34;) val job = scope.launch { try { delay(3000) } catch (e: CancellationException) { log(\u0026#34;job is cancelled\u0026#34;) throw e } log(\u0026#34;end\u0026#34;) } delay(1000) log(\u0026#34;scope job is ${scope.coroutineContext[Job]}\u0026#34;) scope.coroutineContext[Job]?.cancel() } [main] job is JobImpl{Active}@759ebb3d [main] scope job is JobImpl{Active}@759ebb3d [DefaultDispatcher-worker-1] job is cancelled 实际上 CoroutineScope 的 isActive 这个扩展属性只是 coroutineContext[Job]?.isActive ?: true 的一种简便写法\npublic val CoroutineScope.isActive: Boolean get() = coroutineContext[Job]?.isActive ?: true 2、CoroutineDispatcher CoroutineContext 包含一个 CoroutineDispatcher（协程调度器）用于指定执行协程的目标载体，即 运行于哪个线程。CoroutineDispatcher 可以将协程的执行操作限制在特定线程上，也可以将其分派到线程池中，或者让它无限制地运行。所有的协程构造器（如 launch 和 async）都接受一个可选参数，即 CoroutineContext ，该参数可用于显式指定要创建的协程和其它上下文元素所要使用的 CoroutineDispatcher\n要在主线程之外运行代码，可以指定 Kotlin 协程在 Default 或 IO 调度程序上执行工作。在 Kotlin 中，所有协程都必须在 CoroutineDispatcher 中运行，即使它们在主线程上运行也是如此。协程可以自行暂停，而 CoroutineDispatcher 负责将其恢复\nKotlin 协程库提供了四个 Dispatcher 用于指定在哪一类线程中执行协程：\nDispatchers.Default。默认调度器，适合用于执行占用大量 CPU 资源的任务。例如：对列表排序和解析 JSON Dispatchers.IO。适合用于执行磁盘或网络 I/O 的任务。例如：使用 Room 组件、读写磁盘文件，执行网络请求 Dispatchers.Unconfined。对执行协程的线程不做限制，可以直接在当前调度器所在线程上执行 Dispatchers.Main。使用此调度程序可用于在 Android 主线程上运行协程，只能用于与界面交互和执行快速工作，例如：更新 UI、调用 LiveData.setValue fun main() = runBlocking\u0026lt;Unit\u0026gt; { launch { log(\u0026#34;main runBlocking\u0026#34;) } launch(Dispatchers.Default) { log(\u0026#34;Default\u0026#34;) launch(Dispatchers.Unconfined) { log(\u0026#34;Unconfined 1\u0026#34;) } } launch(Dispatchers.IO) { log(\u0026#34;IO\u0026#34;) launch(Dispatchers.Unconfined) { log(\u0026#34;Unconfined 2\u0026#34;) } } launch(newSingleThreadContext(\u0026#34;MyOwnThread\u0026#34;)) { log(\u0026#34;newSingleThreadContext\u0026#34;) launch(Dispatchers.Unconfined) { log(\u0026#34;Unconfined 4\u0026#34;) } } launch(Dispatchers.Unconfined) { log(\u0026#34;Unconfined 3\u0026#34;) } GlobalScope.launch { log(\u0026#34;GlobalScope\u0026#34;) } } [DefaultDispatcher-worker-2] Default [DefaultDispatcher-worker-1] IO [DefaultDispatcher-worker-2] Unconfined 1 [DefaultDispatcher-worker-1] Unconfined 2 [MyOwnThread] newSingleThreadContext [main] Unconfined 3 [MyOwnThread] Unconfined 4 [DefaultDispatcher-worker-1] GlobalScope [main] main runBlocking launch 在不执行 Dispatchers 的情况下使用时，它从外部的协程作用域继承上下文和调度器，即和 runBlocking 保持一致，均在 main 线程执行 IO 和 Default 均依靠后台线程池来执行 Unconfined 则不限定具体的线程类型，当前调度器在哪个线程，就在该线程上进行执行，因此上述例子中每个 Unconfined 协程所在线程均不一样 GlobalScope 启动协程时默认使用的调度器是 Dispatchers.Default，因此也是在后台线程池中执行 newSingleThreadContext 用于为协程专门创建一个新的线程，专用线程是一种成本非常昂贵的资源，在实际开发时必须当不再需要时释放掉线程资源，或者存储在顶级变量中以便在整个应用程序中进行复用 3、withContext 对于以下代码，get方法内使用withContext(Dispatchers.IO) 创建了一个指定在 IO 线程池中运行的代码块，该区间内的任何代码都始终通过 IO 线程来执行。由于 withContext 方法本身就是一个挂起函数，因此 get 方法也必须定义为挂起函数\nsuspend fun fetchDocs() { // Dispatchers.Main val result = get(\u0026#34;developer.android.com\u0026#34;) // Dispatchers.Main show(result) // Dispatchers.Main } suspend fun get(url: String) = // Dispatchers.Main withContext(Dispatchers.IO) { // Dispatchers.IO (main-safety block) /* perform network IO here */ // Dispatchers.IO (main-safety block) } // Dispatchers.Main } 借助协程，你可以细粒度地来调度线程。由于withContext()支持在不引入回调的情况下控制任何代码的执行线程池，因此你可以将其应用于非常小的函数，例如从数据库中读取数据或执行网络请求。一种不错的做法是使用 withContext() 来确保每个函数都是主线程安全的，这意味着，你可以从主线程调用每个函数。这样，调用方就从不需要考虑应该使用哪个线程来执行函数了\n在前面的示例中，fetchDocs() 方法在主线程上执行，不过它可以安全地调用 get方法，因为get方法已确保网络请求会在子线程中执行。由于协程支持 suspend 和 resume操作，因此 withContext 块完成后，主线程上的协程会立即根据 get 结果恢复\n与基于回调的等效实现相比，withContext() 不会增加额外的开销。此外，在某些情况下，还可以优化 withContext() 调用，使其超越基于回调的等效实现。例如，如果某个函数需要先后调用十次网络请求，你可以在最外层调用 withContext() 让协程只切换一次线程，这样即使每个网络请求内部均会使用 withContext()，它也会留在同一调度程序上，从而避免频率切换线程。此外，协程还优化了 Dispatchers.Default 与 Dispatchers.IO 之间的切换，以尽可能避免线程切换\n使用线程池的调度器（例如 Dispatchers.IO 或 Dispatchers.Default）不能保证代码块一直在同一线程上从上到下执行，在某些情况下，协程在 suspend 和 resume 后可能会将任务移交给另一个线程来执行。这意味着，对于整个 withContext() 块，由于多线程并发之间的原子性和可见性等原因，先后读取到的线程局部变量可能并非是同个值\n4、CoroutineName CoroutineName 用于为协程指定一个名字，方便调试和定位问题\nfun main() = runBlocking\u0026lt;Unit\u0026gt;(CoroutineName(\u0026#34;RunBlocking\u0026#34;)) { log(\u0026#34;start\u0026#34;) launch(CoroutineName(\u0026#34;MainCoroutine\u0026#34;)) { launch(CoroutineName(\u0026#34;Coroutine#A\u0026#34;)) { delay(400) log(\u0026#34;launch A\u0026#34;) } launch(CoroutineName(\u0026#34;Coroutine#B\u0026#34;)) { delay(300) log(\u0026#34;launch B\u0026#34;) } } } 5、CoroutineExceptionHandler 在下文的异常处理会讲到\n6、组合上下文元素 有时我们需要为协程上下文定义多个元素，此时就可以用 + 运算符。例如，我们可以同时为协程指定 Dispatcher 和 CoroutineName\nfun main() = runBlocking\u0026lt;Unit\u0026gt; { launch(Dispatchers.Default + CoroutineName(\u0026#34;test\u0026#34;)) { log(\u0026#34;Hello World\u0026#34;) } } 而由于 CoroutineContext 是由一组元素组成的，所以加号右侧的元素会覆盖加号左侧的元素，从而组成新的 CoroutineContext。比如，(Dispatchers.Main, \u0026quot;name\u0026quot;) + (Dispatchers.IO) 的运行结果是：(Dispatchers.IO, \u0026quot;name\u0026quot;)\n八、取消协程 如果用户退出启动了协程的 Activity / Fragment，那正常情况下就应该取消所有协程\njob.cancel()就用于取消协程，job.join()用于阻塞等待协程运行结束。因为 cancel() 函数调用后会马上返回而不是等待协程结束后再返回，所以此时协程不一定就是已经停止运行了。如果需要确保协程结束运行后再执行后续代码，就需要调用 join() 方法来阻塞等待。也可以通过调用 Job 的扩展函数 cancelAndJoin() 来完成相同操作，它结合了 cancel 和 join两个操作\nfun main() = runBlocking { val job = launch { repeat(1000) { i -\u0026gt; log(\u0026#34;job: I\u0026#39;m sleeping $i ...\u0026#34;) delay(500L) } } delay(1300L) log(\u0026#34;main: I\u0026#39;m tired of waiting!\u0026#34;) job.cancel() job.join() log(\u0026#34;main: Now I can quit.\u0026#34;) } [main] job: I\u0026#39;m sleeping 0 ... [main] job: I\u0026#39;m sleeping 1 ... [main] job: I\u0026#39;m sleeping 2 ... [main] main: I\u0026#39;m tired of waiting! [main] main: Now I can quit. 1、协程可能无法取消 并不是所有协程都可以响应取消操作，协程的取消操作是需要协作 (cooperative) 完成的，协程必须协作才能被取消。协程库中的所有挂起函数都是可取消的，它们在运行前检查协程是否被取消了，并在取消时抛出 CancellationException 从而结束整个任务。而如果协程在执行计算任务前没有判断自身是否已被取消的话，此时就无法取消协程\n所以即使以下代码主动取消了协程，协程也只会在完成既定循环后才结束运行，因为协程没有在每次循环前先进行检查，导致任务不受取消操作的影响\nfun main() = runBlocking { val startTime = System.currentTimeMillis() val job = launch(Dispatchers.Default) { var nextPrintTime = startTime var i = 0 while (i \u0026lt; 5) { if (System.currentTimeMillis() \u0026gt;= nextPrintTime) { log(\u0026#34;job: I\u0026#39;m sleeping ${i++} ...\u0026#34;) nextPrintTime += 500L } } } delay(1300L) log(\u0026#34;main: I\u0026#39;m tired of waiting!\u0026#34;) job.cancelAndJoin() log(\u0026#34;main: Now I can quit.\u0026#34;) } [DefaultDispatcher-worker-1] job: I\u0026#39;m sleeping 0 ... [DefaultDispatcher-worker-1] job: I\u0026#39;m sleeping 1 ... [DefaultDispatcher-worker-1] job: I\u0026#39;m sleeping 2 ... [main] main: I\u0026#39;m tired of waiting! [DefaultDispatcher-worker-1] job: I\u0026#39;m sleeping 3 ... [DefaultDispatcher-worker-1] job: I\u0026#39;m sleeping 4 ... [main] main: Now I can quit. 为了实现取消协程的目的，就需要为上述代码加上判断协程是否还处于可运行状态的逻辑，当不可运行时就主动退出协程。isActive 是 CoroutineScope 的扩展属性，就用于判断协程是否还处于可运行状态\nfun main() = runBlocking { val startTime = System.currentTimeMillis() val job = launch(Dispatchers.Default) { var nextPrintTime = startTime var i = 0 while (i \u0026lt; 5) { if (isActive) { if (System.currentTimeMillis() \u0026gt;= nextPrintTime) { log(\u0026#34;job: I\u0026#39;m sleeping ${i++} ...\u0026#34;) nextPrintTime += 500L } } else { return@launch } } } delay(1300L) log(\u0026#34;main: I\u0026#39;m tired of waiting!\u0026#34;) job.cancelAndJoin() log(\u0026#34;main: Now I can quit.\u0026#34;) } 取消协程这个操作类似于在 Java 中调用Thread.interrupt()方法来向线程发起中断请求，这两个操作都不会强制停止协程和线程，外部只是相当于发起一个停止运行的请求，需要依靠协程和线程响应请求后主动停止运行\nJava 和 Kotlin 之所以均没有提供一个可以直接强制停止线程或协程的方法，是因为这个操作可能会带来各种意想不到的情况。例如，在停止线程或协程的时候，它们可能还持有着某些排他性资源（例如：锁，数据库链接），如果强制性地停止，它们持有的锁就会一直无法得到释放，导致其它线程或协程一直无法得到目标资源，最终就可能导致线程死锁。所以Thread.stop()方法目前也是处于废弃状态，Java 官方并没有提供一个可靠的停止线程的方法\n2、用 finally 释放资源 可取消的挂起函数在取消时会抛出 CancellationException，可以依靠try {...} finally {...} 或者 Kotlin 的 use 函数在取消协程后释放持有的资源\nfun main() = runBlocking { val job = launch { try { repeat(1000) { i -\u0026gt; log(\u0026#34;job: I\u0026#39;m sleeping $i ...\u0026#34;) delay(500L) } } catch (e: Throwable) { log(e.message) } finally { log(\u0026#34;job: I\u0026#39;m running finally\u0026#34;) } } delay(1300L) log(\u0026#34;main: I\u0026#39;m tired of waiting!\u0026#34;) job.cancelAndJoin() log(\u0026#34;main: Now I can quit.\u0026#34;) } [main] job: I\u0026#39;m sleeping 0 ... [main] job: I\u0026#39;m sleeping 1 ... [main] job: I\u0026#39;m sleeping 2 ... [main] main: I\u0026#39;m tired of waiting! [main] StandaloneCoroutine was cancelled [main] job: I\u0026#39;m running finally [main] main: Now I can quit. 3、NonCancellable 如果在上一个例子中的 finally 块中再调用挂起函数的话，将会导致抛出 CancellationException，因为此时协程已经被取消了。通常我们并不会遇到这种情况，因为常见的资源释放操作都是非阻塞的，且不涉及任何挂起函数。但在极少数情况下我们需要在取消的协程中再调用挂起函数，此时可以使用 withContext 函数和 NonCancellable上下文将相应的代码包装在 withContext(NonCancellable) {...} 代码块中，NonCancellable 就用于创建一个无法取消的协程作用域\nfun main() = runBlocking { log(\u0026#34;start\u0026#34;) val launchA = launch { try { repeat(5) { delay(50) log(\u0026#34;launchA-$it\u0026#34;) } } finally { delay(50) log(\u0026#34;launchA isCompleted\u0026#34;) } } val launchB = launch { try { repeat(5) { delay(50) log(\u0026#34;launchB-$it\u0026#34;) } } finally { withContext(NonCancellable) { delay(50) log(\u0026#34;launchB isCompleted\u0026#34;) } } } //延时一百毫秒，保证两个协程都已经被启动了 delay(200) launchA.cancel() launchB.cancel() log(\u0026#34;end\u0026#34;) } [main] start [main] launchA-0 [main] launchB-0 [main] launchA-1 [main] launchB-1 [main] launchA-2 [main] launchB-2 [main] end [main] launchB isCompleted 4、父协程和子协程 当一个协程在另外一个协程的协程作用域中启动时，它将通过 CoroutineScope.coroutineContext 继承其上下文，新启动的协程就被称为子协程，子协程的 Job 将成为父协程 Job 的子 Job。父协程总是会等待其所有子协程都完成后才结束自身，所以父协程不必显式跟踪它启动的所有子协程，也不必使用 Job.join 在末尾等待子协程完成\n所以虽然 parentJob 启动的三个子协程的延时时间各不相同，但它们最终都会打印出日志\nfun main() = runBlocking { val parentJob = launch { repeat(3) { i -\u0026gt; launch { delay((i + 1) * 200L) log(\u0026#34;Coroutine $i is done\u0026#34;) } } log(\u0026#34;request: I\u0026#39;m done and I don\u0026#39;t explicitly join my children that are still active\u0026#34;) } } [main] request: I\u0026#39;m done and I don\u0026#39;t explicitly join my children that are still active [main] Coroutine 0 is done [main] Coroutine 1 is done [main] Coroutine 2 is done 5、传播取消操作 一般情况下，协程的取消操作会通过协程的层次结构来进行传播：如果取消父协程或者父协程抛出异常，那么子协程都会被取消；而如果子协程被取消，则不会影响同级协程和父协程，但如果子协程抛出异常则也会导致同级协程和父协程被取消\n对于以下代码，子协程 jon1 被取消并不影响子协程 jon2 和父协程继续运行，但父协程被取消后子协程都会被递归取消\nfun main() = runBlocking { val request = launch { val job1 = launch { repeat(10) { delay(300) log(\u0026#34;job1: $it\u0026#34;) if (it == 2) { log(\u0026#34;job1 canceled\u0026#34;) cancel() } } } val job2 = launch { repeat(10) { delay(300) log(\u0026#34;job2: $it\u0026#34;) } } } delay(1600) log(\u0026#34;parent job canceled\u0026#34;) request.cancel() delay(1000) } [main] job1: 0 [main] job2: 0 [main] job1: 1 [main] job2: 1 [main] job1: 2 [main] job1 canceled [main] job2: 2 [main] job2: 3 [main] job2: 4 [main] parent job canceled 6、withTimeout withTimeout 函数用于指定协程的运行超时时间，如果超时则会抛出 TimeoutCancellationException，从而令协程结束运行\nfun main() = runBlocking { log(\u0026#34;start\u0026#34;) val result = withTimeout(300) { repeat(5) { delay(100) } 200 } log(result) log(\u0026#34;end\u0026#34;) } [main] start Exception in thread \u0026#34;main\u0026#34; kotlinx.coroutines.TimeoutCancellationException: Timed out waiting for 300 ms at kotlinx.coroutines.TimeoutKt.TimeoutCancellationException(Timeout.kt:186) at kotlinx.coroutines.TimeoutCoroutine.run(Timeout.kt:156) at kotlinx.coroutines.EventLoopImplBase$DelayedRunnableTask.run(EventLoop.common.kt:497) at kotlinx.coroutines.EventLoopImplBase.processNextEvent(EventLoop.common.kt:274) at kotlinx.coroutines.DefaultExecutor.run(DefaultExecutor.kt:69) at java.lang.Thread.run(Thread.java:748) withTimeout方法抛出的 TimeoutCancellationException 是 CancellationException 的子类，之前我们并未在输出日志上看到关于 CancellationException 这类异常的堆栈信息，这是因为对于一个已取消的协程来说，CancellationException 被认为是触发协程结束的正常原因。但对于withTimeout方法来说，抛出异常是其上报超时情况的一种手段，所以该异常不会被协程内部消化掉\n如果不希望因为异常导致协程结束，可以改用withTimeoutOrNull方法，如果超时就会返回 null\n九、异常处理 当一个协程由于异常而运行失败时，它会传播这个异常并传递给它的父协程。接下来，父协程会进行下面几步操作：\n取消它自己的子级 取消它自己 将异常传播并传递给它的父级 异常会到达层级的根部，且当前 CoroutineScope 所启动的所有协程都会被取消，但协程并非都是一发现异常就执行以上流程，launch 和 async 在处理异常方面有着一些差异\nlaunch 将异常视为未捕获异常，类似于 Java 的 Thread.uncaughtExceptionHandler，当发现异常时就会马上抛出。async 期望最终通过调用 await 来获取结果 (或者异常)，所以默认情况下它不会抛出异常，这意味着如果使用 async 启动新的协程，它会静默地将异常丢弃，直到调用 async.await() 才会得到目标值或者抛出存在的异常\n例如，以下的 fetchDocs() 方法由于并没有调用 Deferred.await()，因此异常并不会被抛给调用方，而如果使用的是 launch 而非 async 的话，异常就会马上被抛出\nprivate val ioScope = CoroutineScope(Dispatchers.IO) private fun fetchDocs() { ioScope.async { delay(500) log(\u0026#34;taskA throw AssertionError\u0026#34;) throw AssertionError() } } 1、CoroutineExceptionHandler 如果想主动捕获异常信息，可以使用 CoroutineExceptionHandler 作为协程的上下文元素之一，在这里进行自定义日志记录或异常处理，它类似于对线程使用 Thread.uncaughtExceptionHandler。但是，CoroutineExceptionHandler 只会在预计不会由用户处理的异常上调用，因此在 async 中使用它没有任何效果，当 async 内部发生了异常且没有捕获时，那么调用 async.await() 依然会导致应用崩溃\n以下代码只会捕获到 launch 抛出的异常\nfun main() = runBlocking { val handler = CoroutineExceptionHandler { _, exception -\u0026gt; log(\u0026#34;Caught $exception\u0026#34;) } val job = GlobalScope.launch(handler) { throw AssertionError() } val deferred = GlobalScope.async(handler) { throw ArithmeticException() } joinAll(job, deferred) } [DefaultDispatcher-worker-2] Caught java.lang.AssertionError 2、SupervisorJob 由于异常导致的取消在协程中是一种双向关系，会在整个协程层次结构中传播，那如果我们需要的是单向取消该怎么实现呢？\n例如，假设在 Activity 中启动了多个协程，如果单个协程所代表的子任务失败了，此时并不一定需要连锁终止整个 Activity 内部的所有其它协程任务，即此时希望子协程的异常不会传播给同级协程和父协程。而当 Activity 退出后，父协程的异常（即 CancellationException）又应该连锁传播给所有子协程，终止所有子协程\n可以使用 SupervisorJob 来实现上述效果，取消操作只会向下传播，一个子协程的运行失败不会影响到同级协程和父协程\n例如，以下示例中 firstChild 抛出的异常不会导致 secondChild 被取消，但当 supervisor 被取消时 secondChild 也被同时取消了\nfun main() = runBlocking { val supervisor = SupervisorJob() with(CoroutineScope(coroutineContext + supervisor)) { val firstChild = launch(CoroutineExceptionHandler { _, _ -\u0026gt; }) { log(\u0026#34;First child is failing\u0026#34;) throw AssertionError(\u0026#34;First child is cancelled\u0026#34;) } val secondChild = launch { firstChild.join() log(\u0026#34;First child is cancelled: ${firstChild.isCancelled}, but second one is still active\u0026#34;) try { delay(Long.MAX_VALUE) } finally { log(\u0026#34;Second child is cancelled because supervisor is cancelled\u0026#34;) } } firstChild.join() log(\u0026#34;Cancelling supervisor\u0026#34;) //取消所有协程 supervisor.cancel() secondChild.join() } } [main] First child is failing [main] First child is cancelled: true, but second one is still active [main] Cancelling supervisor [main] Second child is cancelled because supervisor is cancelled 但是，如果异常没有被处理且 CoroutineContext 没有包含一个 CoroutineExceptionHandler 的话，异常会到达默认线程的 ExceptionHandler。在 JVM 中，异常会被打印在控制台；而在 Android 中，无论异常在那个 Dispatcher 中发生，都会直接导致应用崩溃。所以如果上述例子中移除了 firstChild 包含的 CoroutineExceptionHandler 的话，就会导致 Android 应用崩溃\n十、Android ktx Android ktx 是包含在 Android Jetpack 及其他 Android 库中的一组 Kotlin 扩展程序。ktx 扩展程序可以为 Jetpack、Android 平台及其他 API 提供简洁的惯用 Kotlin 代码，这些扩展程序利用了多种 Kotlin 语言功能，其中就包括了对 Kotlin 协程的支持\n1、Lifecycle ktx Lifecycle ktx 为每个 Lifecycle 对象（Activity、Fragment、Process 等）定义了一个 LifecycleScope，该作用域具有生命周期安全的保障，在此范围内启动的协程会在 Lifecycle 被销毁时同时取消，可以使用 lifecycle.coroutineScope 或 lifecycleOwner.lifecycleScope 属性来拿到该 CoroutineScope\n引入依赖\ndependencies { implementation \u0026#34;androidx.lifecycle:lifecycle-runtime-ktx:2.4.0\u0026#34; } 使用示例\nclass MyActivity : AppCompatActivity() { override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) lifecycleScope.launch { //Do Something } lifecycle.coroutineScope.launch { //Do Something } } } lifecycleScope 和 lifecycle.coroutineScope 两者是等价的，lifecycleScope只是 ktx 库提供的一种简便写法。从源码也可以看到，lifecycleScope 是存储在抽象类 Lifecycle 的 mInternalScopeRef字段中，且使用的是 SupervisorJob 和 Dispatchers.Main.immediate，因此我们不必担心任意子协程的异常情况会影响到全局的协程任务，且其默认就是在主线程运行协程\npublic val LifecycleOwner.lifecycleScope: LifecycleCoroutineScope get() = lifecycle.coroutineScope public val Lifecycle.coroutineScope: LifecycleCoroutineScope get() { while (true) { val existing = mInternalScopeRef.get() as LifecycleCoroutineScopeImpl? if (existing != null) { return existing } val newScope = LifecycleCoroutineScopeImpl( this, SupervisorJob() + Dispatchers.Main.immediate ) if (mInternalScopeRef.compareAndSet(null, newScope)) { newScope.register() return newScope } } } 2、ViewModel ktx ViewModel ktx 库提供了一个 viewModelScope，用于在 ViewModel 中启动协程，该作用域的生命周期和 ViewModel 相等，当 ViewModel 回调了 onCleared()方法时会自动取消该作用域\n引入依赖\ndependencies { implementation \u0026#34;androidx.lifecycle:lifecycle-viewmodel-ktx:2.4.0\u0026#34; } 例如，以下 fetchDocs() 方法内就依靠 viewModelScope 启动了一个协程，用于在后台线程发起网络请求\nclass MyViewModel : ViewModel() { fun fetchDocs() { viewModelScope.launch { val result = get(\u0026#34;https://developer.android.com\u0026#34;) show(result) } } suspend fun get(url: String) = withContext(Dispatchers.IO) { /* ... */ } } 从源码可以看到其大体实现思路和lifecycleScope 类似，存储在 ViewModel 类的 mBagOfTags 这个 Map 中，且使用的也是 SupervisorJob 和 Dispatchers.Main.immediate\npublic val ViewModel.viewModelScope: CoroutineScope get() { val scope: CoroutineScope? = this.getTag(JOB_KEY) if (scope != null) { return scope } return setTagIfAbsent( JOB_KEY, CloseableCoroutineScope(SupervisorJob() + Dispatchers.Main.immediate) ) } internal class CloseableCoroutineScope(context: CoroutineContext) : Closeable, CoroutineScope { override val coroutineContext: CoroutineContext = context override fun close() { coroutineContext.cancel() } } 3、LiveData ktx 在某些情况下，我们需要先完成特定的异步计算任务，根据计算结果来向 LiveData 回调值，此时就可以使用 LiveData ktx 提供的 liveData 构建器函数来执行 suspend 函数所代表的异步计算任务（耗时任务），并将结果赋值给 LiveData\n引入依赖\ndependencies { implementation \u0026#34;androidx.lifecycle:lifecycle-livedata-ktx:2.4.0\u0026#34; } 在以下示例中，loadUser() 是在其它地方声明的 suspend 函数，你可以使用 liveData 构建器函数异步调用 loadUser()，然后使用 emit() 来发出结果：\nval user: LiveData\u0026lt;User\u0026gt; = liveData { val data = database.loadUser() emit(data) } 从源码可以看到，我们所传入的 suspend 任务体 block 最终是会被 CoroutineLiveData 包装为一个 BlockRunner 对象，而 CoroutineLiveData 会在自身开始有 Observer 监听时执行 blockRunner，并在所有 Observer 均被移除时自动 Cancel 掉 blockRunner\npublic fun \u0026lt;T\u0026gt; liveData( context: CoroutineContext = EmptyCoroutineContext, timeoutInMs: Long = DEFAULT_TIMEOUT, @BuilderInference block: suspend LiveDataScope\u0026lt;T\u0026gt;.() -\u0026gt; Unit ): LiveData\u0026lt;T\u0026gt; = CoroutineLiveData(context, timeoutInMs, block) internal class CoroutineLiveData\u0026lt;T\u0026gt;( context: CoroutineContext = EmptyCoroutineContext, timeoutInMs: Long = DEFAULT_TIMEOUT, block: Block\u0026lt;T\u0026gt; ) : MediatorLiveData\u0026lt;T\u0026gt;() { private var blockRunner: BlockRunner\u0026lt;T\u0026gt;? private var emittedSource: EmittedSource? = null init { val supervisorJob = SupervisorJob(context[Job]) val scope = CoroutineScope(Dispatchers.Main.immediate + context + supervisorJob) blockRunner = BlockRunner( liveData = this, block = block, timeoutInMs = timeoutInMs, scope = scope ) { blockRunner = null } } override fun onActive() { super.onActive() blockRunner?.maybeRun() } override fun onInactive() { super.onInactive() blockRunner?.cancel() } } internal class BlockRunner\u0026lt;T\u0026gt;( private val liveData: CoroutineLiveData\u0026lt;T\u0026gt;, private val block: Block\u0026lt;T\u0026gt;, private val timeoutInMs: Long, private val scope: CoroutineScope, private val onDone: () -\u0026gt; Unit ) { // currently running block job. private var runningJob: Job? = null // cancelation job created in cancel. private var cancellationJob: Job? = null @MainThread fun maybeRun() { cancellationJob?.cancel() cancellationJob = null if (runningJob != null) { return } runningJob = scope.launch { val liveDataScope = LiveDataScopeImpl(liveData, coroutineContext) block(liveDataScope) onDone() } } @MainThread fun cancel() { if (cancellationJob != null) { error(\u0026#34;Cancel call cannot happen without a maybeRun\u0026#34;) } cancellationJob = scope.launch(Dispatchers.Main.immediate) { delay(timeoutInMs) if (!liveData.hasActiveObservers()) { runningJob?.cancel() runningJob = null } } } } 十一、参考资料 本文参考了以下文章中的很多资料，在此表示感谢\nhttps://github.com/Kotlin/Kotlinx.coroutines/blob/master/coroutines-guide.md https://developer.android.google.cn/kotlin/coroutines https://juejin.cn/post/6844904118180380680 https://juejin.cn/post/6888259219008126983 ","permalink":"http://localhost:1313/hugo-blog/public/post/kotlin/%E4%B8%80%E6%96%87%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8-kotlin-%E5%8D%8F%E7%A8%8B/","tags":[],"title":"一文快速入门 Kotlin 协程"},{"categories":[],"content":" 公众号：字节数组 希望对你有所帮助 🤣🤣\n一、概述 在 RxJava 中，一个实现了 Observer 接口的对象可以订阅一个 Observable 类的实例。订阅者对 Observable 发射的任何数据或数据序列作出响应。这种模式简化了并发操作，因为它不需要阻塞等待 Observable 发射数据，而是创建了一个处于待命状态的观察者哨兵，哨兵在未来某个时刻响应 Observable 的通知。RxJava 提供了一套异步编程的 API，并且支持链式调用，所以使用 RxJava 编写的代码的逻辑会非常简洁\nRxJava 有以下三个最基本的元素：\n被观察者（Observable） 观察者（Observer） 订阅（subscribe） 创建被观察者\nObservable\u0026lt;Integer\u0026gt; observable = Observable.create(new ObservableOnSubscribe\u0026lt;Integer\u0026gt;() { @Override public void subscribe(ObservableEmitter\u0026lt;Integer\u0026gt; e) { Log.e(TAG, \u0026#34;subscribe\u0026#34;); Log.e(TAG, \u0026#34;currentThread name: \u0026#34; + Thread.currentThread().getName()); e.onNext(1); e.onNext(2); e.onNext(3); e.onComplete(); } }); 创建观察者\nObserver\u0026lt;Integer\u0026gt; observer = new Observer\u0026lt;Integer\u0026gt;() { @Override public void onSubscribe(Disposable d) { Log.e(TAG, \u0026#34;onSubscribe\u0026#34;); } @Override public void onNext(Integer integer) { Log.e(TAG, \u0026#34;onNext: \u0026#34; + integer); } @Override public void onError(Throwable e) { Log.e(TAG, \u0026#34;onError: \u0026#34; + e.getMessage()); } @Override public void onComplete() { Log.e(TAG, \u0026#34;onComplete\u0026#34;); } }; 完成观察者与被观察者之间的订阅关系\nobservable.subscribe(observer); 也可以以链式调用的方式来完成订阅\nObservable.create(new ObservableOnSubscribe\u0026lt;Integer\u0026gt;() { @Override public void subscribe(ObservableEmitter\u0026lt;Integer\u0026gt; e) { Log.e(TAG, \u0026#34;subscribe\u0026#34;); Log.e(TAG, \u0026#34;currentThread name: \u0026#34; + Thread.currentThread().getName()); e.onNext(1); e.onNext(2); e.onNext(3); e.onComplete(); } }).subscribe(new Observer\u0026lt;Integer\u0026gt;() { @Override public void onSubscribe(Disposable d) { Log.e(TAG, \u0026#34;onSubscribe\u0026#34;); } @Override public void onNext(Integer integer) { Log.e(TAG, \u0026#34;onNext: \u0026#34; + integer); } @Override public void onError(Throwable e) { Log.e(TAG, \u0026#34;onError: \u0026#34; + e.getMessage()); } @Override public void onComplete() { Log.e(TAG, \u0026#34;onComplete\u0026#34;); } }); 最终的输出结果是一样的\nonSubscribe subscribe currentThread name: main onNext: 1 onNext: 2 onNext: 3 onComplete 被观察者发送的事件类型有以下几种\n事件种类 作用 onNext() 发送该事件时，观察者会回调 onNext() 方法 onError() 发送该事件时，观察者会回调 onError() 方法，当发送该事件之后，其他事件将不会继续发送 onComplete() 发送该事件时，观察者会回调 onComplete() 方法，当发送该事件之后，其他事件将不会继续发送 下面来讲解 RxJava 中各种常见的操作符\n二、创建操作符 1、create() 用于创建一个 Observable。一个正确的 Observable 必须尝试调用观察者的 onCompleted 方法或者 onError 方法有且仅有一次，而且此后不能再调用Observable 的任何其它方法\nObservable\u0026lt;Integer\u0026gt; observable = Observable.create(new ObservableOnSubscribe\u0026lt;Integer\u0026gt;() { @Override public void subscribe(ObservableEmitter\u0026lt;Integer\u0026gt; e) { Log.e(TAG, \u0026#34;subscribe\u0026#34;); Log.e(TAG, \u0026#34;currentThread name: \u0026#34; + Thread.currentThread().getName()); e.onNext(1); e.onNext(2); e.onNext(3); e.onComplete(); } }); 2、just() 创建一个 Observable并发送事件，发送的事件总数不可以超出十个\nObservable.just(1, 2, 3).subscribe(new Observer\u0026lt;Integer\u0026gt;() { @Override public void onSubscribe(Disposable d) { Log.e(TAG, \u0026#34;onSubscribe\u0026#34;); } @Override public void onNext(Integer integer) { Log.e(TAG, \u0026#34;onNext: \u0026#34; + integer); } @Override public void onError(Throwable e) { Log.e(TAG, \u0026#34;onError: \u0026#34; + e.getMessage()); } @Override public void onComplete() { Log.e(TAG, \u0026#34;onComplete\u0026#34;); } }); onSubscribe onNext: 1 onNext: 2 onNext: 3 onComplete 3、fromArray 和 just() 类似，但 fromArray 可以传入多于十个的变量，并且可以传入一个数组\nInteger[] arrays = new Integer[]{1, 2, 3}; Observable.fromArray(arrays).subscribe(new Observer\u0026lt;Integer\u0026gt;() { @Override public void onSubscribe(Disposable d) { Log.e(TAG, \u0026#34;onSubscribe\u0026#34;); } @Override public void onNext(Integer integer) { Log.e(TAG, \u0026#34;onNext: \u0026#34; + integer); } @Override public void onError(Throwable e) { Log.e(TAG, \u0026#34;onError: \u0026#34; + e.getMessage()); } @Override public void onComplete() { Log.e(TAG, \u0026#34;onComplete\u0026#34;); } }); 4、fromCallable 这里的 Callable 是指 java.util.concurrent 中的 Callable，Callable 和 Runnable 的用法基本一致，只是它包含一个返回值，这个结果值就是发给观察者的\nObservable.fromCallable(new Callable\u0026lt;Integer\u0026gt;() { @Override public Integer call() { return 100; } }); 5、fromFuture 这里的 Future 是指 java.util.concurrent 中的 Future，Future 的作用是增加了 cancel() 等方法操作 Callable，它可以通过 get() 方法来获取 Callable 返回的值\nfinal FutureTask\u0026lt;Integer\u0026gt; futureTask = new FutureTask\u0026lt;\u0026gt;(new Callable\u0026lt;Integer\u0026gt;() { @Override public Integer call() { return 12; } }); Observable.fromFuture(futureTask).doOnSubscribe(new Consumer\u0026lt;Disposable\u0026gt;() { @Override public void accept(Disposable disposable) { futureTask.run(); } }).subscribe(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer integer) { Log.e(TAG, \u0026#34;accept: \u0026#34; + integer); } }); 6、fromIterable() 用于发送一个 List 集合数据给观察者\nList\u0026lt;Integer\u0026gt; integerList = new ArrayList\u0026lt;\u0026gt;(); integerList.add(1); integerList.add(2); integerList.add(3); Observable.fromIterable(integerList).subscribe(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer integer) { Log.e(TAG, \u0026#34;accept: \u0026#34; + integer); } }); 7、defer() defer 操作符会一直等待直到有观察者订阅它，然后它使用 Observable 工厂方法生成一个 Observable。它对每个观察者都这样做，因此尽管每个订阅者都以为自己订阅的是同一个 Observable ，实际上每个订阅者获取到的都是它们自己的单独的数据序列。在某些情况下，直到发生订阅时才生成 Observable 可以确保 Observable 包含最新的数据\n//全局变量 private Integer value = 100; Observable\u0026lt;Integer\u0026gt; observable = Observable.defer(new Callable\u0026lt;ObservableSource\u0026lt;? extends Integer\u0026gt;\u0026gt;() { @Override public ObservableSource\u0026lt;? extends Integer\u0026gt; call() { return Observable.just(value); } }); value = 200; observable.subscribe(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer integer) { Log.e(TAG, \u0026#34;accept: \u0026#34; + integer); } }); value = 300; observable.subscribe(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer integer) { Log.e(TAG, \u0026#34;accept: \u0026#34; + integer); } }); accept: 200 accept: 300 defer() 操作符能使得每次订阅操作都创建被观察者，因此两次订阅操作会创建不同的被观察者对象，因此两次打印操作返回的值并不一样\n8、timer() 延迟指定时间后会发送一个大小为 0L 的值给观察者\nObservable.timer(2, TimeUnit.SECONDS) .subscribe(new Consumer\u0026lt;Long\u0026gt;() { @Override public void accept(Long aLong) { } }); 9、interval() 每隔一段时间就发送一个事件，传递的值从 0 开始并不断增 1\nObservable.interval(2, TimeUnit.SECONDS) .subscribe(new Consumer\u0026lt;Long\u0026gt;() { @Override public void accept(Long aLong) { Log.e(TAG, \u0026#34;value is: \u0026#34; + aLong); } }); 10、intervalRange() 可以指定发送事件的开始值和数量，其他与 interval() 的功能一样\nObservable.intervalRange(2, 3, 4, 5, TimeUnit.SECONDS) .subscribe(new Observer\u0026lt;Long\u0026gt;() { @Override public void onSubscribe(Disposable d) { Log.e(TAG, \u0026#34;onSubscribe\u0026#34;); } @Override public void onNext(Long aLong) { Log.e(TAG, \u0026#34;onNext：\u0026#34; + aLong); } @Override public void onError(Throwable e) { Log.e(TAG, \u0026#34;onError: \u0026#34; + e.getMessage()); } @Override public void onComplete() { Log.e(TAG, \u0026#34;onComplete\u0026#34;); } }); 起始值从 2 开始递增，事件共传递三次，第一次事件在订阅后延迟 4 秒触发，之后每次延迟 5 秒\n10-06 10:48:40.017 17976-17976/leavesc.hello.rxjavademo E/MainActivity: onSubscribe 10-06 10:48:44.017 17976-17990/leavesc.hello.rxjavademo E/MainActivity: onNext：2 10-06 10:48:49.017 17976-17990/leavesc.hello.rxjavademo E/MainActivity: onNext：3 10-06 10:48:54.017 17976-17990/leavesc.hello.rxjavademo E/MainActivity: onNext：4 10-06 10:48:54.017 17976-17990/leavesc.hello.rxjavademo E/MainActivity: onComplete 11、range() 发送指定范围的事件序列\nObservable.range(2, 5) .subscribe(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer integer) { Log.e(TAG, \u0026#34;values is :\u0026#34; + integer); } }); values is :2 values is :3 values is :4 values is :5 values is :6 12、rangeLong() 作用与 range() 一样，只是数据类型是 Long\nObservable.rangeLong((2, 5) .subscribe(new Consumer\u0026lt;Long\u0026gt;() { @Override public void accept(Long aLong) { Log.e(TAG, \u0026#34;values is :\u0026#34; + aLong); } }); 13、empty() \u0026amp; never() \u0026amp; error() empty() 直接发送 onComplete() 事件\nObservable.empty().subscribe(new Observer\u0026lt;Object\u0026gt;() { @Override public void onSubscribe(Disposable d) { Log.e(TAG, \u0026#34;onSubscribe\u0026#34;); } @Override public void onNext(Object object) { Log.e(TAG, \u0026#34;onNext: \u0026#34; + object); } @Override public void onError(Throwable e) { Log.e(TAG, \u0026#34;onError: \u0026#34; + e.getMessage()); } @Override public void onComplete() { Log.e(TAG, \u0026#34;onComplete\u0026#34;); } }); 打印结果\nonSubscribe onComplete 换成 never()\nonSubscribe 换成 error()\nObservable.error(new Throwable(\u0026#34;Hello\u0026#34;)).subscribe(new Observer\u0026lt;Object\u0026gt;() { @Override public void onSubscribe(Disposable d) { Log.e(TAG, \u0026#34;onSubscribe\u0026#34;); } @Override public void onNext(Object object) { Log.e(TAG, \u0026#34;onNext: \u0026#34; + object); } @Override public void onError(Throwable e) { Log.e(TAG, \u0026#34;onError: \u0026#34; + e.getMessage()); } @Override public void onComplete() { Log.e(TAG, \u0026#34;onComplete\u0026#34;); } }); onSubscribe onError: Hello 三、转换操作符 1、map() map() 用于将被观察者发送的数据类型转变成其他的类型\nObservable.just(1, 2, 3) .map(new Function\u0026lt;Integer, String\u0026gt;() { @Override public String apply(Integer integer) { return \u0026#34;I\u0026#39;m \u0026#34; + integer; } }) .subscribe(new Consumer\u0026lt;String\u0026gt;() { @Override public void accept(String s) { Log.e(TAG, s); } }); 10-06 10:53:16.364 18099-18099/leavesc.hello.rxjavademo E/MainActivity: I\u0026#39;m 1 10-06 10:53:16.364 18099-18099/leavesc.hello.rxjavademo E/MainActivity: I\u0026#39;m 2 10-06 10:53:16.364 18099-18099/leavesc.hello.rxjavademo E/MainActivity: I\u0026#39;m 3 2、flatMap() 用于将事件序列中的元素进行整合加工，返回一个新的被观察者\nList\u0026lt;List\u0026lt;String\u0026gt;\u0026gt; listArrayList = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;String\u0026gt; stringList = new ArrayList\u0026lt;\u0026gt;(); for (int j = 0; j \u0026lt; 2; j++) { stringList.add(\u0026#34;A_\u0026#34; + j); } listArrayList.add(stringList); stringList = new ArrayList\u0026lt;\u0026gt;(); for (int j = 0; j \u0026lt; 2; j++) { stringList.add(\u0026#34;B_\u0026#34; + j); } listArrayList.add(stringList); Observable.fromIterable(listArrayList).flatMap(new Function\u0026lt;List\u0026lt;String\u0026gt;, ObservableSource\u0026lt;String\u0026gt;\u0026gt;() { @Override public ObservableSource\u0026lt;String\u0026gt; apply(List\u0026lt;String\u0026gt; stringList1) throws Exception { return Observable.fromIterable(stringList1); } }).subscribe(new Consumer\u0026lt;String\u0026gt;() { @Override public void accept(String s) throws Exception { Log.e(TAG, \u0026#34;value is: \u0026#34; + s); } }); 10-06 11:02:47.246 18230-18230/leavesc.hello.rxjavademo E/MainActivity: value is: A_0 10-06 11:02:47.246 18230-18230/leavesc.hello.rxjavademo E/MainActivity: value is: A_1 10-06 11:02:47.246 18230-18230/leavesc.hello.rxjavademo E/MainActivity: value is: B_0 10-06 11:02:47.246 18230-18230/leavesc.hello.rxjavademo E/MainActivity: value is: B_1 3、concatMap() concatMap() 和 flatMap() 基本一样，只不过 concatMap() 转发出来的事件是有序的，而 flatMap() 是无序的\n还是用 flatMap()的例子来看\nObservable.fromIterable(listArrayList).flatMap(new Function\u0026lt;List\u0026lt;String\u0026gt;, ObservableSource\u0026lt;String\u0026gt;\u0026gt;() { @Override public ObservableSource\u0026lt;String\u0026gt; apply(List\u0026lt;String\u0026gt; stringList1) throws Exception { if (stringList1.get(0).startsWith(\u0026#34;A\u0026#34;)) { return Observable.fromIterable(stringList1).delay(200, TimeUnit.MILLISECONDS); } return Observable.fromIterable(stringList1); } }).subscribe(new Consumer\u0026lt;String\u0026gt;() { @Override public void accept(String s) throws Exception { Log.e(TAG, \u0026#34;value is: \u0026#34; + s); } }); 进行了一次延时操作，可以看到两次事件的发送顺序颠倒了\n10-06 11:07:30.753 18702-18702/leavesc.hello.rxjavademo E/MainActivity: value is: B_0 10-06 11:07:30.753 18702-18702/leavesc.hello.rxjavademo E/MainActivity: value is: B_1 10-06 11:07:30.953 18702-18716/leavesc.hello.rxjavademo E/MainActivity: value is: A_0 10-06 11:07:30.953 18702-18716/leavesc.hello.rxjavademo E/MainActivity: value is: A_1 使用 concatMap() 则顺序将保持一致\n4、buffer() 从需要发送的事件当中获取指定数量的事件，并将这些事件放到缓冲区当中一并发出。buffer 有两个参数，参数一count用于指点缓冲区大小，参数二 skip用指定当缓冲区满了时，发送下一次事件序列的时候要跳过多少元素\nObservable.just(1, 2, 3, 4, 5, 6) .buffer(2, 2) .subscribe(new Observer\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt;() { @Override public void onSubscribe(Disposable d) { Log.e(TAG, \u0026#34;onSubscribe\u0026#34;); } @Override public void onNext(List\u0026lt;Integer\u0026gt; integers) { Log.e(TAG, \u0026#34;缓冲区大小： \u0026#34; + integers.size()); for (Integer i : integers) { Log.e(TAG, \u0026#34;元素： \u0026#34; + i); } } @Override public void onError(Throwable e) { Log.e(TAG, \u0026#34;onError: \u0026#34; + e.getMessage()); } @Override public void onComplete() { Log.e(TAG, \u0026#34;onComplete\u0026#34;); } }); onSubscribe 缓冲区大小： 2 元素： 1 元素： 2 缓冲区大小： 2 元素： 3 元素： 4 缓冲区大小： 2 元素： 5 元素： 6 onComplete 5、groupBy() 用于将数据进行分组，每个分组都会返回一个被观察者。groupBy() 方法的返回值用于指定分组名，每返回一个新值就代表会创建一个分组\nObservable.just(1, 2, 3, 4, 5, 6, 7) .groupBy(new Function\u0026lt;Integer, String\u0026gt;() { @Override public String apply(Integer integer) { if (integer \u0026lt; 4) { return \u0026#34;hello\u0026#34;; } return \u0026#34;hi\u0026#34;; } }) .subscribe(new Observer\u0026lt;GroupedObservable\u0026lt;String, Integer\u0026gt;\u0026gt;() { @Override public void onSubscribe(Disposable d) { Log.e(TAG, \u0026#34;onSubscribe\u0026#34;); } @Override public void onNext(final GroupedObservable\u0026lt;String, Integer\u0026gt; observable) { observable.subscribe(new Observer\u0026lt;Integer\u0026gt;() { @Override public void onSubscribe(Disposable d) { Log.e(TAG, \u0026#34;GroupedObservable onSubscribe\u0026#34;); } @Override public void onNext(Integer integer) { Log.e(TAG, \u0026#34;GroupedObservable onNext key :\u0026#34; + observable.getKey()); Log.e(TAG, \u0026#34;GroupedObservable onNext value :\u0026#34; + integer); } @Override public void onError(Throwable e) { Log.e(TAG, \u0026#34;GroupedObservable onError\u0026#34;); } @Override public void onComplete() { Log.e(TAG, \u0026#34;GroupedObservable onComplete\u0026#34;); } }); } @Override public void onError(Throwable e) { Log.e(TAG, \u0026#34;onError\u0026#34;); } @Override public void onComplete() { Log.e(TAG, \u0026#34;onComplete\u0026#34;); } }); 10-06 11:16:35.616 19015-19015/? E/MainActivity: onSubscribe 10-06 11:16:35.616 19015-19015/? E/MainActivity: GroupedObservable onSubscribe 10-06 11:16:35.616 19015-19015/? E/MainActivity: GroupedObservable onNext key :hello 10-06 11:16:35.616 19015-19015/? E/MainActivity: GroupedObservable onNext value :1 10-06 11:16:35.616 19015-19015/? E/MainActivity: GroupedObservable onNext key :hello 10-06 11:16:35.616 19015-19015/? E/MainActivity: GroupedObservable onNext value :2 10-06 11:16:35.616 19015-19015/? E/MainActivity: GroupedObservable onNext key :hello 10-06 11:16:35.616 19015-19015/? E/MainActivity: GroupedObservable onNext value :3 10-06 11:16:35.616 19015-19015/? E/MainActivity: GroupedObservable onSubscribe 10-06 11:16:35.616 19015-19015/? E/MainActivity: GroupedObservable onNext key :hi 10-06 11:16:35.616 19015-19015/? E/MainActivity: GroupedObservable onNext value :4 10-06 11:16:35.616 19015-19015/? E/MainActivity: GroupedObservable onNext key :hi 10-06 11:16:35.616 19015-19015/? E/MainActivity: GroupedObservable onNext value :5 10-06 11:16:35.616 19015-19015/? E/MainActivity: GroupedObservable onNext key :hi 10-06 11:16:35.616 19015-19015/? E/MainActivity: GroupedObservable onNext value :6 10-06 11:16:35.616 19015-19015/? E/MainActivity: GroupedObservable onNext key :hi 10-06 11:16:35.616 19015-19015/? E/MainActivity: GroupedObservable onNext value :7 10-06 11:16:35.616 19015-19015/? E/MainActivity: GroupedObservable onComplete 10-06 11:16:35.616 19015-19015/? E/MainActivity: GroupedObservable onComplete 10-06 11:16:35.616 19015-19015/? E/MainActivity: onComplete 6、scan() scan() 操作符对原始 Observable 发射的第一条数据应用一个函数，然后将那个函数的结果作为自己的第一项数据发射。它将函数的结果同第二项数据一起填充给这个函数来产生它自己的第二项数据。它持续进行这个过程来产生剩余的数据序列\nObservable.just(1, 5, 8, 12).scan(new BiFunction\u0026lt;Integer, Integer, Integer\u0026gt;() { @Override public Integer apply(Integer integer, Integer integer2) { Log.e(TAG, \u0026#34;integer : \u0026#34; + integer); Log.e(TAG, \u0026#34;integer2 : \u0026#34; + integer2); return integer + integer2; } }).subscribe(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer integer) { Log.e(TAG, \u0026#34;accept : \u0026#34; + integer); } }); 10-06 11:25:19.389 19158-19158/leavesc.hello.rxjavademo E/MainActivity: accept : 1 10-06 11:25:19.389 19158-19158/leavesc.hello.rxjavademo E/MainActivity: integer : 1 10-06 11:25:19.389 19158-19158/leavesc.hello.rxjavademo E/MainActivity: integer2 : 5 10-06 11:25:19.399 19158-19158/leavesc.hello.rxjavademo E/MainActivity: accept : 6 10-06 11:25:19.399 19158-19158/leavesc.hello.rxjavademo E/MainActivity: integer : 6 10-06 11:25:19.399 19158-19158/leavesc.hello.rxjavademo E/MainActivity: integer2 : 8 10-06 11:25:19.399 19158-19158/leavesc.hello.rxjavademo E/MainActivity: accept : 14 10-06 11:25:19.399 19158-19158/leavesc.hello.rxjavademo E/MainActivity: integer : 14 10-06 11:25:19.409 19158-19158/leavesc.hello.rxjavademo E/MainActivity: integer2 : 12 10-06 11:25:19.409 19158-19158/leavesc.hello.rxjavademo E/MainActivity: accept : 26 四、组合操作符 1、concat() \u0026amp; concatArray() 用于将多个观察者组合在一起，然后按照参数的传入顺序发送事件，concat() 最多只可以发送4个事件\nObservable.concat(Observable.just(1, 2), Observable.just(3, 4), Observable.just(5, 6), Observable.just(7, 8)).subscribe(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer integer) throws Exception { Log.e(TAG, \u0026#34;accept: \u0026#34; + integer); } }); accept: 1 accept: 2 accept: 3 accept: 4 accept: 5 accept: 6 accept: 7 accept: 8 concatArray() 作用与 concat() 作用一样，不过前者可以发送多于 4 个的被观察者\n2、merge() \u0026amp; mergeArray() 这个方法与 concat() 作用基本一样，只是 concat() 是串行发送事件，而 merge() 并行发送事件\nObservable.merge(Observable.interval(1, TimeUnit.SECONDS).map(new Function\u0026lt;Long, String\u0026gt;() { @Override public String apply(Long aLong) { return \u0026#34;Test_A_\u0026#34; + aLong; } }), Observable.interval(1, TimeUnit.SECONDS).map(new Function\u0026lt;Long, String\u0026gt;() { @Override public String apply(Long aLong) { return \u0026#34;Test_B_\u0026#34; + aLong; } })).subscribe(new Consumer\u0026lt;String\u0026gt;() { @Override public void accept(String s) { Log.e(TAG, \u0026#34;accept: \u0026#34; + s); } }); Test_A_0 Test_B_0 Test_A_1 Test_B_1 Test_A_2 Test_B_2 Test_B_3 Test_A_3 Test_A_4 Test_B_4 Test_A_5 Test_B_5 mergeArray() 可以发送 4 个以上的被观察者\n3、concatArrayDelayError() \u0026amp; mergeArrayDelayError() 在 concatArray() 和 mergeArray() 两个方法当中，如果其中有一个被观察者发送了一个 Error 事件，那么就会停止发送事件，如果想 onError() 事件延迟到所有被观察者都发送完事件后再执行的话，可以使用 concatArrayDelayError() 和 mergeArrayDelayError()\n首先使用 concatArray() 来验证其发送 onError() 事件是否会中断其他被观察者的发送事件\nObservable.concatArray(Observable.create(new ObservableOnSubscribe\u0026lt;Integer\u0026gt;() { @Override public void subscribe(ObservableEmitter\u0026lt;Integer\u0026gt; emitter) { emitter.onNext(1); emitter.onNext(2); emitter.onError(new Exception(\u0026#34;Normal Exception\u0026#34;)); } }), Observable.just(30, 40, 50)).subscribe(new Observer\u0026lt;Integer\u0026gt;() { @Override public void onSubscribe(Disposable d) { } @Override public void onNext(Integer integer) { Log.e(TAG, \u0026#34;onNext: \u0026#34; + integer); } @Override public void onError(Throwable e) { Log.e(TAG, \u0026#34;onError: \u0026#34; + e.getMessage()); } @Override public void onComplete() { } }); onNext: 1 onNext: 2 onError: Normal Exception 从结果可以知道，确实中断了，现在换用 concatArrayDelayError()\n10-06 04:00:04.935 6514-6514/? E/MainActivity: onNext: 1 10-06 04:00:04.935 6514-6514/? E/MainActivity: onNext: 2 10-06 04:00:04.935 6514-6514/? E/MainActivity: onNext: 30 10-06 04:00:04.935 6514-6514/? E/MainActivity: onNext: 40 10-06 04:00:04.935 6514-6514/? E/MainActivity: onNext: 50 10-06 04:00:04.935 6514-6514/? E/MainActivity: onError: Normal Exception 从结果可以看到，onError 事件是在所有被观察者发送完事件才发送的\n4、zip() zip() 操作符返回一个 Obversable，它使用这个函数按顺序结合两个或多个 Observables 发射的数据项，然后它发射这个函数返回的结果。它按照严格的顺序应用这个函数。它只发射与发射数据项最少的那个 Observable 一样多的数据\nObservable.zip(Observable.just(1, 2, 3, 4), Observable.just(5, 6, 7, 8, 9), new BiFunction\u0026lt;Integer, Integer, String\u0026gt;() { @Override public String apply(Integer integer, Integer integer2) throws Exception { return String.valueOf(integer) + \u0026#34;_\u0026#34; + String.valueOf(integer2); } }) .subscribe(new Consumer\u0026lt;String\u0026gt;() { @Override public void accept(String s) throws Exception { Log.e(TAG, \u0026#34;accept: \u0026#34; + s); } }); accept: 1_5 accept: 2_6 accept: 3_7 accept: 4_8 5、combineLatest() \u0026amp; combineLatestDelayError() combineLatest() 的作用与 zip() 类似，combineLatest() 发送事件的序列是与发送的时间线有关的，当两个 Observables 中的任何一个发射了一个数据时，通过一个指定的函数组合每个 Observable 发射的最新数据，然后发射这个函数的结果\nObservable.zip( Observable.intervalRange(1, 4, 1, 1, TimeUnit.SECONDS) .map(new Function\u0026lt;Long, String\u0026gt;() { @Override public String apply(Long aLong) { String s1 = \u0026#34;A\u0026#34; + aLong; Log.e(TAG, \u0026#34;A 发送的事件 \u0026#34; + s1); return s1; } }), Observable.intervalRange(1, 4, 2, 1, TimeUnit.SECONDS) .map(new Function\u0026lt;Long, String\u0026gt;() { @Override public String apply(Long aLong) { String s1 = \u0026#34;B\u0026#34; + aLong; Log.e(TAG, \u0026#34;B 发送的事件 \u0026#34; + s1); return s1; } }), new BiFunction\u0026lt;String, String, String\u0026gt;() { @Override public String apply(String value1, String value2) throws Exception { return value1 + \u0026#34;_\u0026#34; + value2; } }) .subscribe(new Consumer\u0026lt;String\u0026gt;() { @Override public void accept(String s) throws Exception { Log.e(TAG, \u0026#34;accept: \u0026#34; + s); } }); 10-06 05:17:06.337 7227-7241/leavesc.hello.rxjavademo E/MainActivity: A 发送的事件 A1 10-06 05:17:07.337 7227-7241/leavesc.hello.rxjavademo E/MainActivity: A 发送的事件 A2 10-06 05:17:07.337 7227-7242/leavesc.hello.rxjavademo E/MainActivity: B 发送的事件 B1 10-06 05:17:07.337 7227-7242/leavesc.hello.rxjavademo E/MainActivity: accept: A1_B1 10-06 05:17:08.337 7227-7241/leavesc.hello.rxjavademo E/MainActivity: A 发送的事件 A3 10-06 05:17:08.337 7227-7242/leavesc.hello.rxjavademo E/MainActivity: B 发送的事件 B2 10-06 05:17:08.337 7227-7242/leavesc.hello.rxjavademo E/MainActivity: accept: A2_B2 10-06 05:17:09.337 7227-7242/leavesc.hello.rxjavademo E/MainActivity: B 发送的事件 B3 10-06 05:17:09.337 7227-7242/leavesc.hello.rxjavademo E/MainActivity: accept: A3_B3 10-06 05:17:09.337 7227-7241/leavesc.hello.rxjavademo E/MainActivity: A 发送的事件 A4 10-06 05:17:10.337 7227-7242/leavesc.hello.rxjavademo E/MainActivity: B 发送的事件 B4 10-06 05:17:10.337 7227-7242/leavesc.hello.rxjavademo E/MainActivity: accept: A4_B4 当发送 A1 和 A2 事件时，B 并没有发送任何事件，所以不会触发到 accept 方法。当发送了 B1 事件之后，就会与 A 最新发送的事件 A2 结合成 A1_B2，之后的发射规则也以此类推\ncombineLatestDelayError() 多了延迟发送 onError() 的功能\n6、reduce() 与 scan() 操作符的作用类似，也是将发送数据以一定逻辑聚合起来，区别在于 scan() 每处理一次数据就会将事件发送给观察者，而 reduce() 会将所有数据聚合在一起才会发送事件给观察者\nObservable.just(1, 3, 5, 7).reduce(new BiFunction\u0026lt;Integer, Integer, Integer\u0026gt;() { @Override public Integer apply(Integer integer, Integer integer2) throws Exception { Log.e(TAG, \u0026#34;integer1 : \u0026#34; + integer); Log.e(TAG, \u0026#34;integer2 : \u0026#34; + integer2); return integer + integer2; } }).subscribe(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer integer) throws Exception { Log.e(TAG, \u0026#34;accept : \u0026#34; + integer); } }); integer1 : 1 integer2 : 3 integer1 : 4 integer2 : 5 integer1 : 9 integer2 : 7 accept : 16 7、collect() collect() 与 reduce() 类似，但它的目的是收集原始 Observable 发射的所有数据到一个可变的数据结构\nObservable.just(1, 2, 3, 4) .collect(new Callable\u0026lt;ArrayList\u0026lt;Integer\u0026gt;\u0026gt;() { @Override public ArrayList\u0026lt;Integer\u0026gt; call() throws Exception { return new ArrayList\u0026lt;\u0026gt;(); } }, new BiConsumer\u0026lt;ArrayList\u0026lt;Integer\u0026gt;, Integer\u0026gt;() { @Override public void accept(ArrayList\u0026lt;Integer\u0026gt; integers, Integer integer) throws Exception { integers.add(integer); } }) .subscribe(new Consumer\u0026lt;ArrayList\u0026lt;Integer\u0026gt;\u0026gt;() { @Override public void accept(ArrayList\u0026lt;Integer\u0026gt; integers) throws Exception { Log.e(TAG, \u0026#34;accept : \u0026#34; + integers); } }); accept : [1, 2, 3, 4] 8、startWith() \u0026amp; startWithArray() 在发送事件之前追加事件，startWith() 追加一个事件，startWithArray() 可以追加多个事件，追加的事件会先发出\nObservable.just(4, 5) .startWithArray(2, 3) .startWith(1) .subscribe(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer integer) throws Exception { Log.e(TAG, \u0026#34;accept : \u0026#34; + integer); } }); 10-06 05:38:21.081 8033-8033/leavesc.hello.rxjavademo E/MainActivity: accept : 1 10-06 05:38:21.081 8033-8033/leavesc.hello.rxjavademo E/MainActivity: accept : 2 10-06 05:38:21.081 8033-8033/leavesc.hello.rxjavademo E/MainActivity: accept : 3 10-06 05:38:21.081 8033-8033/leavesc.hello.rxjavademo E/MainActivity: accept : 4 10-06 05:38:21.081 8033-8033/leavesc.hello.rxjavademo E/MainActivity: accept : 5 9、count() 返回被观察者发送事件的数量\nObservable.just(1, 2, 3) .count() .subscribe(new Consumer\u0026lt;Long\u0026gt;() { @Override public void accept(Long aLong) throws Exception { Log.e(TAG, \u0026#34;aLong : \u0026#34; + aLong); } }); aLong : 3 五、功能操作符 1、delay() 延迟一段事件再发送事件\nObservable.just(1, 2, 3) .delay(3, TimeUnit.SECONDS) .subscribe(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer value) throws Exception { Log.e(TAG, \u0026#34;value : \u0026#34; + value); } }); 2、doOnEach() Observable 发送一次事件之前都会回调这个方法\nObservable.just(1, 2, 3) .doOnEach(new Consumer\u0026lt;Notification\u0026lt;Integer\u0026gt;\u0026gt;() { @Override public void accept(Notification\u0026lt;Integer\u0026gt; integerNotification) throws Exception { Log.e(TAG, \u0026#34;integerNotification value : \u0026#34; + integerNotification.getValue()); } }) .subscribe(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer value) throws Exception { Log.e(TAG, \u0026#34;accept : \u0026#34; + value); } }); 10-06 05:53:28.510 8645-8645/? E/MainActivity: integerNotification value : 1 10-06 05:53:28.510 8645-8645/? E/MainActivity: accept : 1 10-06 05:53:28.510 8645-8645/? E/MainActivity: integerNotification value : 2 10-06 05:53:28.510 8645-8645/? E/MainActivity: accept : 2 10-06 05:53:28.510 8645-8645/? E/MainActivity: integerNotification value : 3 10-06 05:53:28.510 8645-8645/? E/MainActivity: accept : 3 10-06 05:53:28.510 8645-8645/? E/MainActivity: integerNotification value : null 3、doOnNext() Observable 发送 onNext() 之前都会先回调这个方法\nObservable.just(1, 2, 3) .doOnNext(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer integer) throws Exception { Log.e(TAG, \u0026#34;doOnNext accept : \u0026#34; + integer); } }) .subscribe(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer value) throws Exception { Log.e(TAG, \u0026#34;accept : \u0026#34; + value); } }); 10-06 05:55:25.618 8758-8758/leavesc.hello.rxjavademo E/MainActivity: doOnNext accept : 1 10-06 05:55:25.618 8758-8758/leavesc.hello.rxjavademo E/MainActivity: accept : 1 10-06 05:55:25.618 8758-8758/leavesc.hello.rxjavademo E/MainActivity: doOnNext accept : 2 10-06 05:55:25.618 8758-8758/leavesc.hello.rxjavademo E/MainActivity: accept : 2 10-06 05:55:25.618 8758-8758/leavesc.hello.rxjavademo E/MainActivity: doOnNext accept : 3 10-06 05:55:25.618 8758-8758/leavesc.hello.rxjavademo E/MainActivity: accept : 3 4、doAfterNext() Observable 发送 onNext() 之后都会回调这个方法\nObservable.just(1, 2, 3) .doAfterNext(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer integer) throws Exception { Log.e(TAG, \u0026#34;doOnNext accept : \u0026#34; + integer); } }) .subscribe(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer value) throws Exception { Log.e(TAG, \u0026#34;accept : \u0026#34; + value); } }); 10-06 05:57:09.357 8872-8872/leavesc.hello.rxjavademo E/MainActivity: accept : 1 10-06 05:57:09.357 8872-8872/leavesc.hello.rxjavademo E/MainActivity: doOnNext accept : 1 10-06 05:57:09.357 8872-8872/leavesc.hello.rxjavademo E/MainActivity: accept : 2 10-06 05:57:09.357 8872-8872/leavesc.hello.rxjavademo E/MainActivity: doOnNext accept : 2 10-06 05:57:09.357 8872-8872/leavesc.hello.rxjavademo E/MainActivity: accept : 3 10-06 05:57:09.357 8872-8872/leavesc.hello.rxjavademo E/MainActivity: doOnNext accept : 3 5、doOnComplete() Observable 调用 onComplete() 之前都会回调这个方法\nObservable.just(1, 2, 3) .doOnComplete(new Action() { @Override public void run() throws Exception { Log.e(TAG, \u0026#34;doOnComplete run()\u0026#34;); } }) .subscribe(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer value) throws Exception { Log.e(TAG, \u0026#34;accept : \u0026#34; + value); } }); 10-06 06:08:43.688 8982-8982/leavesc.hello.rxjavademo E/MainActivity: accept : 1 10-06 06:08:43.688 8982-8982/leavesc.hello.rxjavademo E/MainActivity: accept : 2 10-06 06:08:43.688 8982-8982/leavesc.hello.rxjavademo E/MainActivity: accept : 3 10-06 06:08:43.688 8982-8982/leavesc.hello.rxjavademo E/MainActivity: doOnComplete run() 6、doOnError() Observable 发送 onError() 之前都会回调这个方法\nObservable.create(new ObservableOnSubscribe\u0026lt;Integer\u0026gt;() { @Override public void subscribe(ObservableEmitter\u0026lt;Integer\u0026gt; emitter) throws Exception { emitter.onNext(1); emitter.onNext(2); emitter.onError(new Exception(\u0026#34;Normal Exception\u0026#34;)); } }).doOnError(new Consumer\u0026lt;Throwable\u0026gt;() { @Override public void accept(Throwable throwable) throws Exception { Log.e(TAG, \u0026#34;doOnError accept() : \u0026#34; + throwable.getMessage()); } }).subscribe(new Observer\u0026lt;Integer\u0026gt;() { @Override public void onSubscribe(Disposable d) { } @Override public void onNext(Integer integer) { Log.e(TAG, \u0026#34;onNext : \u0026#34; + integer); } @Override public void onError(Throwable e) { Log.e(TAG, \u0026#34;onError : \u0026#34; + e.getMessage()); } @Override public void onComplete() { } }); 10-06 06:14:17.894 9230-9230/? E/MainActivity: onNext : 1 10-06 06:14:17.894 9230-9230/? E/MainActivity: onNext : 2 10-06 06:14:17.894 9230-9230/? E/MainActivity: doOnError accept() : Normal Exception 10-06 06:14:17.894 9230-9230/? E/MainActivity: onError : Normal Exception 7、doOnSubscribe() Observable 发送 onSubscribe() 之前会回调这个方法\n8、doOnDispose() 当调用 Disposable 的 dispose() 之后会回调该方法\n9、doOnLifecycle() 在回调 onSubscribe 之前回调该方法的第一个参数的回调方法，可以使用该回调方法决定是否取消订阅，doOnLifecycle() 第二个参数的回调方法的作用与 doOnDispose() 一样\nObservable.create(new ObservableOnSubscribe\u0026lt;Integer\u0026gt;() { @Override public void subscribe(ObservableEmitter\u0026lt;Integer\u0026gt; emitter) throws Exception { emitter.onNext(1); emitter.onNext(2); emitter.onComplete(); } }).doOnLifecycle(new Consumer\u0026lt;Disposable\u0026gt;() { @Override public void accept(Disposable disposable) throws Exception { Log.e(TAG, \u0026#34;doOnLifecycle accept\u0026#34;); } }, new Action() { @Override public void run() throws Exception { Log.e(TAG, \u0026#34;doOnLifecycle run\u0026#34;); } }).subscribe(new Observer\u0026lt;Integer\u0026gt;() { private Disposable disposable; @Override public void onSubscribe(Disposable d) { Log.e(TAG, \u0026#34;onSubscribe\u0026#34;); this.disposable = d; } @Override public void onNext(Integer integer) { Log.e(TAG, \u0026#34;onNext : \u0026#34; + integer); disposable.dispose(); } @Override public void onError(Throwable e) { Log.e(TAG, \u0026#34;onError : \u0026#34; + e.getMessage()); } @Override public void onComplete() { Log.e(TAG, \u0026#34;onComplete\u0026#34;); } }); 10-06 06:31:45.011 9602-9602/leavesc.hello.rxjavademo E/MainActivity: doOnLifecycle accept 10-06 06:31:45.011 9602-9602/leavesc.hello.rxjavademo E/MainActivity: onSubscribe 10-06 06:31:45.011 9602-9602/leavesc.hello.rxjavademo E/MainActivity: onNext : 1 10-06 06:31:45.011 9602-9602/leavesc.hello.rxjavademo E/MainActivity: doOnLifecycle run 10、doOnTerminate() \u0026amp; doAfterTerminate() doOnTerminate 是在 onError 或者 onComplete 发送之前回调，而 doAfterTerminate 则是 onError 或者 onComplete 发送之后回调\nObservable.create(new ObservableOnSubscribe\u0026lt;Integer\u0026gt;() { @Override public void subscribe(ObservableEmitter\u0026lt;Integer\u0026gt; emitter) throws Exception { emitter.onNext(1); emitter.onNext(2); emitter.onComplete(); } }).doOnTerminate(new Action() { @Override public void run() throws Exception { Log.e(TAG, \u0026#34;doOnTerminate run\u0026#34;); } }).doAfterTerminate(new Action() { @Override public void run() throws Exception { Log.e(TAG, \u0026#34;doAfterTerminate run\u0026#34;); } }).subscribe(new Observer\u0026lt;Integer\u0026gt;() { @Override public void onSubscribe(Disposable d) { Log.e(TAG, \u0026#34;onSubscribe\u0026#34;); } @Override public void onNext(Integer integer) { Log.e(TAG, \u0026#34;onNext : \u0026#34; + integer); } @Override public void onError(Throwable e) { Log.e(TAG, \u0026#34;onError : \u0026#34; + e.getMessage()); } @Override public void onComplete() { Log.e(TAG, \u0026#34;onComplete\u0026#34;); } }); 10-06 06:34:55.968 9713-9713/? E/MainActivity: onSubscribe 10-06 06:34:55.968 9713-9713/? E/MainActivity: onNext : 1 10-06 06:34:55.968 9713-9713/? E/MainActivity: onNext : 2 10-06 06:34:55.968 9713-9713/? E/MainActivity: doOnTerminate run 10-06 06:34:55.968 9713-9713/? E/MainActivity: onComplete 10-06 06:34:55.968 9713-9713/? E/MainActivity: doAfterTerminate run 11、doFinally() 在所有事件发送完毕之后回调该方法。 doFinally() 和 doAfterTerminate() 的区别在于取消订阅时，如果取消订阅，之后 doAfterTerminate() 就不会被回调，而 doFinally() 无论怎么样都会被回调，且都会在事件序列的最后\n12、onErrorReturn() 当接受到一个 onError() 事件之后回调，返回的值会回调 onNext() 方法，并正常结束该事件序列\nObservable.create(new ObservableOnSubscribe\u0026lt;Integer\u0026gt;() { @Override public void subscribe(ObservableEmitter\u0026lt;Integer\u0026gt; emitter) throws Exception { emitter.onNext(1); emitter.onNext(2); emitter.onError(new Exception(\u0026#34;Normal Exception\u0026#34;)); } }).onErrorReturn(new Function\u0026lt;Throwable, Integer\u0026gt;() { @Override public Integer apply(Throwable throwable) throws Exception { return 7; } }).subscribe(new Observer\u0026lt;Integer\u0026gt;() { @Override public void onSubscribe(Disposable d) { Log.e(TAG, \u0026#34;onSubscribe\u0026#34;); } @Override public void onNext(Integer integer) { Log.e(TAG, \u0026#34;onNext : \u0026#34; + integer); } @Override public void onError(Throwable e) { Log.e(TAG, \u0026#34;onError : \u0026#34; + e.getMessage()); } @Override public void onComplete() { Log.e(TAG, \u0026#34;onComplete\u0026#34;); } }); 10-06 06:43:13.702 9946-9946/leavesc.hello.rxjavademo E/MainActivity: onSubscribe 10-06 06:43:13.702 9946-9946/leavesc.hello.rxjavademo E/MainActivity: onNext : 1 10-06 06:43:13.702 9946-9946/leavesc.hello.rxjavademo E/MainActivity: onNext : 2 10-06 06:43:13.712 9946-9946/leavesc.hello.rxjavademo E/MainActivity: onNext : 7 10-06 06:43:13.712 9946-9946/leavesc.hello.rxjavademo E/MainActivity: onComplete 13、onErrorResumeNext() 当接收到 onError() 事件时，返回一个新的 Observable，并正常结束事件序列\nObservable.create(new ObservableOnSubscribe\u0026lt;Integer\u0026gt;() { @Override public void subscribe(ObservableEmitter\u0026lt;Integer\u0026gt; emitter) throws Exception { emitter.onNext(1); emitter.onNext(2); emitter.onError(new Exception(\u0026#34;Normal Exception\u0026#34;)); } }).onErrorResumeNext(new Function\u0026lt;Throwable, ObservableSource\u0026lt;? extends Integer\u0026gt;\u0026gt;() { @Override public ObservableSource\u0026lt;? extends Integer\u0026gt; apply(Throwable throwable) throws Exception { Log.e(TAG, \u0026#34;onErrorResumeNext apply: \u0026#34; + throwable.getMessage()); return Observable.just(4, 5, 6); } }).subscribe(new Observer\u0026lt;Integer\u0026gt;() { @Override public void onSubscribe(Disposable d) { Log.e(TAG, \u0026#34;onSubscribe\u0026#34;); } @Override public void onNext(Integer integer) { Log.e(TAG, \u0026#34;onNext : \u0026#34; + integer); } @Override public void onError(Throwable e) { Log.e(TAG, \u0026#34;onError : \u0026#34; + e.getMessage()); } @Override public void onComplete() { Log.e(TAG, \u0026#34;onComplete\u0026#34;); } }); 10-06 06:46:36.650 10243-10243/leavesc.hello.rxjavademo E/MainActivity: onSubscribe 10-06 06:46:36.650 10243-10243/leavesc.hello.rxjavademo E/MainActivity: onNext : 1 10-06 06:46:36.650 10243-10243/leavesc.hello.rxjavademo E/MainActivity: onNext : 2 10-06 06:46:36.650 10243-10243/leavesc.hello.rxjavademo E/MainActivity: onErrorResumeNext apply: Normal Exception 10-06 06:46:36.650 10243-10243/leavesc.hello.rxjavademo E/MainActivity: onNext : 4 10-06 06:46:36.650 10243-10243/leavesc.hello.rxjavademo E/MainActivity: onNext : 5 10-06 06:46:36.650 10243-10243/leavesc.hello.rxjavademo E/MainActivity: onNext : 6 10-06 06:46:36.650 10243-10243/leavesc.hello.rxjavademo E/MainActivity: onComplete 14、 onExceptionResumeNext() 与 onErrorResumeNext() 作用基本一致，但是这个方法只能捕捉 Exception，不能捕获 Error\nObservable.create(new ObservableOnSubscribe\u0026lt;Integer\u0026gt;() { @Override public void subscribe(ObservableEmitter\u0026lt;Integer\u0026gt; emitter) throws Exception { emitter.onNext(1); emitter.onNext(2); emitter.onError(new Exception(\u0026#34;Normal Exception\u0026#34;)); } }).onExceptionResumeNext(new Observable\u0026lt;Integer\u0026gt;() { @Override protected void subscribeActual(Observer\u0026lt;? super Integer\u0026gt; observer) { Log.e(TAG, \u0026#34;onExceptionResumeNext subscribeActual\u0026#34;); observer.onNext(3); observer.onComplete(); } }).subscribe(new Observer\u0026lt;Integer\u0026gt;() { @Override public void onSubscribe(Disposable d) { Log.e(TAG, \u0026#34;onSubscribe\u0026#34;); } @Override public void onNext(Integer integer) { Log.e(TAG, \u0026#34;onNext : \u0026#34; + integer); } @Override public void onError(Throwable e) { Log.e(TAG, \u0026#34;onError : \u0026#34; + e.getMessage()); } @Override public void onComplete() { Log.e(TAG, \u0026#34;onComplete\u0026#34;); } }); 10-06 06:51:49.396 10369-10369/leavesc.hello.rxjavademo E/MainActivity: onSubscribe 10-06 06:51:49.396 10369-10369/leavesc.hello.rxjavademo E/MainActivity: onNext : 1 10-06 06:51:49.396 10369-10369/leavesc.hello.rxjavademo E/MainActivity: onNext : 2 10-06 06:51:49.396 10369-10369/leavesc.hello.rxjavademo E/MainActivity: onExceptionResumeNext subscribeActual 10-06 06:51:49.396 10369-10369/leavesc.hello.rxjavademo E/MainActivity: onNext : 3 10-06 06:51:49.396 10369-10369/leavesc.hello.rxjavademo E/MainActivity: onComplete 将 emitter.onError(new Exception(\u0026quot;Normal Exception\u0026quot;)) 改为 emitter.onError(new Error(\u0026quot;Normal Exception\u0026quot;));\n异常将不会被捕获\n10-06 06:53:21.655 10479-10479/leavesc.hello.rxjavademo E/MainActivity: onSubscribe 10-06 06:53:21.655 10479-10479/leavesc.hello.rxjavademo E/MainActivity: onNext : 1 10-06 06:53:21.655 10479-10479/leavesc.hello.rxjavademo E/MainActivity: onNext : 2 10-06 06:53:21.655 10479-10479/leavesc.hello.rxjavademo E/MainActivity: onError : Normal Exception 15、retry() 如果出现错误事件，则会重新发送所有事件序列指定次数\nObservable.create(new ObservableOnSubscribe\u0026lt;Integer\u0026gt;() { @Override public void subscribe(ObservableEmitter\u0026lt;Integer\u0026gt; emitter) throws Exception { emitter.onNext(1); emitter.onNext(2); emitter.onError(new Error(\u0026#34;Normal Exception\u0026#34;)); } }).retry(2).subscribe(new Observer\u0026lt;Integer\u0026gt;() { @Override public void onSubscribe(Disposable d) { Log.e(TAG, \u0026#34;onSubscribe\u0026#34;); } @Override public void onNext(Integer integer) { Log.e(TAG, \u0026#34;onNext : \u0026#34; + integer); } @Override public void onError(Throwable e) { Log.e(TAG, \u0026#34;onError : \u0026#34; + e.getMessage()); } @Override public void onComplete() { Log.e(TAG, \u0026#34;onComplete\u0026#34;); } }); 10-06 06:55:17.273 10591-10591/? E/MainActivity: onSubscribe 10-06 06:55:17.273 10591-10591/? E/MainActivity: onNext : 1 10-06 06:55:17.273 10591-10591/? E/MainActivity: onNext : 2 10-06 06:55:17.273 10591-10591/? E/MainActivity: onNext : 1 10-06 06:55:17.273 10591-10591/? E/MainActivity: onNext : 2 10-06 06:55:17.273 10591-10591/? E/MainActivity: onNext : 1 10-06 06:55:17.273 10591-10591/? E/MainActivity: onNext : 2 10-06 06:55:17.273 10591-10591/? E/MainActivity: onError : Normal Exception 16、retryUntil() 出现错误事件之后，可以通过此方法判断是否继续发送事件\nprivate int index = 1; Observable.create(new ObservableOnSubscribe\u0026lt;Integer\u0026gt;() { @Override public void subscribe(ObservableEmitter\u0026lt;Integer\u0026gt; emitter) throws Exception { emitter.onNext(1); emitter.onNext(2); emitter.onError(new Exception(\u0026#34;Normal Exception\u0026#34;)); } }).retryUntil(new BooleanSupplier() { @Override public boolean getAsBoolean() throws Exception { Log.e(TAG, \u0026#34;getAsBoolean\u0026#34;); return index == 7; } }).subscribe(new Observer\u0026lt;Integer\u0026gt;() { @Override public void onSubscribe(Disposable d) { Log.e(TAG, \u0026#34;onSubscribe\u0026#34;); } @Override public void onNext(Integer integer) { Log.e(TAG, \u0026#34;onNext : \u0026#34; + integer); index++; } @Override public void onError(Throwable e) { Log.e(TAG, \u0026#34;onError : \u0026#34; + e.getMessage()); } @Override public void onComplete() { Log.e(TAG, \u0026#34;onComplete\u0026#34;); } }); 10-06 07:19:07.675 11433-11433/leavesc.hello.rxjavademo E/MainActivity: onSubscribe 10-06 07:19:07.675 11433-11433/leavesc.hello.rxjavademo E/MainActivity: onNext : 1 10-06 07:19:07.675 11433-11433/leavesc.hello.rxjavademo E/MainActivity: onNext : 2 10-06 07:19:07.675 11433-11433/leavesc.hello.rxjavademo E/MainActivity: getAsBoolean 10-06 07:19:07.675 11433-11433/leavesc.hello.rxjavademo E/MainActivity: onNext : 1 10-06 07:19:07.675 11433-11433/leavesc.hello.rxjavademo E/MainActivity: onNext : 2 10-06 07:19:07.675 11433-11433/leavesc.hello.rxjavademo E/MainActivity: getAsBoolean 10-06 07:19:07.675 11433-11433/leavesc.hello.rxjavademo E/MainActivity: onNext : 1 10-06 07:19:07.675 11433-11433/leavesc.hello.rxjavademo E/MainActivity: onNext : 2 10-06 07:19:07.675 11433-11433/leavesc.hello.rxjavademo E/MainActivity: getAsBoolean 10-06 07:19:07.675 11433-11433/leavesc.hello.rxjavademo E/MainActivity: onError : Normal Exception 17、repeat() 以指定次数重复发送被观察者的事件\nObservable.create(new ObservableOnSubscribe\u0026lt;Integer\u0026gt;() { @Override public void subscribe(ObservableEmitter\u0026lt;Integer\u0026gt; emitter) throws Exception { emitter.onNext(1); emitter.onNext(2); emitter.onComplete(); } }).repeat(2).subscribe(new Observer\u0026lt;Integer\u0026gt;() { @Override public void onSubscribe(Disposable d) { Log.e(TAG, \u0026#34;onSubscribe\u0026#34;); } @Override public void onNext(Integer integer) { Log.e(TAG, \u0026#34;onNext : \u0026#34; + integer); } @Override public void onError(Throwable e) { Log.e(TAG, \u0026#34;onError : \u0026#34; + e.getMessage()); } @Override public void onComplete() { Log.e(TAG, \u0026#34;onComplete\u0026#34;); } }); 10-06 07:38:47.680 12155-12155/? E/MainActivity: onSubscribe 10-06 07:38:47.690 12155-12155/? E/MainActivity: onNext : 1 10-06 07:38:47.690 12155-12155/? E/MainActivity: onNext : 2 10-06 07:38:47.690 12155-12155/? E/MainActivity: onNext : 1 10-06 07:38:47.690 12155-12155/? E/MainActivity: onNext : 2 10-06 07:38:47.690 12155-12155/? E/MainActivity: onComplete 18、repeatWhen() 返回一个新的被观察者来决定是否重复发送事件。如果新的被观察者返回 onComplete 或者 onError 事件，则旧的被观察者不会发送事件。如果新的被观察者返回其他事件，则旧的观察者会发送事件\nObservable.create(new ObservableOnSubscribe\u0026lt;Integer\u0026gt;() { @Override public void subscribe(ObservableEmitter\u0026lt;Integer\u0026gt; e) throws Exception { e.onNext(1); e.onNext(2); e.onNext(3); e.onComplete(); } }).repeatWhen(new Function\u0026lt;Observable\u0026lt;Object\u0026gt;, ObservableSource\u0026lt;?\u0026gt;\u0026gt;() { @Override public ObservableSource\u0026lt;?\u0026gt; apply(Observable\u0026lt;Object\u0026gt; objectObservable) throws Exception { // return Observable.empty(); // return Observable.error(new Exception(\u0026#34;Normal Exception\u0026#34;)); // return Observable.just(1); } }).subscribe(new Observer\u0026lt;Integer\u0026gt;() { @Override public void onSubscribe(Disposable d) { Log.e(TAG, \u0026#34;onSubscribe\u0026#34;); } @Override public void onNext(Integer integer) { Log.e(TAG, \u0026#34;onNext : \u0026#34; + integer); } @Override public void onError(Throwable e) { Log.e(TAG, \u0026#34;onError : \u0026#34; + e.getMessage()); } @Override public void onComplete() { Log.e(TAG, \u0026#34;onComplete\u0026#34;); } }); 以上三种情况的输出结果分别是\n10-06 14:29:05.641 20921-20921/leavesc.hello.rxjavademo E/MainActivity: onSubscribe 10-06 14:29:05.641 20921-20921/leavesc.hello.rxjavademo E/MainActivity: onComplete 10-06 14:29:36.150 21027-21027/? E/MainActivity: onSubscribe 10-06 14:29:36.150 21027-21027/? E/MainActivity: onError : Normal Exception 10-06 14:30:33.220 21135-21135/leavesc.hello.rxjavademo E/MainActivity: onSubscribe 10-06 14:30:33.220 21135-21135/leavesc.hello.rxjavademo E/MainActivity: onNext : 1 10-06 14:30:33.220 21135-21135/leavesc.hello.rxjavademo E/MainActivity: onNext : 2 10-06 14:30:33.220 21135-21135/leavesc.hello.rxjavademo E/MainActivity: onNext : 3 10-06 14:30:33.220 21135-21135/leavesc.hello.rxjavademo E/MainActivity: onComplete 19、subscribeOn() \u0026amp; observeOn() subscribeOn() 用于指定被观察者的线程，要注意的时，如果多次调用此方法，只有第一次有效\nobserveOn() 用于指定观察者的线程，每指定一次就会生效一次\nObservable.create(new ObservableOnSubscribe\u0026lt;Integer\u0026gt;() { @Override public void subscribe(ObservableEmitter\u0026lt;Integer\u0026gt; emitter) throws Exception { Log.e(TAG, \u0026#34;Observable Thread Name: \u0026#34; + Thread.currentThread().getName()); emitter.onNext(1); emitter.onNext(2); emitter.onComplete(); } }).subscribeOn(Schedulers.newThread()).observeOn(AndroidSchedulers.mainThread()).subscribe(new Observer\u0026lt;Integer\u0026gt;() { @Override public void onSubscribe(Disposable d) { Log.e(TAG, \u0026#34;onSubscribe\u0026#34;); Log.e(TAG, \u0026#34;Observer Thread Name: \u0026#34; + Thread.currentThread().getName()); } @Override public void onNext(Integer integer) { Log.e(TAG, \u0026#34;onNext : \u0026#34; + integer); } @Override public void onError(Throwable e) { Log.e(TAG, \u0026#34;onError : \u0026#34; + e.getMessage()); } @Override public void onComplete() { Log.e(TAG, \u0026#34;onComplete\u0026#34;); } }); 10-06 07:54:02.839 12629-12629/leavesc.hello.rxjavademo E/MainActivity: onSubscribe 10-06 07:54:02.839 12629-12629/leavesc.hello.rxjavademo E/MainActivity: Observer Thread Name: main 10-06 07:54:02.839 12629-12643/leavesc.hello.rxjavademo E/MainActivity: Observable Thread Name: RxNewThreadScheduler-1 10-06 07:54:02.859 12629-12629/leavesc.hello.rxjavademo E/MainActivity: onNext : 1 10-06 07:54:02.869 12629-12629/leavesc.hello.rxjavademo E/MainActivity: onNext : 2 10-06 07:54:02.869 12629-12629/leavesc.hello.rxjavademo E/MainActivity: onComplete 调度器 作用 Schedulers.computation( ) 用于使用计算任务，如事件循环和回调处理 Schedulers.immediate( ) 当前线程 Schedulers.io( ) 用于 IO 密集型任务，如果异步阻塞 IO 操作。 Schedulers.newThread( ) 创建一个新的线程 AndroidSchedulers.mainThread() Android 的 UI 线程，用于操作 UI。 六、过滤操作符 1、filter() 通过一定逻辑来过滤被观察者发送的事件，如果返回 true 则会发送事件，否则不会发送\nObservable.just(1, 2, 3, 4).filter(new Predicate\u0026lt;Integer\u0026gt;() { @Override public boolean test(Integer integer) throws Exception { return integer % 2 == 0; } }).subscribe(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer integer) throws Exception { Log.e(TAG, \u0026#34;accept : \u0026#34; + integer); } }); 10-06 07:57:48.196 12753-12753/? E/MainActivity: accept : 2 10-06 07:57:48.196 12753-12753/? E/MainActivity: accept : 4 2、ofType() 过滤不符合该类型的事件\nObservable.just(1, 2, \u0026#34;Hi\u0026#34;, 3, 4, \u0026#34;Hello\u0026#34;).ofType(Integer.class).subscribe(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer integer) throws Exception { Log.e(TAG, \u0026#34;accept : \u0026#34; + integer); } }); 10-06 07:59:41.265 12857-12857/leavesc.hello.rxjavademo E/MainActivity: accept : 1 10-06 07:59:41.265 12857-12857/leavesc.hello.rxjavademo E/MainActivity: accept : 2 10-06 07:59:41.265 12857-12857/leavesc.hello.rxjavademo E/MainActivity: accept : 3 10-06 07:59:41.265 12857-12857/leavesc.hello.rxjavademo E/MainActivity: accept : 4 3、skip() 以正序跳过指定数量的事件\nObservable.just(1, 2, 3, 4).skip(2).subscribe(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer integer) throws Exception { Log.e(TAG, \u0026#34;accept : \u0026#34; + integer); } }); 10-06 08:01:09.183 12971-12971/leavesc.hello.rxjavademo E/MainActivity: accept : 3 10-06 08:01:09.183 12971-12971/leavesc.hello.rxjavademo E/MainActivity: accept : 4 4、skipLast() 以反序跳过指定数量的事件\nObservable.just(1, 2, 3, 4).skipLast(2).subscribe(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer integer) throws Exception { Log.e(TAG, \u0026#34;accept : \u0026#34; + integer); } }); 10-06 08:02:00.753 13079-13079/leavesc.hello.rxjavademo E/MainActivity: accept : 1 10-06 08:02:00.753 13079-13079/leavesc.hello.rxjavademo E/MainActivity: accept : 2 5、distinct() 过滤事件序列中的重复事件\nObservable.just(1, 2, 1, 2, 3, 4, 3).distinct().subscribe(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer integer) throws Exception { Log.e(TAG, \u0026#34;accept : \u0026#34; + integer); } }); 10-06 08:03:27.402 13189-13189/leavesc.hello.rxjavademo E/MainActivity: accept : 1 10-06 08:03:27.402 13189-13189/leavesc.hello.rxjavademo E/MainActivity: accept : 2 10-06 08:03:27.402 13189-13189/leavesc.hello.rxjavademo E/MainActivity: accept : 3 10-06 08:03:27.402 13189-13189/leavesc.hello.rxjavademo E/MainActivity: accept : 4 6、distinctUntilChanged() 过滤掉连续重复的事件\nObservable.just(1, 2, 2, 1, 3, 4, 3, 3).distinctUntilChanged().subscribe(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer integer) throws Exception { Log.e(TAG, \u0026#34;accept : \u0026#34; + integer); } }); 10-06 08:04:44.531 13294-13294/leavesc.hello.rxjavademo E/MainActivity: accept : 1 10-06 08:04:44.541 13294-13294/leavesc.hello.rxjavademo E/MainActivity: accept : 2 10-06 08:04:44.541 13294-13294/leavesc.hello.rxjavademo E/MainActivity: accept : 1 10-06 08:04:44.541 13294-13294/leavesc.hello.rxjavademo E/MainActivity: accept : 3 10-06 08:04:44.541 13294-13294/leavesc.hello.rxjavademo E/MainActivity: accept : 4 10-06 08:04:44.541 13294-13294/leavesc.hello.rxjavademo E/MainActivity: accept : 3 7、take() 控制观察者接收事件的数量\nObservable.just(1, 2, 2, 1, 3, 4, 3, 3).take(3).subscribe(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer integer) throws Exception { Log.e(TAG, \u0026#34;accept : \u0026#34; + integer); } }); 10-06 08:05:43.520 13397-13397/? E/MainActivity: accept : 1 10-06 08:05:43.520 13397-13397/? E/MainActivity: accept : 2 10-06 08:05:43.520 13397-13397/? E/MainActivity: accept : 2 8、debounce() 如果两个事件发送的时间间隔小于设定的时间间隔，则前一件事件不会发送给观察者\nObservable.create(new ObservableOnSubscribe\u0026lt;Integer\u0026gt;() { @Override public void subscribe(ObservableEmitter\u0026lt;Integer\u0026gt; emitter) throws Exception { emitter.onNext(1); Thread.sleep(900); emitter.onNext(2); } }).debounce(1, TimeUnit.SECONDS).subscribe(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer integer) throws Exception { Log.e(TAG, \u0026#34;accept : \u0026#34; + integer); } }); 10-06 08:08:59.337 13509-13523/leavesc.hello.rxjavademo E/MainActivity: accept : 2 9、firstElement() \u0026amp;\u0026amp; lastElement() firstElement() 取事件序列的第一个元素，lastElement() 取事件序列的最后一个元素\nObservable.just(1, 2, 3, 4, 5).firstElement().subscribe(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer integer) throws Exception { Log.e(TAG, \u0026#34;accept : \u0026#34; + integer); } }); 10、elementAt() \u0026amp; elementAtOrError() elementAt() 可以指定取出事件序列中事件，但是输入的 index 超出事件序列的总数的话就不会触发任何调用，想触发异常信息的话就用 elementAtOrError()\nObservable.just(1, 2, 3, 4, 5).elementAt(5).subscribe(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer integer) throws Exception { Log.e(TAG, \u0026#34;accept : \u0026#34; + integer); } }); 以上代码不会触发任何\n改用为 elementAtOrError()，则会抛出异常\nObservable.just(1, 2, 3, 4, 5).elementAtOrError(5).subscribe(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer integer) throws Exception { Log.e(TAG, \u0026#34;accept : \u0026#34; + integer); } }); Process: leavesc.hello.rxjavademo, PID: 13948 io.reactivex.exceptions.OnErrorNotImplementedException: The exception was not handled due to missing onError handler in the subscribe() method call. Further reading: https://github.com/ReactiveX/RxJava/wiki/Error-Handling | null at io.reactivex.internal.functions.Functions$OnErrorMissingConsumer.accept(Functions.java:704) at io.reactivex.internal.functions.Functions$OnErrorMissingConsumer.accept(Functions.java:701) at io.reactivex.internal.observers.ConsumerSingleObserver.onError(ConsumerSingleObserver.java:46) at io.reactivex.internal.operators.observable.ObservableElementAtSingle$ElementAtObserver.onComplete(ObservableElementAtSingle.java:115) at io.reactivex.internal.operators.observable.ObservableFromArray$FromArrayDisposable.run(ObservableFromArray.java:111) at io.reactivex.internal.operators.observable.ObservableFromArray.subscribeActual(ObservableFromArray.java:37) at io.reactivex.Observable.subscribe(Observable.java:12090) at io.reactivex.internal.operators.observable.ObservableElementAtSingle.subscribeActual(ObservableElementAtSingle.java:37) at io.reactivex.Single.subscribe(Single.java:3438) at io.reactivex.Single.subscribe(Single.java:3424) 七、条件操作符 1、all() 判断事件序列是否全部满足某个事件，如果都满足则返回 true，反之则返回 false\nObservable.just(1, 2, 3, 4, 5).all(new Predicate\u0026lt;Integer\u0026gt;() { @Override public boolean test(Integer integer) throws Exception { return integer % 2 == 0; } }).subscribe(new Consumer\u0026lt;Boolean\u0026gt;() { @Override public void accept(Boolean aBoolean) throws Exception { Log.e(TAG, \u0026#34;accept: \u0026#34; + aBoolean); } }); 10-06 08:16:10.212 14043-14043/leavesc.hello.rxjavademo E/MainActivity: accept: false 2、takeWhile() 发射原始 Observable，直到指定的某个条件不成立的那一刻，它停止发射原始 Observable，并终止自己的 Observable\nObservable.just(1, 2, 3, 4, 5, 1, 2).takeWhile(new Predicate\u0026lt;Integer\u0026gt;() { @Override public boolean test(Integer integer) throws Exception { return integer \u0026lt; 4; } }).subscribe(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer integer) throws Exception { Log.e(TAG, \u0026#34;accept: \u0026#34; + integer); } }); 10-06 14:03:42.110 20095-20095/leavesc.hello.rxjavademo E/MainActivity: accept: 1 10-06 14:03:42.110 20095-20095/leavesc.hello.rxjavademo E/MainActivity: accept: 2 10-06 14:03:42.110 20095-20095/leavesc.hello.rxjavademo E/MainActivity: accept: 3 3、skipWhile() 订阅原始的 Observable，但是忽略它的发射物，直到指定的某个条件变为 false 时才开始发射原始 Observable\nObservable.just(1, 2, 4, 1, 3, 4, 5, 1, 5) .skipWhile(new Predicate\u0026lt;Integer\u0026gt;() { @Override public boolean test(Integer integer) throws Exception { return integer \u0026lt; 3; } }) .subscribe(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer integer) throws Exception { Log.e(TAG, \u0026#34;integer \u0026#34; + integer); } }); 10-06 13:59:40.583 19764-19764/leavesc.hello.rxjavademo E/MainActivity: integer 4 10-06 13:59:40.593 19764-19764/leavesc.hello.rxjavademo E/MainActivity: integer 1 10-06 13:59:40.593 19764-19764/leavesc.hello.rxjavademo E/MainActivity: integer 3 10-06 13:59:40.593 19764-19764/leavesc.hello.rxjavademo E/MainActivity: integer 4 10-06 13:59:40.593 19764-19764/leavesc.hello.rxjavademo E/MainActivity: integer 5 10-06 13:59:40.593 19764-19764/leavesc.hello.rxjavademo E/MainActivity: integer 1 10-06 13:59:40.593 19764-19764/leavesc.hello.rxjavademo E/MainActivity: integer 5 4、takeUntil() 用于设置一个条件，当事件满足此条件时，此事件会被发送，但之后的事件就不会被发送了\nObservable.just(1, 2, 4, 1, 3, 4, 5, 1, 5) .takeUntil(new Predicate\u0026lt;Integer\u0026gt;() { @Override public boolean test(Integer integer) throws Exception { return integer \u0026gt; 3; } }) .subscribe(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer integer) throws Exception { Log.e(TAG, \u0026#34;integer \u0026#34; + integer); } }); 10-06 08:54:24.833 17208-17208/? E/MainActivity: integer 1 10-06 08:54:24.833 17208-17208/? E/MainActivity: integer 2 10-06 08:54:24.833 17208-17208/? E/MainActivity: integer 4 5、skipUntil() 当 skipUntil() 中的 Observable 发送事件了，原始的 Observable 才会发送事件给观察者\nObservable.intervalRange(1, 6, 0, 1, TimeUnit.SECONDS) .skipUntil(Observable.intervalRange(10, 3, 1, 1, TimeUnit.SECONDS)) .subscribe(new Observer\u0026lt;Long\u0026gt;() { @Override public void onSubscribe(Disposable d) { Log.e(TAG, \u0026#34;onSubscribe\u0026#34;); } @Override public void onNext(Long along) { Log.e(TAG, \u0026#34;onNext : \u0026#34; + along); } @Override public void onError(Throwable e) { Log.e(TAG, \u0026#34;onError\u0026#34;); } @Override public void onComplete() { Log.e(TAG, \u0026#34;onComplete\u0026#34;); } }); 10-06 08:51:16.926 16877-16877/leavesc.hello.rxjavademo E/MainActivity: onSubscribe 10-06 08:51:17.946 16877-16892/leavesc.hello.rxjavademo E/MainActivity: onNext : 2 10-06 08:51:18.936 16877-16892/leavesc.hello.rxjavademo E/MainActivity: onNext : 3 10-06 08:51:19.946 16877-16892/leavesc.hello.rxjavademo E/MainActivity: onNext : 4 10-06 08:51:20.936 16877-16892/leavesc.hello.rxjavademo E/MainActivity: onNext : 5 10-06 08:51:21.946 16877-16892/leavesc.hello.rxjavademo E/MainActivity: onNext : 6 10-06 08:51:21.946 16877-16892/leavesc.hello.rxjavademo E/MainActivity: onComplete 6、sequenceEqual() 判断两个 Observable 发送的事件是否相同，如果两个序列是相同的（相同的数据，相同的顺序，相同的终止状态），它就发射 true，否则发射 false\nObservable.sequenceEqual(Observable.just(1, 2, 3), Observable.just(1, 2, 3)) .subscribe(new Consumer\u0026lt;Boolean\u0026gt;() { @Override public void accept(Boolean aBoolean) throws Exception { Log.e(TAG, \u0026#34;accept aBoolean : \u0026#34; + aBoolean); } }); 10-06 08:46:59.369 16492-16492/leavesc.hello.rxjavademo E/MainActivity: accept aBoolean : true 7、contains() 判断事件序列中是否含有某个元素，如果有则返回 true，如果没有则返回 false\nObservable.just(1, 2, 3, 4).contains(2).subscribe(new Consumer\u0026lt;Boolean\u0026gt;() { @Override public void accept(Boolean aBoolean) throws Exception { Log.e(TAG, \u0026#34;accept aBoolean : \u0026#34; + aBoolean); } }); 10-06 08:45:58.100 16386-16386/leavesc.hello.rxjavademo E/MainActivity: accept aBoolean : true 8、isEmpty() 判断事件序列是否为空\nObservable.create(new ObservableOnSubscribe\u0026lt;Integer\u0026gt;() { @Override public void subscribe(ObservableEmitter\u0026lt;Integer\u0026gt; emitter) throws Exception { emitter.onComplete(); } }).isEmpty().subscribe(new Consumer\u0026lt;Boolean\u0026gt;() { @Override public void accept(Boolean aBoolean) throws Exception { Log.e(TAG, \u0026#34;accept aBoolean: \u0026#34; + aBoolean); } }); 10-06 08:43:43.201 16278-16278/leavesc.hello.rxjavademo E/MainActivity: accept aBoolean: true 9、amb() amb() 接收一个 Observable 集合，但是只会发送最先发送事件的 Observable 中的事件，不管发射的是一项数据还是一个 onError 或 onCompleted 通知，其余 Observable 将会被丢弃\nList\u0026lt;Observable\u0026lt;Long\u0026gt;\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); list.add(Observable.intervalRange(1, 3, 2, 1, TimeUnit.SECONDS)); list.add(Observable.intervalRange(10, 3, 0, 1, TimeUnit.SECONDS)); Observable.amb(list).subscribe(new Consumer\u0026lt;Long\u0026gt;() { @Override public void accept(Long aLong) throws Exception { Log.e(TAG, \u0026#34;accept: \u0026#34; + aLong); } }); 10-06 08:41:45.783 16053-16068/leavesc.hello.rxjavademo E/MainActivity: accept: 10 10-06 08:41:46.783 16053-16068/leavesc.hello.rxjavademo E/MainActivity: accept: 11 10-06 08:41:47.783 16053-16068/leavesc.hello.rxjavademo E/MainActivity: accept: 12 10、defaultIfEmpty() 如果 Observable 没有发射任何值，则可以利用这个方法发送一个默认值\nObservable.create(new ObservableOnSubscribe\u0026lt;Integer\u0026gt;() { @Override public void subscribe(ObservableEmitter\u0026lt;Integer\u0026gt; emitter) throws Exception { emitter.onComplete(); } }).defaultIfEmpty(100).subscribe(new Consumer\u0026lt;Integer\u0026gt;() { @Override public void accept(Integer integer) throws Exception { Log.e(TAG, \u0026#34;accept: \u0026#34; + integer); } }); 10-06 08:40:04.754 15945-15945/leavesc.hello.rxjavademo E/MainActivity: accept: 100 ","permalink":"http://localhost:1313/hugo-blog/public/post/kotlin/%E4%B8%80%E6%96%87%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8-rxjava-2/","tags":[],"title":"一文快速入门 RxJava 2"},{"categories":[],"content":" 公众号：字节数组 希望对你有所帮助 🤣🤣\nHandler 在整个 Android 开发体系中占据着很重要的地位，是一种标准的事件驱动模型，对开发者来说起到的作用很明确，就是为了实现线程切换或者是执行延时任务，稍微更高级一点的用法可能是为了保证多个任务在执行时的有序性。由于 Android 系统中的主线程有特殊地位，所以像 EventBus 和 Retrofit 这类并非 Android 独有的三方库，都是通过 Handler 来实现对 Android 系统的特殊平台支持。大部分开发者都已经对如何使用 Handler 很熟悉了，这里就再来了解下其内部具体是如何实现的，希望对你有所帮助 🤣🤣\n本文基于 Android API 30（即 Android 11）的系统源码进行讲解\n一、动手实现 Handler 本文不会一上来就直接介绍源码，而是会先根据我们想要实现的效果来反推源码，一步步来自己动手实现一个简单的 Handler\n1、Message 首先，我们需要有个载体来表示要执行的任务，就叫它 Message 吧，Message 应该有什么参数呢？\n需要有一个唯一标识，因为要执行的任务可能有多个，我们要分得清哪个是哪个，用个 Int 类型变量就足够表示了 需要能够承载数据，需要发送的数据类型会有很多种可能，那就直接用一个 Object 类型变量来表示吧，由开发者自己在使用时再来强转类型 需要有一个 long 类型变量来表示任务的执行时间戳 所以，Message 类就应该至少包含以下几个字段：\n/** * @Author: leavesCZY * @Desc: * @公众号：字节数组 */ public final class Message { //唯一标识 public int what; //数据 public Object obj; //时间戳 public long when; } 2、MessageQueue 因为 Message 并不是发送了就能够马上被消费掉，所以就肯定要有个可以用来存放的地方，就叫它 MessageQueue 吧，即消息队列。Message 可能需要延迟处理，那么 MessageQueue 在保存 Message 的时候就应该按照时间戳的大小来顺序存放，时间戳小的 Message 放在队列的头部，在消费 Message 的时候就直接从队列头取值即可\n那么用什么数据结构来存放 Message 比较好呢？\n用数组？不太合适，数组虽然在遍历的时候会比较快，但需要预先就申请固定的内存空间，导致在插入数据和移除数据时可能需要移动大量数据。而 MessageQueue 可能随时会收到数量不定、时间戳大小不定的 Message，消费完 Message 后还需要将该其移出队列，所以使用数组并不合适 用链表？好像可以，链表在插入数据和移除数据时只需要改变指针的引用即可，不需要移动数据，内存空间也只需要按需申请即可。虽然链表在随机访问的时候性能不高，但是对于 MessageQueue 而言无所谓，因为在消费 Message 的时候也只需要取队列头的值，并不需要随机访问 好了，既然决定用链表结构，那么 Message 就需要增加一个字段用于指向下一条消息才行\npublic final class Message { //唯一标识 public int what; //数据 public Object obj; //时间戳 public long when; //下一个节点 public Message next; } MessageQueue 需要提供一个 enqueueMessage方法用来向链表插入 Message，由于存在多个线程同时向队列发送消息的可能，所以方法内部还需要做下线程同步才行\npublic class MessageQueue { //链表中的第一条消息 private Message mMessages; void enqueueMessage(Message msg, long when) { synchronized (this) { Message p = mMessages; //如果链表是空的，或者处于队头的消息的时间戳比 msg 要大，则将 msg 作为链表头部 if (p == null || when == 0 || when \u0026lt; p.when) { msg.next = p; mMessages = msg; } else { Message prev; //从链表头向链表尾遍历，寻找链表中第一条时间戳比 msg 大的消息，将 msg 插到该消息的前面 for (; ; ) { prev = p; p = p.next; if (p == null || when \u0026lt; p.when) { break; } } msg.next = p; prev.next = msg; } } } } 此外，MessageQueue 要有一个可以获取队头消息的方法才行，就叫做next()吧。外部有可能会随时向 MessageQueue 发送 Message，next()方法内部就直接来开启一个无限循环来反复取值吧。如果当前队头的消息可以直接处理的话（即消息的时间戳小于或等于当前时间），那么就直接返回队头消息。而如果队头消息的时间戳比当前时间还要大（即队头消息是一个延时消息），那么就计算当前时间和队头消息的时间戳的差值，计算 next() 方法需要阻塞等待的时间，调用 nativePollOnce()方法来等待一段时间后再继续循环遍历\n//用来标记 next() 方法是否正处于阻塞等待的状态 private boolean mBlocked = false; Message next() { int nextPollTimeoutMillis = 0; for (; ; ) { nativePollOnce(nextPollTimeoutMillis); synchronized (this) { //当前时间 final long now = SystemClock.uptimeMillis(); Message msg = mMessages; if (msg != null) { if (now \u0026lt; msg.when) { //如果当前时间还未到达消息的的处理时间，那么就计算还需要等待的时间 nextPollTimeoutMillis = (int) Math.min(msg.when - now, Integer.MAX_VALUE); } else { //可以处理队头的消息了，第二条消息成为队头 mMessages = msg.next; msg.next = null; mBlocked = false; return msg; } } else { // No more messages. nextPollTimeoutMillis = -1; } mBlocked = true; } } } //将 next 方法的调用线程休眠指定时间 private void nativePollOnce(long nextPollTimeoutMillis) { } 此时就需要考虑到一种情形：当 next()还处于阻塞状态的时候，外部向消息队列插入了一个可以立即处理或者是阻塞等待时间比较短的 Message。此时就需要唤醒休眠的线程，因此 enqueueMessage还需要再改动下，增加判断是否需要唤醒next()方法的逻辑\nvoid enqueueMessage(Message msg, long when) { synchronized (this) { //用于标记是否需要唤醒 next 方法 boolean needWake = false; Message p = mMessages; //如果链表是空的，或者处于队头的消息的时间戳比 msg 要大，则将 msg 作为链表头部 if (p == null || when == 0 || when \u0026lt; p.when) { msg.next = p; mMessages = msg; //需要唤醒 needWake = mBlocked; } else { Message prev; //从链表头向链表尾遍历，寻找链表中第一条时间戳比 msg 大的消息，将 msg 插到该消息的前面 for (; ; ) { prev = p; p = p.next; if (p == null || when \u0026lt; p.when) { break; } } msg.next = p; prev.next = msg; } if (needWake) { //唤醒 next() 方法 nativeWake(); } } } //唤醒 next() 方法 private void nativeWake() { } 3、Handler 既然存放消息的地方已经确定就是 MessageQueue 了，那么自然就还需要有一个类可以用来向 MessageQueue 发送消息了，就叫它 Handler 吧。Handler 可以实现哪些功能呢？\n希望除了可以发送 Message 类型的消息外还可以发送 Runnable 类型的消息。这个简单，Handler 内部将 Runnable 包装为 Message 即可 希望可以发送延时消息，以此来执行延时任务。这个也简单，用 Message 内部的 when 字段来标识希望任务执行时的时间戳即可 希望可以实现线程切换，即从子线程发送的 Message 可以在主线程被执行，反过来也一样。这个也不难，子线程可以向一个特定的 mainMessageQueue 发送消息，然后让主线程负责循环从该队列中取消息并执行即可，这样不就实现了线程切换了吗？ 所以说，Message 的定义和发送是由 Handler 来完成的，但 Message 的分发则可以交由其他线程来完成\n根据以上需求：Runnable 要能够包装为 Message 类型，Message 的处理逻辑要交由 Handler 来定义，所以 Message 就还需要增加两个字段才行\n/** * @Author: leavesCZY * @Desc: * @Github：https://github.com/leavesCZY */ public final class Message { //唯一标识 public int what; //数据 public Object obj; //时间戳 public long when; //下一个节点 public Message next; //用于将 Runnable 包装为 Message public Runnable callback; //指向 Message 的发送者，同时也是 Message 的最终处理者 public Handler target; } Handler 至少需要包含几个方法：用于发送 Message 和 Runnable 的方法、用来处理消息的 handleMessage 方法、用于分发消息的 dispatchMessage方法\n/** * @Author: leavesCZY * @Desc: * @Github：https://github.com/leavesCZY */ public class Handler { private MessageQueue mQueue; public Handler(MessageQueue mQueue) { this.mQueue = mQueue; } public final void post(Runnable r) { sendMessageDelayed(getPostMessage(r), 0); } public final void postDelayed(Runnable r, long delayMillis) { sendMessageDelayed(getPostMessage(r), delayMillis); } public final void sendMessage(Message r) { sendMessageDelayed(r, 0); } public final void sendMessageDelayed(Message msg, long delayMillis) { if (delayMillis \u0026lt; 0) { delayMillis = 0; } sendMessageAtTime(msg, SystemClock.uptimeMillis() + delayMillis); } public void sendMessageAtTime(Message msg, long uptimeMillis) { msg.target = this; mQueue.enqueueMessage(msg, uptimeMillis); } private static Message getPostMessage(Runnable r) { Message m = new Message(); m.callback = r; return m; } //由外部来重写该方法，以此来消费 Message public void handleMessage(Message msg) { } //用于分发消息 public void dispatchMessage(Message msg) { if (msg.callback != null) { msg.callback.run(); } else { handleMessage(msg); } } } 之后，子线程就可以像这样来使用 Handler 了：将子线程持有的 Handler 对象和主线程关联的 mainMessageQueue 绑定在一起，主线程负责循环从 mainMessageQueue 取出 Message 后再来调用 Handler 的 dispatchMessage 方法，以此实现线程切换的目的\nHandler handler = new Handler(mainThreadMessageQueue) { @Override public void handleMessage(Message msg) { switch (msg.what) { case 1: { String ob = (String) msg.obj; break; } case 2: { List\u0026lt;String\u0026gt; ob = (List\u0026lt;String\u0026gt;) msg.obj; break; } } } }; Message messageA = new Message(); messageA.what = 1; messageA.obj = \u0026#34;https://github.com/leavesCZY\u0026#34;; Message messageB = new Message(); messageB.what = 2; messageB.obj = new ArrayList\u0026lt;String\u0026gt;(); handler.sendMessage(messageA); handler.sendMessage(messageB); 4、Looper 现在就再来想想怎么让 Handler 拿到和主线程关联的 MessageQueue，以及主线程怎么从 MessageQueue 获取 Message 并回调 Handler。这之间就一定需要一个中转器，就叫它 Looper 吧。Looper 具体需要实现什么功能呢？\n每个 Looper 对象应该都是对应一个独有的 MessageQueue 实例和 Thread 实例，这样子线程和主线程才可以互相发送 Message 交由对方线程处理 Looper 内部需要开启一个无限循环，其关联的线程就负责从 MessageQueue 循环获取 Message 进行处理 因为主线程较为特殊，所以和主线程关联的 Looper 对象要能够被子线程直接获取到，可以考虑将其作为静态变量存着 这样，Looper 的大体框架就出来了。通过 ThreadLocal 来为不同的线程单独维护一个 Looper 实例，每个线程通过 prepare()方法来初始化本线程独有的 Looper 实例 ，再通过 myLooper()方法来获取和当前线程关联的 Looper 对象，和主线程关联的 sMainLooper 作为静态变量存在，方便子线程获取\n/** * @Author: leavesCZY * @Desc: * @Github：https://github.com/leavesCZY */ final class Looper { final MessageQueue mQueue; final Thread mThread; private static Looper sMainLooper; static final ThreadLocal\u0026lt;Looper\u0026gt; sThreadLocal = new ThreadLocal\u0026lt;Looper\u0026gt;(); private Looper() { mQueue = new MessageQueue(); mThread = Thread.currentThread(); } public static void prepare() { if (sThreadLocal.get() != null) { throw new RuntimeException(\u0026#34;Only one Looper may be created per thread\u0026#34;); } sThreadLocal.set(new Looper()); } public static void prepareMainLooper() { prepare(); synchronized (Looper.class) { if (sMainLooper != null) { throw new IllegalStateException(\u0026#34;The main Looper has already been prepared.\u0026#34;); } sMainLooper = myLooper(); } } public static Looper getMainLooper() { synchronized (Looper.class) { return sMainLooper; } } public static Looper myLooper() { return sThreadLocal.get(); } } Looper 还需要有一个用于循环从 MessageQueue 获取消息并处理的方法，就叫它loop()吧。其作用也能简单，就是循环从 MessageQueue 中取出 Message，然后将 Message 再反过来分发给 Handler 即可\npublic static void loop() { final Looper me = myLooper(); if (me == null) { throw new RuntimeException(\u0026#34;No Looper; Looper.prepare() wasn\u0026#39;t called on this thread.\u0026#34;); } final MessageQueue queue = me.mQueue; for (; ; ) { Message msg = queue.next();//可能会阻塞 msg.target.dispatchMessage(msg); } } 这样，主线程就先通过调用prepareMainLooper()来完成 sMainLooper 的初始化，然后调用loop()开始向 mainMessageQueue 循环取值并进行处理，没有消息的话主线程就暂时休眠着。子线程拿到 sMainLooper 后就以此来初始化 Handler，这样子线程向 Handler 发送的消息就都会被存到 mainMessageQueue 中，最终在主线程被消费掉\n5、做一个总结 这样一步步走下来后，读者对于 Message、MessageQueue、Handler、Looper 这四个类的定位就应该都很清晰了吧？不同线程之间就可以依靠拿到对方的 Looper 来实现消息的跨线程处理了\n例如，对于以下代码，即使 Handler 是在 otherThread 中进行初始化，但 handleMessage 方法最终是会在 mainThread 被调用执行的，\nThread mainThread = new Thread() { @Override public void run() { //初始化 mainLooper Looper.prepareMainLooper(); //开启循环 Looper.loop(); } }; Thread otherThread = new Thread() { @Override public void run() { Looper mainLooper = Looper.getMainLooper(); Handler handler = new Handler(mainLooper.mQueue) { @Override public void handleMessage(Message msg) { switch (msg.what) { case 1: { String ob = (String) msg.obj; break; } case 2: { List\u0026lt;String\u0026gt; ob = (List\u0026lt;String\u0026gt;) msg.obj; break; } } } }; Message messageA = new Message(); messageA.what = 1; messageA.obj = \u0026#34;https://github.com/leavesCZY\u0026#34;; Message messageB = new Message(); messageB.what = 2; messageB.obj = new ArrayList\u0026lt;String\u0026gt;(); handler.sendMessage(messageA); handler.sendMessage(messageB); } }; 再来做个简单的总结：\nMessage：用来表示要执行的任务 Handler：子线程持有的 Handler 如果绑定到的是主线程的 MessageQueue 的话，那么子线程发送的 Message 就可以由主线程来消费，以此来实现线程切换，执行 UI 更新操作等目的 MessageQueue：即消息队列，通过 Handler 发送的消息并非都是立即执行的，需要先按照 Message 的优先级高低（延时时间的长短）保存到 MessageQueue 中，之后再来依次执行 Looper：Looper 用于从 MessageQueue 中循环获取 Message 并将之传递给消息处理者（即消息发送者 Handler 本身）来进行消费，每条 Message 都有个 target 变量用来指向 Handler，以此把 Message 和其处理者关联起来。不同线程之间通过互相拿到对方的 Looper 对象，以此来实现跨线程发送消息 有了以上的认知基础后，下面就来看看实际的源码实现 ~ ~\n二、Handler 源码 1、Handler 如何初始化 Handler 的构造函数一共有七个，除去两个已经废弃的和三个隐藏的，实际上开发者可以使用的只有两个。而不管是使用哪个构造函数，最终的目的都是为了完成 mLooper、mQueue、mCallback、mAsynchronous 这四个常量的初始化，同时也可以看出来 MessageQueue 是由 Looper 来完成初始化的，而且 Handler 对于 Looper 和 MessageQueue 都是一对一的关系，一旦初始化后就不可改变\n大部分开发者使用的应该都是 Handler 的无参构造函数，而在 Android 11 中 Handler 的无参构造函数已经被标记为废弃的了。Google 官方更推荐的做法是通过显式传入 Looper 对象来完成初始化，而非隐式使用当前线程关联的 Looper\nHandler 对于 Looper 和 MessageQueue 都是一对一的关系，但是 Looper 和 MessageQueue 对于 Handler 可以是一对多的关系，这个后面会讲到\n@UnsupportedAppUsage final Looper mLooper; final MessageQueue mQueue; @UnsupportedAppUsage final Callback mCallback; final boolean mAsynchronous; //省略其它构造函数 /** * @hide */ public Handler(@Nullable Callback callback, boolean async) { if (FIND_POTENTIAL_LEAKS) { final Class\u0026lt;? extends Handler\u0026gt; klass = getClass(); if ((klass.isAnonymousClass() || klass.isMemberClass() || klass.isLocalClass()) \u0026amp;\u0026amp; (klass.getModifiers() \u0026amp; Modifier.STATIC) == 0) { Log.w(TAG, \u0026#34;The following Handler class should be static or leaks might occur: \u0026#34; + klass.getCanonicalName()); } } mLooper = Looper.myLooper(); if (mLooper == null) { throw new RuntimeException( \u0026#34;Can\u0026#39;t create handler inside thread \u0026#34; + Thread.currentThread() + \u0026#34; that has not called Looper.prepare()\u0026#34;); } mQueue = mLooper.mQueue; mCallback = callback; mAsynchronous = async; } 2、Looper 如何初始化 在初始化 Handler 时，如果外部调用的构造函数没有传入 Looper，那就会调用Looper.myLooper()来获取和当前线程关联的 Looper 对象，再从 Looper 中取 MessageQueue。如果获取到的 Looper 对象为 null 就会抛出异常。根据异常信息 Can't create handler inside thread that has not called Looper.prepare() 可以看出来，在初始化 Handler 之前需要先调用 Looper.prepare()完成 Looper 的初始化\n走进 Looper 类中可以看到，myLooper()方法是 Looper 类的静态方法，其只是单纯地从 sThreadLocal 变量中取值并返回而已。sThreadLocal 又是通过 prepare(boolean) 方法来进行初始化赋值的，且只能赋值一次，重复调用将抛出异常\n我们知道，ThreadLocal 的特性就是可以为不同的线程分别维护单独的一个变量实例，所以，不同的线程就会分别对应着不同的 Looper 对象，是一一对应的关系\n@UnsupportedAppUsage static final ThreadLocal\u0026lt;Looper\u0026gt; sThreadLocal = new ThreadLocal\u0026lt;Looper\u0026gt;(); /** * Return the Looper object associated with the current thread. Returns * null if the calling thread is not associated with a Looper. */ public static @Nullable Looper myLooper() { return sThreadLocal.get(); } /** Initialize the current thread as a looper. * This gives you a chance to create handlers that then reference * this looper, before actually starting the loop. Be sure to call * {@link #loop()} after calling this method, and end it by calling * {@link #quit()}. */ public static void prepare() { prepare(true); } private static void prepare(boolean quitAllowed) { if (sThreadLocal.get() != null) { //只允许赋值一次 //如果重复赋值则抛出异常 throw new RuntimeException(\u0026#34;Only one Looper may be created per thread\u0026#34;); } sThreadLocal.set(new Looper(quitAllowed)); } 此外，Looper 类的构造函数也是私有的，会初始化两个常量值：mQueue 和 mThread，这说明了 Looper 对于 MessageQueue 和 Thread 都是一一对应的关系，关联之后不能改变\n@UnsupportedAppUsage final MessageQueue mQueue; final Thread mThread; private Looper(boolean quitAllowed) { mQueue = new MessageQueue(quitAllowed); mThread = Thread.currentThread(); } 在日常开发中，我们在通过 Handler 来执行 UI 刷新操作时，经常使用的是 Handler 的无参构造函数，那么此时肯定就是使用了和主线程关联的 Looper 对象，对应 Looper 类中的静态变量 sMainLooper\n@UnsupportedAppUsage private static Looper sMainLooper; // guarded by Looper.class //被标记为废弃的原因是因为 sMainLooper 会交由 Android 系统自动来完成初始化，外部不应该主动来初始化 @Deprecated public static void prepareMainLooper() { prepare(false); synchronized (Looper.class) { if (sMainLooper != null) { throw new IllegalStateException(\u0026#34;The main Looper has already been prepared.\u0026#34;); } sMainLooper = myLooper(); } } /** * Returns the application\u0026#39;s main looper, which lives in the main thread of the application. */ public static Looper getMainLooper() { synchronized (Looper.class) { return sMainLooper; } } prepareMainLooper()就用于为主线程初始化 Looper 对象，该方法又是由 ActivityThread 类的 main() 方法来调用的。该 main() 方法即 Java 程序的运行起始点，所以当应用启动时系统就自动为我们在主线程做好了 mainLooper 的初始化，而且已经调用了Looper.loop()方法开启了消息的循环处理，应用在使用过程中的各种交互逻辑（例如：屏幕的触摸事件、列表的滑动等）就都是在这个循环里完成分发的\n正是因为 Android 系统已经自动完成了主线程 Looper 的初始化，所以我们在主线程中才可以直接使用 Handler 的无参构造函数来完成 UI 相关事件的处理\npublic final class ActivityThread extends ClientTransactionHandler { public static void main(String[] args) { ··· Looper.prepareMainLooper(); ··· Looper.loop(); throw new RuntimeException(\u0026#34;Main thread loop unexpectedly exited\u0026#34;); } } 3、Handler 发送消息 Handler 用于发送消息的方法非常多，有十几个，其中大部分最终调用到的都是 sendMessageAtTime() 方法。uptimeMillis 即 Message 具体要执行的时间戳，如果该时间戳比当前时间大，那么就意味着要执行的是延迟任务。如果为 mQueue 为 null，就会打印异常信息并直接返回，因为 Message 是需要交由 MessageQueue 来处理的\npublic boolean sendMessageAtTime(@NonNull Message msg, long uptimeMillis) { MessageQueue queue = mQueue; if (queue == null) { RuntimeException e = new RuntimeException( this + \u0026#34; sendMessageAtTime() called with no mQueue\u0026#34;); Log.w(\u0026#34;Looper\u0026#34;, e.getMessage(), e); return false; } return enqueueMessage(queue, msg, uptimeMillis); } 需要注意 msg.target = this 这句代码，target 指向了发送消息的主体，即 Handler 对象本身，即由 Handler 对象发给 MessageQueue 的消息最后还是要交由 Handler 对象本身来处理\nprivate boolean enqueueMessage(@NonNull MessageQueue queue, @NonNull Message msg, long uptimeMillis) { msg.target = this; msg.workSourceUid = ThreadLocalWorkSource.getUid(); if (mAsynchronous) { msg.setAsynchronous(true); } //将消息交由 MessageQueue 处理 return queue.enqueueMessage(msg, uptimeMillis); } 4、MessageQueue MessageQueue 通过 enqueueMessage 方法来接收消息\n因为存在多个线程同时往一个 MessageQueue 发送消息的可能，所以 enqueueMessage 内部肯定需要进行线程同步 可以看出 MessageQueue 内部是以链表的结构来存储 Message 的（Message.next），根据 Message 的时间戳大小来决定其在消息队列中的位置 mMessages 代表的是消息队列中的第一条消息。如果 mMessages 为空（消息队列是空的），或者 mMessages 的时间戳要比新消息的时间戳大，则将新消息插入到消息队列的头部；如果 mMessages 不为空，则寻找消息列队中第一条触发时间比新消息晚的非空消息，将新消息插到该消息的前面 到此，一个按照时间戳大小进行排序的消息队列就完成了，后边要做的就是从消息队列中依次取出消息进行处理了\nboolean enqueueMessage(Message msg, long when) { if (msg.target == null) { throw new IllegalArgumentException(\u0026#34;Message must have a target.\u0026#34;); } synchronized (this) { ··· msg.markInUse(); msg.when = when; Message p = mMessages; //用于标记是否需要唤醒线程 boolean needWake; //如果链表是空的，或者处于队头的消息的时间戳比 msg 要大，则将 msg 作为链表头部 //when == 0 说明 Handler 调用的是 sendMessageAtFrontOfQueue 方法，直接将 msg 插到队列头部 if (p == null || when == 0 || when \u0026lt; p.when) { // New head, wake up the event queue if blocked. msg.next = p; mMessages = msg; needWake = mBlocked; } else { //如果当前线程处于休眠状态 + 队头消息是屏障消息 + msg 是异步消息 //那么就需要唤醒线程 needWake = mBlocked \u0026amp;\u0026amp; p.target == null \u0026amp;\u0026amp; msg.isAsynchronous(); Message prev; //从链表头向链表尾遍历，寻找链表中第一条时间戳比 msg 大的消息，将 msg 插到该消息的前面 for (;;) { prev = p; p = p.next; if (p == null || when \u0026lt; p.when) { break; } if (needWake \u0026amp;\u0026amp; p.isAsynchronous()) { //如果在 msg 之前队列中还有异步消息那么就不需要主动唤醒 //因为已经设定唤醒时间了 needWake = false; } } msg.next = p; // invariant: p == prev.next prev.next = msg; } // We can assume mPtr != 0 because mQuitting is false. if (needWake) { nativeWake(mPtr); } } return true; } 知道了 Message 是如何保存的了，再来看下 MessageQueue 是如何取出 Message 并回调给 Handler 的。在 MessageQueue 中读取消息的操作对应的是next() 方法。next() 方法内部开启了一个无限循环，如果消息队列中没有消息或者是队头消息还没到可以处理的时间，该方法就会导致 Loop 线程休眠挂起，直到条件满足后再重新遍历消息\n@UnsupportedAppUsage Message next() { ··· for (;;) { if (nextPollTimeoutMillis != 0) { Binder.flushPendingCommands(); } //将 Loop 线程休眠挂起 nativePollOnce(ptr, nextPollTimeoutMillis); synchronized (this) { // Try to retrieve the next message. Return if found. final long now = SystemClock.uptimeMillis(); Message prevMsg = null; Message msg = mMessages; if (msg != null \u0026amp;\u0026amp; msg.target == null) { // Stalled by a barrier. Find the next asynchronous message in the queue. do { prevMsg = msg; msg = msg.next; } while (msg != null \u0026amp;\u0026amp; !msg.isAsynchronous()); } if (msg != null) { if (now \u0026lt; msg.when) { //队头消息还未到处理时间，计算需要等待的时间 // Next message is not ready. Set a timeout to wake up when it is ready. nextPollTimeoutMillis = (int) Math.min(msg.when - now, Integer.MAX_VALUE); } else { // Got a message. mBlocked = false; if (prevMsg != null) { prevMsg.next = msg.next; } else { mMessages = msg.next; } msg.next = null; if (DEBUG) Log.v(TAG, \u0026#34;Returning message: \u0026#34; + msg); msg.markInUse(); return msg; } } else { // No more messages. nextPollTimeoutMillis = -1; } ··· } ··· } ··· } } next() 方法又是通过 Looper 类的 loop() 方法来循环调用的，loop() 方法内也是一个无限循环，唯一跳出循环的条件就是 queue.next()方法返回为 null。因为 next() 方法可能会触发阻塞操作，所以没有消息需要处理时也会导致 loop() 方法被阻塞着，而当 MessageQueue 有了新的消息，Looper 就会及时地处理这条消息并调用 msg.target.dispatchMessage(msg) 方法将消息回传给 Handler 进行处理\n/** * Run the message queue in this thread. Be sure to call * {@link #quit()} to end the loop. */ public static void loop() { final Looper me = myLooper(); if (me == null) { throw new RuntimeException(\u0026#34;No Looper; Looper.prepare() wasn\u0026#39;t called on this thread.\u0026#34;); } ···\tfor (;;) { Message msg = queue.next(); // might block if (msg == null) { // No message indicates that the message queue is quitting. return; } ··· msg.target.dispatchMessage(msg); ··· } } Handler 的dispatchMessage方法就是在向外部分发处理 Message 了，Message 最终是按如下顺序进行处理的：\n如果该 Message 是通过 post(Runnable)等方法进行发送的，那么就直接回调该 Runnable 对象 如果在初始化 Handler 时传入了 Callback 对象，则优先交由其处理，如果 Callback 的 handleMessage 方法返回了 true，则结束流程 调用 Handler 的handleMessage 方法来处理消息，外部通过重写该方法来定义业务逻辑 public void dispatchMessage(@NonNull Message msg) { if (msg.callback != null) { handleCallback(msg); } else { if (mCallback != null) { if (mCallback.handleMessage(msg)) { return; } } handleMessage(msg); } } private static void handleCallback(Message message) { message.callback.run(); } public void handleMessage(@NonNull Message msg) { } 至此，Message 的整个分发流程就结束了\n5、消息屏障 Android 系统为了保证某些高优先级的 Message（异步消息） 能够被尽快执行，采用了一种消息屏障（Barrier）机制。其大致流程是：先发送一个屏障消息到 MessageQueue 中，当 MessageQueue 遍历到该屏障消息时，就会判断当前队列中是否存在异步消息，有的话则先跳过同步消息（开发者主动发送的都属于同步消息），优先执行异步消息。这种机制就会使得在异步消息被执行完之前，同步消息都不会得到处理\nHandler 的构造函数中的async参数就用于控制发送的 Message 是否属于异步消息\npublic class Handler { final boolean mAsynchronous; public Handler(@NonNull Looper looper, @Nullable Callback callback, boolean async) { ··· mAsynchronous = async; } private boolean enqueueMessage(@NonNull MessageQueue queue, @NonNull Message msg, long uptimeMillis) { msg.target = this; msg.workSourceUid = ThreadLocalWorkSource.getUid(); if (mAsynchronous) { //设为异步消息 msg.setAsynchronous(true); } return queue.enqueueMessage(msg, uptimeMillis); } } MessageQueue 在获取队头消息的时候，如果判断到队头消息的 target 对象为 null 的话，就知道该 Message 属于屏障消息，那么就会再向后遍历找到第一条异步消息优先进行处理，每次调用 next() 方法时都会重复此步骤知道所有异步消息均被处理完\n@UnsupportedAppUsage Message next() { ··· for (;;) { if (nextPollTimeoutMillis != 0) { Binder.flushPendingCommands(); } nativePollOnce(ptr, nextPollTimeoutMillis); synchronized (this) { // Try to retrieve the next message. Return if found. final long now = SystemClock.uptimeMillis(); Message prevMsg = null; Message msg = mMessages; if (msg != null \u0026amp;\u0026amp; msg.target == null) { //target 为 null 即属于屏障消息 // Stalled by a barrier. Find the next asynchronous message in the queue. //循环遍历，找到屏障消息后面的第一条异步消息进行处理 do { prevMsg = msg; msg = msg.next; } while (msg != null \u0026amp;\u0026amp; !msg.isAsynchronous()); } ··· } ··· } } 我们可以通过调用 Message 对象的 setAsynchronous(boolean async) 方法来主动发送异步消息。而如果想要主动发送屏障消息的话，就需要通过反射来调用 MessageQueue 的 postSyncBarrier() 方法了，该方法被系统隐藏起来了\n屏障消息的作用就是可以确保高优先级的异步消息可以优先被处理，ViewRootImpl 就通过该机制来使得 View 的绘制流程可以优先被处理\n6、退出 Looper 循环 Looper 类本身做了方法限制，除了主线程外，子线程关联的 MessageQueue 都支持退出 Loop 循环，即 quitAllowed 只有主线程才能是 false\npublic final class Looper { private Looper(boolean quitAllowed) { mQueue = new MessageQueue(quitAllowed); mThread = Thread.currentThread(); } public static void prepare() { prepare(true); } private static void prepare(boolean quitAllowed) { if (sThreadLocal.get() != null) { throw new RuntimeException(\u0026#34;Only one Looper may be created per thread\u0026#34;); } sThreadLocal.set(new Looper(quitAllowed)); } } MessageQueue 支持两种方式来退出 Loop：\nsafe 为 true，只移除所有尚未执行的消息，不移除时间戳等于当前时间的消息 safe 为 false，移除所有消息 void quit(boolean safe) { if (!mQuitAllowed) { //MessageQueue 设置了不允许退出循环，直接抛出异常 throw new IllegalStateException(\u0026#34;Main thread not allowed to quit.\u0026#34;); } synchronized (this) { if (mQuitting) { //避免重复调用 return; } mQuitting = true; if (safe) { //只移除所有尚未执行的消息，不移除时间戳等于当前时间的消息 removeAllFutureMessagesLocked(); } else { //移除所有消息 removeAllMessagesLocked(); } // We can assume mPtr != 0 because mQuitting was previously false. nativeWake(mPtr); } } 7、IdleHandler IdleHandler 是 MessageQueue 的一个内部接口，可以用于在 Loop 线程处于空闲状态的时候执行一些优先级不高的操作，通过 MessageQueue 的 addIdleHandler 方法来提交要执行的操作\npublic static interface IdleHandler { boolean queueIdle(); } private final ArrayList\u0026lt;IdleHandler\u0026gt; mIdleHandlers = new ArrayList\u0026lt;IdleHandler\u0026gt;(); public void addIdleHandler(@NonNull IdleHandler handler) { if (handler == null) { throw new NullPointerException(\u0026#34;Can\u0026#39;t add a null IdleHandler\u0026#34;); } synchronized (this) { mIdleHandlers.add(handler); } } public void removeIdleHandler(@NonNull IdleHandler handler) { synchronized (this) { mIdleHandlers.remove(handler); } } MessageQueue 在执行 next() 方法时，如果发现当前队列是空的或者队头消息需要延迟处理的话，那么就会去尝试遍历 mIdleHandlers来依次执行 IdleHandler\n@UnsupportedAppUsage Message next() { ··· int pendingIdleHandlerCount = -1; // -1 only during first iteration int nextPollTimeoutMillis = 0; for (;;) { ··· synchronized (this) { ··· //如果队头消息 mMessages 为 null 或者 mMessages 需要延迟处理 //那么就来执行 IdleHandler if (pendingIdleHandlerCount \u0026lt; 0 \u0026amp;\u0026amp; (mMessages == null || now \u0026lt; mMessages.when)) { pendingIdleHandlerCount = mIdleHandlers.size(); } if (pendingIdleHandlerCount \u0026lt;= 0) { // No idle handlers to run. Loop and wait some more. mBlocked = true; continue; } if (mPendingIdleHandlers == null) { mPendingIdleHandlers = new IdleHandler[Math.max(pendingIdleHandlerCount, 4)]; } mPendingIdleHandlers = mIdleHandlers.toArray(mPendingIdleHandlers); } for (int i = 0; i \u0026lt; pendingIdleHandlerCount; i++) { final IdleHandler idler = mPendingIdleHandlers[i]; mPendingIdleHandlers[i] = null; // release the reference to the handler boolean keep = false; try { //执行 IdleHandler //如果返回 false 的话说明之后不再需要执行，那就将其移除 keep = idler.queueIdle(); } catch (Throwable t) { Log.wtf(TAG, \u0026#34;IdleHandler threw exception\u0026#34;, t); } if (!keep) { synchronized (this) { mIdleHandlers.remove(idler); } } } ··· } } 例如，ActivityThread 就向主线程 MessageQueue 添加了一个 GcIdler，用于在主线程空闲时尝试去执行 GC 操作\npublic final class ActivityThread extends ClientTransactionHandler { @UnsupportedAppUsage void scheduleGcIdler() { if (!mGcIdlerScheduled) { mGcIdlerScheduled = true; //添加 IdleHandler Looper.myQueue().addIdleHandler(mGcIdler); } mH.removeMessages(H.GC_WHEN_IDLE); } final class GcIdler implements MessageQueue.IdleHandler { @Override public final boolean queueIdle() { //尝试 GC doGcIfNeeded(); purgePendingResources(); return false; } } } 8、做一个总结 再来总结下以上的所有内容\n每个 Handler 都会和一个 Looper 实例关联在一起，可以在初始化 Handler 时通过构造函数主动传入实例，否则就会默认使用和当前线程关联的 Looper 对象 每个 Looper 都会和一个 MessageQueue 实例关联在一起，每个线程都需要通过调用 Looper.prepare()方法来初始化本线程独有的 Looper 实例，并通过调用Looper.loop()方法来使得本线程循环向 MessageQueue 取出消息并执行。Android 系统默认会为每个应用初始化和主线程关联的 Looper 对象，并且默认就开启了 loop 循环来处理主线程消息 MessageQueue 按照链接结构来保存 Message，执行时间早（即时间戳小）的 Message 会排在链表的头部，Looper 会循环从链表中取出 Message 并回调给 Handler，取值的过程可能会包含阻塞操作 Message、Handler、Looper、MessageQueue 这四者就构成了一个生产者和消费者模式。Message 相当于产品，MessageQueue 相当于传输管道，Handler 相当于生产者，Looper 相当于消费者 Handler 对于 Looper、Handler 对于 MessageQueue、Looper 对于 MessageQueue、Looper 对于 Thread ，这几个之间都是一一对应的关系，在关联后无法更改，但 Looper 对于 Handler、MessageQueue 对于 Handler 可以是一对多的关系 Handler 能用于更新 UI 包含了一个隐性的前提条件：Handler 与主线程 Looper 关联在了一起。在主线程中初始化的 Handler 会默认与主线程 Looper 关联在一起，所以其 handleMessage(Message msg) 方法就会由主线程来调用。在子线程初始化的 Handler 如果也想执行 UI 更新操作的话，则需要主动获取 mainLooper 来初始化 Handler 对于我们自己在子线程中创建的 Looper，当不再需要的时候我们应该主动退出循环，否则子线程将一直无法得到释放。对于主线程 Loop 我们则不应该去主动退出，否则将导致应用崩溃 我们可以通过向 MessageQueue 添加 IdleHandler 的方式，来实现在 Loop 线程处于空闲状态的时候执行一些优先级不高的任务。例如，假设我们有个需求是希望当主线程完成界面绘制等事件后再执行一些 UI 操作，那么就可以通过 IdleHandler 来实现，这可以避免拖慢用户看到首屏页面的速度 三、Handler 在系统中的应用 1、HandlerThread HandlerThread 是 Android SDK 中和 Handler 在同个包下的一个类，从其名字就可以看出来它是一个线程，而且使用到了 Handler\n其用法类似于以下代码。通过 HandlerThread 内部的 Looper 对象来初始化 Handler，同时在 Handler 中声明需要执行的耗时任务，主线程通过向 Handler 发送消息来触发 HandlerThread 去执行耗时任务\nclass MainActivity : AppCompatActivity() { private val handlerThread = HandlerThread(\u0026#34;I am HandlerThread\u0026#34;) private val handler by lazy { object : Handler(handlerThread.looper) { override fun handleMessage(msg: Message) { Thread.sleep(2000) Log.e(\u0026#34;MainActivity\u0026#34;, \u0026#34;这里是子线程，可以用来执行耗时任务：\u0026#34; + Thread.currentThread().name) } } } override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) setContentView(R.layout.activity_main) btn_test.setOnClickListener { handler.sendEmptyMessage(1) } handlerThread.start() } } HandlerThread 的源码还是挺简单的，只有一百多行\nHandlerThread 是 Thread 的子类，其作用就是为了用来执行耗时任务，其 run()方法会自动为自己创建一个 Looper 对象并保存到 mLooper，之后就主动开启消息循环，这样 HandlerThread 就会来循环处理 Message 了\npublic class HandlerThread extends Thread { //线程优先级 int mPriority; //线程ID int mTid = -1; //当前线程持有的 Looper 对象 Looper mLooper; private @Nullable Handler mHandler; public HandlerThread(String name) { super(name); mPriority = Process.THREAD_PRIORITY_DEFAULT; } public HandlerThread(String name, int priority) { super(name); mPriority = priority; } @Override public void run() { mTid = Process.myTid(); //触发当前线程创建 Looper 对象 Looper.prepare(); synchronized (this) { //获取 Looper 对象 mLooper = Looper.myLooper(); //唤醒所有处于等待状态的线程 notifyAll(); } //设置线程优先级 Process.setThreadPriority(mPriority); onLooperPrepared(); //开启消息循环 Looper.loop(); mTid = -1; } } 此外，HandlerThread 还包含一个getLooper()方法用于获取 Looper。当我们在外部调用handlerThread.start()启动线程后，由于其run()方法的执行时机依然是不确定的，所以 getLooper()方法就必须等到 Looper 初始化完毕后才能返回，否则就会由于wait()方法而一直阻塞等待。当run()方法初始化 Looper 完成后，就会调用notifyAll()来唤醒所有处于等待状态的线程。所以外部在使用 HandlerThread 前就记得必须先调用 start() 方法来启动 HandlerThread\n//获取与 HandlerThread 关联的 Looper 对象 //因为 getLooper() 可能先于 run() 被执行 //所以当 mLooper 为 null 时调用者线程就需要阻塞等待 Looper 对象创建完毕 public Looper getLooper() { if (!isAlive()) { return null; } // If the thread has been started, wait until the looper has been created. synchronized (this) { while (isAlive() \u0026amp;\u0026amp; mLooper == null) { try { wait(); } catch (InterruptedException e) { } } } return mLooper; } HandlerThread 起到的作用就是方便了主线程和子线程之间的交互，主线程可以直接通过 Handler 来声明耗时任务并交由子线程来执行。使用 HandlerThread 也方便在多个线程间共享，主线程和其它子线程都可以向 HandlerThread 下发任务，且 HandlerThread 可以保证多个任务执行时的有序性\n2、IntentService IntentService 是系统提供的 Service 子类，用于在后台串行执行耗时任务，在处理完所有任务后会自动停止，不必来手动调用 stopSelf() 方法。而且由于IntentService 是四大组件之一，拥有较高的优先级，不易被系统杀死，因此适合用于执行一些高优先级的异步任务\nGoogle 官方以前也推荐开发者使用 IntentService，但是在 Android 11 中已经被标记为废弃状态了，但这也不妨碍我们来了解下其实现原理\nIntentService 内部依靠 HandlerThread 来实现，其 onCreate()方法会创建一个 HandlerThread，拿到 Looper 对象来初始化 ServiceHandler。ServiceHandler 会将其接受到的每个 Message 都转交由抽象方法 onHandleIntent来处理，子类就通过实现该方法来声明耗时任务\npublic abstract class IntentService extends Service { private volatile Looper mServiceLooper; @UnsupportedAppUsage private volatile ServiceHandler mServiceHandler; private final class ServiceHandler extends Handler { public ServiceHandler(Looper looper) { super(looper); } @Override public void handleMessage(Message msg) { onHandleIntent((Intent)msg.obj); stopSelf(msg.arg1); } } @Override public void onCreate() { super.onCreate(); HandlerThread thread = new HandlerThread(\u0026#34;IntentService[\u0026#34; + mName + \u0026#34;]\u0026#34;); //触发 HandlerThread 创建 Looper 对象 thread.start(); //获取 Looper 对象，构建可以向 HandlerThread 发送 Message 的 Handler mServiceLooper = thread.getLooper(); mServiceHandler = new ServiceHandler(mServiceLooper); } @WorkerThread protected abstract void onHandleIntent(@Nullable Intent intent); } 每次 start IntentService 时，onStart()方法就会被调用，将 intent 和 startId 包装为一个 Message 对象后发送给mServiceHandler。需要特别注意的是 startId 这个参数，它用于唯一标识每次对 IntentService 发起的任务请求，每次回调 onStart() 方法时，startId 的值都是自动递增的。IntentService 不应该在处理完一个 Message 之后就立即停止 IntentService，因为此时 MessageQueue 中可能还有待处理的任务还未取出来，所以如果当调用 stopSelf(int)方法时传入的参数不等于当前最新的 startId 值的话，那么stopSelf(int) 方法就不会导致 IntentService 被停止，从而避免了将尚未处理的 Message 给遗漏了\n@Override public void onStart(@Nullable Intent intent, int startId) { Message msg = mServiceHandler.obtainMessage(); msg.arg1 = startId; msg.obj = intent; mServiceHandler.sendMessage(msg); } @Override public int onStartCommand(@Nullable Intent intent, int flags, int startId) { onStart(intent, startId); return mRedelivery ? START_REDELIVER_INTENT : START_NOT_STICKY; } 四、Handler 在三方库中的应用 1、EventBus EventBus 的 Github 上有这么一句介绍：EventBus is a publish/subscribe event bus for Android and Java. 这说明了 EventBus 是普遍适用于 Java 环境的，只是对 Android 系统做了特殊的平台支持而已。EventBus 的四种消息发送策略包含了ThreadMode.MAIN 用于指定在主线程进行消息回调，其内部就是通过 Handler 来实现的\nEventBusBuilder 会去尝试获取 MainLooper，如果拿得到的话就可以用来初始化 HandlerPoster，从而实现主线程回调\nMainThreadSupport getMainThreadSupport() { if (mainThreadSupport != null) { return mainThreadSupport; } else if (AndroidLogger.isAndroidLogAvailable()) { Object looperOrNull = getAndroidMainLooperOrNull(); return looperOrNull == null ? null : new MainThreadSupport.AndroidHandlerMainThreadSupport((Looper) looperOrNull); } else { return null; } } static Object getAndroidMainLooperOrNull() { try { return Looper.getMainLooper(); } catch (RuntimeException e) { // Not really a functional Android (e.g. \u0026#34;Stub!\u0026#34; maven dependencies) return null; } } public class HandlerPoster extends Handler implements Poster { protected HandlerPoster(EventBus eventBus, Looper looper, int maxMillisInsideHandleMessage) { super(looper); ··· } ··· @Override public void handleMessage(Message msg) { ··· } } 2、Retrofit 和 EventBus 一样，Retrofit 的内部实现也不需要依赖于 Android 平台，而是可以用于任意的 Java 客户端，Retrofit 只是对 Android 平台进行了特殊实现而已\n在构建 Retrofit 对象的时候，我们可以选择传递一个 Platform 对象用于标记调用方所处的平台\npublic static final class Builder { private final Platform platform; Builder(Platform platform) { this.platform = platform; } ··· } Platform 类只具有一个唯一子类，即 Android 类。其主要逻辑就是重写了父类的 defaultCallbackExecutor()方法，通过 Handler 来实现在主线程回调网络请求结果\nstatic final class Android extends Platform { @Override public Executor defaultCallbackExecutor() { return new MainThreadExecutor(); } ··· static final class MainThreadExecutor implements Executor { private final Handler handler = new Handler(Looper.getMainLooper()); @Override public void execute(Runnable r) { handler.post(r); } } } 五、提问环节 1、Handler、Looper、MessageQueue、Thread 的对应关系 首先，Looper 中的 MessageQueue 和 Thread 两个字段都属于常量，且 Looper 实例是存在 ThreadLocal 中，这说明了 Looper 和 MessageQueue 之间是一对一应的关系，且一个 Thread 在其整个生命周期内都只会关联到同一个 Looper 对象和同一个 MessageQueue 对象\npublic final class Looper { final MessageQueue mQueue; final Thread mThread; static final ThreadLocal\u0026lt;Looper\u0026gt; sThreadLocal = new ThreadLocal\u0026lt;Looper\u0026gt;(); private Looper(boolean quitAllowed) { mQueue = new MessageQueue(quitAllowed); mThread = Thread.currentThread(); } } Handler 中的 Looper 和 MessageQueue 两个字段也都属于常量，说明 Handler 对于 Looper 和 MessageQueue 都是一对一的关系。但是 Looper 和 MessageQueue 对于 Handler 却可以是一对多的关系，例如，多个子线程内声明的 Handler 都可以关联到 mainLooper\npublic class Handler { @UnsupportedAppUsage final Looper mLooper; final MessageQueue mQueue; } 2、Handler 的同步机制 MessageQueue 在保存 Message 的时候，enqueueMessage方法内部已经加上了同步锁，从而避免了多个线程同时发送消息导致竞态问题。此外，next()方法内部也加上了同步锁，所以也保障了 Looper 分发 Message 的有序性。最重要的一点是，Looper 总是由一个特定的线程来执行遍历，所以在消费 Message 的时候也不存在竞态\nboolean enqueueMessage(Message msg, long when) { if (msg.target == null) { throw new IllegalArgumentException(\u0026#34;Message must have a target.\u0026#34;); } synchronized (this) { ··· } return true; } @UnsupportedAppUsage Message next() { ··· for (;;) { if (nextPollTimeoutMillis != 0) { Binder.flushPendingCommands(); } nativePollOnce(ptr, nextPollTimeoutMillis); synchronized (this) { ··· } ··· } } 3、Handler 发送同步消息 如果我们在子线程通过 Handler 向主线程发送了一个消息，希望等到消息执行完毕后子线程才继续运行，这该如何实现？其实像这种涉及到多线程同步等待的问题，往往都是需要依赖于线程休眠+线程唤醒机制来实现的\nHandler 本身就提供了一个runWithScissors方法可以用于实现这种功能，只是被隐藏了，我们无法直接调用到。runWithScissors首先会判断目标线程是否就是当前线程，是的话则直接执行 Runnable，否则就需要使用到 BlockingRunnable\n/** * @hide */ public final boolean runWithScissors(@NonNull Runnable r, long timeout) { if (r == null) { throw new IllegalArgumentException(\u0026#34;runnable must not be null\u0026#34;); } if (timeout \u0026lt; 0) { throw new IllegalArgumentException(\u0026#34;timeout must be non-negative\u0026#34;); } if (Looper.myLooper() == mLooper) { r.run(); return true; } BlockingRunnable br = new BlockingRunnable(r); return br.postAndWait(this, timeout); } BlockingRunnable 的逻辑也很简单，在 Runnable 执行完前会通过调用 wait()方法来使发送者线程转为阻塞等待状态，当任务执行完毕后再通过notifyAll()来唤醒发送者线程，从而实现了在 Runnable 被执行完之前发送者线程都会一直处于等待状态\nprivate static final class BlockingRunnable implements Runnable { private final Runnable mTask; //用于标记 mTask 是否已经执行完毕 private boolean mDone; public BlockingRunnable(Runnable task) { mTask = task; } @Override public void run() { try { mTask.run(); } finally { synchronized (this) { mDone = true; notifyAll(); } } } public boolean postAndWait(Handler handler, long timeout) { if (!handler.post(this)) { return false; } synchronized (this) { if (timeout \u0026gt; 0) { final long expirationTime = SystemClock.uptimeMillis() + timeout; while (!mDone) { long delay = expirationTime - SystemClock.uptimeMillis(); if (delay \u0026lt;= 0) { return false; // timeout } try { //限时等待 wait(delay); } catch (InterruptedException ex) { } } } else { while (!mDone) { try { //无限期等待 wait(); } catch (InterruptedException ex) { } } } } return true; } } 虽然 runWithScissors 方法我们无法直接调用，但是我们也可以依靠这思路自己来实现 BlockingRunnable，折中实现这个功能。但这种方式并不安全，如果 Loop 意外退出循环导致该 Runnable 无法被执行的话，就会导致被暂停的线程一直无法被唤醒，需要谨慎使用\n4、Handler 避免内存泄漏 当退出 Activity 时，如果作为内部类的 Handler 中还保存着待处理的延时消息的话，那么就会导致内存泄漏，可以通过调用Handler.removeCallbacksAndMessages(null)来移除所有待处理的 Message\n该方法会将消息队列中所有 Message.obj 等于 token 的 Message 均给移除掉，如果 token 为 null 的话则会移除所有 Message\npublic final void removeCallbacksAndMessages(@Nullable Object token) { mQueue.removeCallbacksAndMessages(this, token); } 5、Message 如何复用 因为 Android 系统本身就存在很多事件需要交由 Message 来交付给 mainLooper，所以 Message 的创建是很频繁的。为了减少 Message 频繁重复创建的情况，Message 提供了 MessagePool 用于实现 Message 的缓存复用，以此来优化内存使用\n当 Looper 消费了 Message 后会调用recycleUnchecked()方法将 Message 进行回收，在清除了各项资源后会缓存到 sPool 变量上，同时将之前缓存的 Message 置为下一个节点 next，通过这种链表结构来缓存最多 50 个Message。这里使用到的是享元设计模式\nobtain()方法则会判断当前是否有可用的缓存，有的话则将 sPool 从链表中移除后返回，否则就返回一个新的 Message 实例。所以我们在发送消息的时候应该尽量通过调用Message.obtain()或者Handler.obtainMessage()方法来获取 Message 实例\npublic final class Message implements Parcelable { /** @hide */ public static final Object sPoolSync = new Object(); private static Message sPool; private static int sPoolSize = 0; private static final int MAX_POOL_SIZE = 50; public static Message obtain() { synchronized (sPoolSync) { if (sPool != null) { Message m = sPool; sPool = m.next; m.next = null; m.flags = 0; // clear in-use flag sPoolSize--; return m; } } return new Message(); } @UnsupportedAppUsage void recycleUnchecked() { // Mark the message as in use while it remains in the recycled object pool. // Clear out all other details. flags = FLAG_IN_USE; what = 0; arg1 = 0; arg2 = 0; obj = null; replyTo = null; sendingUid = UID_NONE; workSourceUid = UID_NONE; when = 0; target = null; callback = null; data = null; synchronized (sPoolSync) { if (sPoolSize \u0026lt; MAX_POOL_SIZE) { next = sPool; sPool = this; sPoolSize++; } } } } 6、Message 复用机制存在的问题 由于 Message 采用了缓存复用机制，从而导致了一个 Message 失效问题。当 handleMessage 方法被回调后，Message 携带的所有参数都会被清空，而如果外部的 handleMessage方法是使用了异步线程来处理 Message 的话，那么异步线程只会得到一个空白的 Message\nval handler = object : Handler() { override fun handleMessage(msg: Message) { handleMessageAsync(msg) } } fun handleMessageAsync(msg: Message) { thread { //只会得到一个空白的 Message 对象 println(msg.obj) } } 7、Message 如何提高优先级 Handler 包含一个 sendMessageAtFrontOfQueue方法可以用于提高 Message 的处理优先级。该方法为 Message 设定的时间戳是 0，使得 Message 可以直接插入到 MessageQueue 的头部，从而做到优先处理。但官方并不推荐使用这个方法，因为最极端的情况下可能会使得其它 Message 一直得不到处理或者其它意想不到的情况\npublic final boolean sendMessageAtFrontOfQueue(@NonNull Message msg) { MessageQueue queue = mQueue; if (queue == null) { RuntimeException e = new RuntimeException( this + \u0026#34; sendMessageAtTime() called with no mQueue\u0026#34;); Log.w(\u0026#34;Looper\u0026#34;, e.getMessage(), e); return false; } return enqueueMessage(queue, msg, 0); } 8、检测 Looper 分发 Message 的效率 Looper 在进行 Loop 循环时，会通过 Observer 向外回调每个 Message 的回调事件。且如果设定了 slowDispatchThresholdMs 和 slowDeliveryThresholdMs 这两个阈值的话，则会对 Message 的分发时机和分发耗时进行监测，存在异常情况的话就会打印 Log。该机制可以用于实现应用性能监测，发现潜在的 Message 处理异常情况，但可惜监测方法被系统隐藏了\npublic static void loop() { final Looper me = myLooper(); ··· for (;;) { Message msg = queue.next(); // might block ··· //用于向外回调通知 Message 的分发事件 final Observer observer = sObserver; final long traceTag = me.mTraceTag; //如果Looper分发Message的时间晚于预定时间且超出这个阈值，则认为Looper分发过慢 long slowDispatchThresholdMs = me.mSlowDispatchThresholdMs; //如果向外分发出去的Message的处理时间超出这个阈值，则认为外部处理过慢 long slowDeliveryThresholdMs = me.mSlowDeliveryThresholdMs; if (thresholdOverride \u0026gt; 0) { slowDispatchThresholdMs = thresholdOverride; slowDeliveryThresholdMs = thresholdOverride; } final boolean logSlowDelivery = (slowDeliveryThresholdMs \u0026gt; 0) \u0026amp;\u0026amp; (msg.when \u0026gt; 0); final boolean logSlowDispatch = (slowDispatchThresholdMs \u0026gt; 0); final boolean needStartTime = logSlowDelivery || logSlowDispatch; final boolean needEndTime = logSlowDispatch; if (traceTag != 0 \u0026amp;\u0026amp; Trace.isTagEnabled(traceTag)) { Trace.traceBegin(traceTag, msg.target.getTraceName(msg)); } //开始分发 Message 的时间 final long dispatchStart = needStartTime ? SystemClock.uptimeMillis() : 0; //Message 分发结束的时间 final long dispatchEnd; Object token = null; if (observer != null) { //开始分发 Message token = observer.messageDispatchStarting(); } long origWorkSource = ThreadLocalWorkSource.setUid(msg.workSourceUid); try { msg.target.dispatchMessage(msg); if (observer != null) { //完成 Message 的分发，且没有抛出异常 observer.messageDispatched(token, msg); } dispatchEnd = needEndTime ? SystemClock.uptimeMillis() : 0; } catch (Exception exception) { if (observer != null) { //分发 Message 时抛出了异常 observer.dispatchingThrewException(token, msg, exception); } throw exception; } finally { ThreadLocalWorkSource.restore(origWorkSource); if (traceTag != 0) { Trace.traceEnd(traceTag); } } if (logSlowDelivery) { if (slowDeliveryDetected) { if ((dispatchStart - msg.when) \u0026lt;= 10) { //如果 Message 的分发时间晚于预定时间，且间隔超出10毫秒，则认为属于延迟交付 Slog.w(TAG, \u0026#34;Drained\u0026#34;); slowDeliveryDetected = false; } } else { if (showSlowLog(slowDeliveryThresholdMs, msg.when, dispatchStart, \u0026#34;delivery\u0026#34;, msg)) { // Once we write a slow delivery log, suppress until the queue drains. slowDeliveryDetected = true; } } } ··· } } 9、主线程 Looper 在哪里创建 由 ActivityThread 类的 main() 方法来创建。该 main() 方法即 Java 程序的运行起始点，当应用启动时系统就自动为我们在主线程做好了 mainLooper 的初始化，而且已经调用了Looper.loop()方法开启了消息的循环处理，应用在使用过程中的各种交互逻辑（例如：屏幕的触摸事件、列表的滑动等）就都是在这个循环里完成分发的。正是因为 Android 系统已经自动完成了主线程 Looper 的初始化，所以我们在主线程中才可以直接使用 Handler 的无参构造函数来完成 UI 相关事件的处理\npublic final class ActivityThread extends ClientTransactionHandler { public static void main(String[] args) { ··· Looper.prepareMainLooper(); ··· Looper.loop(); throw new RuntimeException(\u0026#34;Main thread loop unexpectedly exited\u0026#34;); } } 10、主线程 Looper 什么时候退出循环 当 ActivityThread 内部的 Handler 收到了 EXIT_APPLICATION 消息后，就会退出 Looper 循环\npublic void handleMessage(Message msg) { switch (msg.what) { case EXIT_APPLICATION: if (mInitialApplication != null) { mInitialApplication.onTerminate(); } Looper.myLooper().quit(); break; } } 11、主线程 Looper.loop() 为什么不会导致 ANR 这个问题在网上很常见，我第一次看到时就觉得这种问题很奇怪，主线程凭啥会 ANR？这个问题感觉本身就是特意为了来误导人\n看以下例子。doSomeThing()方法是放在 for 循环这个死循环的后边，对于该方法来说，主线程的确是被阻塞住了，导致该方法一直无法得到执行。可是对于应用来说，应用在主线程内的所有操作其实都是被放在了 for 循环之内，一直有得到执行，是个死循环也无所谓，所以对于应用来说主线程并没有被阻塞，自然不会导致 ANR。此外，当 MessageQueue 中当前没有消息需要处理时，也会依靠 epoll 机制挂起主线程，避免了其一直占用 CPU 资源\npublic static void main(String[] args) { for (; ; ) { //主线程执行.... } doSomeThing(); } 所以在 ActivityThread 的 main 方法中，在开启了消息循环之后，并没有声明什么有意义的代码。正常来说应用是不会退出 loop 循环的，如果能够跳出循环，也只会导致直接就抛出异常\npublic static void main(String[] args) { ··· Looper.prepareMainLooper(); ··· Looper.loop(); throw new RuntimeException(\u0026#34;Main thread loop unexpectedly exited\u0026#34;); } 所以说，loop 循环本身不会导致 ANR，会出现 ANR 是因为在 loop 循环之内 Message 处理时间过长\n12、子线程一定无法弹 Toast 吗 不一定，只能说是在子线程中无法直接弹出 Toast，但可以实现。因为 Toast 的构造函数中会要求拿到一个 Looper 对象，如果构造参数没有传入不为 null 的 Looper 实例的话，则尝试使用调用者线程关联的 Looper 对象，如果都获取不到的话则会抛出异常\npublic Toast(Context context) { this(context, null); } public Toast(@NonNull Context context, @Nullable Looper looper) { mContext = context; mToken = new Binder(); looper = getLooper(looper); mHandler = new Handler(looper); ··· } private Looper getLooper(@Nullable Looper looper) { if (looper != null) { return looper; } //Looper.myLooper() 为 null 的话就会直接抛出异常 return checkNotNull(Looper.myLooper(), \u0026#34;Can\u0026#39;t toast on a thread that has not called Looper.prepare()\u0026#34;); } 为了在子线程弹 Toast，就需要主动为子线程创建 Looper 对象及开启 loop 循环。但这种方法会导致子线程一直无法退出循环，需要通过Looper.myLooper().quit()来主动退出循环\ninner class TestThread : Thread() { override fun run() { Looper.prepare() Toast.makeText( this@MainActivity, \u0026#34;Hello: \u0026#34; + Thread.currentThread().name, Toast.LENGTH_SHORT ).show() Looper.loop() } } 13、子线程一定无法更新 UI？主线程就一定可以？ 在子线程能够弹出 Toast 就已经说明了子线程也是可以更新 UI 的，Android 系统只是限制了必须在同个线程内进行 ViewRootImpl 的创建和更新这两个操作，而不是要求必须在主线程进行\n如果使用不当的话，即使在主线程更新 UI 也可能会导致应用崩溃。例如，在子线程先通过 show+hide 来触发 ViewRootImpl 的创建，然后在主线程再来尝试显示该 Dialog，此时就会发现程序直接崩溃了\nclass MainActivity : AppCompatActivity() { private lateinit var alertDialog: AlertDialog private val thread = object : Thread(\u0026#34;hello\u0026#34;) { override fun run() { Looper.prepare() Handler().post { alertDialog = AlertDialog.Builder(this@MainActivity).setMessage(Thread.currentThread().name) .create() alertDialog.show() alertDialog.hide() } Looper.loop() } } override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) setContentView(R.layout.activity_main) btn_test.setOnClickListener { alertDialog.show() } thread.start() } } E/AndroidRuntime: FATAL EXCEPTION: main Process: github.leavesc.test, PID: 5243 android.view.ViewRootImpl$CalledFromWrongThreadException: Only the original thread that created a view hierarchy can touch its views. at android.view.ViewRootImpl.checkThread(ViewRootImpl.java:6892) at android.view.ViewRootImpl.requestLayout(ViewRootImpl.java:1048) at android.view.View.requestLayout(View.java:19781) at android.view.View.setFlags(View.java:11478) at android.view.View.setVisibility(View.java:8069) at android.app.Dialog.show(Dialog.java:293) ViewRootImpl 在初始化的时候会将当前线程保存到 mThread，在后续进行 UI 更新的时候就会调用checkThread()方法进行线程检查，如果发现存在多线程调用则直接抛出以上的异常信息\npublic final class ViewRootImpl implements ViewParent, View.AttachInfo.Callbacks, ThreadedRenderer.DrawCallbacks { final Thread mThread; public ViewRootImpl(Context context, Display display, IWindowSession session, boolean useSfChoreographer) { mThread = Thread.currentThread(); ··· } void checkThread() { if (mThread != Thread.currentThread()) { throw new CalledFromWrongThreadException( \u0026#34;Only the original thread that created a view hierarchy can touch its views.\u0026#34;); } } } 14、为什么 UI 体系要采用单线程模型 其实这很好理解，就是为了提高运行效率和降低实现难度。如果允许多线程并发访问 UI 的话，为了避免竞态，很多即使只是小范围的局部刷新操作（例如，TextView.setText）都势必需要加上同步锁，这无疑会加大 UI 刷新操作的“成本”，降低了整个应用的运行效率。而且会导致 Android 的 UI 体系在实现时就被迫需要对多线程环境进行“防御”，即使开发者一直是使用同个线程来更新 UI，这就加大了系统的实现难度\n所以，最为简单高效的方式就是采用单线程模型来访问 UI\n15、如何跨线程下发任务 通常情况下，两个线程之间的通信是比较麻烦的，需要做很多线程同步操作。而依靠 Looper 的特性，我们就可以用比较简单的方式来实现跨线程下发任务\n看以下代码，从 TestThread 运行后弹出的线程名可以知道， Toast 是在 Thread_1 被弹出来的。如果将 Thread_2 想像成主线程的话，那么以下代码就相当于从主线程向子线程下发耗时任务了，这个实现思路就相当于 Android 提供的 HandlerThread 类\ninner class TestThread : Thread(\u0026#34;Thread_1\u0026#34;) { override fun run() { Looper.prepare() val looper = Looper.myLooper() object : Thread(\u0026#34;Thread_2\u0026#34;) { override fun run() { val handler = Handler(looper!!) handler.post { //输出结果是：Thread_1 Toast.makeText( this@MainActivity, Thread.currentThread().name, Toast.LENGTH_SHORT ).show() } } }.start() Looper.loop() } } 16、如何判断当前是不是主线程 通过 Looper 来判断\nif (Looper.myLooper() == Looper.getMainLooper()) { //是主线程 } if (Looper.getMainLooper().isCurrentThread){ //是主线程 } 17、如何全局捕获主线程异常 比较卧槽的一个做法就是通过嵌套 Loop 循环来实现。向主线程 Loop 发送 一个 Runnable，在 Runnable 里死循环执行 Loop 循环，这就会使得主线程消息队列中的所有任务都会被交由该 Runnable 来调用，只要加上 try catch 后就可以捕获主线程的任意异常了，做到主线程永不崩溃\nHandler(Looper.getMainLooper()).post { while (true) { try { Looper.loop() } catch (throwable: Throwable) { throwable.printStackTrace() Log.e(\u0026#34;TAG\u0026#34;, throwable.message ?: \u0026#34;\u0026#34;) } } } ","permalink":"http://localhost:1313/hugo-blog/public/post/kotlin/%E4%B8%80%E6%96%87%E8%AF%BB%E6%87%82-handler-%E6%9C%BA%E5%88%B6/","tags":[],"title":"一文读懂 Handler 机制"},{"categories":[],"content":" 公众号：字节数组 希望对你有所帮助 🤣🤣\nJava 和 Kotlin 的泛型算作是一块挺大的知识难点了，涉及到很多很难理解的概念：泛型型参、泛型实参、类型参数、不变、型变、协变、逆变、内联等等。本篇文章就将 Java 和 Kotlin 结合着一起讲，按照我的个人理解来阐述泛型的各个知识难点，希望对你有所帮助 🤣🤣\n一、泛型类型 泛型允许你定义带类型形参的数据类型，当这种类型的实例被创建出来后，类型形参便被替换为称为类型实参的具体类型。例如，对于 List\u0026lt;T\u0026gt;，List 称为基础类型，T 便是类型型参，T 可以是任意类型，当没有指定 T 的具体类型时，我们只能知道List\u0026lt;T\u0026gt;是一个集合列表，但不知道承载的具体数据类型。而对于 List\u0026lt;String\u0026gt;，当中的 String 便是类型实参，我们可以明白地知道该列表承载的都是字符串，在这里 String 就相当于一个参数传递给了 List，在这语义下 String 也称为类型参数\n此外，在 Kotlin 中我们可以实现实化类型参数，在运行时的内联函数中拿到作为类型实参的具体类型，即可以实现 T::class.java，但在 Java 中却无法实现，因为内联函数是 Kotlin 中的概念，Java 中并不存在\n二、为什么需要泛型 泛型是在 Java 5 版本开始引入的，先通过几个小例子来明白泛型的重要性\n以下代码可以成功编译，但是在运行时却抛出了 ClassCastException。了解 ArrayList 源码的同学就知道其内部是用一个Object[]数组来存储数据的，这使得 ArrayList 能够存储任何类型的对象，所以在没有泛型的年代开发者一不小心就有可能向 ArrayList 存入了非期望值，编译期完全正常，等到在运行时就会抛出类型转换异常了\npublic class GenericTest { public static void main(String[] args) { List stringList = new ArrayList(); addData(stringList); String str = (String) stringList.get(0); } public static void addData(List dataList) { dataList.add(1); } } Exception in thread \u0026#34;main\u0026#34; java.lang.ClassCastException: java.lang.Integer cannot be cast to java.lang.String 而有了泛型后，我们就可以写出更加健壮安全的代码，以下错误就完全可以在编译阶段被发现，且取值的时候也不需要进行类型强转\npublic static void main(String[] args) { List\u0026lt;String\u0026gt; stringList = new ArrayList(); addData(stringList); //报错 String str = stringList.get(0); } public static void addData(List\u0026lt;Integer\u0026gt; dataList) { dataList.add(1); } 此外，利用泛型我们可以写出更加具备通用性的代码。例如，假设我们需要从一个 List 中筛选出大于 0 的全部数字，那我们自然不想为 Integer、Float、Double 等多种类型各写一个筛选方法，此时就可以利用泛型来抽象筛选逻辑\npublic static void main(String[] args) { List\u0026lt;Integer\u0026gt; integerList = new ArrayList\u0026lt;\u0026gt;(); integerList.add(-1); integerList.add(1); integerList.add(2); List\u0026lt;Integer\u0026gt; result1 = filter(integerList); List\u0026lt;Float\u0026gt; floatList = new ArrayList\u0026lt;\u0026gt;(); floatList.add(-1f); floatList.add(1f); floatList.add(2f); List\u0026lt;Float\u0026gt; result2 = filter(floatList); } public static \u0026lt;T extends Number\u0026gt; List\u0026lt;T\u0026gt; filter(List\u0026lt;T\u0026gt; data) { List\u0026lt;T\u0026gt; filterList = new ArrayList\u0026lt;\u0026gt;(); for (T datum : data) { if (datum.doubleValue() \u0026gt; 0) { filterList.add(datum); } } return filterList; } 总的来说，泛型有以下几点优势：\n类型检查，在编译阶段就能发现错误 更加语义化，看到 List\u0026lt;String\u0026gt;我们就知道存储的数据类型是 String 自动类型转换，在取值时无需进行手动类型转换 能够将逻辑抽象出来，使得代码更加具有通用性 三、类型擦除 泛型是在 Java 5 版本开始引入的，所以在 Java 4 中 ArrayList 还不属于泛型类，其内部通过 Object 向上转型和外部强制类型转换来实现数据存储和逻辑复用，此时开发者的项目中已经充斥了大量以下类型的代码：\nList stringList = new ArrayList(); stringList.add(\u0026#34;业志陈\u0026#34;); stringList.add(\u0026#34;https://juejin.cn/user/923245496518439\u0026#34;); String str = (String) stringList.get(0); 而在推出泛型的同时，Java 官方也必须保证二进制的向后兼容性，用 Java 4 编译出的 Class 文件也必须能够在 Java 5 上正常运行，即 Java 5 必须保证以下两种类型的代码能够在 Java 5 上共存且正常运行\nList stringList = new ArrayList(); List\u0026lt;String\u0026gt; stringList = new ArrayList(); 为了实现这一目的，Java 就通过类型擦除这种比较别扭的方式来实现泛型。编译器在编译时会擦除类型实参，在运行时不存在任何类型相关的信息，泛型对于 JVM 来说是透明的，有泛型和没有泛型的代码通过编译器编译后所生成的二进制代码是完全相同的\n例如，分别声明两个泛型类和非泛型类，拿到其 class 文件\npublic class GenericTest { public static class NodeA { private Object obj; public NodeA(Object obj) { this.obj = obj; } } public static class NodeB\u0026lt;T\u0026gt; { private T obj; public NodeB(T obj) { this.obj = obj; } } public static void main(String[] args) { NodeA nodeA = new NodeA(\u0026#34;业志陈\u0026#34;); NodeB\u0026lt;String\u0026gt; nodeB = new NodeB\u0026lt;\u0026gt;(\u0026#34;业志陈\u0026#34;); System.out.println(nodeB.obj); } } 可以看到 NodeA 和 NodeB 两个对象对应的字节码其实是完全一样的，最终都是使用 Object 来承载数据，就好像传递给 NodeB 的类型参数 String 不见了一样，这便是类型擦除\npublic class generic.GenericTest { public generic.GenericTest(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V 4: return public static void main(java.lang.String[]); Code: 0: new #2 // class generic/GenericTest$NodeA 3: dup 4: ldc #3 // String 业志陈 6: invokespecial #4 // Method generic/GenericTest$NodeA.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:(Ljava/lang/Object;)V 9: astore_1 10: new #5 // class generic/GenericTest$NodeB 13: dup 14: ldc #3 // String 业志陈 16: invokespecial #6 // Method generic/GenericTest$NodeB.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:(Ljava/lang/Object;)V 19: astore_2 20: getstatic #7 // Field java/lang/System.out:Ljava/io/PrintStream; 23: aload_2 24: invokestatic #8 // Method generic/GenericTest$NodeB.access$000:(Lgeneric/GenericTest$NodeB;)Ljava/lang/Object; 27: checkcast #9 // class java/lang/String 30: invokevirtual #10 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 33: return } 而如果让 NodeA 直接使用 String 类型，并且为泛型类 NodeB 设定上界约束 String，两者的字节码也会完全一样\npublic class GenericTest { public static class NodeA { private String obj; public NodeA(String obj) { this.obj = obj; } } public static class NodeB\u0026lt;T extends String\u0026gt; { private T obj; public NodeB(T obj) { this.obj = obj; } } public static void main(String[] args) { NodeA nodeA = new NodeA(\u0026#34;业志陈\u0026#34;); NodeB\u0026lt;String\u0026gt; nodeB = new NodeB\u0026lt;\u0026gt;(\u0026#34;业志陈\u0026#34;); System.out.println(nodeB.obj); } } 可以看到 NodeA 和 NodeB 的字节码是完全相同的\npublic class generic.GenericTest { public generic.GenericTest(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:()V 4: return public static void main(java.lang.String[]); Code: 0: new #2 // class generic/GenericTest$NodeA 3: dup 4: ldc #3 // String 业志陈 6: invokespecial #4 // Method generic/GenericTest$NodeA.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:(Ljava/lang/String;)V 9: astore_1 10: new #5 // class generic/GenericTest$NodeB 13: dup 14: ldc #3 // String 业志陈 16: invokespecial #6 // Method generic/GenericTest$NodeB.\u0026#34;\u0026lt;init\u0026gt;\u0026#34;:(Ljava/lang/String;)V 19: astore_2 20: getstatic #7 // Field java/lang/System.out:Ljava/io/PrintStream; 23: aload_2 24: invokestatic #8 // Method generic/GenericTest$NodeB.access$000:(Lgeneric/GenericTest$NodeB;)Ljava/lang/String; 27: invokevirtual #9 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 30: return } 所以说，当泛型类型被擦除后有两种转换方式\n如果泛型没有设置上界约束，那么将泛型转化成 Object 类型 如果泛型设置了上界约束，那么将泛型转化成该上界约束 该结论也可以通过反射泛型类的 Class 对象来验证\npublic class GenericTest { public static class NodeA\u0026lt;T\u0026gt; { private T obj; public NodeA(T obj) { this.obj = obj; } } public static class NodeB\u0026lt;T extends String\u0026gt; { private T obj; public NodeB(T obj) { this.obj = obj; } } public static void main(String[] args) { NodeA\u0026lt;String\u0026gt; nodeA = new NodeA\u0026lt;\u0026gt;(\u0026#34;业志陈\u0026#34;); getField(nodeA.getClass()); NodeB\u0026lt;String\u0026gt; nodeB = new NodeB\u0026lt;\u0026gt;(\u0026#34;https://juejin.cn/user/923245496518439\u0026#34;); getField(nodeB.getClass()); } private static void getField(Class clazz) { for (Field field : clazz.getDeclaredFields()) { System.out.println(\u0026#34;fieldName: \u0026#34; + field.getName()); System.out.println(\u0026#34;fieldTypeName: \u0026#34; + field.getType().getName()); } } } NodeA 对应的是 Object，NodeB 对应的是 String\nfieldName: obj fieldTypeName: java.lang.Object fieldName: obj fieldTypeName: java.lang.String 那既然在运行时不存在任何类型相关的信息，泛型又为什么能够实现类型检查和类型自动转换等功能呢？\n其实，类型检查是编译器在编译前帮我们完成的，编译器知道我们声明的具体的类型实参，所以类型擦除并不影响类型检查功能。而类型自动转换其实是通过内部强制类型转换来实现的，上面给出的字节码中也可以看到有一条类型强转 checkcast 的语句\n27: checkcast #9 // class java/lang/String 例如，ArrayList 内部虽然用于存储数据的是 Object 数组，但 get 方法内部会自动完成类型强转\ntransient Object[] elementData; public E get(int index) { rangeCheck(index); return elementData(index); } @SuppressWarnings(\u0026#34;unchecked\u0026#34;) E elementData(int index) { //强制类型转换 return (E) elementData[index]; } 所以 Java 的泛型可以看做是一种特殊的语法糖，因此也被人称为伪泛型\n四、类型擦除的后遗症 Java 泛型对于类型的约束只在编译期存在，运行时仍然会按照 Java 5 之前的机制来运行，泛型的具体类型在运行时已经被删除了，所以 JVM 是识别不到我们在代码中指定的具体的泛型类型的\n例如，虽然List\u0026lt;String\u0026gt;只能用于添加字符串，但我们只能泛化地识别到它属于List\u0026lt;?\u0026gt;类型，而无法具体判断出该 List 内部包含的具体类型\nList\u0026lt;String\u0026gt; stringList = new ArrayList\u0026lt;\u0026gt;(); //正常 if (stringList instanceof ArrayList\u0026lt;?\u0026gt;) { } //报错 if (stringList instanceof ArrayList\u0026lt;String\u0026gt;) { } 我们只能对具体的对象实例进行类型校验，但无法判断出泛型形参的具体类型\npublic \u0026lt;T\u0026gt; void filter(T data) { //正常 if (data instanceof String) { } //报错 if (T instanceof String) { } //报错 Class\u0026lt;T\u0026gt; tClass = T::getClass; } 此外，类型擦除也会导致 Java 中出现多态问题。例如，以下两个方法的方法签名并不完全相同，但由于类型擦除的原因，入参参数的数据类型都会被看成 List\u0026lt;Object\u0026gt;，从而导致两者无法共存在同一个区域内\npublic void filter(List\u0026lt;String\u0026gt; stringList) { } public void filter(List\u0026lt;Integer\u0026gt; stringList) { } 五、Kotlin 泛型 Kotlin 泛型在大体上和 Java 一致，毕竟两者需要保证兼容性\nclass Plate\u0026lt;T\u0026gt;(val t: T) { fun cut() { println(t.toString()) } } class Apple class Banana fun main() { val plateApple = Plate\u0026lt;Apple\u0026gt;(Apple()) //泛型类型自动推导 val plateBanana = Plate(Banana()) plateApple.cut() plateBanana.cut() } Kotlin 也支持在扩展函数中使用泛型\nfun \u0026lt;T\u0026gt; List\u0026lt;T\u0026gt;.find(t: T): T? { val index = indexOf(t) return if (index \u0026gt; -1) get(index) else null } 需要注意的是，为了实现向后兼容，目前高版本 Java 依然允许实例化没有具体类型参数的泛型类，这可以说是一个对新版本 JDK 危险但对旧版本友好的兼容措施。但 Kotlin 要求在使用泛型时需要显式声明泛型类型或者是编译器能够类型推导出具体类型，任何不具备具体泛型类型的泛型类都无法被实例化。因为 Kotlin 一开始就是基于 Java 6 版本的，一开始就存在了泛型，自然就不存在需要兼容老代码的问题，因此以下例子和 Java 会有不同的表现\nval arrayList1 = ArrayList() //错误，编译器报错 val arrayList2 = arrayListOf\u0026lt;Int\u0026gt;() //正常 val arrayList3 = arrayListOf(1, 2, 3) //正常 还有一个比较容易让人误解的点。我们经常会使用 as 和 as? 来进行类型转换，但如果转换对象是泛型类型的话，那就会由于类型擦除而出现误判。如果转换对象有正确的基础类型，那么转换就会成功，而不管类型实参是否相符。因为在运行时转换发生的时候类型实参是未知的，此时编译器只会发出 “unchecked cast” 警告，代码还是可以正常编译的\n例如，在以下例子中代码的运行结果还符合我们的预知。第一个转换操作由于类型相符，所以打印出了相加值。第二个转换操作由于基础类型是 Set 而非 List，所以抛出了 IllegalAccessException\nfun main() { printSum(listOf(1, 2, 3)) //6 printSum(setOf(1, 2, 3)) //IllegalAccessException } fun printSum(c: Collection\u0026lt;*\u0026gt;) { val intList = c as? List\u0026lt;Int\u0026gt; ?: throw IllegalAccessException(\u0026#34;List is expected\u0026#34;) println(intList.sum()) } 而在以下例子中抛出的却是 ClassCastException，这是因为在运行时不会判断且无法判断出类型实参到底是否是 Int，而只会判断基础类型 List 是否相符，所以 as? 操作会成功，等到要执行相加操作时才会发现拿到的是 String 而非 Number\nprintSum(listOf(\u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34;)) Exception in thread \u0026#34;main\u0026#34; java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Number 六、上界约束 泛型本身已经带有类型约束的作用，我们也可以进一步细化其支持的具体类型\n例如，假设存在一个盘子 Plate，我们要求该 Plate 只能用于装水果 Fruit，那么就可以对其泛型声明做进一步约束，Java 中使用 extend 关键字来声明约束规则，而 Kotlin 使用的是 : 。这样 Plate 就只能用于 Fruit 和其子类，而无法用于 Noodles 等不相关的类型，这种类型约束就被称为上界约束\nopen class Fruit class Apple : Fruit() class Noodles class Plate\u0026lt;T : Fruit\u0026gt;(val t: T) fun main() { val applePlate = Plate(Apple()) //正常 val noodlesPlate = Plate(Noodles()) //报错 } 如果上界约束拥有多层类型元素，Java 是使用 \u0026amp; 符号进行链式声明，Kotlin 则是用 where 关键字来依次进行声明\ninterface Soft class Plate\u0026lt;T\u0026gt;(val t: T) where T : Fruit, T : Soft open class Fruit class Apple : Fruit() class Banana : Fruit(), Soft fun main() { val applePlate = Plate(Apple()) //报错 val bananaPlate = Plate(Banana()) //正常 } 此外，没有指定上界约束的类型形参会默认使用 Any? 作为上界，即我们可以使用 String 或 String? 作为具体的类型实参。如果想确保最终的类型实参一定是非空类型，那么就需要主动声明上界约束为 Any\n七、类型通配符 \u0026amp; 星号投影 假设现在有个需求，需要我们提供一个方法用于遍历所有类型的 List 集合并打印元素\n第一种做法就是直接将方法参数类型声明为 List，不包含任何泛型类型声明。这种做法可行，但编译器会警告无法确定 list元素的具体类型，所以这不是最优解法\npublic static void printList1(List list) { for (Object o : list) { System.out.println(o); } } 可能会想到的第二种做法是：将泛型类型直接声明为 Object，希望让其适用于任何类型的 List。这种做法完全不可行，因为即使 String 是 Object 的子类，但 List\u0026lt;String\u0026gt; 和 List\u0026lt;Object\u0026gt;并不具备从属关系，这导致 printList2 方法实际上只能用于List\u0026lt;Object\u0026gt;这一种具体类型\npublic static void printList2(List\u0026lt;Object\u0026gt; list) { for (Object o : list) { System.out.println(o); } } 最优解法就是要用到 Java 的类型通配符 ? 了，printList3方法完全可行且编译器也不会警告报错\npublic static void printList3(List\u0026lt;?\u0026gt; list) { for (Object o : list) { System.out.println(o); } } ？ 表示我们并不关心具体的泛型类型，而只是想配合其它类型进行一些条件限制。例如，printList3方法希望传入的是一个 List，但不限制泛型的具体类型，此时List\u0026lt;?\u0026gt;就达到了这一层限制条件\n类型通配符也存在着一些限制。因为 printList3 方法并不包含具体的泛型类型，所以我们从中取出的值只能是 Object 类型，且无法向其插入值，这都是为了避免发生 ClassCastException\nJava 的类型通配符对应 Kotlin 中的概念就是**星号投影 * **，Java 存在的限制在 Kotlin 中一样有\nfun printList(list: List\u0026lt;*\u0026gt;) { for (any in list) { println(any) } } 此外，星号投影只能出现在类型形参的位置，不能作为类型实参\nval list: MutableList\u0026lt;*\u0026gt; = ArrayList\u0026lt;Number\u0026gt;() //正常 val list2: MutableList\u0026lt;*\u0026gt; = ArrayList\u0026lt;*\u0026gt;() //报错 八、协变 \u0026amp; 不变 看以下例子。Apple 和 Banana 都是 Fruit 的子类，可以发现 Apple[] 类型的对象是可以赋值给 Fruit[] 的，且 Fruit[] 可以容纳 Apple 对象和 Banana 对象，这种设计就被称为协变，即如果 A 是 B 的子类，那么 A[] 就是 B[] 的子类型。相对的，Object[] 就是所有数组对象的父类型\nstatic class Fruit { } static class Apple extends Fruit { } static class Banana extends Fruit { } public static void main(String[] args) { Fruit[] fruitArray = new Apple[10]; //正常 fruitArray[0] = new Apple(); //编译时正常，运行时抛出 ArrayStoreException fruitArray[1] = new Banana(); } 而 Java 中的泛型是不变的，这意味着 String 虽然是 Object 的子类，但List\u0026lt;String\u0026gt;并不是List\u0026lt;Object\u0026gt;的子类型，两者并不具备继承关系\nList\u0026lt;String\u0026gt; stringList = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;Object\u0026gt; objectList = stringList; //报错 那为什么 Java 中的泛型是不变的呢？\n这可以通过看一个例子来解释。假设 Java 中的泛型是协变的，那么以下代码就可以成功通过编译阶段的检查，在运行时就不可避免地将抛出 ClassCastException，而引入泛型的初衷就是为了实现类型安全，支持协变的话那泛型也就没有比数组安全多少了，因此就将泛型被设计为不变的\nList\u0026lt;String\u0026gt; strList = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;Object\u0026gt; objs = strList; //假设可以运行，实际上编译器会报错 objs.add(1); String str = strList.get(0); //将抛出 ClassCastException，无法将整数转换为字符串 再来想个问题，既然协变本身并不安全，那么数组为何又要被设计为协变呢？\nArrays 类包含一个 equals方法用于比较两个数组对象是否相等。如果数组是协变的，那么就需要为每一种数组对象都定义一个 equals方法，包括开发者自定义的数据类型。想要避免这种情况，就需要让 Object[] 可以接收任意数组类型，即让 Object[] 成为所有数组对象的父类型，这就使得数组必须支持协变，这样多态才能生效\npublic class Arrays { public static boolean equals(Object[] a, Object[] a2) { if (a==a2) return true; if (a==null || a2==null) return false; int length = a.length; if (a2.length != length) return false; for (int i=0; i\u0026lt;length; i++) { Object o1 = a[i]; Object o2 = a2[i]; if (!(o1==null ? o2==null : o1.equals(o2))) return false; } return true; } } 需要注意的是，Kotlin 中的数组和 Java 中的数组并不一样，Kotlin 数组并不支持协变，Kotlin 数组类似于集合框架，具有对应的实现类 Array，Array 属于泛型类，支持了泛型因此也不再协变\nval stringArray = arrayOfNulls\u0026lt;String\u0026gt;(3) val anyArray: Array\u0026lt;Any?\u0026gt; = stringArray //报错 Java 的泛型也并非完全不变的，只是实现协变需要满足一些条件，甚至也可以实现逆变，下面就来介绍下泛型如何实现协变和逆变\n九、泛型协变 假设我们定义了一个copyAll希望用于 List 数据迁移。那以下操作在我们看来就是完全安全的，因为 Integer 是 Number 的子类，按道理来说是能够将 Integer 保存为 Number 的，但由于泛型不变性，List\u0026lt;Integer\u0026gt;并不是List\u0026lt;Number\u0026gt;的子类型，所以实际上该操作将报错\npublic static void main(String[] args) { List\u0026lt;Number\u0026gt; numberList = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;Integer\u0026gt; integerList = new ArrayList\u0026lt;\u0026gt;(); integerList.add(1); integerList.add(2); integerList.add(3); copyAll(numberList, integerList); //报错 } private static \u0026lt;T\u0026gt; void copyAll(List\u0026lt;T\u0026gt; to, List\u0026lt;T\u0026gt; from) { to.addAll(from); } 思考下该操作为什么会报错？\n编译器的作用之一就是进行安全检查并阻止可能发生不安全行为的操作，copyAll 方法会报错，那么肯定就是编译器觉得该方法有可能会触发不安全的操作。开发者的本意是希望将 Integer 类型的数据转移到 NumberList 中，只有这种操作且这种操作在我们看来肯定是安全的，但是编译器不知道开发者最终所要做的具体操作啊\n假设 copyAll方法可以正常调用，那么copyAll方法自然只会把 from 当做 List\u0026lt;Number\u0026gt;来看待。因为 Integer 是 Number 的子类，从 integerList 获取到的数据对于 numberList 来说自然是安全的。而如果我们在copyAll方法中偷偷向 integerList 传入了一个 Number 类型的值的话，那么自然就将抛出异常，因为 from 实际上是 List\u0026lt;Integer\u0026gt;类型\n为了阻止这种不安全的行为，编译器选择通过直接报错来进行提示。为了解决报错，我们就需要向编译器做出安全保证：从 from 取出来的值只会当做 Number 类型，且不会向 from 传入任何值\n为了达成以上保证，需要修改下 copyAll 方法\nprivate static \u0026lt;T\u0026gt; void copyAll(List\u0026lt;T\u0026gt; to, List\u0026lt;? extends T\u0026gt; from) { to.addAll(from); } ? extends T 表示 from 接受 T 或者 T 的子类型，而不单单是 T 自身，这意味着我们可以安全地从 from 中取值并声明为 T 类型，但由于我们并不知道 T 代表的具体类型，写入操作并不安全，因此编译器会阻止我们向 from 执行传值操作。有了该限制后，从integerList中取出来的值只能是当做 Number 类型，且避免了向integerList插入非法值的可能，此时List\u0026lt;Integer\u0026gt;就相当于List\u0026lt;? extends Number\u0026gt;的子类型了，从而使得 copyAll 方法可以正常使用\n简而言之，带 extends 限定了上界的通配符类型使得泛型参数类型是协变的，即如果 A 是 B 的子类，那么 Generic\u0026lt;A\u0026gt; 就是Generic\u0026lt;? extends B\u0026gt;的子类型\n十、泛型逆变 协变所能做到的是：如果 A 是 B 的子类，那么 Generic\u0026lt;A\u0026gt; 就是Generic\u0026lt;? extends B\u0026gt;的子类型。逆变相反，其代表的是：如果 A 是 B 的子类，那么 Generic\u0026lt;B\u0026gt; 就是 Generic\u0026lt;? super A\u0026gt; 的子类型\n协变还比较好理解，毕竟其继承关系是相同的，但逆变就比较反直觉了，整个继承关系都倒过来了\n逆变的作用可以通过相同的例子来理解，copyAll 方法如下修改也可以正常使用，此时就是向编译器做出了另一种安全保证：向 numberList 传递的值只会是 Integer 类型，且从 numberList 取出的值也只会当做 Object 类型\nprivate static \u0026lt;T\u0026gt; void copyAll(List\u0026lt;? super T\u0026gt; to, List\u0026lt;T\u0026gt; from) { to.addAll(from); } ? super T表示 to 接收 T 或者 T 的父类型，而不单单是 T 自身，这意味着我们可以安全地向 to 传类型为 T 的值，但由于我们并不知道 T 代表的具体类型，所以从 to 取出来的值只能是 Object 类型。有了该限制后，integerList只能向 numberList传递类型为 Integer 的值，且避免了从 numberList 中获取到非法类型值的可能，此时List\u0026lt;Number\u0026gt;就相当于List\u0026lt;? super Integer\u0026gt;的子类型了，从而使得 copyAll 方法可以正常使用\n简而言之，带 super 限定了下界的通配符类型使得泛型参数类型是逆变的，即如果 A 是 B 的子类，那么 Generic\u0026lt;B\u0026gt; 就是 Generic\u0026lt;? super A\u0026gt; 的子类型\n十一、out \u0026amp; in Java 中关于泛型的困境在 Kotlin 中一样存在，out 和 in 都是 Kotlin 的关键字，其作用都是为了来应对泛型问题。in 和 out 是一个对立面，同时它们又与泛型不变相对立，统称为型变\nout 本身带有出去的意思，本身带有倾向于取值操作的意思，用于泛型协变 in 本身带有进来的意思，本身带有倾向于传值操作的意思，用于泛型逆变 再来看下相同例子，该例子在 Java 中存在的问题在 Kotlin 中一样有\nfun main() { val numberList = mutableListOf\u0026lt;Number\u0026gt;() val intList = mutableListOf(1, 2, 3, 4) copyAll(numberList, intList) //报错 numberList.forEach { println(it) } } fun \u0026lt;T\u0026gt; copyAll(to: MutableList\u0026lt;T\u0026gt;, from: MutableList\u0026lt;T\u0026gt;) { to.addAll(from) } 报错原因和 Java 完全一样，因为此时编译器无法判断出我们到底是否会做出不安全的操作，所以我们依然要来向编译器做出安全保证\n此时就需要在 Kotlin 中来实现泛型协变和泛型逆变了，以下两种方式都可以实现：\nfun \u0026lt;T\u0026gt; copyAll(to: MutableList\u0026lt;T\u0026gt;, from: MutableList\u0026lt;out T\u0026gt;) { to.addAll(from) } fun \u0026lt;T\u0026gt; copyAll(to: MutableList\u0026lt;in T\u0026gt;, from: MutableList\u0026lt;T\u0026gt;) { to.addAll(from) } out 关键字就相当于 Java 中的\u0026lt;? extends T\u0026gt;，其作用就是限制了 from 不能用于接收值而只能向其取值，这样就避免了从 to 取出值然后向 from 赋值这种不安全的行为了，即实现了泛型协变\nin 关键字就相当于 Java 中的\u0026lt;? super T\u0026gt;，其作用就是限制了 to 只能用于接收值而不能向其取值，这样就避免了从 to 取出值然后向 from 赋值这种不安全的行为了，即实现了泛型逆变\n从这也可以联想到，MutableList\u0026lt;*\u0026gt; 就相当于 MutableList\u0026lt;out Any?\u0026gt;了，两者都带有相同的限制条件：不允许写值操作，允许读值操作，且读取出来的值只能当做 Any?进行处理\n十二、支持协变的 List 在上述例子中，想要实现协变还有另外一种方式，那就是使用 List\n将 from 的类型声明从 MutableList\u0026lt;T\u0026gt;修改为 List\u0026lt;T\u0026gt; 后，可以发现 copyAll 方法也可以正常调用了\nfun \u0026lt;T\u0026gt; copyAll(to: MutableList\u0026lt;T\u0026gt;, from: List\u0026lt;T\u0026gt;) { to.addAll(from) } 对 Kotlin 有一定了解的同学应该知道，Kotlin 中的集合框架分为两种大类：可读可写和只能读不能写\n以 Java 中的 ArrayList 为例，Kotlin 将之分为了 MutableList 和 List 两种类型的接口。而 List 接口中的泛型已经使用 out 关键字进行修饰了，且不包含任何传入值并保存的方法，即 List 接口只支持读值而不支持写值，其本身就已经满足了协变所需要的条件，因此copyAll 方法可以正常使用\npublic interface List\u0026lt;out E\u0026gt; : Collection\u0026lt;E\u0026gt; { override val size: Int override fun isEmpty(): Boolean override fun contains(element: @UnsafeVariance E): Boolean override fun iterator(): Iterator\u0026lt;E\u0026gt; override fun containsAll(elements: Collection\u0026lt;@UnsafeVariance E\u0026gt;): Boolean public operator fun get(index: Int): E public fun indexOf(element: @UnsafeVariance E): Int public fun lastIndexOf(element: @UnsafeVariance E): Int public fun listIterator(): ListIterator\u0026lt;E\u0026gt; public fun listIterator(index: Int): ListIterator\u0026lt;E\u0026gt; public fun subList(fromIndex: Int, toIndex: Int): List\u0026lt;E\u0026gt; } 虽然 List 接口中有几个方法也接收了 E 类型的入参参数，但该方法本身不会进行写值操作，所以实际上可以正常使用，Kotlin 也使用 @UnsafeVariance抑制了编译器警告\n十三、reified \u0026amp; inline 上文讲了，由于类型擦除，Java 和 Kotlin 的泛型类型实参都会在编译阶段被擦除，在 Kotlin 中存在一个额外手段可以来解决这个问题，即内联函数\n用关键字 inline 标记的函数就称为内联函数，再用 reified 关键字修饰内联函数中的泛型形参，编译器在进行编译的时候便会将内联函数的字节码插入到每一个调用的地方，当中就包括泛型的类型实参。而内联函数的类型形参能够被实化，就意味着我们可以在运行时引用实际的类型实参了\n例如，我们可以写出以下这样的一个内联函数，用于判断一个对象是否是指定类型\nfun main() { println(1.isInstanceOf\u0026lt;String\u0026gt;()) println(\u0026#34;string\u0026#34;.isInstanceOf\u0026lt;Int\u0026gt;()) } inline fun \u0026lt;reified T\u0026gt; Any.isInstanceOf(): Boolean { return this is T } 将以上的 Kotlin 代码反编译为 Java 代码，可以看出来 main()方法最终是没有调用 isInstanceOf 方法的，具体的判断逻辑都被插入到了main()方法内部，最终是执行了 instanceof 操作，且指定了具体的泛型类型参数 String 和 Integer\npublic final class GenericTest6Kt { public static final void main() { Object $this$isInstanceOf$iv = 1; int $i$f$isInstanceOf = false; boolean var2 = $this$isInstanceOf$iv instanceof String; $i$f$isInstanceOf = false; System.out.println(var2); Object $this$isInstanceOf$iv = \u0026#34;string\u0026#34;; $i$f$isInstanceOf = false; var2 = $this$isInstanceOf$iv instanceof Integer; $i$f$isInstanceOf = false; System.out.println(var2); } // $FF: synthetic method public static void main(String[] var0) { main(); } // $FF: synthetic method public static final boolean isInstanceOf(Object $this$isInstanceOf) { int $i$f$isInstanceOf = 0; Intrinsics.checkNotNullParameter($this$isInstanceOf, \u0026#34;$this$isInstanceOf\u0026#34;); Intrinsics.reifiedOperationMarker(3, \u0026#34;T\u0026#34;); return $this$isInstanceOf instanceof Object; } } inline 和 reified 比较有用的一个场景是用在 Gson 反序列的时候。由于泛型运行时类型擦除的问题，目前用 Gson 反序列化泛型类时步骤是比较繁琐的，利用 inline 和 reified 我们就可以简化很多操作\nval gson = Gson() inline fun \u0026lt;reified T\u0026gt; toBean(json: String): T { return gson.fromJson(json, T::class.java) } data class BlogBean(val name: String, val url: String) fun main() { val json = \u0026#34;\u0026#34;\u0026#34;{\u0026#34;name\u0026#34;:\u0026#34;业志陈\u0026#34;,\u0026#34;url\u0026#34;:\u0026#34;https://juejin.cn/user/923245496518439\u0026#34;}\u0026#34;\u0026#34;\u0026#34; val listJson = \u0026#34;\u0026#34;\u0026#34;[{\u0026#34;name\u0026#34;:\u0026#34;业志陈\u0026#34;,\u0026#34;url\u0026#34;:\u0026#34;https://juejin.cn/user/923245496518439\u0026#34;},{\u0026#34;name\u0026#34;:\u0026#34;业志陈\u0026#34;,\u0026#34;url\u0026#34;:\u0026#34;https://juejin.cn/user/923245496518439\u0026#34;}]\u0026#34;\u0026#34;\u0026#34; val blogBean = toBean\u0026lt;BlogBean\u0026gt;(json) val blogMap = toBean\u0026lt;Map\u0026lt;String, String\u0026gt;\u0026gt;(json) val blogBeanList = toBean\u0026lt;List\u0026lt;BlogBean\u0026gt;\u0026gt;(listJson) //BlogBean(name=业志陈, url=https://juejin.cn/user/923245496518439) println(blogBean) //{name=业志陈, url=https://juejin.cn/user/923245496518439} println(blogMap) //[{name=业志陈, url=https://juejin.cn/user/923245496518439}, {name=业志陈, url=https://juejin.cn/user/923245496518439}] println(blogBeanList) } 我也利用 Kotlin 的这个强大特性写了一个用于简化 Java / Kotlin 平台的序列化和反序列化操作的库：JsonHolder 十四、总结 最后来做个简单的总结\n协变 逆变 不变 Kotlin \u0026lt;out T\u0026gt;，只能作为消费者，只能读取不能添加 \u0026lt;in T\u0026gt;，只能作为生产者，只能添加，读取出的值只能当做 Any 类型 \u0026lt;T\u0026gt;，既可以添加也可以读取 Java \u0026lt;? extends T\u0026gt;，只能作为消费者，只能读取不能添加 \u0026lt;? super T\u0026gt;，只能作为生产者，只能添加，读取出的值只能当做 Object 类型 \u0026lt;T\u0026gt;，既可以添加也可以读取 ","permalink":"http://localhost:1313/hugo-blog/public/post/kotlin/%E4%B8%80%E6%96%87%E8%AF%BB%E6%87%82-java-%E5%92%8C-kotlin-%E7%9A%84%E6%B3%9B%E5%9E%8B%E9%9A%BE%E7%82%B9/","tags":[],"title":"一文读懂 Java 和 Kotlin 的泛型难点"},{"categories":[],"content":" 公众号：字节数组 希望对你有所帮助 🤣🤣\n开头先说一下，我不是标题党，本教程真的有两万六千字，以前我也曾写过 Kotlin 的入门教程，但由于隔得比较久了，所以就对原有教程进行了修正，并且补充了 Kotlin 新版本的一些新特性，希望对你有所帮助 🤣🤣\n一、Hello World 按照国际惯例，学习一门新的语言通常都是要从打印 Hello World 开始的\npackage main fun main() { val msg: String = \u0026#34;Hello World\u0026#34; println(msg) } 从这个简单的函数就可以列出 kotlin 和 Java 的几个不同点\n函数可以定义在文件的最外层，不需要把它放在类中 用关键字 fun 来声明一个函数 可以省略 main 方法的参数 参数类型写在变量名之后，这有助于在类型自动推导时省略类型声明 使用 println 代替了 System.out.println ，这是 kotlin 标准库提供的对 Java 标准库函数的简易封装 可以省略代码结尾的分号 二、Package kotlin 文件都以 package 开头，同个文件中定义的所有声明（类、函数和属性）都会被放到这个包中。同个包中的声明可以直接使用，不同包的声明需要导入后使用\n包的声明要放在文件顶部，import 语句紧随其后\npackage base import java.text.SimpleDateFormat import java.util.* kotlin 不区分导入的是类还是函数，可以使用 import 关键字导入任何种类的声明。此外也可以在包名称后加上 .* 来导入包中定义的所有声明，从而让包中定义的类、顶层函数、和属性都可以直接引用\npackage learn.package2 val index = 10 fun Test(status: Boolean) = println(status) class Point(val x: Int, val y: Int) { val isEquals1: Boolean get() { return x == y } val isEquals2 get() = x == y var isEquals3 = false get() = x \u0026gt; y set(value) { field = !value } } package learn.package1 import learn.package2.Point import learn.package2.Test import learn.package2.index fun main() { val point = Point(10, index) Test(true) } Java 语言规定类要放到和包结构匹配的文件夹目录结构中，且文件名必须和类名相同。而 kotlin 允许把多个类放到同一个文件中，文件名也可以任意选择。kotlin 也没有文件夹目录施加任何限制，包层级结构不需要遵循同样的目录层级结构 ,但 kotlin 官方还是建议根据包声明把源码文件放到相应的目录中\n如果包名出现命名冲突，可以使用 as 关键字在本地重命名冲突项来消歧义\nimport learn.package1.Point import learn.package2.Point as PointTemp //PointTemp 可以用来表示 learn.package2.Point 了 kotlin 中也有一个类似的概念可以用来重命名现有类型，叫做类型别名。类型别名用于为现有类型提供一个替代名称，如果类型名称比较长，就可以通过引入一个较短或者更为简略的名称来方便记忆\n类型别名不会引入新的类型，依然对应其底层类型，所以在下述代码中输出的 class 类型是一致的\nclass Base { class InnerClass } typealias BaseInner = Base.InnerClass fun main() { val baseInner1 = Base.InnerClass() val baseInner2 = BaseInner() println(baseInner1.javaClass) //class test2.Base$InnerClass println(baseInner2.javaClass) //class test2.Base$InnerClass } 三、变量与数据类型 在 Java 中，大部分的变量是可变的（非 final 的），意味着任何可以访问到这个变量的代码都可以去修改它。而在 kotlin 中，变量可以分为 可变变量(var) 和 不可变变量(val) 两类\n声明变量的关键字有两个：\nval（value / varible+final）——不可变引用。使用 val 声明的变量不能在初始化之后再次赋值，对应的是 Java 中的 final 变量 var（variable）——可变引用。var 变量的值可以被改变，对应的是 Java 中的非 final 变量 不可变变量在赋值之后就不能再去改变它的状态了，因此不可变变量可以说是线程安全的，因为它们无法改变，所有线程访问到的对象都是同一个，因此也不需要去做访问控制。开发者应当尽可能地使用不可变变量，这样可以让代码更加接近函数式编程风格\n编程领域也推崇一种开发原则：尽可能使用 val，不可变对象及纯函数来设计程序。这样可以尽量避免副作用带来的影响\nfun main() { //只读变量即赋值后不可以改变值的变量，用 val 声明 //声明一个整数类型的不可变变量 val intValue: Int = 100 //声明一个双精度类型的可变变量 var doubleValue: Double = 100.0 } 在声明变量时我们通常不需要显式指明变量的类型，这可以由编译器根据上下文自动推导出来。如果只读变量在声明时没有初始的默认值，则必须指明变量类型，且在使用前必须确保在各个分支条件下变量可以被初始化，否则编译器就会报异常\nfun main() { val intValue = 1002222222222 val doubleValue = 100.0 val longValue = 100L //如果只读变量在声明时没有初始值，则必须指明变量类型 val intValue2: Int if (false) { intValue2 = 10 } println(intValue2) //error， Variable \u0026#39;intValue2\u0026#39; must be initialized } 1、基本数据类型 与 Java 不同，kotlin 并不区分基本数据类型和它的包装类，在 kotlin 中一切都是对象，可以在任何变量上调用其成员函数和属性。kotlin 没有像 Java 中那样的原始基本类型，但 byte、char、integer、float 或者 boolean 等类型仍然有保留，但是全部都作为对象存在\n对于基本类型，kotlin 相比 Java 有几点特殊的地方\n数字、字符和布尔值可以在运行时表示为原生类型值，但对开发者来说，它们看起来就像普通的类 对于数字没有隐式拓宽转换，而在 Java 中 int 可以隐式转换为 long 所有未超出 Int 最⼤值的整型值初始化的变量都会自动推断为 Int 类型，如果初始值超过了其最⼤值，则会推断为 Long 类型， 如需显式指定 Long 类型值可在该值后追加 L 后缀 字符不能视为数字 不支持八进制 //在 kotlin 中，int、long、float 等类型仍然存在，但是是作为对象存在的 val intIndex: Int = 100 //等价于，编译器会自动进行类型推导 val intIndex = 100 //数字类型不会自动转型，必须要进行明确的类型转换 val doubleIndex: Double = intIndex.toDouble() //以下代码会提示错误，需要进行明确的类型转换 //val doubleIndex: Double = intIndex val intValue: Int = 1 val longValue: Long = 1 //以下代码会提示错误，因为两者的数据类型不一致，需要转换为同一类型后才能进行比较 //println(intValue == longValue) //Char 不能直接作为数字来处理，需要主动转换 val ch: Char = \u0026#39;c\u0026#39; val charValue: Int = ch.toInt() //以下代码会提示错误 //val charValue: Int = ch //二进制 val value1 = 0b00101 //十六进制 val value2 = 0x123 此外，kotlin 的可空类型不能用 Java 的基本数据类型表示，因为 null 只能被存储在 Java 的引用类型的变量中，这意味着只要使用了基本数据类型的可空版本，它就会被编译成对应的包装类型\n//基本数据类型 val intValue_1: Int = 200 //包装类 val intValue_2: Int? = intValue_1 val intValue_3: Int? = intValue_1 //== 比较的是数值相等性，因此结果是 true println(intValue_2 == intValue_3) //=== 比较的是引用是否相等，因此结果是 false println(intValue_2 === intValue_3) 如果 intValue_1 的值是100，就会发现 intValue_2 === intValue_3 的比较结果是 true，这就涉及到 Java 对包装类对象的复用问题了\n2、字符串 kotlin 与 Java 一样用 String 类型来表示字符串，字符串是不可变的，可以使用索引运算符访问[] 来访问包含的单个字符，也可以用 for 循环来迭代字符串，此外也可以用 + 来连接字符串\nval str = \u0026#34;leavesCZY\u0026#34; println(str[1]) for (c in str) { println(c) } val str1 = str + \u0026#34; hello\u0026#34; kotlin 支持在字符串字面值中引用局部变量，只需要在变量名前加上字符 $ 即可，此外还可以包含用花括号括起来的表达式，此时会自动求值并把结果合并到字符串中\nval intValue = 100 //可以直接包含变量 println(\u0026#34;intValue value is $intValue\u0026#34;) //intValue value is 100 //也可以包含表达式 println(\u0026#34;(intValue + 100) value is ${intValue + 100}\u0026#34;) //(intValue + 100) value is 200 如果你需要在原始字符串中表示字面值（$）字符（它不支持反斜杠转义），可以用下列语法：\nval price = \u0026#34;${\u0026#39;$\u0026#39;}100.99\u0026#34; println(price) //$100.99 3、数组 kotlin 中的数组是带有类型参数的类，其元素类型被指定为相应的类型参数，使用 Array 类来表示， Array 类定义了 get 与 set 函数（按照运算符重载约定这会转变为 [ ] ）以及 size 属性等\n创建数组的方法有以下几种：\n用 arrayOf 函数创建一个数组，包含的元素是指定为该函数的实参 用 arrayOfNulls 创建一个给定大小的数组，包含的元素均为 null，只能用来创建包含元素类型可空的数组 调用 Array 类的构造方法，传递数组的大小和一个 lambda 表达式，调用 lambda 表达式来创建每一个数组元素 //包含给定元素的字符串数组 val array1 = arrayOf(\u0026#34;leavesCZY\u0026#34;, \u0026#34;叶\u0026#34;, \u0026#34;https://github.com/leavesCZY\u0026#34;) array1[0] = \u0026#34;leavesCZY\u0026#34; println(array1[1]) println(array1.size) //初始元素均为 null ，大小为 10 的字符数组 val array2 = arrayOfNulls\u0026lt;String\u0026gt;(10) //创建从 “a” 到 “z” 的字符串数组 val array3 = Array(26) { i -\u0026gt; (\u0026#39;a\u0026#39; + i).toString() } 需要注意的是，数组类型的类型参数始终会变成对象类型，因此声明 Array\u0026lt; Int \u0026gt; 将是一个包含装箱类型（java.lang.Integer）的数组。如果想要创建没有装箱的基本数据类型的数组，必须使用一个基本数据类型数组的特殊类\n为了表示基本数据类型的数组，kotlin 为每一种基本数据类型都提供了若干相应的类并做了特殊的优化。例如，有 IntArray、ByteArray、BooleanArray 等类型，这些类型都会被编译成普通的 Java 基本数据类型数组，比如 int[]、byte[]、boolean[] 等，这些数组中的值存储时没有进行装箱，而是使用了可能的最高效的方式。需要注意，IntArray 等并不是 Array 的子类\n要创建一个基本数据类型的数组，有以下几种方式：\n向对应类型的类（如 IntArray）的构造函数传递数组大小，这将返回一个使用对应基本数据类型默认值初始化好的数组 向对应类型的类（如 IntArray）的构造函数传递数组大小以及用来初始化每个元素的 lambda 向工厂函数（如 charArrayOf）传递变长参数的值，从而得到指定元素值的数组 //指定数组大小，包含的元素将是对应基本数据类型的默认值(int 的默认值是 0) val intArray = IntArray(5) //指定数组大小以及用于初始化每个元素的 lambda val doubleArray = DoubleArray(5) { Random().nextDouble() } //接收变长参数的值来创建存储这些值的数组 val charArray = charArrayOf(\u0026#39;H\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;l\u0026#39;, \u0026#39;l\u0026#39;, \u0026#39;o\u0026#39;) 4、Any 和 Any? Any 类型是 kotlin 所有非空类型的超类型，包括像 Int 这样的基本数据类型\n如果把基本数据类型的值赋给 Any 类型的变量，则会自动装箱\nval any: Any = 100 println(any.javaClass) //class java.lang.Integer 如果想要使变量可以存储包括 null 在内的所有可能的值，则需要使用 Any?\nval any: Any? = null 5、Unit kotlin 中的 Unit 类型类似于 Java 中的 void，可以用于函数没有返回值时的情况\nfun check(): Unit { } //如果返回值为 Unit，则可以省略该声明 fun check() { } Unit 是一个完备的类型，可以作为类型参数，但 void 不行\ninterface Test\u0026lt;T\u0026gt; { fun test(): T } class NoResultClass : Test\u0026lt;Unit\u0026gt; { //返回 Unit，但可以省略类型说明，函数也不需要显式地 return override fun test() { } } 6、Nothing Nothing 类型没有任何值，只有被当做函数返回值使用，或者被当做泛型函数返回值的类型参数使用时才会有意义，可以用 Nothing 来表示一个函数不会被正常终止，从而帮助编译器对代码进行诊断\n编译器知道返回值为 Nothing 类型的函数从不会正常终止，所以编译器会把 name1 的类型推断为非空，因为 name1 在为 null 时的分支处理会始终抛出异常\ndata class User(val name: String?) fun fail(message: String): Nothing { throw IllegalStateException(message) } fun main() { val user = User(\u0026#34;leavesC\u0026#34;) val name = user.name ?: fail(\u0026#34;no name\u0026#34;) println(name) //leavesC val user1 = User(null) val name1 = user1.name ?: fail(\u0026#34;no name\u0026#34;) println(name1.length) //IllegalStateException } 四、函数 kotlin 中的函数以关键字 fun 作为开头，函数名称紧随其后，再之后是用括号包裹起来的参数列表，如果函数有返回值，则再加上返回值类型，用一个冒号与参数列表隔开\n//fun 用于表示声明一个函数，getNameLastChar 是函数名 //空括号表示该函数无传入参数，Char 表示函数的返回值类型是字符 fun getNameLastChar(): Char { return name.get(name.length - 1) } //带有两个不同类型的参数，一个是 String 类型，一个是 Int 类型 //返回值为 Int 类型 fun test1(str: String, int: Int): Int { return str.length + int } 此外，表达式函数体的返回值类型可以省略，返回值类型可以自动推断，这种用单行表达式与等号定义的函数叫做表达式函数体。但对于一般情况下的有返回值的代码块函数体，必须显式地写出返回类型和 return 语句\n//getNameLastChar 函数的返回值类型以及 return 关键字是可以省略的 //返回值类型可以由编译器根据上下文进行推导 //因此，函数可以简写为以下形式 fun getNameLastChar() = name.get(name.length - 1) 如果函数没有有意义的返回值，则可以声明为 Unit ，也可以省略 Unit\n以下三种写法都是等价的\nfun test(str: String, int: Int): Unit { println(str.length + int) } fun test(str: String, int: Int) { println(str.length + int) } fun test(str: String, int: Int) = println(str.length + int) 1、命名参数 为了增强代码的可读性，kotlin 允许我们使用命名参数，即在调用某函数的时候，可以将函数参数名一起标明，从而明确地表达该参数的含义与作用，但是在指定了一个参数的名称后，之后的所有参数都需要标明名称\nfun main() { //错误，在指定了一个参数的名称后，之后的所有参数都需要标明名称 //compute(index = 110, \u0026#34;leavesC\u0026#34;) compute(index = 120, value = \u0026#34;leavesC\u0026#34;) compute(130, value = \u0026#34;leavesC\u0026#34;) } fun compute(index: Int, value: String) { } 2、默认参数值 可以在声明函数的时候指定参数的默认值，从而避免创建重载的函数\nfun main() { compute(24) compute(24, \u0026#34;leavesC\u0026#34;) } fun compute(age: Int, name: String = \u0026#34;leavesC\u0026#34;) { } 对于以上这个例子，如果按照常规的调用语法时，必须按照函数声明定义的参数顺序来给定参数，可以省略的只有排在末尾的参数\nfun main() { //错误，不能省略参数 name // compute(24) // compute(24,100) //可以省略参数 value compute(\u0026#34;leavesC\u0026#34;, 24) } fun compute(name: String = \u0026#34;leavesC\u0026#34;, age: Int, value: Int = 100) {} 如果使用命名参数，可以省略任何有默认值的参数，而且也可以按照任意顺序传入需要的参数\nfun main() { compute(age = 24) compute(age = 24, name = \u0026#34;leavesC\u0026#34;) compute(age = 24, value = 90, name = \u0026#34;leavesC\u0026#34;) compute(value = 90, age = 24, name = \u0026#34;leavesC\u0026#34;) } fun compute(name: String = \u0026#34;leavesC\u0026#34;, age: Int, value: Int = 100) { } 3、可变参数 可变参数可以让我们把任意个数的参数打包到数组中传给函数，kotlin 的语法相比 Java 有所不同，改为通过使用 vararg 关键字声明可变参数\n例如，以下的几种函数调用方式都是正确的\nfun main() { compute() compute(\u0026#34;leavesC\u0026#34;) compute(\u0026#34;leavesC\u0026#34;, \u0026#34;leavesc\u0026#34;) compute(\u0026#34;leavesC\u0026#34;, \u0026#34;leavesc\u0026#34;, \u0026#34;叶\u0026#34;) } fun compute(vararg name: String) { name.forEach { println(it) } } 在 Java 中，可以直接将数组传递给可变参数，而 kotlin 要求显式地解包数组，以便每个数组元素在函数中能够作为单独的参数来调用，这个功能被称为展开运算符，使用方式就是在数组参数前加一个 *\nfun main() { val names = arrayOf(\u0026#34;leavesC\u0026#34;, \u0026#34;leavesc\u0026#34;, \u0026#34;叶\u0026#34;) compute(* names) } fun compute(vararg name: String) { name.forEach { println(it) } } 4、局部函数 kotlin 支持在函数中嵌套函数，被嵌套的函数称为局部函数\nfun main() { compute(\u0026#34;leavesC\u0026#34;, \u0026#34;country\u0026#34;) } fun compute(name: String, country: String) { fun check(string: String) { if (string.isEmpty()) { throw IllegalArgumentException(\u0026#34;参数错误\u0026#34;) } } check(name) check(country) } 五、表达式和条件循环 1、语句和表达式 这里需要先区分“语句”和“表达式”这两个概念。语句是可以单独执行，能够产生实际效果的代码，表现为赋值逻辑、打印操作、流程控制等形式，Java 中的流程控制（if，while，for）等都是语句。表达式可以是一个值、变量、常量、操作符、或它们之间的组合，表达式可以看做是包含返回值的语句\n例如，以下的赋值操作、流程控制、打印输出都是语句，其是作为一个整体存在的，且不包含返回值\nval a = 10 for (i in 0..a step 2) { println(i) } 再看几个表达式的例子\n1 //字面表达式，返回 1 ++1 //也属于表达式，自增会返回 2 //与 Java 不同，kotlin 中的 if 是作为表达式存在的，其可以拥有返回值 fun getLength(str: String?): Int { return if (str.isNullOrBlank()) 0 else str.length } 2、If 表达式 if 的分支可以是代码块，最后的表达式作为该块的返回值\nval maxValue = if (20 \u0026gt; 10) { println(\u0026#34;maxValue is 20\u0026#34;) 20 } else { println(\u0026#34;maxValue is 10\u0026#34;) 10 } println(maxValue) //20 以下代码可以显示地看出 if 的返回值，完全可以用来替代 Java 中的三元运算符，因此 kotlin 并没有三元运算符\nval list = listOf(1, 4, 10, 4, 10, 30) val value = if (list.size \u0026gt; 0) list.size else null println(value) //6 如果 if 表达式分支是用于执行某个命令，那么此时的返回值类型就是 Unit ，此时的 if 语句就看起来和 Java 的一样了\nval value1 = if (list.size \u0026gt; 0) println(\u0026#34;1\u0026#34;) else println(\u0026#34;2\u0026#34;) println(value1.javaClass) //class kotlin.Unit 如果将 if 作为表达式而不是语句（例如：返回它的值或者把它赋给变量），该表达式需要有 else 分支\n3、when 表达式 when 表达式与 Java 中的 switch/case 类似，但是要强大得多。when 既可以被当做表达式使用也可以被当做语句使用，when 将参数和所有的分支条件顺序比较直到某个分支满足条件，然后它会运行右边的表达式。如果 when 被当做表达式来使用，符合条件的分支的值就是整个表达式的值，如果当做语句使用， 则忽略个别分支的值。与 Java 的 switch/case 不同之处是 when 表达式的参数可以是任何类型，并且分支也可以是一个条件\n和 if 一样，when 表达式每一个分支可以是一个代码块，它的值是代码块中最后的表达式的值，如果其它分支都不满足条件将会求值于 else 分支\n如果 when 作为一个表达式使用，则必须有 else 分支， 除非编译器能够检测出所有的可能情况都已经覆盖了。如果很多分支需要用相同的方式处理，则可以把多个分支条件放在一起，用逗号分隔\nval value = 2 when (value) { in 4..9 -\u0026gt; println(\u0026#34;in 4..9\u0026#34;) //区间判断 3 -\u0026gt; println(\u0026#34;value is 3\u0026#34;) //相等性判断 2, 6 -\u0026gt; println(\u0026#34;value is 2 or 6\u0026#34;) //多值相等性判断 is Int -\u0026gt; println(\u0026#34;is Int\u0026#34;) //类型判断 else -\u0026gt; println(\u0026#34;else\u0026#34;) //如果以上条件都不满足，则执行 else } fun main() { //返回 when 表达式 fun parser(obj: Any): String = when (obj) { 1 -\u0026gt; \u0026#34;value is 1\u0026#34; \u0026#34;4\u0026#34; -\u0026gt; \u0026#34;value is string 4\u0026#34; is Long -\u0026gt; \u0026#34;value type is long\u0026#34; else -\u0026gt; \u0026#34;unknown\u0026#34; } println(parser(1)) println(parser(1L)) println(parser(\u0026#34;4\u0026#34;)) println(parser(100L)) println(parser(100.0)) } value is 1 value type is long value is string 4 value type is long unknown 此外，when 语句也可以不带参数来使用\nwhen { 1 \u0026gt; 5 -\u0026gt; println(\u0026#34;1 \u0026gt; 5\u0026#34;) 3 \u0026gt; 1 -\u0026gt; println(\u0026#34;3 \u0026gt; 1\u0026#34;) } 4、for 循环 和 Java 中的 for 循环最为类似的形式是\nval list = listOf(1, 4, 10, 34, 10) for (value in list) { println(value) } 通过索引来遍历\nval items = listOf(\u0026#34;H\u0026#34;, \u0026#34;e\u0026#34;, \u0026#34;l\u0026#34;, \u0026#34;l\u0026#34;, \u0026#34;o\u0026#34;) //通过索引来遍历List for (index in items.indices) { println(\u0026#34;${index}对应的值是：${items[index]}\u0026#34;) } 也可以在每次循环中获取当前索引和相应的值\nval list = listOf(1, 4, 10, 34, 10) for ((index, value) in list.withIndex()) { println(\u0026#34;index : $index , value :$value\u0026#34;) } 也可以自定义循环区间\nfor (index in 2..10) { println(index) } 5、while 和 do/while 循环 while 和 do/while 与 Java 中的区别不大\nval list = listOf(1, 4, 15, 2, 4, 10, 0, 9) var index = 0 while (index \u0026lt; list.size) { println(list[index]) index++ } val list = listOf(1, 4, 15, 2, 4, 10, 0, 9) var index = 0 do { println(list[index]) index++ } while (index \u0026lt; list.size) 6、返回和跳转 kotlin 有三种结构化跳转表达式：\nreturn 默认从最直接包围它的函数或者匿名函数返回 break 终止最直接包围它的循环 continue 继续下一次最直接包围它的循环 在 kotlin 中任何表达式都可以用标签（label）来标记，标签的格式为标识符后跟 @ 符号，例如：abc@ 、fooBar@ 都是有效的标签\nfun main() { fun1() } fun fun1() { val list = listOf(1, 4, 6, 8, 12, 23, 40) loop@ for (it in list) { if (it == 8) { continue } if (it == 23) { break@loop } println(\u0026#34;value is $it\u0026#34;) } println(\u0026#34;function end\u0026#34;) } value is 1 value is 4 value is 6 value is 12 function end kotlin 有函数字面量、局部函数和对象表达式。因此 kotlin 的函数可以被嵌套\n标签限制的 return 允许我们从外层函数返回，最重要的一个用途就是从 lambda 表达式中返回。通常情况下使用隐式标签更方便，该标签与接受该 lambda 的函数同名\nfun main() { fun1() fun2() fun3() fun4() fun5() } fun fun1() { val list = listOf(1, 4, 6, 8, 12, 23, 40) list.forEach { if (it == 8) { return } println(\u0026#34;value is $it\u0026#34;) } println(\u0026#34;function end\u0026#34;) // value is 1 // value is 4 // value is 6 } fun fun2() { val list = listOf(1, 4, 6, 8, 12, 23, 40) list.forEach { if (it == 8) { return@fun2 } println(\u0026#34;value is $it\u0026#34;) } println(\u0026#34;function end\u0026#34;) // value is 1 // value is 4 // value is 6 } //fun3() 和 fun4() 中使用的局部返回类似于在常规循环中使用 continue fun fun3() { val list = listOf(1, 4, 6, 8, 12, 23, 40) list.forEach { if (it == 8) { return@forEach } println(\u0026#34;value is $it\u0026#34;) } println(\u0026#34;function end\u0026#34;) // value is 1 // value is 4 // value is 6 // value is 12 // value is 23 // value is 40 // function end } fun fun4() { val list = listOf(1, 4, 6, 8, 12, 23, 40) list.forEach loop@{ if (it == 8) { return@loop } println(\u0026#34;value is $it\u0026#34;) } println(\u0026#34;function end\u0026#34;) // value is 1 // value is 4 // value is 6 // value is 12 // value is 23 // value is 40 // function end } fun fun5() { listOf(1, 2, 3, 4, 5).forEach(fun(value: Int) { if (value == 3) { //局部返回到匿名函数的调用者，即 forEach 循环 return } println(\u0026#34;value is $value\u0026#34;) }) println(\u0026#34;function end\u0026#34;) } 六、区间 Ranges 表达式使用一个 .. 操作符来声明一个闭区间，它被用于定义实现一个 RangTo 方法\n以下三种声明方式都是等价的\nvar index = 5 if (index \u0026gt;= 0 \u0026amp;\u0026amp; index \u0026lt;= 10) { } if (index in 0..10) { } if (index in 0.rangeTo(10)) { } 数字类型的 ranges 在被迭代时，编译器会将它们转换为与 Java 中使用 index 的 for 循环的相同字节码的方式来进行优化\nRanges 默认会自增长，所以像以下的代码就不会被执行\nfor (index in 10..0) { println(index) } 可以改用 downTo 函数来将之改为递减\nfor (index in 10 downTo 0) { println(index) } 可以在 ranges 中使用 step 来定义每次循环递增或递增的长度：\nfor (index in 1..8 step 2){ println(index) } for (index in 8 downTo 1 step 2) { println(index) } 以上声明的都是闭区间，如果想声明的是开区间，可以使用 until 函数：\nfor (index in 0 until 4){ println(index) } 扩展函数 reversed() 可用于返回将区间反转后的序列\nval rangeTo = 1.rangeTo(3) for (i in rangeTo) { println(i) //1 2 3 } for (i in rangeTo.reversed()) { println(i) //3 2 1 } 七、修饰符 1、final 和 open kotlin 中的类和方法默认都是 final 的，即不可继承的，如果想允许创建一个类的子类，需要使用 open 修饰符来标识这个类，此外，也需要为每一个希望被重写的属性和方法添加 open 修饰符\nopen class View { open fun click() { } //不能在子类中被重写 fun longClick() { } } class Button : View() { override fun click() { super.click() } } 如果重写了一个基类或者接口的成员，重写了的成员同样默认是 open 的。例如，如果 Button 类是 open 的，则其子类也可以重写其 click() 方法\nopen class Button : View() { override fun click() { super.click() } } class CompatButton : Button() { override fun click() { super.click() } } 如果想要类的子类重写该方法的实现，可以显式地将重写的成员标记为 final\nopen class Button : View() { override final fun click() { super.click() } } 2、public public 修饰符是限制级最低的修饰符，是默认的修饰符。如果一个定义为 public 的成员被包含在一个 private 修饰的类中，那么这个成员在这个类以外也是不可见的\n3、protected protected 修饰符只能被用在类或者接口中的成员上。在 Java 中，可以从同一个包中访问一个 protected 的成员，但对于 kotlin 来说，protected 成员只在该类和它的子类中可见。此外，protected 不适用于顶层声明\n4、internal 一个定义为 internal 的包成员，对其所在的整个 module 可见，但对于其它 module 而言就是不可见的了。例如，假设我们想要发布一个开源库，库中包含某个类，我们希望这个类对于库本身是全局可见的，但对于外部使用者来说它不能被引用到，此时就可以选择将其声明为 internal 的来实现这个目的\n根据 Jetbrains 的定义，一个 module 应该是一个单独的功能性的单位，可以看做是一起编译的 kotlin 文件的集合，它应该是可以被单独编译、运行、测试、debug 的。相当于在 Android Studio 中主工程引用的 module，Eclipse 中在一个 workspace 中的不同的 project\n5、private private 修饰符是限制级最高的修饰符，kotlin 允许在顶层声明中使用 private 可见性，包括类、函数和属性，这表示只在自己所在的文件中可见，所以如果将一个类声明为 private，就不能在定义这个类之外的地方中使用它。此外，如果在一个类里面使用了 private 修饰符，那访问权限就被限制在这个类里面，继承这个类的子类也不能使用它。所以如果类、对象、接口等被定义为 private，那么它们只对被定义所在的文件可见。如果被定义在了类或者接口中，那它们只对这个类或者接口可见\n6、总结 修饰符 类成员 顶层声明 public（默认） 所有地方可见 所有地方可见 internal 模块中可见 模块中可见 protected 子类中可见 private 类中可见 文件中可见 八、空安全 1、可空性 在 kotlin 中，类型系统将一个引用分为可以容纳 null （可空引用）或者不能容纳 null（非空引用）两种类型。 例如，String 类型的常规变量不能指向 null\nvar name: String = \u0026#34;leavesC\u0026#34; //编译错误 //name = null 如果希望一个变量可以储存 null 引用，需要显式地在类型名称后面加上问号\nvar name: String? = \u0026#34;leavesC\u0026#34; name = null 问号可以加在任何类型的后面来表示这个类型的变量可以存储 null 引用：Int?、Doubld? 、Long? 等\nkotlin 对可空类型的显式支持有助于防止 NullPointerException 导致的异常问题，编译器不允许不对可空变量做 null 检查就直接调用其属性。这个强制规定使得开发者必须在编码初期就考虑好变量的可赋值范围并为其各个情况做好分支处理\nfun check(name: String?): Boolean { //error，编译器不允许不对 name 做 null 检查就直接调用其属性 return name.isNotEmpty() } 正确的做法是显式地进行 null 检查\nfun check(name: String?): Boolean { if (name != null) { return name.isNotEmpty() } return false } 2、安全调用运算符：?. 安全调用运算符：?. 允许把一次 null 检查和一次方法调用合并为一个操作，如果变量值非空，则方法或属性会被调用，否则直接返回 null\n例如，以下两种写法是完全等同的：\nfun check(name: String?) { if (name != null) { println(name.toUpperCase()) } else { println(null) } } fun check(name: String?) { println(name?.toUpperCase()) } 3、Elvis 运算符：?: Elvis 运算符：?: 用于替代 ?. 直接返回默认值 null 的情况，Elvis 运算符接收两个运算数，如果第一个运算数不为 null ，运算结果就是其运算结果值，如果第一个运算数为 null ，运算结果就是第二个运算数\n例如，以下两种写法是完全等同的：\nfun check(name: String?) { if (name != null) { println(name) } else { println(\u0026#34;default\u0026#34;) } } fun check(name: String?) { println(name ?: \u0026#34;default\u0026#34;) } 4、安全转换运算符：as? 安全转换运算符：as? 用于把值转换为指定的类型，如果值不适合该类型则返回 null\nfun check(any: Any?) { val result = any as? String println(result ?: println(\u0026#34;is not String\u0026#34;)) } 5、非空断言：!! 非空断言用于把任何值转换为非空类型，如果对 null 值做非空断言，则会抛出异常\nfun main() { var name: String? = \u0026#34;leavesC\u0026#34; check(name) //7 name = null check(name) //kotlinNullPointerException } fun check(name: String?) { println(name!!.length) } 6、可空类型的扩展 为可空类型定义扩展函数是一种更强大的处理 null 值的方式，可以允许接收者为 null 的调用，并在该函数中处理 null ，而不是在确保变量不为 null 之后再调用它的方法\n例如，如下方法可以被正常调用而不会发生空指针异常\nval name: String? = null println(name.isNullOrEmpty()) //true isNullOrEmpty() 的方法签名如下所示，可以看到这是为可空类型 CharSequence? 定义的扩展函数，方法中已经处理了方法调用者为 null 的情况\n@kotlin.internal.InlineOnly public inline fun CharSequence?.isNullOrEmpty(): Boolean { contract { returns(false) implies (this@isNullOrEmpty != null) } return this == null || this.length == 0 } 7、平台类型 平台类型是 kotlin 对 java 所作的一种平衡性设计。kotlin 将对象的类型分为了可空类型和不可空类型两种，但 java 平台的一切对象类型均为可空的，当在 kotlin 中引用 java 变量时，如果将所有变量均归为可空类型，最终将多出许多 null 检查；如果均看成不可空类型，那么就很容易就写出忽略了NPE 风险的代码。为了平衡两者，kotlin 引入了平台类型，即当在 kotlin 中引用 java 变量值时，既可以将之看成可空类型，也可以将之看成不可空类型，由开发者自己来决定是否进行 null 检查\n九、类型的检查与转换 1、类型检查 is 与 !is 操作符用于在运行时检查对象是否符合给定类型：\nfun main() { val strValue = \u0026#34;leavesC\u0026#34; parserType(strValue) //value is String , length : 7 val intValue = 100 parserType(intValue) //value is Int , toLong : 100 val doubleValue = 100.22 parserType(doubleValue) //value !is Long val longValue = 200L parserType(longValue) //unknown } fun parserType(value: Any) { when (value) { is String -\u0026gt; println(\u0026#34;value is String , length : ${value.length}\u0026#34;) is Int -\u0026gt; println(\u0026#34;value is Int , toLong : ${value.toLong()}\u0026#34;) !is Long -\u0026gt; println(\u0026#34;value !is Long\u0026#34;) else -\u0026gt; println(\u0026#34;unknown\u0026#34;) } } 同时，is 操作符也附带了一个智能转换功能。在许多情况下，不需要在 kotlin 中使用显式转换操作符，因为编译器跟踪不可变值的 is 检查以及显式转换，并在需要时自动插入安全的转换\n例如，在上面的例子中，当判断 value 为 String 类型通过时，就可以直接将 value 当做 String 类型变量并调用其内部属性，这个过程就叫做智能转换\n编译器会指定根据上下文环境，将变量智能转换为合适的类型\nif (value !is String) return //如果 value 非 String 类型时直接被 return 了，所以此处可以直接访问其 length 属性 println(value.length) // || 右侧的 value 被自动隐式转换为字符串，所以可以直接访问其 length 属性 if (value !is String || value.length \u0026gt; 0) { } // \u0026amp;\u0026amp; 右侧的 value 被自动隐式转换为字符串，所以可以直接访问其 length 属性 if (value is String \u0026amp;\u0026amp; value.length \u0026gt; 0) { } 2、不安全的转换操作符 如果转换是不可能的，转换操作符 as 会抛出一个异常。因此，我们称之为不安全的转换操作符\nfun main() { parserType(\u0026#34;leavesC\u0026#34;) //value is String , length is 7 parserType(10) //会抛出异常 ClassCastException } fun parserType(value: Any) { val tempValue = value as String println(\u0026#34;value is String , length is ${tempValue.length}\u0026#34;) } 需要注意的是，null 不能转换为 String 变量，因为该类型不是可空的\n因此如下转换会抛出异常\nval x = null val y: String = x as String //会抛出异常 TypeCastException 为了匹配安全，可以转换的类型声明为可空类型\nval x = null val y: String? = x as String? 3、安全的转换操作符 可以使用安全转换操作符 as? 来避免在转换时抛出异常，它在失败时返回 null\nval x = null val y: String? = x as? String 尽管以上例子 as? 的右边是一个非空类型的 String，但是其转换的结果是可空的\n十、类 1、基本概念 类的概念就是把数据和处理数据的代码封装成一个单一的实体。在 Java 中，数据存储在一个私有字段中，通过提供访问器方法：getter 和 setter 来访问或者修改数据\n在 Java 中以下的示例代码是很常见的，Point 类包含很多重复的代码：通过构造函数把参数赋值给有着相同名称的字段，通过 getter 来获取属性值\npublic final class Point { private final int x; private final int y; public Point(int x, int y) { this.x = x; this.y = y; } public final int getX() { return this.x; } public final int getY() { return this.y; } } 使用 kotlin 来声明 Point 类则只需要一行代码，两者完全等同\nclass Point(val x: Int, val y: Int) kotlin 也使用关键字 class 来声明类，类声明由类名、类头（指定其类型参数、主构造函数等）以及由花括号包围的类体构成，类头与类体都是可选的，如果一个类没有类体，可以省略花括号。此外，kotlin 中类默认是 publish（公有的） 且 final （不可继承）的\nkotlin 区分了主构造方法（在类体外部声明）和次构造方法（在类体内部声明），一个类可以有一个主构造函数和多个次构造函数，此外也允许在初始化代码块中 init 添加额外的初始化逻辑\n2、主构造函数 主构造函数是类头的一部分，跟在类名（和可选的类型参数）后，主构造函数的参数可以是可变的（var）或只读的（val）\nclass Point constructor(val x: Int, val y: Int) { } 如果主构造函数没有任何注解或者可见性修饰符，可以省略 constructor 关键字\nclass Point(val x: Int, val y: Int) { } //如果不包含类体，则可以省略花括号 class Point(val x: Int, val y: Int) 如果构造函数有注解或可见性修饰符，则 constructor 关键字是必需的，并且这些修饰符在它前面\nclass Point public @Inject constructor(val x: Int, val y: Int) { } 主构造函数不能包含任何的代码，初始化的代码可以放到以 init 关键字作为前缀的初始化块（initializer blocks）中，初始化块包含了在类被创建时执行的代码，主构造函数的参数可以在初始化块中使用。如果需要的话，也可以在一个类中声明多个初始化语句块。需要注意的是，构造函数的参数如果用 val/var 进行修饰，则相当于在类内部声明了一个同名的全局属性。如果不加 val/var 进行修饰，则构造函数只能在 init 函数块和全局属性初始化时进行引用\n此外，要创建一个类的实例不需要使用 Java 中的 new 关键字，像普通函数一样调用构造函数即可\nclass Point(val x: Int, val y: Int) { init { println(\u0026#34;initializer blocks , x value is: $x , y value is: $y\u0026#34;) } } fun main() { Point(1, 2) // initializer blocks , x value is: 1 , y value is: 2 } 主构造函数的参数也可以在类体内声明的属性初始化器中使用\nclass Point(val x: Int, val y: Int) { private val localX = x + 1 private val localY = y + 1 init { println(\u0026#34;initializer blocks , x value is: $x , y value is: $y\u0026#34;) println(\u0026#34;initializer blocks , localX value is: $localX , localY value is: $localY\u0026#34;) } } fun main() { Point(1, 2) //initializer blocks , x value is: 1 , y value is: 2 //initializer blocks , localX value is: 2 , localY value is: 3 } 3、次构造函数 类也可以声明包含前缀 constructor 的次构造函数。如果类有一个主构造函数，每个次构造函数都需要直接委托给主构造函数或者委托给另一个次构造函数以此进行间接委托，用 this 关键字来进行指定即可\nclass Point(val x: Int, val y: Int) { private val localX = x + 1 private val localY = y + 1 init { println(\u0026#34;initializer blocks , x value is: $x , y value is: $y\u0026#34;) println(\u0026#34;initializer blocks , localX value is: $localX , localY value is: $localY\u0026#34;) } constructor(base: Int) : this(base + 1, base + 1) { println(\u0026#34;constructor(base: Int)\u0026#34;) } constructor(base: Long) : this(base.toInt()) { println(\u0026#34;constructor(base: Long)\u0026#34;) } } fun main() { Point(100) //initializer blocks , x value is: 101 , y value is: 101 //initializer blocks , localX value is: 102 , localY value is: 102 //constructor(base: Int) Point(100L) //initializer blocks , x value is: 101 , y value is: 101 //initializer blocks , localX value is: 102 , localY value is: 102 //constructor(base: Int) //constructor(base: Long) } 初始化块中的代码实际上会成为主构造函数的一部分，委托给主构造函数会作为次构造函数的第一条语句，因此所有初始化块中的代码都会在次构造函数体之前执行。即使该类没有主构造函数，这种委托仍会隐式发生，并且仍会执行初始化块。如果一个非抽象类没有声明任何（主或次）构造函数，会默认生成一个不带参数的公有主构造函数\n4、属性 在 Java 中，字段和其访问器的组合被称作属性。在 kotlin 中，属性是头等的语言特性，完全替代了字段和访问器方法。在类中声明一个属性和声明一个变量一样是使用 val 和 var 关键字。val 变量只有一个 getter ，var 变量既有 getter 也有 setter\nfun main() { val user = User() println(user.name) user.age = 200 } class User() { val name: String = \u0026#34;leavesC\u0026#34; var age: Int = 25 } 5、自定义访问器 访问器的默认实现逻辑很简单：创建一个存储值的字段，以及返回属性值的 getter 和更新属性值的 setter。如果需要的话，也可以自定义访问器\n例如，以下就声明了三个带自定义访问器的属性\nclass Point(val x: Int, val y: Int) { val isEquals1: Boolean get() { return x == y } val isEquals2 get() = x == y var isEquals3 = false get() = x \u0026gt; y set(value) { field = !value } } 如果仅需要改变一个访问器的可见性或者为其添加注解，那么可以定义访问器而不定义其实现\nfun main() { val point = Point(10, 10) println(point.isEquals1) //以下代码会报错 //point.isEquals1 = true } class Point(val x: Int, val y: Int) { var isEquals1: Boolean = false get() { return x == y } private set } 6、延迟初始化 一般地，非空类型的属性必须在构造函数中初始化，但像使用了 Dagger2 这种依赖注入框架的项目来说就十分的不方便了，为了应对这种情况，可以用 lateinit 修饰符来标记该属性，用于告诉编译器该属性会在稍后的时间被初始化\n用 lateinit 修饰的属性或变量必须为非空类型，并且不能是原生类型\nclass Point(val x: Int, val y: Int) class Example { lateinit var point: Point var point2: Point constructor() { point2 = Point(10, 20) } } 如果访问了一个未经过初始化的 lateinit 变量，则会抛出一个包含具体原因（该变量未初始化）的异常信息\nException in thread \u0026#34;main\u0026#34; kotlin.UninitializedPropertyAccessException: lateinit property point has not been initialized 十一、类的分类 1、抽象类 声明为 abstract 的类内部可以包含没有实现体的成员方法，且该成员方法也用 abstract 标记，这种类称为抽象类，没有实现体的方法就称为抽象方法\n此外，我们并不需要用 open 标注一个抽象类或者抽象方法，因为这是默认声明的\nabstract class BaseClass { abstract fun fun1() } class Derived : BaseClass() { override fun fun1() { } } 2、数据类 数据类是一种非常强大的类，可以避免重复创建 Java 中的用于保存状态但又操作非常简单的 POJO 的模版代码，它们通常只提供了用于访问它们属性的简单的 getter 和 setter\n定义一个新的数据类非常简单，例如\ndata class Point(val x: Int, val y: Int) 数据类默认地为主构造函数中声明的所有属性生成了如下几个方法\ngetter、setter（需要是 var） componentN()。按主构造函数的属性声明顺序进行对应 copy() toString() hashCode() equals() 为了确保生成的代码的一致性以及有意义的行为，数据类必须满足以下要求：\n主构造函数需要包含一个参数 主构造函数的所有参数需要标记为 val 或 var 数据类不能是抽象、开放、密封或者内部的 可以利用 IDEA 来反编译查看 Point 类的 Java 实现，了解其内部实现\npublic final class Point { private final int x; private final int y; public final int getX() { return this.x; } public final int getY() { return this.y; } public Point(int x, int y) { this.x = x; this.y = y; } public final int component1() { return this.x; } public final int component2() { return this.y; } @NotNull public final Point copy(int x, int y) { return new Point(x, y); } // $FF: synthetic method // $FF: bridge method @NotNull public static Point copy$default(Point var0, int var1, int var2, int var3, Object var4) { if ((var3 \u0026amp; 1) != 0) { var1 = var0.x; } if ((var3 \u0026amp; 2) != 0) { var2 = var0.y; } return var0.copy(var1, var2); } public String toString() { return \u0026#34;Point(x=\u0026#34; + this.x + \u0026#34;, y=\u0026#34; + this.y + \u0026#34;)\u0026#34;; } public int hashCode() { return this.x * 31 + this.y; } public boolean equals(Object var1) { if (this != var1) { if (var1 instanceof Point) { Point var2 = (Point)var1; if (this.x == var2.x \u0026amp;\u0026amp; this.y == var2.y) { return true; } } return false; } else { return true; } } } 通过数据类可以简化很多的通用操作，可以很方便地进行：格式化输出变量值、映射对象到变量、对比变量之间的相等性、复制变量等操作\nfun main() { val point1 = Point(10, 20) val point2 = Point(10, 20) println(\u0026#34;point1 toString() : $point1\u0026#34;) //point1 toString() : Point(x=10, y=20) println(\u0026#34;point2 toString() : $point2\u0026#34;) //point2 toString() : Point(x=10, y=20) val (x, y) = point1 println(\u0026#34;point1 x is $x,point1 y is $y\u0026#34;) //point1 x is 10,point1 y is 20 //在 kotlin 中，“ == ” 相当于 Java 的 equals 方法 //而 “ === ” 相当于 Java 的 “ == ” 方法 println(\u0026#34;point1 == point2 : ${point1 == point2}\u0026#34;) //point1 == point2 : true println(\u0026#34;point1 === point2 : ${point1 === point2}\u0026#34;) //point1 === point2 : false val point3 = point1.copy(y = 30) println(\u0026#34;point3 toString() : $point3\u0026#34;) //point3 toString() : Point(x=10, y=30) } 需要注意的是，数据类的 toString()、equals()、hashCode()、copy() 等方法只考虑主构造函数中声明的属性，因此在比较两个数据类对象的时候可能会有一些意想不到的结果\ndata class Point(val x: Int) { var y: Int = 0 } fun main() { val point1 = Point(10) point1.y = 10 val point2 = Point(10) point2.y = 20 println(\u0026#34;point1 == point2 : ${point1 == point2}\u0026#34;) //point1 == point2 : true println(\u0026#34;point1 === point2 : ${point1 === point2}\u0026#34;) //point1 === point2 : false } 3、密封类 Sealed 类（密封类）用于对类可能创建的子类进行限制，用 Sealed 修饰的类的直接子类只允许被定义在 Sealed 类所在的文件中（密封类的间接继承者可以定义在其他文件中），这有助于帮助开发者掌握父类与子类之间的变动关系，避免由于代码更迭导致的潜在 bug，且密封类的构造函数只能是 private 的\n例如，对于 View 类，其子类只能定义在与之同一个文件里，Sealed 修饰符修饰的类也隐含表示该类为 open 类，因此无需再显式地添加 open 修饰符\nsealed class View { fun click() { } } class Button : View() { } class TextView : View() { } 因为 Sealed 类的子类对于编译器来说是可控的，所以如果在 when 表达式中处理了所有 Sealed 类的子类，那就不需要再提供 else 默认分支。即使以后由于业务变动又新增了 View 子类，编译器也会检测到 check 方法缺少分支检查后报错，所以说 check 方法是类型安全的\nfun check(view: View): Boolean { when (view) { is Button -\u0026gt; { println(\u0026#34;is Button\u0026#34;) return true } is TextView -\u0026gt; { println(\u0026#34;is TextView\u0026#34;) return true } } } 4、枚举类 kotlin 也提供了枚举的实现，相比 Java 需要多使用 class 关键字来声明枚举\nenum class Day { SUNDAY, MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY, SATURDAY } 枚举可以声明一些参数\nenum class Day(val index: Int) { SUNDAY(0), MONDAY(1), TUESDAY(2), WEDNESDAY(3), THURSDAY(4), FRIDAY(5), SATURDAY(6) } 此外，枚举也可以实现接口\ninterface OnChangedListener { fun onChanged() } enum class Day(val index: Int) : OnChangedListener { SUNDAY(0) { override fun onChanged() { } }, MONDAY(1) { override fun onChanged() { } } } 枚举也包含有一些共有函数\nfun main() { val day = Day.FRIDAY //获取值 val value = day.index //5 //通过 String 获取相应的枚举值 val value1 = Day.valueOf(\u0026#34;SUNDAY\u0026#34;) //SUNDAY //获取包含所有枚举值的数组 val value2 = Day.values() //获取枚举名 val value3 = Day.SUNDAY.name //SUNDAY //获取枚举声明的位置 val value4 = Day.TUESDAY.ordinal //2 } 5、嵌套类 在 kotlin 中在类里面再定义的类默认是嵌套类，此时嵌套类不会包含对外部类的隐式引用\nclass Outer { private val bar = 1 class Nested { fun foo1() = 2 //错误 //fun foo2() = bar } } fun main() { val demo = Outer.Nested().foo1() } 以上代码通过 IDEA 反编译后可以看到其内部的 Java 实现方式\n可以看到 Nested 其实就是一个静态类，因此 foo2() 不能访问外部类的非静态成员，也不用先声明 Outer 变量再指向 Nested 类，而是直接通过 Outer 类指向 Nested 类\npublic final class Outer { private final int bar = 1; public static final class Nested { public final int foo1() { return 2; } } } public final class MainkotlinKt { public static final void main(@NotNull String[] args) { Intrinsics.checkParameterIsNotNull(args, \u0026#34;args\u0026#34;); int demo = (new Outer.Nested()).foo1(); } } 6、内部类 如果需要去访问外部类的成员，需要用 inner 修饰符来标注被嵌套的类，这称为内部类。内部类会隐式持有对外部类的引用\nclass Outer { private val bar = 1 inner class Nested { fun foo1() = 2 fun foo2() = bar } } fun main() { val demo = Outer().Nested().foo2() } 再来看其内部的 Java 实现方式\n使用 inner 来声明 Nested 类后，就相当于将之声明为非静态内部类，因此 foo2() 能访问其外部类的非静态成员，在声明 Nested 变量前也需要通过 Outer 变量来指向其内部的 Nested 类\npublic final class Outer { private final int bar = 1; public final class Nested { public final int foo1() { return 2; } public final int foo2() { return Outer.this.bar; } } } public final class MainkotlinKt { public static final void main(@NotNull String[] args) { Intrinsics.checkParameterIsNotNull(args, \u0026#34;args\u0026#34;); int demo = (new Outer().new Nested()).foo2(); } } 类A在类B中声明 在Java中 在kotlin中 嵌套类（不存储外部类的引用） static class A class A 内部类（存储外部类的引用） class A inner class A 7、匿名内部类 可以使用对象表达式来创建匿名内部类实例\ninterface OnClickListener { fun onClick() } class View { fun setClickListener(clickListener: OnClickListener) { } } fun main() { val view = View() view.setClickListener(object : OnClickListener { override fun onClick() { } }) } 8、内联类 在有些时候，我们需要对原生类型进行包装以便提升程序的健壮性。例如，对于 sendEmail 方法的入参参数而言，我们无法严格限制入参参数的含义类型，有的开发者可能会将 delay 理解为以毫秒为单位，有的开发者可能又会理解为以分钟为单位\nfun sendEmail(delay: Long) { println(delay) } 为了提升程序的健壮性，我们可以通过声明一个包装类来作为参数类型：\nfun sendEmail(delay: Time) { println(delay.second) } class Time(val second: Long) class Minute(private val count: Int) { fun toTime(): Time { return Time(count * 60L) } } fun main() { sendEmail(Minute(10).toTime()) } 这样，在代码源头上就限制了开发者能够传入的参数类型，开发者通过类名就能直接表达出自己希望的时间大小。然而这种方式由于额外的堆内存分配问题，就引入了运行时的性能开销，新的包装类相对原生类型所需要的性能消耗要大得多，可是此时又需要考虑程序的健壮性和可读性，所以包装类也是需要的\n内联类（InlineClass）就是为了解决这两者的矛盾而诞生的。上述代码可以改为以下方式来实现\nfun sendEmail(delay: Time) { println(delay.second) } inline class Time(val second: Long) inline class Minute(private val count: Int) { fun toTime(): Time { return Time(count * 60L) } } fun main() { sendEmail(Minute(10).toTime()) } 使用 inline 修饰的类就称为内联类，内联类必须含有唯一的一个属性在主构造函数中初始化，在运行时将使用这个唯一属性来表示内联类的实例，从而避免了包装类在运行时的额外开销\n例如，通过查看字节码可以看到sendEmail 方法会被解释为一个以 long 类型作为入参类型的函数，并不包含任何对象\npublic static final void sendEmail_G1aXmDY/* $FF was: sendEmail-G1aXmDY*/(long delay) { boolean var4 = false; System.out.println(delay); } 十二、接口 1、抽象方法与默认方法 kotlin 中的接口与 Java 8 中的类似，可以包含抽象方法的定义以及非抽象方法的实现，不需要使用 default 关键字来标注有默认实现的非抽象方法，但在实现接口的抽象方法时需要使用 override 进行标注\nfun main() { val view = View() view.click() view.longClick() } class View : Clickable { override fun click() { println(\u0026#34;clicked\u0026#34;) } } interface Clickable { fun click() fun longClick() = println(\u0026#34;longClicked\u0026#34;) } 如果一个类实现了多个接口，而接口包含带有默认实现且签名相同的方法，此时编译器就会要求开发者必须显式地实现该方法，可以选择在该方法中调用不同接口的相应实现\nclass View : Clickable, Clickable2 { override fun click() { println(\u0026#34;clicked\u0026#34;) } override fun longClick() { super\u0026lt;Clickable\u0026gt;.longClick() super\u0026lt;Clickable2\u0026gt;.longClick() } } interface Clickable { fun click() fun longClick() = println(\u0026#34;longClicked\u0026#34;) } interface Clickable2 { fun click() fun longClick() = println(\u0026#34;longClicked2\u0026#34;) } 2、抽象属性 接口中可以包含抽象属性声明，接口不定义该抽象属性是应该存储到一个支持字段还是通过 getter 来获取，接口本身并不包含任何状态，因此只有实现这个接口的类在需要的情况下会存储这个值\n看以下例子，Button 类和 TextView 类都实现了 Clickable 接口，并都提供了取得 statusValue 值的方式\nButton 类提供了一个自定义的 getter 用于在每次访问时重新获取 statusValue 值，因此在多次获取属性值时其值可能都会不一致，因为每次 getRandom() 方法都会被调用\nTextView 类中的 statusValue 属性有一个支持字段来存储在类初始化时得到的数据，因此其值在初始化后是不会再次获取值，即 TextView 类中的 getRandom() 只会被调用一次\nfun main() { val button = Button() println(button.statusValue) val textView = TextView() println(textView.statusValue) } class Button : Clickable { override val statusValue: Int get() = getRandom() private fun getRandom() = Random().nextInt(10) } class TextView : Clickable { override val statusValue: Int = getRandom() private fun getRandom() = Random().nextInt(10) } interface Clickable { val statusValue: Int } 除了可以声明抽象属性外，接口还可以包含具有 getter 和 setter 的属性，只要它们没有引用一个支持字段（支持字段需要在接口中存储状态，而这是不允许的）\ninterface Clickable { val statusValue: Int val check: Boolean get() = statusValue \u0026gt; 10 } 十三、SAM 接口 对于以下例子，在 Kotlin 1.4 之前第二种写法是不支持的，我们必须完全实现 SelfRunnable 才可以调用 setRunnable 方法\n/** * @Author: leavesCZY * @Github：https://github.com/leavesCZY */ interface SelfRunnable { fun run() } fun setRunnable(selfRunnable: SelfRunnable) { selfRunnable.run() } fun main() { setRunnable(object : SelfRunnable { override fun run() { println(\u0026#34;hello,leavesC\u0026#34;) } }) //错误，Kotlin 1.4 之前不支持 // setRunnable { // println(\u0026#34;hello,leavesC\u0026#34;) // } } 而在 Kotlin 1.4 之后，Kotlin 开始支持 SAM 转换。只有一个抽象方法的接口称为函数式接口或 SAM（单一抽象方法）接口，函数式接口可以有多个非抽象成员，但只能有一个抽象成员。SAM 转换即 Single Abstract Method Conversions，对于只有单个非默认抽象方法的接口，可以直接用 Lambda 来表示，前提是 Lambda 所表示的函数类型能够跟接口中的方法签名相匹配\n所以，在 Kotlin 1.4 之后，就支持直接以 Lambda 的方式来声明 SelfRunnable 的实现类，从而使得在方法调用上可以更加简洁，但这也要求 interface 同时使用 fun 关键字修饰\n/** * @Author: leavesCZY * @Github：https://github.com/leavesCZY */ fun interface SelfRunnable { fun run() } fun setRunnable(selfRunnable: SelfRunnable) { selfRunnable.run() } fun main() { setRunnable { println(\u0026#34;hello,leavesC\u0026#34;) } } 十四、继承 在 kotlin 中所有类都有一个共同的超类 Any ，对于没有超类声明的类来说它就是默认超类。需要注意的是， Any 并不是 java.lang.Object ，它除了 equals() 、 hashCode() 与 toString() 外没有其他属性或者函数\n要声明一个显式的超类，需要把父类名放到类头的冒号之后\nopen class Base() class SubClass() : Base() 当中，类上的 open 标注与 Java 中的 final 含义相反，用于允许其它类从这个类继承。默认情况下，kotlin 中所有的类都是 final\n如果派生类有一个主构造函数，其基类型必须直接或间接调用基类的主构造函数\nopen class Base(val str: String) class SubClass(val strValue: String) : Base(strValue) class SubClass2 : Base { constructor(strValue: String) : super(strValue) constructor(intValue: Int) : super(intValue.toString()) constructor(doubValue: Double) : this(doubValue.toString()) } 1、覆盖方法 与 Java 不同，kotlin 需要显式标注可覆盖的成员和覆盖后的成员：\nopen class Base() { open fun fun1() { } fun fun2() { } } class SubClass() : Base() { override fun fun1() { super.fun1() } } 用 open 标注的函数才可以被子类重载，子类用 override 表示该函数是要对父类的同签名函数进行覆盖。标记为 override 的成员本身也是开放的，也就是说，它可以被子类覆盖。如果想禁止再次覆盖，可以使用 final 关键字标记如果父类没有使用 open 对函数进行标注，则子类不允许定义相同签名的函数。对于一个 final 类（没有用 open 标注的类）来说，使用 open 标记属性和方法是无意义的\n2、属性覆盖 属性覆盖与方法覆盖类似。在超类中声明为 open 的属性，如果要进行覆盖则必须在派生类中重新声明且以 override 开头，并且它们必须具有兼容的类型\n每个声明的属性可以由具有初始化器的属性或者具有 getter 方法的属性覆盖\nopen class Base { open val x = 10 open val y: Int get() { return 100 } } class SubClass : Base() { override val x = 100 override var y = 200 } fun main() { val base = Base() println(base.x) //10 println(base.y) //100 val base1: Base = SubClass() println(base1.x) //100 println(base1.y) //200 val subClass = SubClass() println(subClass.x) //100 println(subClass.y) //200 } 此外，也可以用一个 var 属性覆盖一个 val 属性，但反之则不行。因为一个 val 属性本质上声明了一个 getter 方法，而将其覆盖为 var 只是在子类中额外声明一个 setter 方法\n可以在主构造函数中使用 override 关键字作为属性声明的一部分\nopen class Base { open val str: String = \u0026#34;Base\u0026#34; } class SubClass(override val str: String) : Base() fun main() { val base = Base() println(base.str) //Base val subClass = SubClass(\u0026#34;leavesC\u0026#34;) println(subClass.str) //leavesC } 3、调用超类实现 派生类可以通过 super 关键字调用其超类的函数与属性访问器的实现\nopen class BaseClass { open fun fun1() { println(\u0026#34;BaseClass fun1\u0026#34;) } } class SubClass : BaseClass() { override fun fun1() { super.fun1() } } 对于内部类来说，其本身就可以直接调用调用外部类的函数\nopen class BaseClass2 { private fun fun1() { println(\u0026#34;BaseClass fun1\u0026#34;) } inner class InnerClass { fun fun2() { fun1() } } } 但如果想要在一个内部类中访问外部类的超类，则需要通过由外部类名限定的 super 关键字来实现\nopen class BaseClass { open fun fun1() { println(\u0026#34;BaseClass fun1\u0026#34;) } } class SubClass : BaseClass() { override fun fun1() { println(\u0026#34;SubClass fun1\u0026#34;) } inner class InnerClass { fun fun2() { super@SubClass.fun1() } } } fun main() { val subClass = SubClass() val innerClass = subClass.InnerClass() //BaseClass fun1 innerClass.fun2() } 如果一个类从它的直接超类和实现的接口中继承了相同成员的多个实现， 则必须覆盖这个成员并提供其自己的实现来消除歧义\n为了表示采用从哪个超类型继承的实现，使用由尖括号中超类型名限定的 super 来指定，如 super\u0026lt; BaseClass \u0026gt;\nopen class BaseClass { open fun fun1() { println(\u0026#34;BaseClass fun1\u0026#34;) } } interface BaseInterface { //接口成员默认就是 open 的 fun fun1() { println(\u0026#34;BaseInterface fun1\u0026#34;) } } class SubClass() : BaseClass(), BaseInterface { override fun fun1() { //调用 SubClass 的 fun1() 函数 super\u0026lt;BaseClass\u0026gt;.fun1() //调用 BaseInterface 的 fun1() 函数 super\u0026lt;BaseInterface\u0026gt;.fun1() } } 十五、集合 1、只读集合与可变集合 kotlin 的集合设计和 Java 不同的另一项特性是：kotlin 把访问数据的接口和修改集合数据的接口分开了，kotlin.collections.Collection 接口提供了遍历集合元素、获取集合大小、判断集合是否包含某元素等操作，但这个接口没有提供添加和移除元素的方法。kotlin.collections.MutableCollection 接口继承于 kotlin.collections.Collection 接口，扩展出了用于添加、移除、清空元素的方法\n就像 kotlin 对 val 和 var 的区分一样，只读集合接口与可变集合接口的分离能提高对代码的可控性，如果函数接收 Collection 作为形参，那么就可以知道该函数不会修改集合，而只是对数据进行读取\n以下是用来创建不同类型集合的函数\n集合元素 只读 可变 List listOf mutableListOf、arrayListOf Set setOf mutableSetOf、hashSetOf、linkedSetOf、sortedSetOf Map mapOf mutableMapOf、hashMapOf、linkedMapOf、sortedMapOf val list = listOf(10, 20, 30, 40) //不包含 add 方法 //list.add(100) println(list.size) println(list.contains(20)) val mutableList = mutableListOf(\u0026#34;leavesC\u0026#34;, \u0026#34;leavesc\u0026#34;, \u0026#34;叶\u0026#34;) mutableList.add(\u0026#34;Ye\u0026#34;) println(mutableList.size) println(mutableList.contains(\u0026#34;leavesC\u0026#34;)) 2、集合与 Java 因为 Java 并不会区分只读集合与可变集合，即使 kotlin 中把集合声明为只读的， Java 代码也可以修改这个集合，而 Java 代码中的集合对 kotlin 来说也是可变性未知的，kotlin 代码可以将之视为只读的或者可变的，包含的元素也是可以为 null 或者不为 null 的\n例如，在 Java 代码中 names 这么一个 List\u0026lt; String \u0026gt; 类型的变量\npublic class JavaMain { public static List\u0026lt;String\u0026gt; names = new ArrayList\u0026lt;\u0026gt;(); static { names.add(\u0026#34;leavesC\u0026#34;); names.add(\u0026#34;Ye\u0026#34;); } } 在 kotlin 中可以用以下四种方式来引用变量 names\nval list1: List\u0026lt;String?\u0026gt; = JavaMain.names val list2: List\u0026lt;String\u0026gt; = JavaMain.names val list3: MutableList\u0026lt;String\u0026gt; = JavaMain.names val list4: MutableList\u0026lt;String?\u0026gt; = JavaMain.names 3、只读集合的可变性 只读集合不一定就是不可变的。例如，假设存在一个拥有只读类型接口的对象，该对象存在两个不同的引用，一个只读，一个可变，当可变引用修改了该对象后，这对只读引用来说就相当于“只读集合被修改了”，因此只读集合并不总是线程安全的。如果需要在多线程环境下处理数据，需要保证正确地同步了对数据的访问，或者使用支持并发访问的数据结构\n例如，list1 和 list1 引用到同一个集合对象， list3 对集合的修改同时会影响到 list1\nval list1: List\u0026lt;String\u0026gt; = JavaMain.names val list3: MutableList\u0026lt;String\u0026gt; = JavaMain.names list1.forEach { it -\u0026gt; println(it) } //leavesC Ye list3.forEach { it -\u0026gt; println(it) } //leavesC Ye for (index in list3.indices) { list3[index] = list3[index].toUpperCase() } list1.forEach { it -\u0026gt; println(it) } //LEAVESC YE 4、集合与可空性 集合的可空性可以分为三种：\n可以包含为 null 的集合元素 集合本身可以为 null 集合本身可以为 null，且可以包含为 null 的集合元素 例如，intList1 可以包含为 null 的集合元素，但集合本身不能指向 null；intList2 不可以包含为 null 的集合元素，但集合本身可以指向 null；intList3 可以包含为 null 的集合元素，且集合本身能指向 null\n//List\u0026lt;Int?\u0026gt; 是能持有 Int? 类型值的列表 val intList1: List\u0026lt;Int?\u0026gt; = listOf(10, 20, 30, 40, null) //List\u0026lt;Int\u0026gt;? 是可以为 null 的列表 var intList2: List\u0026lt;Int\u0026gt;? = listOf(10, 20, 30, 40) intList2 = null //List\u0026lt;Int?\u0026gt;? 是可以为 null 的列表，且能持有 Int? 类型值 var intList3: List\u0026lt;Int?\u0026gt;? = listOf(10, 20, 30, 40, null) intList3 = null 十六、扩展函数和扩展属性 1、扩展函数 扩展函数用于为一个类增加一种新的行为，这是为缺少有用函数的类进行扩展的途径。扩展函数的用途就类似于在 Java 中实现的静态工具方法。而在 kotlin 中使用扩展函数的一个优势就是我们不需要在调用方法的时候把整个对象当作参数传入，扩展函数表现得就像是属于这个类本身的一样，可以使用 this 关键字并直接调用其所有 public 方法\n扩展函数并不允许你打破它的封装性，和在类内部定义的方法不同的是，扩展函数不能访问私有的或是受保护的成员\n//为 String 类声明一个扩展函数 lastChar() ，用于返回字符串的最后一个字符 //get方法是 String 类的内部方法，length 是 String 类的内部成员变量，在此处可以直接调用 fun String.lastChar() = get(length - 1) //为 Int 类声明一个扩展函数 doubleValue() ，用于返回其两倍值 //this 关键字代表了 Int 值本身 fun Int.doubleValue() = this * 2 之后，我们就可以像调用类本身内部声明的方法一样，直接调用扩展函数\nfun main() { val name = \u0026#34;leavesC\u0026#34; println(\u0026#34;$name lastChar is: \u0026#34; + name.lastChar()) val age = 24 println(\u0026#34;$age doubleValue is: \u0026#34; + age.doubleValue()) } 如果需要声明一个静态的扩展函数，则必须将其定义在伴生对象上，这样就可以在没有 Namer 实例的情况下调用其扩展函数，就如同在调用 Java 的静态函数一样\nclass Namer { companion object { val defaultName = \u0026#34;mike\u0026#34; } } fun Namer.Companion.getName(): String { return defaultName } fun main() { Namer.getName() } 需要注意的是，如果扩展函数声明于 class 内部，则该扩展函数只能该类和其子类内部调用，因为此时相当于声明了一个非静态函数，外部无法引用到。所以一般都是将扩展函数声明为全局函数\n2、扩展属性 扩展函数也可以用于属性\n//扩展函数也可以用于属性 //为 String 类新增一个属性值 customLen var String.customLen: Int get() = length set(value) { println(\u0026#34;set\u0026#34;) } fun main() { val name = \u0026#34;leavesC\u0026#34; println(name.customLen) name.customLen = 10 println(name.customLen) //7 //set //7 } 3、不可重写的扩展函数 看以下例子，子类 Button 重写了父类 View 的 click() 函数，此时如果声明一个 View 变量，并赋值为 Button 类型的对象，调用的 click() 函数将是 Button 类重写的方法\nfun main() { val view: View = Button() view.click() //Button clicked } open class View { open fun click() = println(\u0026#34;View clicked\u0026#34;) } class Button : View() { override fun click() = println(\u0026#34;Button clicked\u0026#34;) } 对于扩展函数来说，与以上的例子却不一样。如果基类和子类都分别定义了一个同名的扩展函数，此时要调用哪个扩展函数是由变量的静态类型来决定的，而非这个变量的运行时类型\nfun main() { val view: View = Button() view.longClick() //View longClicked } open class View { open fun click() = println(\u0026#34;View clicked\u0026#34;) } class Button : View() { override fun click() = println(\u0026#34;Button clicked\u0026#34;) } fun View.longClick() = println(\u0026#34;View longClicked\u0026#34;) fun Button.longClick() = println(\u0026#34;Button longClicked\u0026#34;) 此外，如果一个类的成员函数和扩展函数有相同的签名，成员函数会被优先使用\n扩展函数并不是真正地修改了原来的类，其底层其实是以静态导入的方式来实现的。扩展函数可以被声明在任何一个文件中，因此有个通用的实践是把一系列有关的函数放在一个新建的文件里\n需要注意的是，扩展函数不会自动地在整个项目范围内生效，如果需要使用到扩展函数，需要进行导入\n4、可空接收者 可以为可空的接收者类型定义扩展，即使接受者为 null，使得开发者在调用扩展函数前不必进行判空操作，且可以通过 this == null 来检查接收者是否为空\nfun main() { var name: String? = null name.check() //this == null name = \u0026#34;leavesC\u0026#34; name.check() //this != null } fun String?.check() { if (this == null) { println(\u0026#34;this == null\u0026#34;) return } println(\u0026#34;this != null\u0026#34;) } 十七、Lambda 表达式 Lambda 表达式本质上就是可以传递给其它函数的一小段代码，通过 Lambda 表达式可以把通用的代码结构抽取成库函数，也可以把 Lambda 表达式存储在一个变量中，把这个变量当做普通函数对待\n//由于存在类型推导，所以以下三种声明方式都是完全相同的 val plus1: (Int, Int) -\u0026gt; Int = { x: Int, y: Int -\u0026gt; x + y } val plus2: (Int, Int) -\u0026gt; Int = { x, y -\u0026gt; x + y } val plus3 = { x: Int, y: Int -\u0026gt; x + y } println(plus3(1, 2)) 一个 Lambda 表达式始终用花括号包围，通过箭头把实参列表和函数体分开 如果 Lambda 声明了函数类型，那么就可以省略函数体的类型声明 如果 Lambda 声明了参数类型，且返回值支持类型推导，那么就可以省略函数类型声明 虽然说倾向于尽量避免让 Lambda 表达式引用外部变量以避免副作用，但有些情况下让 Lambda 引用外部变量也可以简化计算结构。访问了外部环境变量的 Lambda 表达式称之为闭包，闭包可以被当做参数传递或者直接使用。与 Java 不同，kotlin 中的闭包不仅可以访问外部变量也可以对其进行修改\n例如，假设我们需要一个计算总和的方法，每次调用函数时都返回当前的总和大小。方法外部不提供保存当前总和的变量，由 Lambda 表达式内部进行存储\nfun main() { val sum = sumFunc() println(sum(10)) //10 println(sum(20)) //30 println(sum(30)) //60 } fun sumFunc(): (Int) -\u0026gt; Int { var base = 0 return fun(va: Int): Int { base += va return base } } 此外，kotlin 也支持一种自动运行的语法\n{ va1: Int, va2: Int -\u0026gt; println(va1 + va2) }(10, 20) Lambda 表达式最常见的用途就是和集合一起工作，看以下例子\n要从一个人员列表中取出年龄最大的一位\ndata class Person(val name: String, val age: Int) fun main() { val people = listOf(Person(\u0026#34;leavesC\u0026#34;, 24), Person(\u0026#34;Ye\u0026#34;, 22)) println(people.maxBy { it.age }) //Person(name=leavesC, age=24) } 当中，库函数 maxBy 可以在任何集合上调用，其需要一个实参：一个函数，用于指定要用来进行比较的函数。花括号中的代码 { it.age } 就是实现了这个逻辑的 Lambda 表达式\n上述 maxBy 函数的实参是简化后的写法，这里来看下 maxBy 函数的简化过程\n最原始的语法声明应该是这样的，用括号包裹着 Lambda 表达式\nprintln(people.maxBy({ p: Person -\u0026gt; p.age })) kotlin 有一种语法约定，如果 Lambda 表达式是函数调用的最后一个实参，可以将之放到括号的外边\nprintln(people.maxBy() { p: Person -\u0026gt; p.age }) 当 Lamdba 表达式是函数唯一的实参时，可以去掉调用代码中的空括号对\nprintln(people.maxBy { p: Person -\u0026gt; p.age }) 当 Lambda 表达式的参数类型是可以被推导出来时就可以省略声明参数类型\nprintln(people.maxBy { p -\u0026gt; p.age }) 如果当前上下文期待的是只有一个参数的 Lambda 表达式且参数类型可以被推断出来，就会为该参数生成一个默认名称：it\nprintln(people.maxBy { it.age }) kotlin 和 Java 的一个显著区别就是，在 kotlin 中函数内部的 Lambda 表达式不会仅限于访问函数的参数以及 final 变量，在 Lambda 内部也可以访问并修改非 final 变量\n从 Lambda 内部访问外部变量，我们称这些变量被 Lambda 捕捉。当捕捉 final 变量时，变量值和使用这个值的 Lambda 代码一起存储，对非 final 变量来说，其值被封装在一个特殊的包装器中，对这个包装器的引用会和 Lambda 代码一起存储\nvar number = 0 val list = listOf(10, 20, 30, 40) list.forEach { if (it \u0026gt; 20) { number++ } } println(number) //2 成员引用用于创建一个调用单个方法或者访问单个属性的函数值，通过双冒号把类名称和要引用的成员（一个方法或者一个属性）名称分隔开\n成员引用的一个用途就是：如果要当做参数传递的代码块已经被定义成了函数，此时不必专门创建一个调用该函数的 Lambda 表达式，可以直接通过成员引用的方式来传递该函数（也可以传递属性）。此外，成员引用对扩展函数一样适用\ndata class Person(val name: String, val age: Int) { val myAge = age fun getPersonAge() = age } fun Person.filterAge() = age fun main() { val people = listOf(Person(\u0026#34;leavesC\u0026#34;, 24), Person(\u0026#34;Ye\u0026#34;, 22)) println(people.maxBy { it.age }) //Person(name=leavesC, age=24) println(people.maxBy(Person::age)) //Person(name=leavesC, age=24) println(people.maxBy(Person::myAge)) //Person(name=leavesC, age=24) println(people.maxBy(Person::getPersonAge)) //Person(name=leavesC, age=24) println(people.maxBy(Person::filterAge)) //Person(name=leavesC, age=24) } 不管引用的是函数还是属性，都不要在成员引用的名称后面加括号\n此外，还可以引用顶层函数\nfun test() { println(\u0026#34;test\u0026#34;) } fun main() { val t = ::test } 也可以用构造方法引用存储或者延期执行创建类实例的动作\ndata class Person(val name: String, val age: Int) fun main() { val createPerson = ::Person val person = createPerson(\u0026#34;leavesC\u0026#34;, 24) println(person) } 十八、标准库中的扩展函数 kotlin 标准库中提供了几个比较实用的扩展函数，定义在 Standard 文件下\n1、run run 函数接收一个函数参数并以该函数的返回值作为 run 函数的返回值\n@kotlin.internal.InlineOnly public inline fun \u0026lt;T, R\u0026gt; T.run(block: T.() -\u0026gt; R): R { contract { callsInPlace(block, InvocationKind.EXACTLY_ONCE) } return block() } 用例\nfun main() { var nickName = \u0026#34;leavesC\u0026#34; nickName = nickName.run { if (isNotEmpty()) { this } else { \u0026#34;\u0026#34; } } println(nickName) } 2、with with 函数并不是扩展函数，不过由于作用相近，此处就一起介绍了。with 函数的第一个参数是接受者对象 receiver，第二个参数是在 receiver 对象类型上定义的扩展函数，所以可以在函数内部直接调用 receiver 其公开的方法和属性\n@kotlin.internal.InlineOnly public inline fun \u0026lt;T, R\u0026gt; with(receiver: T, block: T.() -\u0026gt; R): R { contract { callsInPlace(block, InvocationKind.EXACTLY_ONCE) } return receiver.block() } with 函数用于对同一个对象执行多次操作而不需要反复把对象的名称写出来\n例如，为了构建一个包含指定内容的字符串，需要先后如下调用\nfun main() { val result = StringBuilder() result.append(\u0026#34;leavesC\u0026#34;) result.append(\u0026#34;\\n\u0026#34;) for (letter in \u0026#39;A\u0026#39;..\u0026#39;Z\u0026#39;) { result.append(letter) } println(result.toString()) } 改为通过 with 函数来构建的话会代码会简洁许多\nval result = with(StringBuilder()) { append(\u0026#34;leavesC\u0026#34;) append(\u0026#34;\\n\u0026#34;) for (letter in \u0026#39;A\u0026#39;..\u0026#39;Z\u0026#39;) { append(letter) } toString() } println(result) with 函数是一个接受两个参数的函数，在这个例子中就是一个 StringBuilder 和一个 Lambda 表达式，这里利用了把 Lambda 表达式放在括号外的约定\nwith 函数的返回值是执行 Lambda 表达式的结果，该结果就是 Lambda 中的最后一个表达式的返回值，因此如果将代码修改为如下所示的话，因为 println() 方法无返回值，所以打印出来的内容将是 kotlin.Unit\nval result = with(StringBuilder()) { append(\u0026#34;leavesC\u0026#34;) append(\u0026#34;\\n\u0026#34;) for (letter in \u0026#39;A\u0026#39;..\u0026#39;Z\u0026#39;) { append(letter) } println(\u0026#34;Hello\u0026#34;) } println(result) //kotin.Unit 3、apply apply 函数被声明为类型 T 的扩展函数，它的接收者是作为实参的 Lambda 的接受者，最终函数返回 this 即对象本身\n@kotlin.internal.InlineOnly public inline fun \u0026lt;T\u0026gt; T.apply(block: T.() -\u0026gt; Unit): T { contract { callsInPlace(block, InvocationKind.EXACTLY_ONCE) } block() return this } 所以apply 函数和 with 函数的唯一区别在于：apply 函数始终会返回作为实参传递给它的对象\nval result = StringBuilder().apply { append(\u0026#34;leavesC\u0026#34;) append(\u0026#34;\\n\u0026#34;) for (letter in \u0026#39;A\u0026#39;..\u0026#39;Z\u0026#39;) { append(letter) } toString() } println(result) println(result.javaClass) //class java.lang.StringBuilder 4、also also 函数接收一个函数类型的参数，该参数又以接收者本身作为参数，最终返回接收者对象本身\n@kotlin.internal.InlineOnly @SinceKotlin(\u0026#34;1.1\u0026#34;) public inline fun \u0026lt;T\u0026gt; T.also(block: (T) -\u0026gt; Unit): T { contract { callsInPlace(block, InvocationKind.EXACTLY_ONCE) } block(this) return this } 用例\nfun main() { val nickName = \u0026#34;leavesC\u0026#34; val also = nickName.also { it.length } println(also) //leavesC } 5、let let 函数接收一个函数类型的参数，该参数又以接收者本身作为参数，最终返回函数的求值结果\n@kotlin.internal.InlineOnly public inline fun \u0026lt;T, R\u0026gt; T.let(block: (T) -\u0026gt; R): R { contract { callsInPlace(block, InvocationKind.EXACTLY_ONCE) } return block(this) } 用例\nfun main() { val nickName = \u0026#34;leavesC\u0026#34; val also = nickName.let { it.length } println(also) //7 } 6、takeIf takeIf 接收一个返回值类型为 bool 的函数，当该参数返回值为 true 时返回接受者对象本身，否则返回 null\n@kotlin.internal.InlineOnly @SinceKotlin(\u0026#34;1.1\u0026#34;) public inline fun \u0026lt;T\u0026gt; T.takeIf(predicate: (T) -\u0026gt; Boolean): T? { contract { callsInPlace(predicate, InvocationKind.EXACTLY_ONCE) } return if (predicate(this)) this else null } 用例\nfun main() { println(check(\u0026#34;leavesC\u0026#34;)) //7 println(check(null)) //0 } fun check(name: String?): Int { return name.takeIf { !it.isNullOrBlank() }?.length ?: 0 } 7、takeUnless takeUnless 的判断条件与 takeIf 相反，这里不再赘述\n@kotlin.internal.InlineOnly @SinceKotlin(\u0026#34;1.1\u0026#34;) public inline fun \u0026lt;T\u0026gt; T.takeUnless(predicate: (T) -\u0026gt; Boolean): T? { contract { callsInPlace(predicate, InvocationKind.EXACTLY_ONCE) } return if (!predicate(this)) this else null } 十九、函数操作符 1、总数操作符 1、any 如果至少有一个元素符合给出的判断条件，则返回 true\nval list = listOf(1, 3, 5, 7, 9) println(list.any { it \u0026gt; 13 }) //false println(list.any { it \u0026gt; 7 }) //true 2、all 如果全部的元素符合给出的判断条件，则返回 true\nval list = listOf(1, 3, 5, 7, 9) println(list.all { it \u0026gt; 13 }) //false println(list.all { it \u0026gt; 0 }) //true 3、count 返回符合给出判断条件的元素总数\nval list = listOf(1, 3, 5, 7, 9) println(list.count { it \u0026gt; 7 }) //1 println(list.count { it \u0026gt; 2 }) //4 4、fold 在一个初始值的基础上从第一项到最后一项通过一个函数累计所有的元素\nfun main() { val list = listOf(1, 3, 5, 7, 9) println(list.fold(2) { total, next-\u0026gt; println(\u0026#34;$next , $total\u0026#34;) next + total }) } 1 , 2 3 , 3 5 , 6 7 , 11 9 , 18 27 5、foldRight 与 fold 一样，但顺序是从最后一项到第一项\nval list = listOf(1, 3, 5, 7, 9) println(list.foldRight(2) { next, total-\u0026gt; println(\u0026#34;$next , $total\u0026#34;) next + total }) 9 , 2 7 , 11 5 , 18 3 , 23 1 , 26 27 6、forEach val list = listOf(1, 3, 5, 7, 9) list.forEach { print(it + 1) } //246810 7、forEachIndexed 类似于 forEach ，同时可以得到元素的索引\nval list = listOf(1, 3, 5, 7, 9) list.forEachIndexed { index, value -\u0026gt; println(\u0026#34;$index value is $value\u0026#34;) } 0 value is 1 1 value is 3 2 value is 5 3 value is 7 4 value is 9 8、max 返回最大的一项，如果没有则返回null\nval list = listOf(1, 3, 5, 7, 9) println(list.max()) //9 9、maxBy 根据给定的函数返回最大的一项，如果没有则返回 null\nval list = listOf(1, 3, 5, 7, 9) println(list.maxBy { -it }) //1 10、min 返回最小的一项，如果没有则返回null\nval list = listOf(1, 3, 5, 7, 9) println(list.min()) //1 11、minBy 根据给定的函数返回最小的一项，如果没有则返回null\nval list = listOf(1, 3, 5, 7, 9) println(list.minBy { -it }) //9 12、none 如果没有任何元素与给定的函数匹配，则返回true\nval list = listOf(1, 3, 5, 7, 9) println(list.none { it \u0026gt; 10 }) //true 13、reduce 与 fold 一样，但是没有一个初始值。通过一个函数从第一项到最后一项进行累计\nval list = listOf(1, 3, 5, 7, 9) println(list.reduce { total, next -\u0026gt; println(\u0026#34;$next , $total\u0026#34;) total + next }) 3 , 1 5 , 4 7 , 9 9 , 16 25 14、reduceRight 与 reduce 一样，但是顺序是从最后一项到第一项\nval list = listOf(1, 3, 5, 7, 9) println(list.reduceRight { next, total -\u0026gt; println(\u0026#34;$next , $total\u0026#34;) total + next }) 7 , 9 5 , 16 3 , 21 1 , 24 25 15、sumBy 返回所有每一项通过函数转换之后的数据的总和\nval list = listOf(1, 3, 5, 7, 9) println(list.sumBy { it + 1 }) //30 2、过滤操作符 1、drop 返回包含去掉前n个元素的所有元素的列表\nval list = listOf(1, 3, 5, 7, 9) println(list.drop(2)) //[5, 7, 9] 2、dropWhile 返回从第一个开始不符合给定函数的元素起之后的列表\nval list = listOf(1, 3, 5, 7, 9, 2) println(list.dropWhile { it \u0026lt; 4 }) //[5, 7, 9, 2] 3、dropLastWhile 从最后一项开始，返回从开始不符合给定函数的元素起之后的列表\nval list = listOf(10, 1, 3, 5, 7, 9) println(list.dropLastWhile { it \u0026gt; 4 }) //[10, 1, 3] 4、filter 过滤所有符合给定函数条件的元素\nval list = listOf(1, 3, 5, 7, 9, 2) println(list.filter { it \u0026lt; 4 }) //[1, 3, 2] 5、filterNot 过滤所有不符合给定函数条件的元素\nval list = listOf(1, 3, 5, 7, 9, 2) println(list.filterNot { it \u0026lt; 4 }) //[5, 7, 9] 6、filterNotNull 过滤所有元素中不是null的元素\nval list = listOf(1, 3, 5, 7, 9, 2, null) println(list.filterNotNull()) //[1, 3, 5, 7, 9, 2] 7、slice 过滤一个list中指定index的元素\nval list = listOf(1, 3, 5, 7, 9, 2, null) println(list.slice(listOf(0, 3))) //[1, 7] 8、take 返回从第一个开始的n个元素\nval list = listOf(1, 3, 5, 7, 9, 2, null) println(list.take(2)) //[1, 3] 9、takeLast 返回从最后一个开始的n个元素\nval list = listOf(1, 3, 5, 7, 9, 2, null) println(list.takeLast(2)) //[2, null] 10、takeWhile 返回从第一个开始符合给定函数条件的元素。\nval list = listOf(1, 3, 5, -1, 7, 9, 2) println(list.takeWhile { it \u0026gt; 2 }) //[] println(list.takeWhile { it \u0026gt; 0 }) //[1, 3, 5] 3、映射操作符 1、flatMap 遍历所有的元素，为每一个创建一个集合，最后把所有的集合放在一个集合中\nval list = listOf(1, 3, 5, -1, 7, 9, 2) println(list.flatMap { listOf(it, it + 1) }) //[1, 2, 3, 4, 5, 6, -1, 0, 7, 8, 9, 10, 2, 3] 2、groupBy 返回一个根据给定函数分组后的map\nval list = listOf(1, 3, 5, -1, 7, 9, 2) println(list.groupBy { listOf(it) }) //{[1]=[1], [3]=[3], [5]=[5], [-1]=[-1], [7]=[7], [9]=[9], [2]=[2]} println(list.groupBy { listOf(it, it + 1) }) //{[1, 2]=[1], [3, 4]=[3], [5, 6]=[5], [-1, 0]=[-1], [7, 8]=[7], [9, 10]=[9], [2, 3]=[2]} 3、map 返回一个每一个元素根据给定的函数转换所组成的List。\nval list = listOf(1, 3, 5, -1, 7, 9, 2) println(list.map { listOf(it) }) //[[1], [3], [5], [-1], [7], [9], [2]] println(list.map { listOf(it, it + 1) }) //[[1, 2], [3, 4], [5, 6], [-1, 0], [7, 8], [9, 10], [2, 3]] 4、mapIndexed 返回一个每一个元素根据给定的包含元素index的函数转换所组成的List\nval list = listOf(1, 3, 5, -1, 7, 9, 2) println(list.mapIndexed { index, value -\u0026gt; index }) //[0, 1, 2, 3, 4, 5, 6] println(list.mapIndexed { index, value -\u0026gt; index * value }) //[0, 3, 10, -3, 28, 45, 12] 5、mapNotNull 返回一个每一个非null元素根据给定的函数转换所组成的List\nval list = listOf(1, 3, 5, -1, 7, 9, null, 2) println(list.mapNotNull { it }) //[1, 3, 5, -1, 7, 9, 2] 4、元素操作符 1、contains 如果指定元素可以在集合中找到，则返回true\nval list = listOf(1, 3, 5, -1, 7, 9, null, 2) println(list.contains(3)) //true println(list.contains(13)) //false 2、elementAt 返回给定index对应的元素，如果index数组越界则会抛出 IndexOutOfBoundsException\nval list = listOf(1, 3, 5, -1, 7, 9, null, 2) println(list.elementAt(3)) //-1 println(list.elementAt(6)) //null 3、elementAtOrElse 返回给定index对应的元素，如果index数组越界则会根据给定函数返回默认值\nval list = listOf(1, 3, 5, -1, 7, 9, null, 2) println(list.elementAtOrElse(3, { it * 2 })) //-1 println(list.elementAtOrElse(16, { it * 2 })) //32 4、elementAtOrNull 返回给定index对应的元素，如果index数组越界则会返回null\nval list = listOf(1, 3, 5, -1, 7, 9, null, 2) println(list.elementAtOrNull(3)) //-1 println(list.elementAtOrNull(16)) //null 5、first 返回符合给定函数条件的第一个元素\nval list = listOf(1, 3, 5, -1, 7, 9, 2) println(list.first { it % 3 == 0 }) //3 6、firstOrNull 返回符合给定函数条件的第一个元素，如果没有符合则返回null\nval list = listOf(1, 3, 5, -1, 7, 9, 2) println(list.firstOrNull { it % 3 == 0 }) //3 println(list.firstOrNull { it % 8 == 0 }) //null 7、indexOf 返回指定元素的第一个index，如果不存在，则返回 -1\nval list = listOf(1, 3, 5, -1, 7, 9, 2) println(list.indexOf(5)) //2 println(list.indexOf(12)) //-1 8、indexOfFirst 返回第一个符合给定函数条件的元素的index，如果没有符合则返回 -1\nval list = listOf(1, 3, 5, 1, 7, 9, 2) println(list.indexOfFirst { it % 2 == 0 }) //6 println(list.indexOfFirst { it % 12 == 0 }) //-1 9、indexOfLast 返回最后一个符合给定函数条件的元素的index，如果没有符合则返回 -1\nval list = listOf(1, 3, 5, 6, 7, 9, 2) println(list.indexOfLast { it % 2 == 0 }) //6 println(list.indexOfLast { it % 12 == 0 }) //-1 10、last 返回符合给定函数条件的最后一个元素\nval list = listOf(1, 3, 5, 6, 7, 9, 2) println(list.last { it % 2 == 0 }) //2 println(list.last { it % 3 == 0 }) //9 11、lastIndexOf 返回指定元素的最后一个index，如果不存在，则返回 -1\nval list = listOf(1, 3, 2, 6, 7, 9, 2) println(list.lastIndexOf(2)) //6 println(list.lastIndexOf(12)) //-1 12、lastOrNull 返回符合给定函数条件的最后一个元素，如果没有符合则返回null\nval list = listOf(1, 3, 2, 6, 7, 9, 2) println(list.lastOrNull { it / 3 == 3 }) //9 println(list.lastOrNull { it == 10 }) //null 13、single 返回符合给定函数的单个元素，如果没有符合或者超过一个，则抛出异常\nval list = listOf(1, 9, 2, 6, 7, 9, 2) println(list.single { it % 7 == 0 }) //7 println(list.single { it == 2 }) //IllegalArgumentException 14、singleOrNull 返回符合给定函数的单个元素，如果没有符合或者超过一个，则返回null\nval list = listOf(1, 9, 2, 6, 7, 9, 2) println(list.singleOrNull { it % 7 == 0 }) //7 println(list.singleOrNull { it == 2 }) //null 5、生产操作符 1、partition 把一个给定的集合分割成两个，第一个集合是由原集合每一项元素匹配给定函数条 件返回 true 的元素组成，第二个集合是由原集合每一项元素匹配给定函数条件返回 false 的元素组成\nval list = listOf(1, 9, 2, 6, 7, 9, 2) val (list1, list2) = list.partition { it % 2 == 0 } println(list1) //[2, 6, 2] println(list2) //[1, 9, 7, 9] 2、plus 返回一个包含原集合和给定集合中所有元素的集合，因为函数的名字原因，我们可以使用 + 操作符\nval list1 = listOf(1, 9, 2, 6, 7, 9, 2) val list2 = listOf(1, 2, 4, 6, 8, 10) println(list1.plus(list2)) //[1, 9, 2, 6, 7, 9, 2, 1, 2, 4, 6, 8, 10] println(list1 + list2) //[1, 9, 2, 6, 7, 9, 2, 1, 2, 4, 6, 8, 10] 3、zip 返回由 pair 组成的List，每个 pair 由两个集合中相同index的元素组成。这个返回的List的大小由最小的那个集合决定\nval list1 = listOf(1, 9, 2, 6, 7, 9, 2) val list2 = listOf(1, 2, 4, 6, 8, 10) val list3 = list1.zip(list2) println(list3.javaClass) println(list3.get(0).javaClass) println(\u0026#34;${list3.get(0).first} , ${list3.get(0).second}\u0026#34;) list3.forEach { println(it) } class java.util.ArrayList class kotlin.Pair 1 , 1 (1, 1) (9, 2) (2, 4) (6, 6) (7, 8) (9, 10) 4、unzip 从包含pair的List中生成包含List的Pair\nval list1 = listOf(Pair(\u0026#34;leavesC\u0026#34;, 1), Pair(\u0026#34;leavesC_2\u0026#34;, 2), Pair(\u0026#34;leavesC_3\u0026#34;, 3)) val list2 = list1.unzip() println(list2.javaClass) println(list2.first) println(list2.second) class kotlin.Pair [leavesC, leavesC_2, leavesC_3] [1, 2, 3] 6、顺序操作符 1、reverse 返回一个与指定list相反顺序的list\nval list1 = listOf(Pair(\u0026#34;leavesC\u0026#34;, 1), Pair(\u0026#34;leavesC_2\u0026#34;, 2), Pair(\u0026#34;leavesC_3\u0026#34;, 3)) val list2 = list1.reversed() println(list2) //[(leavesC_3, 3), (leavesC_2, 2), (leavesC, 1)] 2、sort 返回一个自然排序后的list\nval list1 = listOf(2, 4, 1, 9, 5, 10) val list2 = list1.sorted() println(list2) //[1, 2, 4, 5, 9, 10] val list3 = listOf(\u0026#34;a\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;ab\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;cdd\u0026#34;, \u0026#34;cda\u0026#34;) val list4 = list3.sorted() println(list4) //[a, ab, b, c, cda, cdd] 3、sortBy 返回一个根据指定函数排序后的list\nval list1 = listOf(2, 4, 1, 9, 5, 10) val list2 = list1.sortedBy { it - 3 } println(list2) //[1, 2, 4, 5, 9, 10] 4、sortDescending 返回一个降序排序后的List\nval list1 = listOf(2, 4, 1, 9, 5, 10) val list2 = list1.sortedDescending() println(list2) //[10, 9, 5, 4, 2, 1] 5、sortDescendingBy 返回一个根据指定函数降序排序后的list\nval list1 = listOf(2, 4, 1, 9, 5, 10) val list2 = list1.sortedByDescending { it % 2 } println(list2) //[1, 9, 5, 2, 4, 10] 二十、异常 kotlin 中异常处理的基本形式和 Java 类似\nfun compute(index: Int): Boolean { if (index !in 0..10) { throw IllegalArgumentException(\u0026#34;参数错误\u0026#34;) } return true } 和 Java 不同的是，kotlin 中 throw 结构是一个表达式，可以作为另一个表达式的一部分来使用\n例如下面这个例子，如果条件不满足，则将抛出异常，从而导致 status 变量也不会初始化\nval status = if (index in 0..10) index else throw IllegalArgumentException(\u0026#34;参数错误\u0026#34;) 此外，在 Java 中对于受检异常必须显式地处理，通过 try/catch 语句捕获异常或者是抛给其调用者来处理。而 kotlin 不区分受检异常和未受检异常，不用指定函数抛出的异常，可以处理也可以不处理异常\n在 kotlin 中 ，try 关键字引入了一个表达式，从而可以把表达式的值赋给一个变量。如果一个 try 代码块执行正常，代码块中最后一个表达式就是结果，如果捕获到了一个异常，则相应 catch 代码块中最后一个表达式就是结果\n看以下例子，如果 try 表达式包裹的表达式会抛出异常，则返回值为 null ，否则为 true\nfun main() { compute(5) //fun end : true compute(100) //fun end : null } fun compute(index: Int) { val status = try { if (index in 0..10) true else throw IllegalArgumentException(\u0026#34;参数错误\u0026#34;) } catch (e: Exception) { null } println(\u0026#34;fun end : \u0026#34; + status) } 但是，如果在 catch 语句中使用 return 结束了 compute 函数，则没有任何输出\nfun main() { compute(5) //fun end : true compute(100) //没有任何输出 } fun compute(index: Int) { val status = try { if (index in 0..10) true else throw IllegalArgumentException(\u0026#34;参数错误\u0026#34;) } catch (e: Exception) { return } println(\u0026#34;fun end : \u0026#34; + status) } 二十一、运算符重载 kotlin 允许为类型提供预定义的操作符实现，这些操作符具有固定的符号表示（例如 + 和 * ）和固定的优先级，通过操作符重载可以将操作符的行为映射到指定的方法。为实现这样的操作符，需要为类提供一个固定名字的成员函数或扩展函数，相应的重载操作符的函数需要用 operator 修饰符标记\n1、一元操作符 操作符 函数 +a a.unaryPlus() -a a.unaryMinus() !a a.not() a++ a.inc() a\u0026ndash; a.dec() 2、二元操作符 操作符 函数 a + b a.plus(b) a - b a.minus(b) a * b a.times(b) a / b a.div(b) a % b a.rem(b) a..b a.rangeTo(b) a in b b.contains(a) a !in b !b.contains(a) a += b a.plusAssign(b) a -= b a.minusAssign(b) a *= b a.timesAssign(b) a /= b a.divAssign(b) a %= b a.remAssign(b) 3、数组操作符 操作符 函数 a[i] a.get(i) a[i, j] a.get(i, j) a[i_1, \u0026hellip;, i_n] a.get(i_1, \u0026hellip;, i_n) a[i] = b a.set(i, b) a[i, j] = b a.set(i, j, b) a[i_1, \u0026hellip;, i_n] = b a.set(i_1, \u0026hellip;, i_n, b) 4、等于操作符 操作符 函数 a == b a?.equals(b) ?: b === null a != b !(a?.equals(b) ?: b === null) 相等操作符有一点不同，为了达到正确合适的相等检查做了更复杂的转换，因为要得到一个确切的函数结构比较，不仅仅是指定的名称\n方法必须要如下准确地被实现：\noperator fun equals(other: Any?): Boolean 操作符 === 和 !== 用来做身份检查（它们分别是 Java 中的 == 和 != ），并且它们不能被重载\n5、比较操作符 操作符 函数 a \u0026gt; b a.compareTo(b) \u0026gt; 0 a \u0026lt; b a.compareTo(b) \u0026lt; 0 a \u0026gt;= b a.compareTo(b) \u0026gt;= 0 a \u0026lt;= b a.compareTo(b) \u0026lt;= 0 所有的比较都转换为对 compareTo 的调用，这个函数需要返回 Int 值\n6、函数调用 方法 调用 a() a.invoke() a(i) a.invoke(i) a(i, j) a.invoke(i, j) a(i_1, \u0026hellip;, i_n) a.invoke(i_1, \u0026hellip;, i_n) 7、例子 看几个例子\ndata class Point(val x: Int, val y: Int) { //+Point operator fun unaryPlus() = Point(+x, +y) //Point++ / ++Point operator fun inc() = Point(x + 1, y + 1) //Point + Point operator fun plus(point: Point) = Point(x + point.x, y + point.y) //Point + Int operator fun plus(value: Int) = Point(x + value, y + value) //Point[index] operator fun get(index: Int): Int { return when (index) { 0 -\u0026gt; x 1 -\u0026gt; y else -\u0026gt; throw IndexOutOfBoundsException(\u0026#34;无效索引\u0026#34;) } } //Point(index) operator fun invoke(index: Int) = when (index) { 0 -\u0026gt; x 1 -\u0026gt; y else -\u0026gt; throw IndexOutOfBoundsException(\u0026#34;无效索引\u0026#34;) } } fun main() { //+Point(x=10, y=-20) = Point(x=10, y=-20) println(\u0026#34;+${Point(10, -20)} = ${+Point(10, -20)}\u0026#34;) //Point(x=10, y=-20)++ = Point(x=10, y=-20) var point = Point(10, -20) println(\u0026#34;${Point(10, -20)}++ = ${point++}\u0026#34;) //++Point(x=10, y=-20) = Point(x=11, y=-19) point = Point(10, -20) println(\u0026#34;++${Point(10, -20)} = ${++point}\u0026#34;) //Point(x=10, y=-20) + Point(x=10, y=-20) = Point(x=20, y=-40) println(\u0026#34;${Point(10, -20)} + ${Point(10, -20)} = ${Point(10, -20) + Point(10, -20)}\u0026#34;) //Point(x=10, y=-20) + 5 = Point(x=15, y=-15) println(\u0026#34;${Point(10, -20)} + ${5} = ${Point(10, -20) + 5}\u0026#34;) point = Point(10, -20) //point[0] value is: 10 println(\u0026#34;point[0] value is: ${point[0]}\u0026#34;) //point[1] value is: -20 println(\u0026#34;point[1] value is: ${point[1]}\u0026#34;) //point(0) values is: 10 println(\u0026#34;point(0) values is: ${point(0)}\u0026#34;) } 二十二、中缀调用与解构声明 1、中缀调用 可以以以下形式创建一个 Map 变量\nfun main() { val maps = mapOf(1 to \u0026#34;leavesC\u0026#34;, 2 to \u0026#34;ye\u0026#34;, 3 to \u0026#34;https://juejin.cn/user/923245496518439\u0026#34;) maps.forEach { key, value -\u0026gt; println(\u0026#34;key is : $key , value is : $value\u0026#34;) } } 使用 “to” 来声明 map 的 key 与 value 之间的对应关系，这种形式的函数调用被称为中缀调用\nkotlin 标准库中对 to 函数的声明如下所示，其作为扩展函数存在，且是一个泛型函数，返回值 Pair 最终再通过解构声明分别将 key 和 value 传给 Map\npublic infix fun \u0026lt;A, B\u0026gt; A.to(that: B): Pair\u0026lt;A, B\u0026gt; = Pair(this, that) 中缀调用只能与只有一个参数的函数一起使用，无论是普通的函数还是扩展函数。中缀符号需要通过 infix 修饰符来进行标记\nfun main() { val pair = 10 test \u0026#34;leavesC\u0026#34; val pair2 = 1.2 test 20 println(pair2.javaClass) //class kotlin.Pair } infix fun Any.test(other: Any) = Pair(this, other) 对于 mapOf 函数来说，它可以接收不定数量的 Pair 类型对象，因此我们也可以通过自定义的中缀调用符 test 来创建一个 map 变量\npublic fun \u0026lt;K, V\u0026gt; mapOf(vararg pairs: Pair\u0026lt;K, V\u0026gt;): Map\u0026lt;K, V\u0026gt; = if (pairs.size \u0026gt; 0) pairs.toMap(LinkedHashMap(mapCapacity(pairs.size))) else emptyMap() val map = mapOf(10 test \u0026#34;leavesC\u0026#34;, 20 test \u0026#34;hello\u0026#34;) 2、解构声明 有时会有把一个对象拆解成多个变量的需求，在 kotlin 中这种语法称为解构声明\n例如，以下例子将 Person 变量结构为了两个新变量：name 和 age，并且可以独立使用它们\ndata class Person(val name: String, val age: Int) fun main() { val (name, age) = Person(\u0026#34;leavesC\u0026#34;, 24) println(\u0026#34;Name: $name , age: $age\u0026#34;) //Name: leavesC , age: 24 } 一个解构声明会被编译成以下代码：\nval name = person.component1() val age = person.component2() 其中的 component1() 和 component2() 函数是在 kotlin 中广泛使用的约定原则的另一个例子。任何表达式都可以出现在解构声明的右侧，只要可以对它调用所需数量的 component 函数即可\n需要注意的是，componentN() 函数需要用 operator 关键字标记，以允许在解构声明中使用它们\n对于数据类来说，其自动生成了 componentN() 函数，而对非数据类，为了使用解构声明，需要我们自己来手动声明函数\nclass Point(val x: Int, val y: Int) { operator fun component1() = x operator fun component2() = y } fun main() { val point = Point(100, 200) val (x, y) = point println(\u0026#34;x: $x , y: $y\u0026#34;) //x: 100 , y: 200 } 如果我们需要从一个函数返回两个或者更多的值，这时候使用解构声明就会比较方便了\n这里使用的是标准类 Pair 来包装要传递的数据，当然，也可以自定义数据类\nfun computer(): Pair\u0026lt;String, Int\u0026gt; { //各种计算 return Pair(\u0026#34;leavesC\u0026#34;, 24) } fun main() { val (name, age) = computer() println(\u0026#34;Name: $name , age: $age\u0026#34;) } 此外，解构声明也可以用在 for 循环中\nval list = listOf(Person(\u0026#34;leavesC\u0026#34;, 24), Person(\u0026#34;leavesC\u0026#34;, 25)) for ((name, age) in list) { println(\u0026#34;Name: $name , age: $age\u0026#34;) } 对于遍历 map 同样适用\nval map = mapOf(\u0026#34;leavesC\u0026#34; to 24, \u0026#34;ye\u0026#34; to 25) for ((name, age) in map) { println(\u0026#34;Name: $name , age: $age\u0026#34;) } 同样也适用于 lambda 表达式\nval map = mapOf(\u0026#34;leavesC\u0026#34; to 24, \u0026#34;ye\u0026#34; to 25) map.mapKeys { (key, value) -\u0026gt; println(\u0026#34;key : $key , value : $value\u0026#34;) } 如果在解构声明中不需要某个变量，那么可以用下划线取代其名称，此时不会调用相应的 componentN() 操作符函数\nval map = mapOf(\u0026#34;leavesC\u0026#34; to 24, \u0026#34;ye\u0026#34; to 25) for ((_, age) in map) { println(\u0026#34;age: $age\u0026#34;) } 二十三、Object 关键字 1、对象声明 在 kotlin 的世界中，可以通过对象声明这一功能来实现 Java 中的单例模式，将类声明与该类的单一实例声明结合到一起。与类一样，一个对象声明可以包含属性、方法、初始化语句块等的声明，且可以继承类和实现接口，唯一不被允许的是构造方法\n与普通类的实例不同，对象声明在定义的时候就被立即创建了，不需要在代码的其它地方调用构造方法，因此为对象声明定义构造方法是没有意义的\ninterface Fly { fun fly() } open class Eat { fun eat() { println(\u0026#34;eat\u0026#34;) } } object Animal : Eat(), Fly { override fun fly() { println(\u0026#34;fly\u0026#34;) } } fun main() { Animal.fly() Animal.eat() } kotlin 中的对象声明被编译成了通过静态字段来持有它的单一实例的类，这个字段名字始终都是 INSTANCE\n例如，对于 kotlin 中的如下两个对象声明\nclass Test { object SingleClass { val names = arrayListOf\u0026lt;String\u0026gt;() } object SingleClass2 { val names = arrayListOf\u0026lt;String\u0026gt;() } } 在 Java 代码中来访问这两个对象\npublic static void main(String[] args) { Test.SingleClass.INSTANCE.getNames(); Test.SingleClass2.INSTANCE.getNames(); } 2、伴生对象 如果需要一个可以在没有类实例的情况下调用但是需要访问类内部的函数（类似于 Java 中的静态变量/静态函数），可以将其写成那个类中的对象声明的成员\n通过关键字 companion ，就可以获得通过容器类名称来访问这个对象的方法和属性的能力，不再需要显式地指明对象的名称\nclass Test { companion object { const val NAME = \u0026#34;\u0026#34; fun testFun() { } } } fun main() { Test.NAME Test.testFun() } 1、工厂模式 可以利用伴生对象来实现工厂模式\nprivate class User private constructor(val name: String) { companion object { fun newById(id: Int) = User(id.toString()) fun newByDouble(double: Double) = User(double.toString()) } } fun main() { //构造函数私有，无法创建 //val user1 = User(\u0026#34;leavesC\u0026#34;) val user2 = User.newById(10) val user3 = User.newByDouble(1.3) } 2、指定名称 伴生对象既可以为其指定名字，也可以直接使用其默认名 Companion，在引用伴生对象时，可以自由选择是否要在类名后加上伴生对象名\n如果使用的是其默认名 Companion（没有自定义名称），则以下两种引用方式都是等价的\nval user2 = User.Companion.newById(10) val user3 = User.newByDouble(1.3) 如果为伴生对象声明了自定义名称，引用方式等同\nprivate class User private constructor(val name: String) { companion object UserLoader { fun newById(id: Int) = User(id.toString()) fun newByDouble(double: Double) = User(double.toString()) } } fun main() { //构造函数私有，无法创建 //val user1 = User(\u0026#34;leavesC\u0026#34;) val user2 = User.UserLoader.newById(10) val user3 = User.newByDouble(1.3) } 3、实现接口 伴生对象也可以实现接口，且可以直接将包含它的类的名字当做实现了该接口的对象实例来使用\nprivate class User private constructor(val name: String) { companion object UserLoader : Runnable { override fun run() { } } } fun newThread(runnable: Runnable) = Thread(runnable) fun main() { //User 会直接被当做 Runnable 的实例 val thread = newThread(User) val thread2 = newThread(User.UserLoader) } 3、对象表达式 object 能用来声明匿名对象，可用于替代 Java 中的匿名内部类，且对象表达式中的代码可以访问并修改其外部的非 final 型的变量\nfun newThread(runnable: Runnable) = Thread(runnable) fun main() { var count = 0 val thread = newThread(object : Runnable { override fun run() { count++ } }) } 二十四、委托 1、委托模式 委托模式是一种基本的设计模式，该模式下有两个对象参与处理同一个请求，接受请求的对象将请求委托给另一个对象来处理。kotlin 原生支持委托模式，可以零样板代码来实现，通过关键字 by 实现委托\ninterface Printer { fun print() } class DefaultPrinter : Printer { override fun print() { println(\u0026#34;DefaultPrinter print\u0026#34;) } } class CustomPrinter(val printer: Printer) : Printer by printer fun main() { val printer = CustomPrinter(DefaultPrinter()) printer.print() //DefaultPrinter print } CustomPrinter 的 by 子句表示将会在 CustomPrinter 中存储 printer 变量，并且编译器将为 CustomPrinter 隐式生成 Printer 接口的所有抽象方法，并将这些方法的调用操作转发给 printer\n此外，CustomPrinter 也可以决定自己实现部分方法或全部自己实现，但重写的成员不会在委托对象的成员中调用 ，委托对象的成员只能访问其自身对接口成员实现\ninterface Printer { val message: String fun print() fun reprint() } class DefaultPrinter : Printer { override val message: String = \u0026#34;DefaultPrinter message\u0026#34; override fun print() { println(message) } override fun reprint() { println(\u0026#34;DefaultPrinter reprint\u0026#34;) } } class CustomPrinter(val printer: Printer) : Printer by printer { override val message: String = \u0026#34;CustomPrinter message\u0026#34; override fun reprint() { println(\u0026#34;CustomPrinter reprint\u0026#34;) } } fun main() { val printer = CustomPrinter(DefaultPrinter()) printer.print() //DefaultPrinter message printer.reprint() //CustomPrinter reprint } 2、属性委托 kotlin 支持通过委托属性将对一个属性的访问操作委托给另外一个对象来完成，对应的语法格式是：\nval/var \u0026lt;属性名\u0026gt;: \u0026lt;类型\u0026gt; by \u0026lt;表达式\u0026gt; 属性的委托不必实现任何的接口，但需要提供一个 getValue() 方法与 setValue()（对于 var 属性），对一个属性的 get 和 set 操作会被委托给属性的委托的这两个方法\nclass Delegate { //第一个参数表示被委托的对象、第二个参数表示被委托对象自身的描述 operator fun getValue(thisRef: Any?, property: KProperty\u0026lt;*\u0026gt;): String { } //第一个参数表示被委托的对象、第二个参数表示被委托对象自身的描述，第三个参数是将要赋予的值 operator fun setValue(thisRef: Any?, property: KProperty\u0026lt;*\u0026gt;, value: String) { } } 看以下的小例子，通过输出值就可以看出各个方法的调用时机\npackage test import kotlin.reflect.KProperty class Delegate { private var message: String? = null operator fun getValue(thisRef: Any?, property: KProperty\u0026lt;*\u0026gt;): String { println(\u0026#34;${thisRef?.javaClass?.name}, thank you for delegating \u0026#39;${property.name}\u0026#39; to me!\u0026#34;) return message ?: \u0026#34;null value\u0026#34; } operator fun setValue(thisRef: Any?, property: KProperty\u0026lt;*\u0026gt;, value: String) { println(\u0026#34;$value has been assigned to \u0026#39;${property.name}\u0026#39; in ${thisRef?.javaClass?.name}.\u0026#34;) message = value } } class Example { var strValue: String by Delegate() } fun main() { val example = Example() println(example.strValue) example.strValue = \u0026#34;leaveC\u0026#34; println(example.strValue) // test.Example, thank you for delegating \u0026#39;strValue\u0026#39; to me! // null value // leaveC has been assigned to \u0026#39;strValue\u0026#39; in test.Example. // test.Example, thank you for delegating \u0026#39;strValue\u0026#39; to me! // leaveC } 3、延迟属性 lazy() 是接受一个 lambda 并返回一个 Lazy \u0026lt; T \u0026gt; 实例的函数，返回的实例可以作为实现延迟属性的委托，第一次调用 get() 会执行已传递给 lazy() 函数的 lambda 表达式并记录结果， 后续调用 get() 只是返回记录的结果\nclass Example { val lazyValue1: String by lazy { println(\u0026#34;lazyValue1 computed!\u0026#34;) \u0026#34;Hello\u0026#34; } val lazyValue2: String by lazy(LazyThreadSafetyMode.SYNCHRONIZED) { println(\u0026#34;lazyValue2 computed!\u0026#34;) computeLazyValue() } private fun computeLazyValue() = \u0026#34;leavesC\u0026#34; } fun main() { val example = Example() println(example.lazyValue1) //lazyValue1 computed! Hello println(example.lazyValue1) //Hello println(example.lazyValue2) //lazyValue2 computed! leavesC } 默认情况下，对于 lazy 属性的求值是带同步锁的（synchronized），即带有 LazyThreadSafetyMode.SYNCHRONIZED 参数，此时该值只允许同一时刻只能有一个线程对其进行初始化，并且所有线程会看到相同的初始化值。如果初始化委托的同步锁不是必需的，即如果允许多个线程同时执行，那么可以将 LazyThreadSafetyMode.PUBLICATION 作为参数传递给 lazy() 函数。 而如果你确定初始化将总是发生在单个线程，那么可以使用 LazyThreadSafetyMode.NONE 模式， 此时不会有任何线程安全的保证以及相关的资源开销\n4、可观察属性 Delegates.observable() 接受两个参数：初始值以及修改属性值时的回调函数。当为属性赋值后就会调用该回调函数，该回调函数包含三个参数：被赋值的属性、旧值与新值\nfun main() { val example = Example() example.age = 24 //kProperty.name: age , oldValue: -100 , newValue: 24 example.age = 27 //kProperty.name: age , oldValue: 24 , newValue: 27 } class Example { var age: Int by Delegates.observable(-100) { kProperty: KProperty\u0026lt;*\u0026gt;, oldValue: Int, newValue: Int -\u0026gt; println(\u0026#34;kProperty.name: ${kProperty.name} , oldValue: $oldValue , newValue: $newValue\u0026#34;) } } 如果想要拦截一个赋值操作并判断是否进行否决，可以使用 vetoable() 函数，通过返回一个布尔值来决定是否进行拦截，该判断逻辑是在属性被赋新值生效之前进行\nfun main() { val example = Example() example.age = 24 //kProperty.name: age , oldValue: -100 , newValue: 24 example.age = -10 //kProperty.name: age , oldValue: 24 , newValue: -10 example.age = 30 //kProperty.name: age , oldValue: 24 , newValue: 30 (oldValue 依然是 24，说明第二次的赋值操作被否决了) } class Example { var age: Int by Delegates.vetoable(-100) { kProperty: KProperty\u0026lt;*\u0026gt;, oldValue: Int, newValue: Int -\u0026gt; println(\u0026#34;kProperty.name: ${kProperty.name} , oldValue: $oldValue , newValue: $newValue\u0026#34;) age \u0026lt;= 0 //返回true 则表示拦截该赋值操作 } } 5、把属性储存在映射中 可以在一个 map 映射里存储属性的值，然后把属性的存取操作委托给 map 进行管理\nfun main() { val student = Student( mapOf( \u0026#34;name\u0026#34; to \u0026#34;leavesCZY\u0026#34;, \u0026#34;age\u0026#34; to 24 ) ) println(student.name) println(student.age) } class Student(val map: Map\u0026lt;String, Any?\u0026gt;) { val name: String by map val age: Int by map } 在上述示例中，属性 name 和 age 都是不可变的（val），因此 map 的类型也是 Map 而非 MutableMap（MutableMap 在赋值后可以修改），因此如果为了支持 var 属性，可以将只读的 Map 换成 MutableMap\n6、局部委托属性 可以将局部变量声明为委托属性\nclass Printer { fun print() { println(\u0026#34;temp.Printer print\u0026#34;) } } fun getPrinter(): Printer { println(\u0026#34;temp.Printer getPrinter\u0026#34;) return Printer() } //局部委托 fun example(getPrinter: () -\u0026gt; Printer) { val lPrinter by lazy(getPrinter) val valid = true if (valid) { lPrinter.print() } } fun main() { example { getPrinter() } //temp.Printer getPrinter //temp.Printer print } 委托变量只会在第一次访问时才会进行初始化，因此如果 valid 为 false 的话，getPrinter() 方法就不会被调用\n二十五、注解 注解是将元数据附加到代码元素上的一种方式，附件的元数据就可以在编译后的类文件或者运行时被相关的源代码工具访问\n注解的语法格式如下所示：\nannotation class AnnotationName() 注解的附加属性可以通过用元注解标注注解类来指定：\n@Target 指定该注解标注的允许范围（类、函数、属性等） @Retention 指定该注解是否要存储在编译后的 class 文件中，如果要保存，则在运行时可以通过反射来获取到该注解值 @Repeatable 标明允许在单个元素上多次使用相同的该注解 @MustBeDocumented 指定该注解是公有 API 的一部分，并且应该包含在生成的 API 文档中显示的类或方法的签名中 @Target(AnnotationTarget.FUNCTION, AnnotationTarget.FIELD) @Retention(AnnotationRetention.RUNTIME) @Repeatable @MustBeDocumented annotation class AnnotationName() 注解可以声明包含有参数的构造函数\nannotation class OnClick(val viewId: Long) 允许的参数类型有：\n原生数据类型，对应 Java 原生的 int 、long、char 等 字符串 class 对象 枚举 其他注解 以上类型的数组 注解参数不能包含有可空类型，因为 JVM 不支持将 null 作为注解属性的值来存储\n看一个在运行时获取注解值的例子\n@Target(AnnotationTarget.FUNCTION, AnnotationTarget.FIELD) @Retention(AnnotationRetention.RUNTIME) annotation class OnClick(val viewId: Long) class AnnotationsTest { @OnClick(200300) fun onClickButton() { println(\u0026#34;Clicked\u0026#34;) } } fun main() { val annotationsTest = AnnotationsTest() for (method in annotationsTest.javaClass.methods) { for (annotation in method.annotations) { if (annotation is OnClick) { println(\u0026#34;method name: \u0026#34; + method.name) //method name: onClickButton println(\u0026#34;OnClick viewId: \u0026#34; + annotation.viewId) //OnClick viewId: 200300 } } } } ","permalink":"http://localhost:1313/hugo-blog/public/post/kotlin/%E4%B8%A4%E4%B8%87%E5%85%AD%E5%8D%83%E5%AD%97%E5%B8%A6%E4%BD%A0-kotlin-%E5%85%A5%E9%97%A8/","tags":[],"title":"两万六千字带你 Kotlin 入门"},{"categories":[],"content":" \\\\ // \\\\ .ooo. // .@@@@@@@@@. :@@@@@@@@@@@@@: :@@. \u0026#39;@@@@@\u0026#39; .@@: @@@@@@@@@@@@@@@@@ @@@@@@@@@@@@@@@@@ :@@ :@@@@@@@@@@@@@@@@@. @@: @@@ \u0026#39;@@@@@@@@@@@@@@@@@, @@@ @@@ \u0026#39;@@@@@@@@@@@@@@@@@, @@@ @@@ \u0026#39;@@@@@@@@@@@@@@@@@, @@@ @@@ \u0026#39;@@@@@@@@@@@@@@@@@, @@@ @@@ \u0026#39;@@@@@@@@@@@@@@@@@, @@@ @@@ \u0026#39;@@@@@@@@@@@@@@@@@, @@@ @@@@@@@@@@@@@@@@@ \u0026#39;@@@@@@@@@@@@@@@\u0026#39; @@@@ @@@@ @@@@ @@@@ @@@@ @@@@ \u0026#39;@@\u0026#39; \u0026#39;@@\u0026#39; :@@@. .@@@@@@@: +@@ `@@ @@` @@ @@ .@@@@\u0026#39;@@@@: +@@ `@@ @@` @@ @@ @@@ @@@ +@@ `@@ @@` @@ @@ .@@ @@: +@@ @@@ `@@ @@` @@@@@@ @@@@@@ @@;@@@@@ @@@ @@@ +@@ @@@ `@@ @@` @@@@@@ @@@@@@ @@@@@@@@@ @@@ @@@ +@@ @@@ `@@@@@@@@@@` @@ @@ @@@ :@@ @@@ @@@ +@@@@@ `@@@@@@@@@@` @@ @@ @@# @@+ @@@ @@@ +@@@@@+ `@@ @@` @@ @@ @@: @@# @@: .@@` +@@@+@@ `@@ @@` @@ @@ @@# @@+ @@@. .@@@ +@@ @@@ `@@ @@` @@ @@ @@@ ,@@ @@@@@@@@@ +@@ @@@ `@@ @@` @@@@ @@@@ @@@@#@@@@ @@@@@@@ +@@ #@@ `@@ @@` @@@@: @@@@: @@\u0026#39;@@@@@ @@: @@: @@: 公众号：字节数组 希望对你有所帮助 🤣🤣\n对于 Android Developer 来说，很多开源库都是属于开发必备的知识点，从使用方式到实现原理再到源码解析，这些都需要我们有一定程度的了解和运用能力。所以我打算来写一系列关于开源库源码解析和实战演练的文章，初定的目标是 EventBus、ARouter、LeakCanary、Retrofit、Glide、OkHttp、Coil 等七个知名开源库，希望对你有所帮助 🤣🤣\n本文基于 OkHttp 的以下版本进行讲解。值得一提的是，OkHttp 和 OkIO 目前已经被官方用 Kotlin 语言重写了一遍，所以还没学 Kotlin 的同学可能连源码都比较难看懂了，Kotlin 入门可以看我的这篇文章：两万六千字带你 Kotlin 入门 dependencies { implementation \u0026#39;com.squareup.okhttp3:okhttp:4.9.0\u0026#39; } 先来看一个小例子，后面的讲解都会基于这个例子涉及到的模块来展开\n/** * @Author: leavesCZY * @Github：https://github.com/leavesCZY */ const val URL = \u0026#34;https://publicobject.com/helloworld.txt\u0026#34; fun main() { val okHttClient = OkHttpClient.Builder() .connectTimeout(Duration.ofSeconds(10)) .readTimeout(Duration.ofSeconds(10)) .writeTimeout(Duration.ofSeconds(10)) .retryOnConnectionFailure(true) .build() val request = Request.Builder().url(URL).build() val call = okHttClient.newCall(request) val response = call.execute() println(response.body?.string()) } 以上代码就完成了一次 Get 请求，其包含的操作有：\n通过 Builder 模式得到 OkHttpClient，OkHttpClient 包含了对网络请求的全局配置信息，包括 链接超时时间、读写超时时间、链接失败重试 等各种配置 通过 Builder 模式得到 Request，Request 包含了本次网络请求的所有请求参数，包括 url、method、headers、body 等 通过 newCall 方法得到 Call，Call 就用于发起请求，可用于执行 同步请求（execute）、异步请求（enqueue）、取消请求（cancel） 等各种操作 调用 execute 方法发起同步请求并返回一个 Response 对象，Response 就包含了此次网络请求的所有返回信息，如果请求失败的话此方法会抛出异常 拿到 Response 对象的 body 并以字符串流的方式进行读取，打印结果即文章开头的 Android 机器人彩蛋 一、OkHttpClient OkHttpClient 使用了 Builder 模式来完成初始化，其提供了很多的配置参数，每个选项都有默认值，但大多数时候我们还是需要来进行自定义，所以也有必要来了解下其包含的所有参数\nclass Builder constructor() { //调度器 internal var dispatcher: Dispatcher = Dispatcher() //连接池 internal var connectionPool: ConnectionPool = ConnectionPool() //拦截器列表 internal val interceptors: MutableList\u0026lt;Interceptor\u0026gt; = mutableListOf() //网络拦截器列表 internal val networkInterceptors: MutableList\u0026lt;Interceptor\u0026gt; = mutableListOf() //事件监听 internal var eventListenerFactory: EventListener.Factory = EventListener.NONE.asFactory() //连接失败的时候是否重试 internal var retryOnConnectionFailure = true //源服务器身份验证 internal var authenticator: Authenticator = Authenticator.NONE //是否允许重定向 internal var followRedirects = true //是否允许ssl重定向 internal var followSslRedirects = true //Cookie internal var cookieJar: CookieJar = CookieJar.NO_COOKIES //缓存 internal var cache: Cache? = null //DNS internal var dns: Dns = Dns.SYSTEM //代理 internal var proxy: Proxy? = null //代理选择器 internal var proxySelector: ProxySelector? = null //代理身份验证 internal var proxyAuthenticator: Authenticator = Authenticator.NONE //Socket工厂 internal var socketFactory: SocketFactory = SocketFactory.getDefault() //安全套接层 internal var sslSocketFactoryOrNull: SSLSocketFactory? = null internal var x509TrustManagerOrNull: X509TrustManager? = null internal var connectionSpecs: List\u0026lt;ConnectionSpec\u0026gt; = DEFAULT_CONNECTION_SPECS //HTTP 协议 internal var protocols: List\u0026lt;Protocol\u0026gt; = DEFAULT_PROTOCOLS //主机名字确认 internal var hostnameVerifier: HostnameVerifier = OkHostnameVerifier //证书链 internal var certificatePinner: CertificatePinner = CertificatePinner.DEFAULT internal var certificateChainCleaner: CertificateChainCleaner? = null internal var callTimeout = 0 internal var connectTimeout = 10_000 //读超时 internal var readTimeout = 10_000 //写超时 internal var writeTimeout = 10_000 //ping 之间的时间间隔 internal var pingInterval = 0 internal var minWebSocketMessageToCompress = RealWebSocket.DEFAULT_MINIMUM_DEFLATE_SIZE internal var routeDatabase: RouteDatabase? = null } 二、Request Request 包含了网络请求时的所有请求参数，一共包含以下五个：\nurl。即本次的网络请求地址以及可能包含的 query 键值对 method。即请求方式，可选参数有 GET、HEAD、POST、DELETE、PUT、PATCH headers。即请求头，可用来存 token、时间戳等 body。即请求体 tags。可用来唯一标识本次请求 internal var url: HttpUrl? = null internal var method: String internal var headers: Headers.Builder internal var body: RequestBody? = null /** A mutable map of tags, or an immutable empty map if we don\u0026#39;t have any. */ internal var tags: MutableMap\u0026lt;Class\u0026lt;*\u0026gt;, Any\u0026gt; = mutableMapOf() 三、Call 当调用 okHttClient.newCall(request)时就会得到一个 Call 对象\n/** Prepares the [request] to be executed at some point in the future. */ override fun newCall(request: Request): Call = RealCall(this, request, forWebSocket = false) Call 是一个接口，我们可以将其看做是网络请求的启动器，可用于发起同步请求或异步请求，但重复发起多次请求的话会抛出异常\ninterface Call : Cloneable { //返回本次网络请求的 Request 对象 fun request(): Request //发起同步请求，可能会抛出异常 @Throws(IOException::class) fun execute(): Response //发起异步请求，通过 Callback 来回调最终结果 fun enqueue(responseCallback: Callback) //取消网络请求 fun cancel() //是否已经发起过请求 fun isExecuted(): Boolean //是否已经取消请求 fun isCanceled(): Boolean //超时计算 fun timeout(): Timeout //同个 Call 不允许重复发起请求，想要再次发起请求可以通过此方法得到一个新的 Call 对象 public override fun clone(): Call fun interface Factory { fun newCall(request: Request): Call } } newCall 方法返回的实际类型是 RealCall，它是 Call 接口的唯一实现类\n当我们调用 execute 方法发起同步请求时，其主要逻辑是：\n判读是否重复请求 事件记录 将自身加入到 dispatcher 中，并在请求结束时从 dispatcher 中移除自身 通过 getResponseWithInterceptorChain 方法得到 Response 对象 class RealCall( val client: OkHttpClient, /** The application\u0026#39;s original request unadulterated by redirects or auth headers. */ val originalRequest: Request, val forWebSocket: Boolean ) : Call { override fun execute(): Response { check(executed.compareAndSet(false, true)) { \u0026#34;Already Executed\u0026#34; } timeout.enter() callStart() try { client.dispatcher.executed(this) return getResponseWithInterceptorChain() } finally { client.dispatcher.finished(this) } } } 四、Dispatcher 从上面的分析可以看出来，getResponseWithInterceptorChain 方法就是重头戏了，其返回了我们最终得到的 Response。但这里先不介绍该方法，先来看看 Dispatcher 的逻辑\nDispatcher 是一个调度器，用于对全局的网络请求进行缓存调度，其包含以下几个成员变量\nvar maxRequests = 64 var maxRequestsPerHost = 5 /** Ready async calls in the order they\u0026#39;ll be run. */ private val readyAsyncCalls = ArrayDeque\u0026lt;AsyncCall\u0026gt;() /** Running asynchronous calls. Includes canceled calls that haven\u0026#39;t finished yet. */ private val runningAsyncCalls = ArrayDeque\u0026lt;AsyncCall\u0026gt;() /** Running synchronous calls. Includes canceled calls that haven\u0026#39;t finished yet. */ private val runningSyncCalls = ArrayDeque\u0026lt;RealCall\u0026gt;() maxRequests。同一时间允许并发执行网络请求的最大线程数 maxRequestsPerHost。同一 host 下的最大同时请求数 readyAsyncCalls。保存当前等待执行的异步任务 runningAsyncCalls。保存当前正在执行的异步任务 runningSyncCalls。保存当前正在执行的同步任务 客户端不应该无限制地同时发起多个网络请求，因为除了网络资源所限外，系统资源也是有限的，每个请求都需要由一个线程来执行，而系统支持并发执行的线程数量是有限的，所以 OkHttp 内部就使用 maxRequests 来控制同时执行异步请求的最大线程数。此外，OkHttp 为了提高效率，允许多个指向同一 host 的网络请求共享同一个 Socket，而最大共享数量即 maxRequestsPerHost\n为了统计以上两个运行参数，就需要使用 readyAsyncCalls、runningAsyncCalls 和 runningSyncCalls 来保存当前正在执行或者准备执行的网络请求。runningSyncCalls 用于保存当前正在执行的同步任务，其存储的是 RealCall。readyAsyncCalls 和 runningAsyncCalls 用于保存异步任务，其存储的是 AsyncCall\n1、同步请求 RealCall 的 execute() 方法在开始请求前，会先将自身传给 dispatcher，在请求结束后又会从 dispatcher 中移除\nclass RealCall( val client: OkHttpClient, /** The application\u0026#39;s original request unadulterated by redirects or auth headers. */ val originalRequest: Request, val forWebSocket: Boolean ) : Call { override fun execute(): Response { check(executed.compareAndSet(false, true)) { \u0026#34;Already Executed\u0026#34; } timeout.enter() callStart() try { //添加到 dispatcher client.dispatcher.executed(this) return getResponseWithInterceptorChain() } finally { //从 dispatcher 中移除 client.dispatcher.finished(this) } } } Dispatcher 内部也只是相应的将 RealCall 添加到 runningSyncCalls 中或者是将其从 runningSyncCalls 中移除，保存到 runningSyncCalls 的目的是为了方便统计当前所有正在运行的请求总数以及能够取消所有请求。此外，由于同步请求会直接运行在调用者所在线程上，所以同步请求并不会受 maxRequests 的限制\nclass Dispatcher constructor() { /** Used by [Call.execute] to signal it is in-flight. */ @Synchronized internal fun executed(call: RealCall) { runningSyncCalls.add(call) } /** Used by [Call.execute] to signal completion. */ internal fun finished(call: RealCall) { finished(runningSyncCalls, call) } private fun \u0026lt;T\u0026gt; finished(calls: Deque\u0026lt;T\u0026gt;, call: T) { val idleCallback: Runnable? synchronized(this) { if (!calls.remove(call)) throw AssertionError(\u0026#34;Call wasn\u0026#39;t in-flight!\u0026#34;) idleCallback = this.idleCallback } //判断是否有需要处理的网络请求 val isRunning = promoteAndExecute() if (!isRunning \u0026amp;\u0026amp; idleCallback != null) { idleCallback.run() } } } 2、异步请求 RealCall 的 enqueue方法会将外部传入的 Callback 包装为一个 AsyncCall 对象后传给 dispatcher\nclass RealCall( val client: OkHttpClient, /** The application\u0026#39;s original request unadulterated by redirects or auth headers. */ val originalRequest: Request, val forWebSocket: Boolean ) : Call { override fun enqueue(responseCallback: Callback) { check(executed.compareAndSet(false, true)) { \u0026#34;Already Executed\u0026#34; } callStart() client.dispatcher.enqueue(AsyncCall(responseCallback)) } } 由于 enqueue对应的是异步请求，所以 OkHttp 内部就需要自己构造一个线程来执行请求，在请求结束后再通过 Callback 来将结果值回调给外部，异步请求逻辑对应的载体就是 AsyncCall 这个类\nAsyncCall 是 RealCall 的非静态内部类，所以 AsyncCall 可以访问到 RealCall 的所有变量和方法。此外，AsyncCall 继承了 Runnable 接口，其 executeOn 方法就用于传入一个线程池对象来执行run 方法。run 方法内还是调用了 getResponseWithInterceptorChain()方法来获取 response，并通过 Callback 来将执行结果（不管成功还是失败）回调出去，在请求结束后也会将自身从 dispatcher 中移除\ninternal inner class AsyncCall(private val responseCallback: Callback) : Runnable { @Volatile var callsPerHost = AtomicInteger(0) private set fun reuseCallsPerHostFrom(other: AsyncCall) { this.callsPerHost = other.callsPerHost } fun executeOn(executorService: ExecutorService) { client.dispatcher.assertThreadDoesntHoldLock() var success = false try { executorService.execute(this) success = true } catch (e: RejectedExecutionException) { val ioException = InterruptedIOException(\u0026#34;executor rejected\u0026#34;) ioException.initCause(e) noMoreExchanges(ioException) responseCallback.onFailure(this@RealCall, ioException) } finally { if (!success) { client.dispatcher.finished(this) // This call is no longer running! } } } override fun run() { threadName(\u0026#34;OkHttp ${redactedUrl()}\u0026#34;) { var signalledCallback = false timeout.enter() try { val response = getResponseWithInterceptorChain() signalledCallback = true responseCallback.onResponse(this@RealCall, response) } catch (e: IOException) { if (signalledCallback) { // Do not signal the callback twice! Platform.get().log(\u0026#34;Callback failure for ${toLoggableString()}\u0026#34;, Platform.INFO, e) } else { responseCallback.onFailure(this@RealCall, e) } } catch (t: Throwable) { cancel() if (!signalledCallback) { val canceledException = IOException(\u0026#34;canceled due to $t\u0026#34;) canceledException.addSuppressed(t) responseCallback.onFailure(this@RealCall, canceledException) } throw t } finally { client.dispatcher.finished(this) } } } } Dispatcher 在拿到 AsyncCall 对象后，会先将其存到 readyAsyncCalls 中，然后通过 findExistingCallWithHost方法来查找当前是否有指向同一 Host 的异步请求，有的话则交换 callsPerHost 变量，该变量就用于标记当前指向同一 Host 的请求数量，最后调用 promoteAndExecute 方法来判断当前是否允许发起请求\nclass Dispatcher constructor() { internal fun enqueue(call: AsyncCall) { synchronized(this) { readyAsyncCalls.add(call) // Mutate the AsyncCall so that it shares the AtomicInteger of an existing running call to // the same host. if (!call.call.forWebSocket) { //查找当前是否有指向同一 Host 的异步请求 val existingCall = findExistingCallWithHost(call.host) if (existingCall != null) call.reuseCallsPerHostFrom(existingCall) } } promoteAndExecute() } private fun findExistingCallWithHost(host: String): AsyncCall? { for (existingCall in runningAsyncCalls) { if (existingCall.host == host) return existingCall } for (existingCall in readyAsyncCalls) { if (existingCall.host == host) return existingCall } return null } } 由于当前正在执行的网络请求总数可能已经达到限制，或者是指向同一 Host 的请求也达到限制了，所以 promoteAndExecute()方法就用于从待执行列表 readyAsyncCalls 中获取当前符合运行条件的所有请求，将请求存到 runningAsyncCalls 中，并调用线程池来执行\nprivate fun promoteAndExecute(): Boolean { this.assertThreadDoesntHoldLock() val executableCalls = mutableListOf\u0026lt;AsyncCall\u0026gt;() val isRunning: Boolean synchronized(this) { val i = readyAsyncCalls.iterator() while (i.hasNext()) { val asyncCall = i.next() //如果当前正在执行的异步请求总数已经超出限制，则直接返回 if (runningAsyncCalls.size \u0026gt;= this.maxRequests) break // Max capacity. //如果指向同个 Host 的请求总数已经超出限制，则取下一个请求 if (asyncCall.callsPerHost.get() \u0026gt;= this.maxRequestsPerHost) continue // Host max capacity. i.remove() //将 callsPerHost 递增加一，表示指向该 Host 的链接数加一了 asyncCall.callsPerHost.incrementAndGet() //将 asyncCall 存到可执行列表中 executableCalls.add(asyncCall) //将 asyncCall 存到正在执行列表中 runningAsyncCalls.add(asyncCall) } isRunning = runningCallsCount() \u0026gt; 0 } //执行所有符合条件的请求 for (i in 0 until executableCalls.size) { val asyncCall = executableCalls[i] asyncCall.executeOn(executorService) } return isRunning } 3、ArrayDeque 上面有讲到，三种请求的存储容器是 ArrayDeque。ArrayDeque 属于非线程安全的双端队列，所以涉及到多线程操作时都需要外部主动线程同步。那么让我们想一想，OkHttp 选择 ArrayDeque 作为任务容器的理由是什么？以我粗浅的眼光来看，有以下几点：\nArrayDeque 内部使用数组结构来存储数据，元素具有明确的先后顺序，这符合我们对网络请求先到先执行的基本预期 在选择符合运行条件的异步请求时，需要对 readyAsyncCalls 进行遍历，数组在遍历效率上会比较高 在遍历到符合条件的请求后，需要将请求从 readyAsyncCalls 中移除并转移到 runningAsyncCalls 中，而 ArrayDeque 作为双端队列，在内存空间利用率上比较高 Dispatcher 面对的就是多线程环境，本身就需要进行线程同步，选择 ArrayDeque 这个非线程安全的容器可以省去多余的线程同步消耗 4、线程池 OkHttp 的异步请求是交由其内部的线程池来完成的，该线程池就长这样：\nprivate var executorServiceOrNull: ExecutorService? = null @get:Synchronized @get:JvmName(\u0026#34;executorService\u0026#34;) val executorService: ExecutorService get() { if (executorServiceOrNull == null) { executorServiceOrNull = ThreadPoolExecutor(0, Int.MAX_VALUE, 60, TimeUnit.SECONDS, SynchronousQueue(), threadFactory(\u0026#34;$okHttpName Dispatcher\u0026#34;, false)) } return executorServiceOrNull!! } 该线程池的参数设置有什么优势呢？以我粗浅的眼光来看，有以下两点：\n核心线程数为 0，线程超时时间是 60 秒。说明在没有待执行的任务的时候，如果线程闲置了 60 秒，那么线程就会被回收，这可以避免空闲线程白白浪费系统资源，适合于移动设备资源紧缺的情景 允许的最大线程数为 Int.MAX_VALUE，可以看做是完全没有限制的，且任务队列是 SynchronousQueue。SynchronousQueue 的特点是当有任务入队时，必须等待该任务被消费否则入队操作就会一直被阻塞，而由于线程池允许的最大线程数量是无限的，所以每个入队的任务都能马上交由线程处理（交付给空闲线程或者新建一个线程来处理），这就保证了任务的处理及时性，符合我们对网络请求应该尽快发起并完成的期望 虽然线程池本身对于最大线程数几乎没有限制，但是由于提交任务的操作还受 maxRequests 的控制，所以实际上该线程池最多同时运行 maxRequests 个线程\n5、推动请求执行 既然 OkHttp 内部的线程池是不可能无限制地新建线程来执行请求的，那么当请求总数已达到 maxRequests 后，后续的请求只能是先处于等待状态，那么这些等待状态的请求会在什么时候被启动呢？\n同步请求和异步请求结束后都会调用到 Dispatcher 的两个 finished 方法，在这两个方法里又会触发到 promoteAndExecute()方法去遍历任务列表来执行，此时就推动了待处理列表的任务执行操作。所以说，Dispatcher 中的请求都可以看做是在自发性地启动，每个请求结束都会自动触发下一个请求执行（如果有的话），省去了多余的定时检查这类操作\n/** Used by [AsyncCall.run] to signal completion. */ internal fun finished(call: AsyncCall) { call.callsPerHost.decrementAndGet() finished(runningAsyncCalls, call) } /** Used by [Call.execute] to signal completion. */ internal fun finished(call: RealCall) { finished(runningSyncCalls, call) } private fun \u0026lt;T\u0026gt; finished(calls: Deque\u0026lt;T\u0026gt;, call: T) { val idleCallback: Runnable? synchronized(this) { if (!calls.remove(call)) throw AssertionError(\u0026#34;Call wasn\u0026#39;t in-flight!\u0026#34;) idleCallback = this.idleCallback } //判断当前是否有可以启动的待执行任务，有的话则启动 val isRunning = promoteAndExecute() if (!isRunning \u0026amp;\u0026amp; idleCallback != null) { idleCallback.run() } } 6、总结 如果是同步请求，那么网络请求过程就会直接在调用者所在线程上完成，不受 Dispatcher 的控制 如果是异步请求，该请求会先存到待执行列表 readyAsyncCalls 中，该请求是否可以立即发起受 maxRequests 和 maxRequestsPerHost 两个条件的限制。如果符合条件，那么就会从 readyAsyncCalls 取出并存到 runningAsyncCalls 中，然后交由 OkHttp 内部的线程池来执行 不管外部是同步请求还是异步请求，内部都是通过调用getResponseWithInterceptorChain()方法来拿到 Response 的 Dispatcher 内部的线程池本身允许同时运行 Int.MAX_VALUE 个线程，但是实际上的线程数量还是受 maxRequests 的控制 五、RealInterceptorChain 重点再来看 getResponseWithInterceptorChain()方法，其主要逻辑就是通过拦截器来完成整个网络请求过程。在该方法中，除了会获取外部主动设置的拦截器外，也会默认添加以下几个拦截器\nRetryAndFollowUpInterceptor。负责失败重试以及重定向 BridgeInterceptor。负责对用户构造的 Request 进行转换，添加必要的 header 和 cookie，在得到 response 后如果有需要的会进行 gzip 解压 CacheInterceptor。用于处理缓存 ConnectInterceptor。负责和服务器建立连接 CallServerInterceptor。负责向服务器发送请求和从服务器接收数据 最后，request 和 interceptors 会用来生成一个 RealInterceptorChain 对象，由其来最终返回 response\n@Throws(IOException::class) internal fun getResponseWithInterceptorChain(): Response { // Build a full stack of interceptors. val interceptors = mutableListOf\u0026lt;Interceptor\u0026gt;() //添加开发者设置的拦截器 interceptors += client.interceptors //添加默认的拦截器 interceptors += RetryAndFollowUpInterceptor(client) interceptors += BridgeInterceptor(client.cookieJar) interceptors += CacheInterceptor(client.cache) interceptors += ConnectInterceptor if (!forWebSocket) { //如果不是 WebSocket 的话，那就再添加开发者设置的 NetworkInterceptors interceptors += client.networkInterceptors } //CallServerInterceptor 是实际上发起网络请求的地方 interceptors += CallServerInterceptor(forWebSocket) val chain = RealInterceptorChain( call = this, interceptors = interceptors, index = 0, exchange = null, request = originalRequest, connectTimeoutMillis = client.connectTimeoutMillis, readTimeoutMillis = client.readTimeoutMillis, writeTimeoutMillis = client.writeTimeoutMillis ) var calledNoMoreExchanges = false try { val response = chain.proceed(originalRequest) if (isCanceled()) { response.closeQuietly() throw IOException(\u0026#34;Canceled\u0026#34;) } return response } catch (e: IOException) { calledNoMoreExchanges = true throw noMoreExchanges(e) as Throwable } finally { if (!calledNoMoreExchanges) { noMoreExchanges(null) } } } Interceptor 是 OkHttp 里很重要的一环，OkHttp 也是靠此为开发者提供了很高的自由度。Interceptor 接口本身只包含一个 intercept 方法，在此方法内可拿到原始的 Request 对象以及最终的 Response\nfun interface Interceptor { @Throws(IOException::class) fun intercept(chain: Chain): Response } 例如，我们可以自定义一个 LogInterceptor 来打印网络请求的请求参数以及最终的返回值\nclass LogInterceptor : Interceptor { override fun intercept(chain: Interceptor.Chain): Response { val request = chain.request() println(request) val response = chain.proceed(request) println(response) return response } } Interceptor 的实现初衷是为了给开发者提供一个可以控制网络请求的发起过程及收尾工作的入口，例如**添加 header、日志记录、请求拦截、ResponseBody修改 **等，每个 Interceptor 只负责自己关心的操作，那么势必就会有添加多个 Interceptor 的需求\n我们知道，只有让每个 Interceptor 都依次处理完 request 之后，OkHttp 才能根据最终的 request 对象去联网请求得到 response，所以每个 Interceptor 需要依次拿到 request 进行自定义处理。请求到 response 后，Interceptor 可能还需要对 response 进行处理，那么就还需要将 response 再依次传递给每个 Interceptor。那么，怎么实现将多个 Interceptor 给串联起来呢？\n这里来看一个简化版本的 Interceptor 实现思路\n假设我们自己定义的 Interceptor 实现类有两个：LogInterceptor 和 HeaderInterceptor，这里只是简单地将获取到 request 和 response 的时机给打印出来，重点是要看每个 Interceptor 的先后调用顺序。为了将两个 Interceptor 给串联起来，RealInterceptorChain 会循环获取 index 指向的下一个 Interceptor 对象，每次构建一个新的 RealInterceptorChain 对象作为参数来调用 intercept 方法，这样外部只需要调用一次 realInterceptorChain.proceed 就可以拿到最终的 response 对象\nclass Request class Response interface Chain { fun request(): Request fun proceed(request: Request): Response } interface Interceptor { fun intercept(chain: Chain): Response } class RealInterceptorChain( private val request: Request, private val interceptors: List\u0026lt;Interceptor\u0026gt;, private val index: Int ) : Chain { private fun copy(index: Int): RealInterceptorChain { return RealInterceptorChain(request, interceptors, index) } override fun request(): Request { return request } override fun proceed(request: Request): Response { val next = copy(index = index + 1) val interceptor = interceptors[index] val response = interceptor.intercept(next) return response } } class LogInterceptor : Interceptor { override fun intercept(chain: Chain): Response { val request = chain.request() println(\u0026#34;LogInterceptor -- getRequest\u0026#34;) val response = chain.proceed(request) println(\u0026#34;LogInterceptor ---- getResponse\u0026#34;) return response } } class HeaderInterceptor : Interceptor { override fun intercept(chain: Chain): Response { val request = chain.request() println(\u0026#34;HeaderInterceptor -- getRequest\u0026#34;) val response = chain.proceed(request) println(\u0026#34;HeaderInterceptor ---- getResponse\u0026#34;) return response } } fun main() { val interceptorList = mutableListOf\u0026lt;Interceptor\u0026gt;() interceptorList.add(LogInterceptor()) interceptorList.add(HeaderInterceptor()) val request = Request() val realInterceptorChain = RealInterceptorChain(request, interceptorList, 0) val response = realInterceptorChain.proceed(request) println(\u0026#34;main response\u0026#34;) } 上面的代码看着思路还可以，可是当运行后就会发现抛出了 IndexOutOfBoundsException，因为代码里并没有对 index 进行越界判断。而且，上面的代码也缺少了一个真正的生成 Response 对象的地方，每个 Interceptor 只是在进行中转调用而已，因此还需要一个来真正地完成网络请求并返回 Response 对象的地方，即 CallServerInterceptor\n所以，CallServerInterceptor 的intercept 方法就用来真正地执行网络请求并生成 Response 对象，在这里就不能再调用 proceed 方法了，且 CallServerInterceptor 需要放在 interceptorList 的最后一位\nclass CallServerInterceptor : Interceptor { override fun intercept(chain: Chain): Response { val request = chain.request() println(\u0026#34;CallServerInterceptor -- getRequest\u0026#34;) val response = Response() println(\u0026#34;CallServerInterceptor ---- getResponse\u0026#34;) return response } } fun main() { val interceptorList = mutableListOf\u0026lt;Interceptor\u0026gt;() interceptorList.add(LogInterceptor()) interceptorList.add(HeaderInterceptor()) interceptorList.add(CallServerInterceptor()) val request = Request() val realInterceptorChain = RealInterceptorChain(request, interceptorList, 0) val response = realInterceptorChain.proceed(request) println(\u0026#34;main response\u0026#34;) } 最终的运行结果如下所示，可以看出来，intercept 方法是根据添加顺序来调用，而 response 是按照反方向来传递\nLogInterceptor -- getRequest HeaderInterceptor -- getRequest CallServerInterceptor -- getRequest CallServerInterceptor ---- getResponse HeaderInterceptor ---- getResponse LogInterceptor ---- getResponse main response 以上代码我简化了 OkHttp 在实现 RealInterceptorChain 时的思路，其本质上就是通过将多个拦截器以责任链的方式来一层层调用，上一个拦截器处理完后将就将结果传给下一个拦截器，直到最后一个拦截器（即 CallServerInterceptor ）处理完后将 Response 再一层层往上传递\nclass RealInterceptorChain( internal val call: RealCall, private val interceptors: List\u0026lt;Interceptor\u0026gt;, private val index: Int, internal val exchange: Exchange?, internal val request: Request, internal val connectTimeoutMillis: Int, internal val readTimeoutMillis: Int, internal val writeTimeoutMillis: Int ) : Interceptor.Chain { internal fun copy( index: Int = this.index, exchange: Exchange? = this.exchange, request: Request = this.request, connectTimeoutMillis: Int = this.connectTimeoutMillis, readTimeoutMillis: Int = this.readTimeoutMillis, writeTimeoutMillis: Int = this.writeTimeoutMillis ) = RealInterceptorChain(call, interceptors, index, exchange, request, connectTimeoutMillis, readTimeoutMillis, writeTimeoutMillis) @Throws(IOException::class) override fun proceed(request: Request): Response { ··· val next = copy(index = index + 1, request = request) val interceptor = interceptors[index] @Suppress(\u0026#34;USELESS_ELVIS\u0026#34;) val response = interceptor.intercept(next) ?: throw NullPointerException( \u0026#34;interceptor $interceptor returned null\u0026#34;) ··· return response } } 六、Interceptor 我们在构建 OkHttpClient 的时候，添加拦截器的方法分为两类：addInterceptor和addNetworkInterceptor\nval okHttClient = OkHttpClient.Builder() .addInterceptor { chain -\u0026gt; chain.proceed(chain.request()) } .addNetworkInterceptor { chain -\u0026gt; chain.proceed(chain.request()) } .build() Interceptor 和 NetworkInterceptor 分别被称为应用拦截器和网络拦截器，那么它们有什么区别呢？\n前面有讲到，OkHttp 在执行拦截器的时候，是按照如下顺序的，这个顺序就已经决定了不同拦截器的调用时机差异\nval interceptors = mutableListOf\u0026lt;Interceptor\u0026gt;() interceptors += client.interceptors interceptors += RetryAndFollowUpInterceptor(client) interceptors += BridgeInterceptor(client.cookieJar) interceptors += CacheInterceptor(client.cache) interceptors += ConnectInterceptor if (!forWebSocket) { interceptors += client.networkInterceptors } interceptors += CallServerInterceptor(forWebSocket) 由于应用拦截器处于列表头部，所以在整个责任链路中应用拦截器会首先被执行，即使之后在 RetryAndFollowUpInterceptor 中发生了请求失败重试或者网络重定向等情况，应用拦截器也只会被触发一次，但网络拦截器会被调用多次 网络拦截器位于 CacheInterceptor 之后，那么当 CacheInterceptor 命中缓存的时候就不会去执行网络请求了，此时网络拦截器就不会被调用，因此网络拦截器是存在短路的可能。此外，网络拦截器位于 ConnectInterceptor 之后，在调用网络拦截器之前就已经准备好网络链接了，说明网络拦截器本身就关联着实际的网络请求逻辑 从单次请求流程上来看，应用拦截器被调用并不意味着真正有发起了网络请求，而网络拦截器被调用就说明的确发起了一次网络请求。因此如果我们希望通过拦截器来记录网络请求详情的话，就需要考虑两者的调用时机差异：应用拦截器无法感知到 OkHttp 自动添加的一些 header，但是网络拦截器可以；应用拦截器除非主动中断请求，否则每次请求一定都会被执行，但网络拦截器可能存在被短路的可能 借用官方的一张图片来表示\n这里可以根据 square 官方提供的一个例子，来实现在下载一张 10 MB 图片的时候通过拦截器对下载进度进行监听，并同时把图片下载到系统的桌面\n实现思路就是对原始的 ResponseBody 进行多一层代理，计算已经从网络中读取到的字节数和资源的 contentLength 之间的百分比，从而得到下载进度。此外，因为该拦截器是和确切的网络请求相关，所以应该要设为网络拦截器才比较合理\n/** * @Author: leavesCZY * @Github：https://github.com/leavesCZY */ fun main() { run() } interface ProgressListener { fun update(bytesRead: Long, contentLength: Long, done: Boolean) } private fun run() { val request = Request.Builder() .url(\u0026#34;https://images.pexels.com/photos/5177790/pexels-photo-5177790.jpeg\u0026#34;) .build() val progressListener: ProgressListener = object : ProgressListener { var firstUpdate = true override fun update(bytesRead: Long, contentLength: Long, done: Boolean) { if (done) { println(\u0026#34;completed\u0026#34;) } else { if (firstUpdate) { firstUpdate = false if (contentLength == -1L) { println(\u0026#34;content-length: unknown\u0026#34;) } else { System.out.format(\u0026#34;content-length: %d\\n\u0026#34;, contentLength) } } println(bytesRead) if (contentLength != -1L) { System.out.format(\u0026#34;%d%% done\\n\u0026#34;, 100 * bytesRead / contentLength) } } } } val client = OkHttpClient.Builder() .addNetworkInterceptor { chain: Interceptor.Chain -\u0026gt; val originalResponse = chain.proceed(chain.request()) originalResponse.newBuilder() .body(ProgressResponseBody(originalResponse.body!!, progressListener)) .build() } .build() client.newCall(request).execute().use { response -\u0026gt; if (!response.isSuccessful) { throw IOException(\u0026#34;Unexpected code $response\u0026#34;) } val desktopDir = FileSystemView.getFileSystemView().homeDirectory val imageFile = File(desktopDir, \u0026#34;${System.currentTimeMillis()}.jpeg\u0026#34;) imageFile.createNewFile() //读取 InputStream 写入到图片文件中 response.body!!.byteStream().copyTo(imageFile.outputStream()) } } private class ProgressResponseBody constructor( private val responseBody: ResponseBody, private val progressListener: ProgressListener ) : ResponseBody() { private var bufferedSource: BufferedSource? = null override fun contentType(): MediaType? { return responseBody.contentType() } override fun contentLength(): Long { return responseBody.contentLength() } override fun source(): BufferedSource { if (bufferedSource == null) { bufferedSource = source(responseBody.source()).buffer() } return bufferedSource!! } private fun source(source: Source): Source { return object : ForwardingSource(source) { var totalBytesRead = 0L @Throws(IOException::class) override fun read(sink: Buffer, byteCount: Long): Long { val bytesRead = super.read(sink, byteCount) // read() returns the number of bytes read, or -1 if this source is exhausted. totalBytesRead += if (bytesRead != -1L) bytesRead else 0 progressListener.update(totalBytesRead, responseBody.contentLength(), bytesRead == -1L) return bytesRead } } } } 进度输出就类似于：\ncontent-length: 11448857 467 0% done 1836 0% done 3205 ··· 99% done 11442570 99% done 11448857 100% done completed 七、结尾 关于 OkHttp 的源码讲解到这里就结束了，但本文还缺少了对 ConnectInterceptor 和 CallServerInterceptor 的讲解，这两者是 OkHttp 完成实际网络请求的地方，涉及到了 Connection 和 Socket 这些比较底层的领域，我没法讲得多清晰，就直接略过这块内容了~~\nOkHttp 的运行效率很高，但在使用上还是比较原始，一般我们还是需要在 OkHttp 之上进行一层封装，Retrofit 就是一个对 OkHttp 的优秀封装库，对 Retrofit 的源码讲解可以看我的这篇文章：三方库源码笔记（7）-Retrofit 源码详解 下篇文章就来写关于 OkHttp 拦截器的实战内容吧\n","permalink":"http://localhost:1313/hugo-blog/public/post/kotlin/%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E5%BA%93%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%9011okhttp-%E6%BA%90%E7%A0%81%E8%AF%A6%E8%A7%A3/","tags":[],"title":"主流开源库源码分析（11）OkHttp 源码详解"},{"categories":[],"content":" 公众号：字节数组 希望对你有所帮助 🤣🤣\n对于 Android Developer 来说，很多开源库都是属于开发必备的知识点，从使用方式到实现原理再到源码解析，这些都需要我们有一定程度的了解和运用能力。所以我打算来写一系列关于开源库源码解析和实战演练的文章，初定的目标是 EventBus、ARouter、LeakCanary、Retrofit、Glide、OkHttp、Coil 等七个知名开源库，希望对你有所帮助 🤣🤣\n在使用 OkHttp 或者 Retrofit 的时候，我觉得大部分开发者做得最多的自定义实现就是拦截器了。因为 OkHttp 的拦截器真的是太有用了，我们的很多需求：添加 Header、计算并添加签名信息、网络请求记录 等都可以通过拦截器来自动完成，只要定义好规则，就可以覆盖到全局的 OkHttp 网络请求\n按照我写 [Android 主流开源库源码分析] 这系列文章的习惯，我每写一篇关于源码讲解的文章，就会接着写一篇关于该三方库的自定义实现或者是扩展阅读。所以，承接上一篇文章：Android 主流开源库源码分析（十一）- OkHttp 源码详解 ，本篇文章就来写关于 OkHttp 的实战内容，来实现一个移动端的可视化抓包工具：Monitor 一、Monitor Monitor 适用于使用了 OkHttp / Retrofit 作为网络请求框架的项目，只要添加了 MonitorInterceptor 拦截器，Monitor 就会自动记录并保存所有的网络请求信息且自动弹窗展示\n最后实现的效果如下所示：\n二、实现思路 这里来简单地介绍下 Monitor 的实现思路\n其实 Monitor 是我蛮久前写的一个开源库了，刚好和我现在要写的文章主题相符，就趁着这机会做了一次整体重构，完全使用 Kotlin 语言来实现，请放心食用。其核心思路就是通过 Interceptor 拿到 Request 和 Response，记录各项请求信息，存到数据库中进行持久化保存，在实现思路上类似于 squareup 官方的ogging-interceptor，只是说 Monitor 会更加直接和方便😋😋\ndebug 版本的 MonitorInterceptor 的大体框架如下所示。HttpInformation 是对 request 和 response 的一个实体封装，也是最终会存到数据库中的实体类。通过 chain 拿到 request，先对本地数据库进行预先占位，在 proceed 后拿到 response，对本次请求结果进行解析，所有信息都存到 HttpInformation 中再来更新数据库，同时弹出 Notification\n/** * @Author: leavesCZY * @Github：https://github.com/leavesCZY */ class MonitorInterceptor(context: Context) : Interceptor { @Throws(IOException::class) override fun intercept(chain: Interceptor.Chain): Response { val request = chain.request() val httpInformation = HttpInformation() processRequest(request, httpInformation) httpInformation.id = insert(httpInformation) val response: Response try { response = chain.proceed(request) } catch (e: Throwable) { httpInformation.error = e.toString() throw e } finally { update(httpInformation) } processResponse(response, httpInformation) update(httpInformation) return response } private fun processRequest(request: Request, httpInformation: HttpInformation) { ··· } private fun processResponse(response: Response, httpInformation: HttpInformation) { ··· } private fun showNotification(httpInformation: HttpInformation) { ··· } } release 版本的 MonitorInterceptor 则不会做任何操作，只是单纯将请求转发出去而已，不会造成多余的性能消耗和引用\nclass MonitorInterceptor(context: Context) : Interceptor { @Throws(IOException::class) override fun intercept(chain: Interceptor.Chain): Response { val request = chain.request() return chain.proceed(request) } } HttpInformation 包含了单次网络请求下所有关于 request 和 response 的请求参数和返回值信息，responseBody 只会保存文本类型的返回值（例如 Json 和 XML），图片这类二进制文件则不会进行保存\nclass HttpInformation { var url = \u0026#34;\u0026#34; var host = \u0026#34;\u0026#34; var path = \u0026#34;\u0026#34; var scheme = \u0026#34;\u0026#34; var protocol = \u0026#34;\u0026#34; var method = \u0026#34;\u0026#34; var requestHeaders = mutableListOf\u0026lt;HttpHeader\u0026gt;() var responseHeaders = mutableListOf\u0026lt;HttpHeader\u0026gt;() var requestBody = \u0026#34;\u0026#34; var requestContentType = \u0026#34;\u0026#34; var requestContentLength = 0L var responseBody = \u0026#34;\u0026#34; var responseContentType = \u0026#34;\u0026#34; var responseContentLength = 0L var requestDate = 0L var responseDate = 0L var responseTlsVersion = \u0026#34;\u0026#34; var responseCipherSuite = \u0026#34;\u0026#34; var responseCode = DEFAULT_RESPONSE_CODE var responseMessage = \u0026#34;\u0026#34; var error: String? = null } HttpInformation 则是用 Room 数据库来持久化保存，不得不说的是，Jetpack 中的 Room 和 LiveData 来搭配使用还是很爽的，将 LiveData 作为数据库的返回值，可以很方便地以观察者模式来实时监听数据库中的数据变化\n/** * @Author: leavesCZY * @Desc: */ @Dao interface MonitorHttpInformationDao { @Query(\u0026#34;SELECT * FROM monitor_httpInformation WHERE id =:id\u0026#34;) fun queryRecordObservable(id: Long): LiveData\u0026lt;HttpInformation\u0026gt; @Query(\u0026#34;SELECT * FROM monitor_httpInformation order by id desc limit :limit\u0026#34;) fun queryAllRecordObservable(limit: Int): LiveData\u0026lt;List\u0026lt;HttpInformation\u0026gt;\u0026gt; @Query(\u0026#34;SELECT * FROM monitor_httpInformation order by id desc\u0026#34;) fun queryAllRecordObservable(): LiveData\u0026lt;List\u0026lt;HttpInformation\u0026gt;\u0026gt; } UI 层则不用自己去考虑线程切换和内存泄露这类问题，直接进行 observe 即可\nprivate val monitorViewModel by lazy { ViewModelProvider(this).get(MonitorViewModel::class.java).apply { allRecordLiveData.observe(this@MonitorActivity, Observer { monitorAdapter.setData(it) }) } } 三、远程引用 代码我已经发布到了 jitpack，方便大家直接远程依赖使用\n同时引入 debug 和 release 版本的依赖，release 版本的 MonitorInterceptor 不会做任何操作，避免了信息泄露，也不会增加 Apk 体积大小\nallprojects { repositories { maven { url \u0026#39;https://jitpack.io\u0026#39; } } } dependencies { debugImplementation \u0026#39;com.github.leavesCZY.Monitor:monitor:1.1.5\u0026#39; releaseImplementation \u0026#39;com.github.leavesCZY.Monitor:monitor-no-op:1.1.5\u0026#39; } 只要向 OkHttpClient 添加了 MonitorInterceptor，之后的操作就都会自动完成\nval okHttpClient = OkHttpClient.Builder() .addInterceptor(MonitorInterceptor(context = application)) .build() 四、Github GitHub 链接点击这里：Monitor ","permalink":"http://localhost:1313/hugo-blog/public/post/kotlin/%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E5%BA%93%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%9012okhttp--retrofit-%E5%BC%80%E5%8F%91%E8%B0%83%E8%AF%95%E5%88%A9%E5%99%A8/","tags":[],"title":"主流开源库源码分析（12）OkHttp \u0026 Retrofit 开发调试利器"},{"categories":[],"content":" day01.md ","permalink":"http://localhost:1313/hugo-blog/public/post/dev-log/readme/","tags":[],"title":"开发日志"},{"categories":[],"content":" 公众号：字节数组 希望对你有所帮助 🤣🤣\nBitmap 应该是很多应用中最占据内存空间的一类资源了，Bitmap 也是导致应用 OOM 的常见原因之一。例如，Pixel 手机的相机拍摄的照片最大可达 4048 * 3036 像素（1200 万像素），如果使用的位图配置为 ARGB_8888（Android 2.3 及更高版本的默认设置），将单张照片加载到内存大约需要 48MB 内存（4048 * 3036 * 4 字节），如此庞大的内存需求可能会立即耗尽应用的所有可用内存\n本篇文章就来讲下 Bitmap 一些比较有用的知识点，希望对你有所帮助 🤣🤣\n全文可以概括为以下几个问题：\nBitmap 所占内存大小的计算公式？ Bitmap 所占内存大小和所在的 drawable 文件夹的关系？ Bitmap 所占内存大小和 ImageView 的宽高的关系？ Bitmap 如何减少内存大小？ 1、预备知识 在开始讲关于 Bitmap 的知识点前，需要先阐述一些基础概念作为预备知识\n我们知道，在不同手机屏幕上 1dp 所对应的 px 值可能是会有很大差异的。例如，在小屏幕手机上 1dp 可能对应 1px，在大屏幕手机上对应的可能是 3px，这也是我们的应用实现屏幕适配的原理基础之一。想要知道在特定一台手机上 1dp 对应多少 px，或者是想要知道屏幕宽高大小，这些信息都可以通过 DisplayMetrics 来获取\nval displayMetrics = applicationContext.resources.displayMetrics 打印出本文所使用的模拟器的 DisplayMetrics 信息：\nDisplayMetrics{density=3.0, width=1080, height=1920, scaledDensity=3.0, xdpi=480.0, ydpi=480.0} 从中就可以提取出几点信息：\ndensity 等于 3，说明在该模拟器上 1dp 等于 3px 屏幕宽高大小为 1920 x 1080 px，即 640 x 360 dp 屏幕像素密度为 480dpi dpi 是一个很重要的值，指的是在系统软件上指定的单位尺寸的像素数量，往往是写在系统出厂配置文件的一个固定值。Android 系统定义的屏幕像素密度基准值是 160dpi，该基准值下 1dp 就等于 1px，依此类推 320dpi 下 1dp 就等于 2px\ndpi 决定了应用在显示 drawable 时是选择哪一个文件夹内的切图。每个 drawable 文件夹都对应不同的 dpi 大小，Android 系统会自动根据当前手机的实际 dpi 大小从合适的 drawable 文件夹内选取图片，不同的后缀名对应的 dpi 大小就如以下表格所示。如果 drawable 文件夹名不带后缀，那么该文件夹就对应 160dpi\ndrawable dpi ldpi 120 dpi mdpi 160 dpi hdpi 240 dpi xhdpi 320 dpi xxhdpi 480 dpi xxxhdpi 640 dpi 举个例子。对于 320dpi 的设备来说，应用在选择图片时就会优先从 drawable-xhdpi 文件夹拿，如果该文件夹内没找到图片，就会依照 xxhdpi -\u0026gt; xxxhdpi -\u0026gt; hdpi -\u0026gt; mdpi -\u0026gt; ldpi 的顺序进行查找，优先使用高密度版本，然后从中选择最接近当前屏幕密度的图片资源\n2、内存大小的计算公式 先将一张大小为 1920 x 1080 px 的图片保存到 drawable-xxhdpi 文件夹内，然后将其显示在一个宽高均为 180dp 的 ImageView 上，该 Bitmap 所占用的内存就通过 bitmap.byteCount来获取\nval options = BitmapFactory.Options() val bitmap = BitmapFactory.decodeResource(resources, R.drawable.icon_awe, options) imageView.setImageBitmap(bitmap) log(\u0026#34;imageView width: \u0026#34; + imageView.width) log(\u0026#34;imageView height: \u0026#34; + imageView.height) log(\u0026#34;bitmap width: \u0026#34; + bitmap.width) log(\u0026#34;bitmap height: \u0026#34; + bitmap.height) log(\u0026#34;bitmap config: \u0026#34; + bitmap.config) log(\u0026#34;inDensity: \u0026#34; + options.inDensity) log(\u0026#34;inTargetDensity: \u0026#34; + options.inTargetDensity) log(\u0026#34;bitmap byteCount: \u0026#34; + bitmap.byteCount) BitmapMainActivity: imageView width: 540 BitmapMainActivity: imageView height: 540 BitmapMainActivity: bitmap width: 1920 BitmapMainActivity: bitmap height: 1080 BitmapMainActivity: bitmap config: ARGB_8888 BitmapMainActivity: inDensity: 480 BitmapMainActivity: inTargetDensity: 480 BitmapMainActivity: bitmap byteCount: 8294400 由于模拟器的 density 等于 3，所以 ImageView 的宽高都是 540 px Bitmap 的宽高还是保持其原有大小，即1920 x 1080 px ARGB_8888 代表的是该 Bitmap 的编码格式，该格式下一个像素点需要占用 4 byte inDensity 代表的是系统最终选择的 drawable 文件夹类型，等于 480 说明取的是 drawable-xxhdpi文件夹下的图片 inTargetDensity 代表的是当前设备的 dpi 8294400 就是 Bitmap 所占用的内存大小，单位是 byte 从最终结果可以很容易地就逆推出 Bitmap 所占内存大小的计算公式：bitmapWidth * bitmapHeight * 单位像素点所占用的字节数，即 1920 * 1080 * 4 = 8294400\n3、和 drawable 文件夹的关系 上面之所以很容易就逆推出了 Bitmap 所占内存大小的计算公式，是因为所有条件都被我故意设定为最优情况了，才使得计算过程这么简单。而实际上 Bitmap 所占内存大小和其所在的 drawable 文件夹是有很大关系的，虽然计算公式没变\n现在的大部分应用为了达到最优的显示效果，会为应用准备多套切图放在不同的 drawable 文件夹下，而BitmapFactory.decodeResource 方法在解码 Bitmap 的时候，就会自动根据当前设备的 dpi 和 drawable 文件夹类型来判断是否需要对图片进行缩放显示\n将图片从 drawable-xxhdpi迁移到 drawable-xhdpi文件夹，然后再打印日志信息\nBitmapMainActivity: imageView width: 540 BitmapMainActivity: imageView height: 540 BitmapMainActivity: bitmap width: 2880 BitmapMainActivity: bitmap height: 1620 BitmapMainActivity: bitmap config: ARGB_8888 BitmapMainActivity: inDensity: 320 BitmapMainActivity: inTargetDensity: 480 BitmapMainActivity: bitmap byteCount: 18662400 可以看到，Bitmap 的宽高都发生了变化，inDensity 等于 320 也说明了选取的是drawable-xhdpi文件夹内的图片，Bitmap 所占内存居然增加了一倍多\n模拟器的 dpi 是 480，拿到了 dpi 为 320 的drawable-xhdpi文件夹下的图片，在系统的理解中该文件夹存放的都是小图标，是为小屏幕手机准备的，现在要在大屏幕手机上展示的话就需要对其进行放大，放大的比例就是 480 / 320 = 1.5 倍，因此 Bitmap 的宽就会变为 1920 * 1.5 = 2880 px，高就会变为 1080 * 1.5 = 1620 px，最终占用的内存空间大小就是 2880 * 1620 * 4 = 18662400\n所以说，对于同一台手机，Bitmap 在不同 drawable 文件夹下对其最终占用的内存大小是有很大关系的，虽然计算公式没变，但是由于系统会进行自动缩放，导致 Bitmap 的最终宽高都发生了变化，从而影响到了其占用的内存空间大小。同理，对于同个 drawable 文件夹下的同一张图片，在不同的手机屏幕上也可能会占用不同的内存空间，因为不同的手机的 dpi 大小可能是不一样的，BitmapFactory 进行缩放的比例也就不一样\n4、和 ImageView 的宽高的关系 在上一个例子里，Bitmap 的宽高是 2880 * 1620 px，ImageView 的宽高是 540 * 540 px，该 Bitmap 肯定是会显示不全的，读者可以试着自己改变 ImageView 的宽高大小来验证是否会对 Bitmap 的大小产生影响\n这里就不贴代码了，直接来说结论，答案是没有关系。原因也很简单，毕竟上述例子是先将 Bitmap 加载到内存中后再设置给 ImageView 的，ImageView 自然不会影响到 Bitmap 的加载过程，该 Bitmap 的大小也只受其所在的 drawable 文件夹类型以及手机的 dpi 大小这两个因素的影响。但这个结论是需要考虑测试方式的，如果你是使用 Glide 来加载图片，Glide 内部实现了按需加载的机制，会根据 ImageView 的大小对 Bitmap 进行自动缩放，避免内存浪费的情况，这种情况下 ImageView 的宽高就会影响到 Bitmap 的内存大小了\n5、BitmapFactory BitmapFactory 提供了很多个方法用于加载 Bitmap 对象：decodeFile、decodeResourceStream、decodeResource、decodeByteArray、decodeStream 等多个，但只有 decodeResourceStream 和 decodeResource 这两个方法才会根据 dpi 进行自动缩放。如果是从磁盘或者 assert 目录加载图片的话是不会进行自动缩放的，毕竟这些来源也不具备 dpi 信息，Bitmap 的分辨率也只能保持其原有大小\ndecodeResource 方法也会调用到decodeResourceStream方法，decodeResourceStream方法如果判断到inDensity 和 inTargetDensity 两个属性外部没有主动赋值的话，就会根据实际情况进行赋值\n@Nullable public static Bitmap decodeResourceStream(@Nullable Resources res, @Nullable TypedValue value, @Nullable InputStream is, @Nullable Rect pad, @Nullable Options opts) { validate(opts); if (opts == null) { opts = new Options(); } if (opts.inDensity == 0 \u0026amp;\u0026amp; value != null) { final int density = value.density; if (density == TypedValue.DENSITY_DEFAULT) { //如果 density 没有赋值的话（等于0），那么就使用基准值 160 dpi opts.inDensity = DisplayMetrics.DENSITY_DEFAULT; } else if (density != TypedValue.DENSITY_NONE) { //在这里进行赋值，density 就等于 drawable 对应的 dpi opts.inDensity = density; } } if (opts.inTargetDensity == 0 \u0026amp;\u0026amp; res != null) { //如果没有主动设置 inTargetDensity 的话，inTargetDensity 就等于设备的 dpi opts.inTargetDensity = res.getDisplayMetrics().densityDpi; } return decodeStream(is, pad, opts); } 6、BitmapConfig Bitmap.Config 定义了四种常见的编码格式，分别是：\nALPHA_8。每个像素点需要一个字节的内存，只存储位图的透明度，没有颜色信息 ARGB_4444。A(Alpha)、R(Red)、G(Green)、B（Blue）各占四位精度，共计十六位的精度，折合两个字节，也就是说一个像素点占两个字节的内存，会存储位图的透明度和颜色信息 ARGB_8888。ARGB 各占八个位的精度，折合四个字节，会存储位图的透明度和颜色信息 RGB_565。R占五位精度，G占六位精度，B占五位精度，一共是十六位精度，折合两个字节，只存储颜色信息，没有透明度信息 7、优化 Bitmap 根据 Bitmap 所占内存大小的计算公式：bitmapWidth * bitmapHeight * 单位像素点所占用的字节数，想要尽量减少 Bitmap 占用的内存大小的话就要从降低图片分辨率和降低单位像素需要的字节数这两方面来考虑了\n在一开始的情况下加载到的 Bitmap 的宽高是 1920 * 1080，占用的内存空间是 1920 * 1080 * 4 = 8294400，约 7.9 MB，这是优化前的状态\nval options = BitmapFactory.Options() val bitmap = BitmapFactory.decodeResource(resources, R.drawable.icon_awe, options) imageView.setImageBitmap(bitmap) log(\u0026#34;bitmap width: \u0026#34; + bitmap.width) log(\u0026#34;bitmap height: \u0026#34; + bitmap.height) log(\u0026#34;bitmap config: \u0026#34; + bitmap.config) log(\u0026#34;inDensity: \u0026#34; + options.inDensity) log(\u0026#34;inTargetDensity: \u0026#34; + options.inTargetDensity) log(\u0026#34;bitmap byteCount: \u0026#34; + bitmap.byteCount) BitmapMainActivity: bitmap width: 1920 BitmapMainActivity: bitmap height: 1080 BitmapMainActivity: bitmap config: ARGB_8888 BitmapMainActivity: inDensity: 480 BitmapMainActivity: inTargetDensity: 480 BitmapMainActivity: bitmap byteCount: 8294400 1、inSampleSize 由于 ImageView 的宽高只有 540 * 540 px，如果按照原图进行加载的话其实会造成很大的内存浪费，此时我们就可以通过 inSampleSize 属性来压缩图片尺寸\n例如，将 inSampleSize 设置为 2 后，Bitmap 的宽高就都会缩减为原先的一半，占用的内存空间就变成了原先的四分之一， 960 * 540 * 4 = 2073600，约 1.9 MB\nval options = BitmapFactory.Options() options.inSampleSize = 2 val bitmap = BitmapFactory.decodeResource(resources, R.drawable.icon_awe, options) imageView.setImageBitmap(bitmap) log(\u0026#34;bitmap width: \u0026#34; + bitmap.width) log(\u0026#34;bitmap height: \u0026#34; + bitmap.height) log(\u0026#34;bitmap config: \u0026#34; + bitmap.config) log(\u0026#34;inDensity: \u0026#34; + options.inDensity) log(\u0026#34;inTargetDensity: \u0026#34; + options.inTargetDensity) log(\u0026#34;bitmap byteCount: \u0026#34; + bitmap.byteCount) BitmapMainActivity: bitmap width: 960 BitmapMainActivity: bitmap height: 540 BitmapMainActivity: bitmap config: ARGB_8888 BitmapMainActivity: inDensity: 480 BitmapMainActivity: inTargetDensity: 480 BitmapMainActivity: bitmap byteCount: 2073600 可以看出来，inSampleSize 属性应该设置多少是需要根据 Bitmap 的实际宽高和 ImageView 的实际宽高这两个条件来一起决定的。我们在正式加载 Bitmap 前要先获取到 Bitmap 的实际宽高大小，这可以通过 inJustDecodeBounds 属性来实现。设置 inJustDecodeBounds 为 true 后 decodeResource方法只会去读取 Bitmap 的宽高属性而不会去进行实际加载，这个操作是比较轻量级的。然后通过每次循环对半折减，计算出 inSampleSize 需要设置为多少才能尽量接近到 ImageView 的实际宽高，之后将 inJustDecodeBounds 设置为 false 去实际加载 Bitmap\n需要注意的是，inSampleSize 使用的最终值将是向下舍入为最接近的 2 的幂，BitmapFactory 内部会自动会该值进行校验修正\nval options = BitmapFactory.Options() options.inJustDecodeBounds = true BitmapFactory.decodeResource(resources, R.drawable.icon_awe, options) val inSampleSize = calculateInSampleSize(options, imageView.width, imageView.height) options.inSampleSize = inSampleSize options.inJustDecodeBounds = false val bitmap = BitmapFactory.decodeResource(resources, R.drawable.icon_awe, options) imageView.setImageBitmap(bitmap) fun calculateInSampleSize(options: BitmapFactory.Options, reqWidth: Int, reqHeight: Int): Int { // Raw height and width of image val (height: Int, width: Int) = options.run { outHeight to outWidth } var inSampleSize = 1 if (height \u0026gt; reqHeight || width \u0026gt; reqWidth) { val halfHeight: Int = height / 2 val halfWidth: Int = width / 2 // Calculate the largest inSampleSize value that is a power of 2 and keeps both // height and width larger than the requested height and width. while (halfHeight / inSampleSize \u0026gt;= reqHeight \u0026amp;\u0026amp; halfWidth / inSampleSize \u0026gt;= reqWidth) { inSampleSize *= 2 } } return inSampleSize } 2、inTargetDensity 如果我们不主动设置 inTargetDensity 的话，decodeResource 方法会自动根据当前设备的 dpi 来对 Bitmap 进行缩放处理，我们可以通过主动设置 inTargetDensity 来控制缩放比例，从而控制 Bitmap 的最终宽高。最终宽高的生成规则： 180 / 480 * 1920 = 720，180 / 480 * 1080 = 405，占用的内存空间是 720 * 405 * 4 = 1166400，约 1.1 MB\nval options = BitmapFactory.Options() options.inTargetDensity = 180 val bitmap = BitmapFactory.decodeResource(resources, R.drawable.icon_awe, options) imageView.setImageBitmap(bitmap) log(\u0026#34;bitmap width: \u0026#34; + bitmap.width) log(\u0026#34;bitmap height: \u0026#34; + bitmap.height) log(\u0026#34;bitmap config: \u0026#34; + bitmap.config) log(\u0026#34;inDensity: \u0026#34; + options.inDensity) log(\u0026#34;inTargetDensity: \u0026#34; + options.inTargetDensity) log(\u0026#34;bitmap byteCount: \u0026#34; + bitmap.byteCount) BitmapMainActivity: bitmap width: 720 BitmapMainActivity: bitmap height: 405 BitmapMainActivity: bitmap config: ARGB_8888 BitmapMainActivity: inDensity: 480 BitmapMainActivity: inTargetDensity: 480 BitmapMainActivity: bitmap byteCount: 1166400 3、Bitmap.Config BitmapFactory 默认使用的编码图片格式是 ARGB_8888，每个像素点占用四个字节，我们可以按需改变要采用的图片格式。例如，如果要加载的 Bitmap 不包含透明通道的，我们可以使用 RGB_565，该格式每个像素点占用两个字节，占用的内存空间是 1920 * 1080 * 2 = 4147200，约 3.9 MB\nval options = BitmapFactory.Options() options.inPreferredConfig = Bitmap.Config.RGB_565 val bitmap = BitmapFactory.decodeResource(resources, R.drawable.icon_awe, options) imageView.setImageBitmap(bitmap) log(\u0026#34;bitmap width: \u0026#34; + bitmap.width) log(\u0026#34;bitmap height: \u0026#34; + bitmap.height) log(\u0026#34;bitmap config: \u0026#34; + bitmap.config) log(\u0026#34;inDensity: \u0026#34; + options.inDensity) log(\u0026#34;inTargetDensity: \u0026#34; + options.inTargetDensity) log(\u0026#34;bitmap byteCount: \u0026#34; + bitmap.byteCount) BitmapMainActivity: bitmap width: 1920 BitmapMainActivity: bitmap height: 1080 BitmapMainActivity: bitmap config: RGB_565 BitmapMainActivity: inDensity: 480 BitmapMainActivity: inTargetDensity: 480 BitmapMainActivity: bitmap byteCount: 4147200 ","permalink":"http://localhost:1313/hugo-blog/public/post/kotlin/%E6%8E%A2%E7%A9%B6-bitmap-%E7%9A%84%E4%BC%98%E5%8C%96%E6%89%8B%E6%AE%B5/","tags":[],"title":"探究 Bitmap 的优化手段"},{"categories":[],"content":" 公众号：字节数组 希望对你有所帮助 🤣🤣\n在 2019 年 Google I/O 大会上，Google 宣布了今后 Android 开发将优先使用 Kotlin ，即 Kotlin-first，随之在 Android 开发界兴起了一阵全民学习 Kotlin 的热潮。之后 Google 也推出了一系列用 Kotlin 实现的 ktx 扩展库，例如 activity-ktx、fragment-ktx、core-ktx等，提供了各种方便的扩展方法用于简化开发者的工作，Kotlin 协程目前也是官方在 Android 上进行异步编程的推荐解决方案\nGoogle 推荐优先使用 Kotlin，也宣称不会放弃 Java，但目前各种 ktx 扩展库还是需要由 Kotlin 代码进行使用才能最大化地享受到其便利性，Java 代码来调用显得有点不伦不类。作为 Jetpack 主要组件之一的 Paging 3.x 版本目前也已经完全用 Kotlin 实现，为 Kotlin 协程提供了一流的支持。刚出正式版本不久的 Jetpack Compose 也只支持 Kotlin，Java 无缘声明式 UI\n开发者可以感受到 Kotlin 在 Android 开发中的重要性在不断提高，虽然 Google 说不会放弃 Java，但以后的事谁说得准呢？开发者还是需要尽早迁移到 Kotlin，这也是必不可挡的技术趋势\nKotlin 在设计理念上有很多和 Java 不同的地方，开发者能够直观感受到的是语法层面上的差异性，背后也包含有一系列隐藏的性能开销以及一些隐藏得很深的“坑”，本篇文章就来介绍在使用 Kotlin 过程中存在的隐藏性能开销，帮助读者避坑，希望对你有所帮助 🤣🤣\n慎用 @JvmOverloads @JvmOverloads 注解大家应该不陌生，其作用在具有默认参数的方法上，用于向 Java 代码生成多个重载方法\n例如，以下的 println 方法对于 Java 代码来说就相当于两个重载方法，默认使用空字符串作为入参参数\n//Kotlin @JvmOverloads fun println(log: String = \u0026#34;\u0026#34;) { } //Java public void println(String log) { } public void println() { println(\u0026#34;\u0026#34;); } @JvmOverloads 很方便，减少了 Java 代码调用 Kotlin 代码时的调用成本，使得 Java 代码也可以享受到默认参数的便利，但在某些特殊场景下也会引发一个隐藏得很深的 bug\n举个例子\n我们知道 Android 系统的 View 类包含有多个构造函数，我们在实现自定义 View 时至少就要声明一个包含有两个参数的构造函数，参数类型必须依次是 Context 和 AttributeSet，这样该自定义 View 才能在布局文件中使用。而 View 类的构造函数最多包含有四个入参参数，最少只有一个，为了省事，我们在用 Kotlin 代码实现自定义 View 时，就可以用 @JvmOverloads 来很方便地继承 View 类，就像以下代码\nopen class BaseView @JvmOverloads constructor( context: Context, attrs: AttributeSet? = null, defStyleAttr: Int = 0, defStyleRes: Int = 0 ) : View(context, attrs, defStyleAttr, defStyleRes) 如果我们是像 BaseView 一样直接继承于 View 的话，此时使用@JvmOverloads就不会产生任何问题，可如果我们继承的是 TextView 的话，那么问题就来了\n直接继承于 TextView 不做任何修改，在布局文件中分别使用 MyTextView 和 TextView，给它们完全一样的参数，看看运行效果\nopen class MyTextView @JvmOverloads constructor( context: Context, attrs: AttributeSet? = null, defStyleAttr: Int = 0, defStyleRes: Int = 0 ) : TextView(context, attrs, defStyleAttr, defStyleRes) \u0026lt;github.leavesc.demo.MyTextView android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:gravity=\u0026#34;center\u0026#34; android:text=\u0026#34;业志陈\u0026#34; android:textSize=\u0026#34;42sp\u0026#34; /\u0026gt; \u0026lt;TextView android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:gravity=\u0026#34;center\u0026#34; android:text=\u0026#34;业志陈\u0026#34; android:textSize=\u0026#34;42sp\u0026#34; /\u0026gt; 此时两个 TextView 就会呈现出不一样的文本颜色了，十分神奇\n这就是 @JvmOverloads 带来的一个隐藏问题。因为 TextView 的 defStyleAttr 实际上是有一个默认值的，即 R.attr.textViewStyle，当中就包含了 TextView 的默认文本颜色，而由于 MyTextView 为 defStyleAttr 指定了一个默认值 0，这就导致 MyTextView 丢失了一些默认风格属性\npublic TextView(Context context, @Nullable AttributeSet attrs) { this(context, attrs, com.android.internal.R.attr.textViewStyle); } 因此，如果我们要直接继承的是 View 类的话可以直接使用@JvmOverloads，此时不会有任何问题，而如果我们要继承的是现有控件的话，就需要考虑应该如何设置默认值了\n慎用 解构声明 有时我们会有把一个对象拆解成多个变量的需求，Kotlin 也提供了这类语法糖支持，称为解构声明\n例如，以下代码就将 People 变量解构为了两个变量：name 和 nickname，变量名可以随意取，每个变量就按顺序对应着 People 中的字段\ndata class People(val name: String, val nickname: String) private fun printInfo(people: People) { val (name, nickname) = people println(name) println(nickname) } 每个解构声明其实都会被编译成以下代码，解构操作其实就是在按照顺序获取特定方法的返回值\nString name = people.component1(); String nickname = people.component2(); component1() 和 component2() 函数是 Kotlin 为数据类自动生成的方法，People 反编译为 Java 代码后就可以看到，每个方法返回的其实都是成员变量，方法名包含的数字对应的就是成员变量在数据类中的声明顺序\npublic final class People { @NotNull private final String name; @NotNull private final String nickname; @NotNull public final String component1() { return this.name; } @NotNull public final String component2() { return this.nickname; } } 解构声明和数据类配套使用时就有一个隐藏的知识点，看以下例子\n假设后续我们为 People 添加了一个新字段 city，此时 printInfo 方法一样可以正常调用，但 nickname 指向的其实就变成了 people 变量内的 city 字段了，含义悄悄发生了变化，此时就会导致逻辑错误了\ndata class People(val name: String, val city: String, val nickname: String) private fun printInfo(people: People) { val (name, nickname) = people println(name) println(nickname) } 数据类中的字段是可以随时增减或者变换位置的，从而使得解构结果和我们一开始预想的不一致，因此我觉得解构声明和数据类不太适合放在一起使用\n慎用 toLowerCase 和 toUpperCase 当我们要以忽略大小写的方式比较两个字符串是否相等时，通常想到的是通过 toUpperCase 或 toLowerCase 方法将两个字符串转换为全大写或者全小写，然后再进行比较，这种方式完全可以满足需求，但当中也包含着一个隐藏开销\n例如，以下的 Kotlin 代码反编译为 Java 代码后，可以看到每次调用toUpperCase方法都会创建一个新的临时变量，然后再去调用临时变量的 equals 方法进行比较\nfun main() { val name = \u0026#34;leavesC\u0026#34; val nickname = \u0026#34;leavesc\u0026#34; println(name.toUpperCase() == nickname.toUpperCase()) } public static final void main() { String name = \u0026#34;leavesC\u0026#34;; String nickname = \u0026#34;leavesc\u0026#34;; String var10000 = name.toUpperCase(); String var10001 = nickname.toUpperCase(); boolean var2 = Intrinsics.areEqual(var10000, var10001); System.out.println(var2); } 以上代码就多创建了两个临时变量，这样的代码无疑会比较低效\n有一个更好的解决方案，就是通过 Kotlin 提供的支持忽略大小写的 equals 扩展方法来进行比较，此方法内部会调用 String 类原生的 equalsIgnoreCase来进行比较，从而避免了创建临时变量，相对来说会比较高效一些\nfun main() { val name = \u0026#34;leavesC\u0026#34; val nickname = \u0026#34;leavesc\u0026#34; println(name.equals(other = nickname, ignoreCase = true)) } public static final void main() { String name = \u0026#34;leavesC\u0026#34;; String nickname = \u0026#34;leavesc\u0026#34;; boolean var2 = StringsKt.equals(name, nickname, true); boolean var3 = false; System.out.println(var2); } 慎用 arrayOf Kotlin 中的数组类型可以分为两类：\nIntArray、LongArray、FloatArray 形式的基本数据类型数组，通过 intArrayOf、longArrayOf、floatArrayOf 等方法来声明 Array\u0026lt;T\u0026gt; 形式的对象类型数组，通过 arrayOf、arrayOfNulls 等方法来声明 例如，以下的 Kotlin 代码都是用于声明整数数组，但实际上存储的数据类型并不一样\nval intArray: IntArray = intArrayOf(1, 2, 3) val integerArray: Array\u0026lt;Int\u0026gt; = arrayOf(1, 2, 3) 将以上代码反编译为 Java 代码后，就可以明确地看出一种是基本数据类型 int，一种是包装类型 Integer，arrayOf 方法会自动对入参值进行装箱\nprivate final int[] intArray = new int[]{1, 2, 3}; private final Integer[] integerArray = new Integer[]{1, 2, 3}; 为了表示基本数据类型的数组，Kotlin 为每一种基本数据类型都提供了若干相应的类并做了特殊的优化。例如，IntArray、ByteArray、BooleanArray 等类型都会被编译成普通的 Java 基本数据类型数组：int[]、byte[]、boolean[]，这些数组中的值在存储时不会进行装箱操作，而是使用了可能的最高效的方式\n因此，如果没有必要的话，我们在开发中要慎用 arrayOf 方法，避免不必要的装箱消耗\n慎用 vararg 和 Java 一样，Kotlin 也支持可变参数，允许将任意多个参数打包到一个数组中再一并传给函数，Kotlin 通过使用 varage 关键字来声明可变参数\n我们可以向 printValue 方法传递任意数量的入参参数，也可以直接传入一个数组对象，但 Kotlin 要求显式地解包数组，以便每个数组元素在函数中能够作为单独的参数来调用，这个功能被称为展开运算符，使用方式就是在数组前加一个 *\nfun printValue(vararg values: Int) { values.forEach { println(it) } } fun main() { printValue() printValue(1) printValue(2, 3) val values = intArrayOf(4, 5, 6) printValue(*values) } 如果我们是以直接传递若干个入参参数的形式来调用 printValue 方法的话，Kotlin 会自动将这些参数打包为一个数组进行传递，这里面就包含着创建数组的开销，这方面和 Java 保持一致。 如果我们传入的参数就已经是数组的话，Kotlin 相比 Java 就存在着一个隐藏开销，Kotlin 会复制现有数组作为参数拿来使用，相当于多分配了额外的数组空间，这可以从反编译后的 Java 代码看出来\npublic static final void printValue(@NotNull int... values) { Intrinsics.checkNotNullParameter(values, \u0026#34;values\u0026#34;); int $i$f$forEach = false; int[] var3 = values; int var4 = values.length; for(int var5 = 0; var5 \u0026lt; var4; ++var5) { int element$iv = var3[var5]; int var8 = false; boolean var9 = false; System.out.println(element$iv); } } public static final void main() { printValue(); printValue(1); printValue(2, 3); int[] values = new int[]{4, 5, 6}; //复制后再进行调用 printValue(Arrays.copyOf(values, values.length)); } // $FF: synthetic method public static void main(String[] var0) { main(); } 可以看到 Kotlin 会通过 Arrays.copyOf 复制现有数组，将复制后的数组作为参数进行调用，这样做的好处就是可以避免 printValue 方法影响到原有数组，坏处就是会额外消耗多一份的内存空间\n慎用 lazy 我们经常会使用lazy()函数来惰性加载只读属性，将加载操作延迟到需要使用的时候，适用于某些不适合立刻加载或者加载成本较高的情况\n例如，以下的 lazyValue 只会等到我们调用到的时候才会被赋值\nval lazyValue by lazy { \u0026#34;it is lazy value\u0026#34; } 而在使用lazy()函数时很容易被忽略的地方就是其包含有一个可选的 model 参数：\nLazyThreadSafetyMode.SYNCHRONIZED。只允许由单个线程来完成初始化，且初始化操作包含有双重锁检查，从而使得所有线程都得到相同的值 LazyThreadSafetyMode.PUBLICATION。允许多个线程同时执行初始化操作，但只有第一个初始化成功的值会被当做最终值，最终所有线程也都会得到相同的值 LazyThreadSafetyMode.NONE。允许多个线程同时执行初始化操作，不进行任何线程同步，导致不同线程可能会得到不同的初始化值，因此不应该用于多线程环境 lazy()函数默认情况下使用的就是LazyThreadSafetyMode.SYNCHRONIZED，从 SynchronizedLazyImpl 可以看到，其内部就使用到了synchronized来实现多线程同步，以此避免多线程竞争\npublic actual fun \u0026lt;T\u0026gt; lazy(initializer: () -\u0026gt; T): Lazy\u0026lt;T\u0026gt; = SynchronizedLazyImpl(initializer) private class SynchronizedLazyImpl\u0026lt;out T\u0026gt;(initializer: () -\u0026gt; T, lock: Any? = null) : Lazy\u0026lt;T\u0026gt;, Serializable { private var initializer: (() -\u0026gt; T)? = initializer @Volatile private var _value: Any? = UNINITIALIZED_VALUE // final field is required to enable safe publication of constructed instance private val lock = lock ?: this override val value: T get() { val _v1 = _value if (_v1 !== UNINITIALIZED_VALUE) { @Suppress(\u0026#34;UNCHECKED_CAST\u0026#34;) return _v1 as T } return synchronized(lock) { val _v2 = _value if (_v2 !== UNINITIALIZED_VALUE) { @Suppress(\u0026#34;UNCHECKED_CAST\u0026#34;) (_v2 as T) } else { val typedValue = initializer!!() _value = typedValue initializer = null typedValue } } } override fun isInitialized(): Boolean = _value !== UNINITIALIZED_VALUE override fun toString(): String = if (isInitialized()) value.toString() else \u0026#34;Lazy value not initialized yet.\u0026#34; private fun writeReplace(): Any = InitializedLazyImpl(value) } 对于 Android 开发者来说，大多数情况下我们都是在主线程中调用 lazy() 函数，此时使用 LazyThreadSafetyMode.SYNCHRONIZED 就会带来不必要的线程同步开销，因此可以根据实际情况考虑替换为LazyThreadSafetyMode.NONE\n慎用 lateinit var lateinit var 适用于某些不方便马上就初始化变量的场景，用于将初始化操作延后，同时也存在一些使用上的限制：如果在未初始化的情况下就使用该变量的话会导致 NPE\n例如，如果在 name 变量还未初始化时就调用了 print 方法的话，此时就会导致 NPE。且由于 lateinit var 变量不允许为 null，因此此时我们也无法通过判空来得知 name 是否已经被初始化了，而且判空操作本身也相当于在调用 name 变量，在未初始化的时候一样会导致 NPE\nlateinit var name: String fun print() { println(name) } 我们可以通过另一种方式来判断 lateinit 变量是否已初始化\nlateinit 实际上是通过代理机制来实现的，关联的是 KProperty0 接口，KProperty0 就提供了一个扩展属性用于判断其代理的值是否已经初始化了\n@SinceKotlin(\u0026#34;1.2\u0026#34;) @InlineOnly inline val @receiver:AccessibleLateinitPropertyLiteral KProperty0\u0026lt;*\u0026gt;.isInitialized: Boolean get() = throw NotImplementedError(\u0026#34;Implementation is intrinsic\u0026#34;) 因此我们可以通过以下方式来进行判断，从而避免不安全的访问操作\nlateinit var name: String fun print() { if (this::name.isInitialized) { println(\u0026#34;isInitialized true\u0026#34;) println(name) } else { println(\u0026#34;isInitialized false\u0026#34;) println(name) //会导致 NPE } } lambda 表达式 lambda 表达式在语义上很简洁，既避免了冗长的函数声明，也解决了以前需要强类型声明函数类型的情况\n例如，以下代码就通过 lambda 表达式声明了一个回调函数 callback，我们无需创建一个具体的函数类型，而只需声明需要的入参参数、入参类型、函数返回值就可以\nfun requestHttp(callback: (code: Int, data: String) -\u0026gt; Unit) { callback(200, \u0026#34;success\u0026#34;) } fun main() { requestHttp { code, data -\u0026gt; println(\u0026#34;code: $code\u0026#34;) println(\u0026#34;data: $data\u0026#34;) } } lambda 表达式语法虽然方便，但也隐藏着两个性能问题：\n每次调用 lambda 表达式都相当于在创建一个对象 lambda 表达式内部隐藏了自动装箱和自动拆箱的操作 将以上代码反编译为 Java 代码后，可以看到 callback 最终的实际类型就是 Function2，每次调用requestHttp 方法就相当于是在创建一个 Function2 变量\npublic static final void requestHttp(@NotNull Function2 callback) { Intrinsics.checkNotNullParameter(callback, \u0026#34;callback\u0026#34;); callback.invoke(200, \u0026#34;success\u0026#34;); } Function2 是 Kotlin 提供的一个的泛型接口，数字 2 即代表其包含两个入参值\npublic interface Function2\u0026lt;in P1, in P2, out R\u0026gt; : Function\u0026lt;R\u0026gt; { /** Invokes the function with the specified arguments. */ public operator fun invoke(p1: P1, p2: P2): R } Kotlin 会在编译阶段将开发者声明的 lambda 表达式转换为相应的 FunctionX 对象，调用 lambda 表达式就相当于在调用其 invoke 方法，以此为低版本 JVM 平台（例如 Java 6 / 7）也能提供 lambda 表达式功能。此外，我们也知道泛型类型不可能是基本数据类型，因此我们在 Kotlin 中声明的 Int 最终会被自动装箱为 Integer，lambda 表达式内部自动完成了装箱和拆箱的操作\n所以说，简洁的 lambda 表达式背后就隐藏了自动创建 Function 对象进行中转调用，自动装箱和自动拆箱的过程，且最终创建的方法总数要多于表面上看到的\n如果想要避免 lambda 表达式的以上开销，可以通过使用 inline 内联函数来实现\n在使用 inline 关键字修饰 requestHttp 方法后，可以看到此时 requestHttp 的逻辑就相当于被直接复制到了 main 方法内部，不会创建任何多余的对象，且此时使用的也是 int 而非 Integer\ninline fun requestHttp(callback: (code: Int, data: String) -\u0026gt; Unit) { callback(200, \u0026#34;success\u0026#34;) } fun main() { requestHttp { code, data -\u0026gt; println(\u0026#34;code: $code\u0026#34;) println(\u0026#34;data: $data\u0026#34;) } } public static final void main() { String data = \u0026#34;success\u0026#34;; int code = 200; String var4 = \u0026#34;code: \u0026#34; + code; System.out.println(var4); var4 = \u0026#34;data: \u0026#34; + data; System.out.println(var4); } 通过内联函数，可以使得编译器直接在调用方中使用内联函数体中的代码，相当于直接把内联函数中的逻辑复制到了调用方中，完全避免了调用带来的开销。对于高阶函数，作为参数传递的 lambda 表达式的主体也将被内联，这使得：\n声明和调用 lambda 表达式时，不会实例化 Function 对象 没有自动装箱和拆箱的操作 不会导致方法数增多，但如果内联函数方法体较大且被多处调用的话，可能导致最终代码量显著增加 init 的声明顺序很重要 看以下代码，我们可以在 init 块中调用 parameter1，却无法调用 parameter2，从 IDE 的提示信息 Variable 'parameter2' must be initialized也可以看出来，对于 init 块来说 parameter2 此时还未赋值，自然就无法使用了\nclass KotlinMode { private val parameter1 = \u0026#34;leavesC\u0026#34; init { println(parameter1) //error: Variable \u0026#39;parameter2\u0026#39; must be initialized //println(parameter2) } private val parameter2 = \u0026#34;业志陈\u0026#34; } 从反编译出的 Java 代码也可以看出来，由于 parameter2 是声明在 init 块之后，所以 parameter2 的赋值操作其实是放在构造函数中的最后面，因此 IDE 的语法检查器就会阻止我们在 init 块中来调用 parameter2 了\npublic final class KotlinMode { private final String parameter1 = \u0026#34;leavesC\u0026#34;; private final String parameter2; public KotlinMode() { String var1 = this.parameter1; System.out.println(var1); this.parameter2 = \u0026#34;业志陈\u0026#34;; } } IDE 会阻止开发者去调用还未初始化的变量，防止我们写出不安全的代码，我们也可以用以下方式来绕过语法检查，但同时也写出了不安全的代码\n我们可以通过在 init 块中调用 print() 方法的方式来间接访问 parameter2，此时代码是可以正常编译的，但此时 parameter2 也只会为 null\nclass KotlinMode { private val parameter1 = \u0026#34;leavesC\u0026#34; init { println(parameter1) print() } private fun print() { println(parameter2) } private val parameter2 = \u0026#34;业志陈\u0026#34; } 从反编译出的 Java 代码可以看出来，print()方法依旧是会在 parameter2 初始化之前被调用，此时print()方法访问到的 parameter2 也只会为 null，从而引发意料之外的 NPE\npublic final class KotlinMode { private final String parameter1 = \u0026#34;leavesC\u0026#34;; private final String parameter2; private final void print() { String var1 = this.parameter2; System.out.println(var1); } public KotlinMode() { String var1 = this.parameter1; System.out.println(var1); this.print(); this.parameter2 = \u0026#34;业志陈\u0026#34;; } } 所以说，init 块和成员变量之间的声明顺序决定了在构造函数中的初始化顺序，我们应该先声明成员变量再声明 init 块，否则就有可能导致 NPE\nGson \u0026amp; data class 来看个小例子，猜猜其运行结果会是怎样的\nUserBean 是一个 dataClass，其 userName 字段被声明为非 null 类型，而 json 字符串中 userName 对应的值明确就是 null，那用 Gson 到底能不能反序列化成功呢？程序能不能成功运行完以下三个步骤？\ndata class UserBean(val userName: String, val userAge: Int) fun main() { val json = \u0026#34;\u0026#34;\u0026#34;{\u0026#34;userName\u0026#34;:null,\u0026#34;userAge\u0026#34;:26}\u0026#34;\u0026#34;\u0026#34; val userBean = Gson().fromJson(json, UserBean::class.java) //第一步 println(userBean) //第二步 printMsg(userBean.userName) //第三步 } fun printMsg(msg: String) { } 实际上程序能够正常运行到第二步，但在执行第三步的时候反而直接报 NPE 异常了\nUserBean(userName=null, userAge=26) Exception in thread \u0026#34;main\u0026#34; java.lang.NullPointerException: Parameter specified as non-null is null: method temp.TestKt.printMsg, parameter msg at temp.TestKt.printMsg(Test.kt) at temp.TestKt.main(Test.kt:16) at temp.TestKt.main(Test.kt) printMsg 方法接收了参数后实际上什么也没做，为啥会抛出 NPE ？\n将printMsg反编译为 Java 方法，可以发现方法内部会对入参进行空校验，当发现为 null 时就会直接抛出 NPE。这个比较好理解，毕竟 Kotlin 的类型系统会严格区分 可 null 和 不可为 null 两种类型，其区分手段之一就是会自动在我们的代码里插入一些类型校验逻辑，即自动加上了非空断言，当发现不可为 null 的参数传入了 null 的话就会马上抛出 NPE，即使我们并没有使用到该参数\npublic static final void printMsg(@NotNull String msg) { Intrinsics.checkNotNullParameter(msg, \u0026#34;msg\u0026#34;); } 那既然 UserBean 中的 userName 字段已经被声明为非 null 类型了，那么为什么还可以反序列化成功呢？按照我自己的第一直觉，应该在进行反序列的时候就直接抛出异常才对\n将 UserBean 反编译为 Java 代码后，也可以看到其构造函数中是有对 userName 进行 null 检查的，当发现为 null 的话会直接抛出 NPE\npublic final class UserBean { @NotNull private final String userName; private final int userAge; @NotNull public final String getUserName() { return this.userName; } public final int getUserAge() { return this.userAge; } public UserBean(@NotNull String userName, int userAge) { //进行 null 检查 Intrinsics.checkNotNullParameter(userName, \u0026#34;userName\u0026#34;); super(); this.userName = userName; this.userAge = userAge; } ··· } 那 Gson 是怎么绕过 Kotlin 的 null 检查的呢？\n其实，通过查看 Gson 内部源码，可以知道 Gson 是通过 Unsafe 包来实例化 UserBean 对象的，Unsafe 提供了一个非常规实例化对象的方法：allocateInstance，该方法提供了通过 Class 对象就可以创建出相应实例的功能，而且不需要调用其构造函数、初始化代码、JVM 安全检查等，即使构造函数是 private 的也能通过此方法进行实例化。因此 Gson 实际上并不会调用到 UserBean 的构造函数，相当于绕过了 Kotlin 的 null 检查，所以即使 userName 值为 null 最终也能够反序列化成功\n此问题的出现场景大多是在移动端解析服务端传来的数据的时候，移动端将数据声明为非空类型，但服务端给过来的数据却为 null 值，此时用户看到的可能就是应用崩溃了……\n一方面，我觉得移动端应该对服务端传来的数据保持不信任的态度，不能觉得对方传来的数据就一定是符合约定的，为了保证安全需要将数据均声明为可空类型。另一方面，这也无疑导致移动端需要加上很多多余的判空操作，简直有点无解 =_=\nARouter \u0026amp; JvmField 在 Java 中，字段和其访问器的组合被称作属性。在 Kotlin 中，属性是头等的语言特性，完全替代了字段和访问器方法。在类中声明一个属性和声明一个变量一样是使用 val 和 var 关键字，两者在使用上的差异就在于赋值后是否还允许修改，在字节码上的差异性之一就在于是否会自动生成相应的 setValue 方法\n例如，以下的 Kotlin 代码在反编译为 Java 代码后，可以看到两个属性的可见性都变为了 private， name 变量会同时包含有getValue和setValue 方法，而 nickname 变量只有 getValue 方法，这也是我们在 Java 代码中只能以 kotlinMode.getName() 的方式来访问 name 变量的原因\nclass KotlinMode { var name = \u0026#34;业志陈\u0026#34; val nickname = \u0026#34;leavesC\u0026#34; } public final class KotlinMode { @NotNull private String name = \u0026#34;业志陈\u0026#34;; @NotNull private final String nickname = \u0026#34;leavesC\u0026#34;; @NotNull public final String getName() { return this.name; } public final void setName(@NotNull String var1) { Intrinsics.checkNotNullParameter(var1, \u0026#34;\u0026lt;set-?\u0026gt;\u0026#34;); this.name = var1; } @NotNull public final String getNickname() { return this.nickname; } } 为了不让 Kotlin 的 var / val 变量自动生成 getValue 或 setValue 方法，达到和在 Java 代码中声明公开变量一样的效果，此时就需要为属性添加 @JvmField 注解了，添加后就会变为 public 类型的成员变量，且不包含任何 getValue 和 setValue 方法\nclass KotlinMode { @JvmField var name = \u0026#34;业志陈\u0026#34; @JvmField val nickname = \u0026#34;leavesC\u0026#34; } public final class KotlinMode { @JvmField @NotNull public String name = \u0026#34;业志陈\u0026#34;; @JvmField @NotNull public final String nickname = \u0026#34;leavesC\u0026#34;; } @JvmField 的一个使用场景就是在配套使用 ARouter 的时候。我们在使用 ARouter 进行参数自动注入时，就需要为待注入的参数添加 @JvmField注解，就像以下代码一样，不添加的话就会导致编译失败\n@Route(path = RoutePath.USER_HOME) class UserHomeActivity : AppCompatActivity() { @Autowired(name = RoutePath.USER_HOME_PARAMETER_ID) @JvmField var userId: Long = 0 override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) setContentView(R.layout.activity_user_home) ARouter.getInstance().inject(this) } } 那为什么不添加该注解就会导致编译失败呢？\n其实，ARouter 实现参数自动注入是需要依靠注解处理器生成的辅助文件来实现的，即会生成以下的辅助代码，当中会以 substitute.userId 、substitute.userName的形式来调用 Activity 中的两个参数值，如果不添加 @JvmField注解，辅助文件就没法以直接调用变量名的方式来完成注入，自然就会导致编译失败了\npublic class UserHomeActivity$$ARouter$$Autowired implements ISyringe { private SerializationService serializationService; @Override public void inject(Object target) { serializationService = ARouter.getInstance().navigation(SerializationService.class); UserHomeActivity substitute = (UserHomeActivity)target; substitute.userId = substitute.getIntent().getLongExtra(\u0026#34;userHomeId\u0026#34;, substitute.userId); } } Kotlin 这套为属性自动生成 getValue和setValue 方法的机制有一个缺点，就是可能会导致方法数极速膨胀，使得 Android App 的 dex 文件很快就达到最大方法数限制，不得不进行分包处理\n推荐阅读 Gson 和 Kotlin data class 的避坑指南 更加详细地介绍了 Gson 和 Kotlin data class 在配套使用时可能出现的坑，值得一看 ！！！\n两万六千字带你 Kotlin 入门 读者是否还未开始学习 Kotlin 呢？或者是对 Kotlin 还了解得不够清楚呢？如果是的话，推荐阅读我的一篇 Kotlin 入门教程，全文两万六千多字，手把手教你学会 Kotlin ！！！\n","permalink":"http://localhost:1313/hugo-blog/public/post/kotlin/%E6%8E%A2%E7%A9%B6-kotlin-%E7%9A%84%E9%9A%90%E8%97%8F%E6%80%A7%E8%83%BD%E5%BC%80%E9%94%80%E4%B8%8E%E9%81%BF%E5%9D%91%E6%8C%87%E5%8D%97/","tags":[],"title":"探究 Kotlin 的隐藏性能开销与避坑指南"},{"categories":[{"LinkTitle":"自定义 Slug 的分类","RelPermalink":"/hugo-blog/public/zh-cn/categories/with-slug/"}],"content":" Photo by Behnam Norouzi on Unsplash\nTest for external image Test for svg ","permalink":"http://localhost:1313/hugo-blog/public/zh-cn/post/i18n-blog/image-process/","tags":[{"LinkTitle":"随便一个标签","RelPermalink":"/hugo-blog/public/zh-cn/tags/custom/"}],"title":"图片处理"},{"categories":[{"LinkTitle":"Themes","RelPermalink":"/hugo-blog/public/zh-cn/categories/themes/"},{"LinkTitle":"Syntax","RelPermalink":"/hugo-blog/public/zh-cn/categories/syntax/"}],"content":"本文档提供可用于 Hugo 内容文件的基本 Markdown 语法示例，并且还展示了 Hugo 主题中是否用 CSS 修饰了 HTML 基本元素。\n标题 以下 HTML \u0026lt;h1\u0026gt;-\u0026lt;h6\u0026gt; 元素表示六个级别的分节标题。 \u0026lt;h1\u0026gt; 是最高级别分节标题，而 \u0026lt;h6\u0026gt; 是最低级别分节标题。\nH1 H2 H3 H4 H5 H6 段落 Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\n块引用 blockquote 元素表示从另一个资源引用的内容，可能带有一个在 footer 或 cite 元素内的引用，或者带有诸如注释和缩写之类的行内更改。\n没有归属的块引用 Tiam, ad mint andaepu dandae nostion secatur sequo quae.请注意在代码块中可以使用 Markdown 语法。\n带有归属的块引用 不要通过共享内存进行通信，而是通过通信共享内存。\nRob Pike[^1] [^1] 上述引用摘自 Rob Pike 于 2015 年 11 月 18 日在 Gopherfest 期间进行的 演讲 。\n表格 表格不是核心 Markdown 规范的一部分，但 Hugo 开箱即用地支持表格。\nName Age Bob 27 Alice 23 表格中的行内 Markdown 斜体 粗体 代码 斜体 粗体 代码 代码块 带反引号的代码块 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 用四个空格缩进的代码块 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 带有 Hugo 内部高亮短代码的代码块 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 列表类型 有序列表 第一个项目 第二个项目 第三个项目 无序列表 项目一 项目二 项目三 嵌套列表 水果 苹果 橙子 香蕉 乳制品 牛奶 奶酪 带有复选框的列表 创建 Hugo 网站 添加内容 添加样式 其他元素 - abbr、sub、sup、kbd、mark GIF 是一种位图图像格式。\nH2O\nXn + Yn = Zn\n按 CTRL+ALT+Delete 结束会话。\n大多数 火蜥蜴 在夜间活动，并捕食昆虫、蠕虫和其他小型生物。\n","permalink":"http://localhost:1313/hugo-blog/public/zh-cn/post/i18n-blog/markdown-syntax/","tags":[{"LinkTitle":"Markdown","RelPermalink":"/hugo-blog/public/zh-cn/tags/markdown/"},{"LinkTitle":"Css","RelPermalink":"/hugo-blog/public/zh-cn/tags/css/"},{"LinkTitle":"Html","RelPermalink":"/hugo-blog/public/zh-cn/tags/html/"},{"LinkTitle":"Tag1","RelPermalink":"/hugo-blog/public/zh-cn/tags/tag1/"},{"LinkTitle":"Tag2","RelPermalink":"/hugo-blog/public/zh-cn/tags/tag2/"}],"title":"Markdown语法指导"},{"categories":[],"content":"在 Hugo 项目中，可以通过使用第三方 JavaScript 库来启用数学符号。\n在本示例中，我们将使用 KaTeX 在 /layouts/partials/math.html 下创建一个局部文件 在此局部文件中引用 自动渲染扩展名 或在本地托管这些脚本。 以以下方式在模板中包含局部文件： {{ if or .Params.math .Site.Params.math }} {{ partial \u0026#34;math.html\u0026#34; . }} {{ end }} 要在全局启用 KaTeX，请在项目的配置中将参数 math 设置为 true 要逐页启用 KaTeX，请在内容文件中包含参数 math: true **注意：**使用 Supported TeX Functions 的在线参考\n示例 行内数学：\\( arphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887…\\) 块级数学： $$ arphi = 1+\frac{1} {1+\frac{1} {1+\frac{1} {1+\\cdots} } } $$\n","permalink":"http://localhost:1313/hugo-blog/public/zh-cn/post/i18n-blog/math-typesetting/","tags":[],"title":"数学符号"},{"categories":[],"content":"可以在一个 Hugo 项目中通过多种方式启用 Emoji。\nemojify 函数可以被直接在模板或 Inline Shortcodes 中调用。\n若要全局启用 emoji，在你的网站的 配置 中将 enableEmoji 设置为 true，然后你就可以直接在内容文件中输入 emoji 的简写代码；例如：\n🙈 :see_no_evil: 🙉 :hear_no_evil: 🙊 :speak_no_evil:\nEmoji 速查表 是 emoji 简写代码的有用参考。\n注 上述步骤可以在 Hugo 中启用 Unicode 标准的 emoji 字符和序列，但是这些字形的呈现取决于浏览器和平台。要给 emoji 设置样式，你可以使用第三方 emoji 字体或字体堆栈；例如：\n.emoji { font-family: Apple Color Emoji, Segoe UI Emoji, NotoColorEmoji, Segoe UI Symbol, Android Emoji, EmojiSymbols; } ","permalink":"http://localhost:1313/hugo-blog/public/zh-cn/post/i18n-blog/emoji-support/","tags":[{"LinkTitle":"Emoji","RelPermalink":"/hugo-blog/public/zh-cn/tags/emoji/"}],"title":"Emoji 支持"},{"categories":[],"content":"multilingual中文测试页面\n","permalink":"http://localhost:1313/hugo-blog/public/zh-cn/about/","tags":[],"title":"关于"},{"categories":[],"content":"// : # (\n)\n","permalink":"http://localhost:1313/hugo-blog/public/zh-cn/post/i18n-blog/rich-content/","tags":[],"title":""}]